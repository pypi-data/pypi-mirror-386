# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.classifier_rule import ClassifierRule
from ..types.classify_job import ClassifyJob
from ..types.classify_job_results import ClassifyJobResults
from ..types.classify_parsing_configuration import ClassifyParsingConfiguration
from ..types.paginated_response_classify_job import PaginatedResponseClassifyJob
from .raw_client import AsyncRawClassifierClient, RawClassifierClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ClassifierClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawClassifierClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawClassifierClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawClassifierClient
        """
        return self._raw_client

    def list(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseClassifyJob:
        """
        List classify jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseClassifyJob
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.classifier.list(
            project_id="project_id",
            organization_id="organization_id",
            page_size=1,
            page_token="page_token",
        )
        """
        _response = self._raw_client.list(
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            request_options=request_options,
        )
        return _response.data

    def create(
        self,
        *,
        rules: typing.Sequence[ClassifierRule],
        file_ids: typing.Sequence[str],
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parsing_configuration: typing.Optional[ClassifyParsingConfiguration] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ClassifyJob:
        """
        Create a classify job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        rules : typing.Sequence[ClassifierRule]
            The rules to classify the files

        file_ids : typing.Sequence[str]
            The IDs of the files to classify

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        parsing_configuration : typing.Optional[ClassifyParsingConfiguration]
            The configuration for the parsing job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ClassifyJob
            Successful Response

        Examples
        --------
        from llamaindex_test import ClassifierRule, LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.classifier.create(
            project_id="project_id",
            organization_id="organization_id",
            rules=[
                ClassifierRule(
                    type="invoice",
                    description="contains invoice number, line items, and total amount",
                )
            ],
            file_ids=["file_ids"],
        )
        """
        _response = self._raw_client.create(
            rules=rules,
            file_ids=file_ids,
            project_id=project_id,
            organization_id=organization_id,
            parsing_configuration=parsing_configuration,
            request_options=request_options,
        )
        return _response.data

    def get(
        self,
        classify_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ClassifyJob:
        """
        Get a classify job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        classify_job_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ClassifyJob
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.classifier.get(
            classify_job_id="classify_job_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get(
            classify_job_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def get_results(
        self,
        classify_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ClassifyJobResults:
        """
        Get the results of a classify job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        classify_job_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ClassifyJobResults
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.classifier.get_results(
            classify_job_id="classify_job_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_results(
            classify_job_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data


class AsyncClassifierClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawClassifierClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawClassifierClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawClassifierClient
        """
        return self._raw_client

    async def list(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseClassifyJob:
        """
        List classify jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseClassifyJob
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.classifier.list(
                project_id="project_id",
                organization_id="organization_id",
                page_size=1,
                page_token="page_token",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list(
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            request_options=request_options,
        )
        return _response.data

    async def create(
        self,
        *,
        rules: typing.Sequence[ClassifierRule],
        file_ids: typing.Sequence[str],
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parsing_configuration: typing.Optional[ClassifyParsingConfiguration] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ClassifyJob:
        """
        Create a classify job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        rules : typing.Sequence[ClassifierRule]
            The rules to classify the files

        file_ids : typing.Sequence[str]
            The IDs of the files to classify

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        parsing_configuration : typing.Optional[ClassifyParsingConfiguration]
            The configuration for the parsing job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ClassifyJob
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud, ClassifierRule

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.classifier.create(
                project_id="project_id",
                organization_id="organization_id",
                rules=[
                    ClassifierRule(
                        type="invoice",
                        description="contains invoice number, line items, and total amount",
                    )
                ],
                file_ids=["file_ids"],
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create(
            rules=rules,
            file_ids=file_ids,
            project_id=project_id,
            organization_id=organization_id,
            parsing_configuration=parsing_configuration,
            request_options=request_options,
        )
        return _response.data

    async def get(
        self,
        classify_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ClassifyJob:
        """
        Get a classify job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        classify_job_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ClassifyJob
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.classifier.get(
                classify_job_id="classify_job_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get(
            classify_job_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def get_results(
        self,
        classify_job_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ClassifyJobResults:
        """
        Get the results of a classify job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        classify_job_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ClassifyJobResults
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.classifier.get_results(
                classify_job_id="classify_job_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_results(
            classify_job_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data
