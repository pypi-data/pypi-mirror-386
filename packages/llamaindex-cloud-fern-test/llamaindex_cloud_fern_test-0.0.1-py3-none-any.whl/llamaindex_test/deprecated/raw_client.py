# This file was auto-generated by Fern from our API Definition.

import contextlib
import typing
from json.decoder import JSONDecodeError

from .. import core
from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.http_response import AsyncHttpResponse, HttpResponse
from ..core.jsonable_encoder import jsonable_encoder
from ..core.request_options import RequestOptions
from ..core.unchecked_base_model import construct_type
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.fail_page_mode import FailPageMode
from ..types.http_validation_error import HttpValidationError
from ..types.llama_parse_supported_file_extensions import LlamaParseSupportedFileExtensions
from ..types.parser_languages import ParserLanguages
from ..types.parsing_history_item import ParsingHistoryItem
from ..types.parsing_job import ParsingJob
from ..types.parsing_job_json_result import ParsingJobJsonResult
from ..types.parsing_job_markdown_result import ParsingJobMarkdownResult
from ..types.parsing_job_structured_result import ParsingJobStructuredResult
from ..types.parsing_job_text_result import ParsingJobTextResult
from ..types.parsing_mode import ParsingMode
from ..types.presigned_url import PresignedUrl

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class RawDeprecatedClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    @contextlib.contextmanager
    def get_job_image_result(
        self, job_id: str, name: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.Iterator[HttpResponse[typing.Iterator[bytes]]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        name : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.

        Returns
        -------
        typing.Iterator[HttpResponse[typing.Iterator[bytes]]]
            Successful Response
        """
        with self._client_wrapper.httpx_client.stream(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/image/{jsonable_encoder(name)}",
            method="GET",
            request_options=request_options,
        ) as _response:

            def _stream() -> HttpResponse[typing.Iterator[bytes]]:
                try:
                    if 200 <= _response.status_code < 300:
                        _chunk_size = request_options.get("chunk_size", None) if request_options is not None else None
                        return HttpResponse(
                            response=_response, data=(_chunk for _chunk in _response.iter_bytes(chunk_size=_chunk_size))
                        )
                    _response.read()
                    if _response.status_code == 422:
                        raise UnprocessableEntityError(
                            headers=dict(_response.headers),
                            body=typing.cast(
                                HttpValidationError,
                                construct_type(
                                    type_=HttpValidationError,  # type: ignore
                                    object_=_response.json(),
                                ),
                            ),
                        )
                    _response_json = _response.json()
                except JSONDecodeError:
                    raise ApiError(
                        status_code=_response.status_code, headers=dict(_response.headers), body=_response.text
                    )
                raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

            yield _stream()

    def get_supported_file_extensions(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.List[LlamaParseSupportedFileExtensions]]:
        """
        Get a list of supported file extensions

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.List[LlamaParseSupportedFileExtensions]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/parsing/supported_file_extensions",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[LlamaParseSupportedFileExtensions],
                    construct_type(
                        type_=typing.List[LlamaParseSupportedFileExtensions],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def screenshot(
        self,
        *,
        file: core.File,
        organization_id: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        do_not_cache: typing.Optional[bool] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_s_3_path: typing.Optional[str] = OMIT,
        input_s_3_region: typing.Optional[str] = OMIT,
        input_url: typing.Optional[str] = OMIT,
        invalidate_cache: typing.Optional[bool] = OMIT,
        max_pages: typing.Optional[int] = OMIT,
        output_s_3_path_prefix: typing.Optional[str] = OMIT,
        output_s_3_region: typing.Optional[str] = OMIT,
        target_pages: typing.Optional[str] = OMIT,
        webhook_url: typing.Optional[str] = OMIT,
        webhook_configurations: typing.Optional[str] = OMIT,
        job_timeout_in_seconds: typing.Optional[float] = OMIT,
        job_timeout_extra_time_per_page_in_seconds: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ParsingJob]:
        """
        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        organization_id : typing.Optional[str]

        project_id : typing.Optional[str]

        do_not_cache : typing.Optional[bool]

        http_proxy : typing.Optional[str]

        input_s_3_path : typing.Optional[str]

        input_s_3_region : typing.Optional[str]

        input_url : typing.Optional[str]

        invalidate_cache : typing.Optional[bool]

        max_pages : typing.Optional[int]

        output_s_3_path_prefix : typing.Optional[str]

        output_s_3_region : typing.Optional[str]

        target_pages : typing.Optional[str]

        webhook_url : typing.Optional[str]

        webhook_configurations : typing.Optional[str]

        job_timeout_in_seconds : typing.Optional[float]

        job_timeout_extra_time_per_page_in_seconds : typing.Optional[float]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJob]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/parsing/screenshot",
            method="POST",
            params={
                "organization_id": organization_id,
                "project_id": project_id,
            },
            data={
                "do_not_cache": do_not_cache,
                "http_proxy": http_proxy,
                "input_s3_path": input_s_3_path,
                "input_s3_region": input_s_3_region,
                "input_url": input_url,
                "invalidate_cache": invalidate_cache,
                "max_pages": max_pages,
                "output_s3_path_prefix": output_s_3_path_prefix,
                "output_s3_region": output_s_3_region,
                "target_pages": target_pages,
                "webhook_url": webhook_url,
                "webhook_configurations": webhook_configurations,
                "job_timeout_in_seconds": job_timeout_in_seconds,
                "job_timeout_extra_time_per_page_in_seconds": job_timeout_extra_time_per_page_in_seconds,
            },
            files={
                "file": file,
            },
            request_options=request_options,
            omit=OMIT,
            force_multipart=True,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJob,
                    construct_type(
                        type_=ParsingJob,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def upload_file(
        self,
        *,
        file: core.File,
        organization_id: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        adaptive_long_table: typing.Optional[bool] = OMIT,
        annotate_links: typing.Optional[bool] = OMIT,
        auto_mode: typing.Optional[bool] = OMIT,
        auto_mode_trigger_on_image_in_page: typing.Optional[bool] = OMIT,
        auto_mode_trigger_on_table_in_page: typing.Optional[bool] = OMIT,
        auto_mode_trigger_on_text_in_page: typing.Optional[str] = OMIT,
        auto_mode_trigger_on_regexp_in_page: typing.Optional[str] = OMIT,
        auto_mode_configuration_json: typing.Optional[str] = OMIT,
        azure_openai_api_version: typing.Optional[str] = OMIT,
        azure_openai_deployment_name: typing.Optional[str] = OMIT,
        azure_openai_endpoint: typing.Optional[str] = OMIT,
        azure_openai_key: typing.Optional[str] = OMIT,
        bbox_bottom: typing.Optional[float] = OMIT,
        bbox_left: typing.Optional[float] = OMIT,
        bbox_right: typing.Optional[float] = OMIT,
        bbox_top: typing.Optional[float] = OMIT,
        compact_markdown_table: typing.Optional[bool] = OMIT,
        disable_ocr: typing.Optional[bool] = OMIT,
        disable_reconstruction: typing.Optional[bool] = OMIT,
        disable_image_extraction: typing.Optional[bool] = OMIT,
        do_not_cache: typing.Optional[bool] = OMIT,
        do_not_unroll_columns: typing.Optional[bool] = OMIT,
        extract_charts: typing.Optional[bool] = OMIT,
        guess_xlsx_sheet_name: typing.Optional[bool] = OMIT,
        high_res_ocr: typing.Optional[bool] = OMIT,
        html_make_all_elements_visible: typing.Optional[bool] = OMIT,
        layout_aware: typing.Optional[bool] = OMIT,
        specialized_chart_parsing_agentic: typing.Optional[bool] = OMIT,
        specialized_chart_parsing_plus: typing.Optional[bool] = OMIT,
        specialized_chart_parsing_efficient: typing.Optional[bool] = OMIT,
        specialized_image_parsing: typing.Optional[bool] = OMIT,
        precise_bounding_box: typing.Optional[bool] = OMIT,
        html_remove_fixed_elements: typing.Optional[bool] = OMIT,
        html_remove_navigation_elements: typing.Optional[bool] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_s_3_path: typing.Optional[str] = OMIT,
        input_s_3_region: typing.Optional[str] = OMIT,
        input_url: typing.Optional[str] = OMIT,
        invalidate_cache: typing.Optional[bool] = OMIT,
        language: typing.Optional[typing.List[ParserLanguages]] = OMIT,
        extract_layout: typing.Optional[bool] = OMIT,
        max_pages: typing.Optional[int] = OMIT,
        merge_tables_across_pages_in_markdown: typing.Optional[bool] = OMIT,
        outlined_table_extraction: typing.Optional[bool] = OMIT,
        aggressive_table_extraction: typing.Optional[bool] = OMIT,
        output_pdf_of_document: typing.Optional[bool] = OMIT,
        output_s_3_path_prefix: typing.Optional[str] = OMIT,
        output_s_3_region: typing.Optional[str] = OMIT,
        page_prefix: typing.Optional[str] = OMIT,
        page_separator: typing.Optional[str] = OMIT,
        page_suffix: typing.Optional[str] = OMIT,
        preserve_layout_alignment_across_pages: typing.Optional[bool] = OMIT,
        preserve_very_small_text: typing.Optional[bool] = OMIT,
        skip_diagonal_text: typing.Optional[bool] = OMIT,
        spreadsheet_extract_sub_tables: typing.Optional[bool] = OMIT,
        spreadsheet_force_formula_computation: typing.Optional[bool] = OMIT,
        inline_images_in_markdown: typing.Optional[bool] = OMIT,
        structured_output: typing.Optional[bool] = OMIT,
        structured_output_json_schema: typing.Optional[str] = OMIT,
        structured_output_json_schema_name: typing.Optional[str] = OMIT,
        take_screenshot: typing.Optional[bool] = OMIT,
        target_pages: typing.Optional[str] = OMIT,
        vendor_multimodal_api_key: typing.Optional[str] = OMIT,
        vendor_multimodal_model_name: typing.Optional[str] = OMIT,
        model: typing.Optional[str] = OMIT,
        webhook_url: typing.Optional[str] = OMIT,
        webhook_configurations: typing.Optional[str] = OMIT,
        preset: typing.Optional[str] = OMIT,
        parse_mode: typing.Optional[ParsingMode] = OMIT,
        page_error_tolerance: typing.Optional[float] = OMIT,
        replace_failed_page_mode: typing.Optional[FailPageMode] = OMIT,
        replace_failed_page_with_error_message_prefix: typing.Optional[str] = OMIT,
        replace_failed_page_with_error_message_suffix: typing.Optional[str] = OMIT,
        system_prompt: typing.Optional[str] = OMIT,
        system_prompt_append: typing.Optional[str] = OMIT,
        user_prompt: typing.Optional[str] = OMIT,
        job_timeout_in_seconds: typing.Optional[float] = OMIT,
        job_timeout_extra_time_per_page_in_seconds: typing.Optional[float] = OMIT,
        strict_mode_image_extraction: typing.Optional[bool] = OMIT,
        strict_mode_image_ocr: typing.Optional[bool] = OMIT,
        strict_mode_reconstruction: typing.Optional[bool] = OMIT,
        strict_mode_buggy_font: typing.Optional[bool] = OMIT,
        save_images: typing.Optional[bool] = OMIT,
        ignore_document_elements_for_layout_detection: typing.Optional[bool] = OMIT,
        output_tables_as_html: typing.Optional[bool] = OMIT,
        markdown_table_multiline_header_separator: typing.Optional[str] = OMIT,
        use_vendor_multimodal_model: typing.Optional[bool] = OMIT,
        bounding_box: typing.Optional[str] = OMIT,
        gpt_4_o_mode: typing.Optional[bool] = OMIT,
        gpt_4_o_api_key: typing.Optional[str] = OMIT,
        complemental_formatting_instruction: typing.Optional[str] = OMIT,
        content_guideline_instruction: typing.Optional[str] = OMIT,
        premium_mode: typing.Optional[bool] = OMIT,
        is_formatting_instruction: typing.Optional[bool] = OMIT,
        continuous_mode: typing.Optional[bool] = OMIT,
        parsing_instruction: typing.Optional[str] = OMIT,
        fast_mode: typing.Optional[bool] = OMIT,
        formatting_instruction: typing.Optional[str] = OMIT,
        hide_headers: typing.Optional[bool] = OMIT,
        hide_footers: typing.Optional[bool] = OMIT,
        page_header_prefix: typing.Optional[str] = OMIT,
        page_header_suffix: typing.Optional[str] = OMIT,
        page_footer_prefix: typing.Optional[str] = OMIT,
        page_footer_suffix: typing.Optional[str] = OMIT,
        remove_hidden_text: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ParsingJob]:
        """
        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        organization_id : typing.Optional[str]

        project_id : typing.Optional[str]

        adaptive_long_table : typing.Optional[bool]

        annotate_links : typing.Optional[bool]

        auto_mode : typing.Optional[bool]

        auto_mode_trigger_on_image_in_page : typing.Optional[bool]

        auto_mode_trigger_on_table_in_page : typing.Optional[bool]

        auto_mode_trigger_on_text_in_page : typing.Optional[str]

        auto_mode_trigger_on_regexp_in_page : typing.Optional[str]

        auto_mode_configuration_json : typing.Optional[str]

        azure_openai_api_version : typing.Optional[str]

        azure_openai_deployment_name : typing.Optional[str]

        azure_openai_endpoint : typing.Optional[str]

        azure_openai_key : typing.Optional[str]

        bbox_bottom : typing.Optional[float]

        bbox_left : typing.Optional[float]

        bbox_right : typing.Optional[float]

        bbox_top : typing.Optional[float]

        compact_markdown_table : typing.Optional[bool]

        disable_ocr : typing.Optional[bool]

        disable_reconstruction : typing.Optional[bool]

        disable_image_extraction : typing.Optional[bool]

        do_not_cache : typing.Optional[bool]

        do_not_unroll_columns : typing.Optional[bool]

        extract_charts : typing.Optional[bool]

        guess_xlsx_sheet_name : typing.Optional[bool]

        high_res_ocr : typing.Optional[bool]

        html_make_all_elements_visible : typing.Optional[bool]

        layout_aware : typing.Optional[bool]

        specialized_chart_parsing_agentic : typing.Optional[bool]

        specialized_chart_parsing_plus : typing.Optional[bool]

        specialized_chart_parsing_efficient : typing.Optional[bool]

        specialized_image_parsing : typing.Optional[bool]

        precise_bounding_box : typing.Optional[bool]

        html_remove_fixed_elements : typing.Optional[bool]

        html_remove_navigation_elements : typing.Optional[bool]

        http_proxy : typing.Optional[str]

        input_s_3_path : typing.Optional[str]

        input_s_3_region : typing.Optional[str]

        input_url : typing.Optional[str]

        invalidate_cache : typing.Optional[bool]

        language : typing.Optional[typing.List[ParserLanguages]]

        extract_layout : typing.Optional[bool]

        max_pages : typing.Optional[int]

        merge_tables_across_pages_in_markdown : typing.Optional[bool]

        outlined_table_extraction : typing.Optional[bool]

        aggressive_table_extraction : typing.Optional[bool]

        output_pdf_of_document : typing.Optional[bool]

        output_s_3_path_prefix : typing.Optional[str]

        output_s_3_region : typing.Optional[str]

        page_prefix : typing.Optional[str]

        page_separator : typing.Optional[str]

        page_suffix : typing.Optional[str]

        preserve_layout_alignment_across_pages : typing.Optional[bool]

        preserve_very_small_text : typing.Optional[bool]

        skip_diagonal_text : typing.Optional[bool]

        spreadsheet_extract_sub_tables : typing.Optional[bool]

        spreadsheet_force_formula_computation : typing.Optional[bool]

        inline_images_in_markdown : typing.Optional[bool]

        structured_output : typing.Optional[bool]

        structured_output_json_schema : typing.Optional[str]

        structured_output_json_schema_name : typing.Optional[str]

        take_screenshot : typing.Optional[bool]

        target_pages : typing.Optional[str]

        vendor_multimodal_api_key : typing.Optional[str]

        vendor_multimodal_model_name : typing.Optional[str]

        model : typing.Optional[str]

        webhook_url : typing.Optional[str]

        webhook_configurations : typing.Optional[str]

        preset : typing.Optional[str]

        parse_mode : typing.Optional[ParsingMode]

        page_error_tolerance : typing.Optional[float]

        replace_failed_page_mode : typing.Optional[FailPageMode]

        replace_failed_page_with_error_message_prefix : typing.Optional[str]

        replace_failed_page_with_error_message_suffix : typing.Optional[str]

        system_prompt : typing.Optional[str]

        system_prompt_append : typing.Optional[str]

        user_prompt : typing.Optional[str]

        job_timeout_in_seconds : typing.Optional[float]

        job_timeout_extra_time_per_page_in_seconds : typing.Optional[float]

        strict_mode_image_extraction : typing.Optional[bool]

        strict_mode_image_ocr : typing.Optional[bool]

        strict_mode_reconstruction : typing.Optional[bool]

        strict_mode_buggy_font : typing.Optional[bool]

        save_images : typing.Optional[bool]

        ignore_document_elements_for_layout_detection : typing.Optional[bool]

        output_tables_as_html : typing.Optional[bool]

        markdown_table_multiline_header_separator : typing.Optional[str]

        use_vendor_multimodal_model : typing.Optional[bool]

        bounding_box : typing.Optional[str]

        gpt_4_o_mode : typing.Optional[bool]

        gpt_4_o_api_key : typing.Optional[str]

        complemental_formatting_instruction : typing.Optional[str]

        content_guideline_instruction : typing.Optional[str]

        premium_mode : typing.Optional[bool]

        is_formatting_instruction : typing.Optional[bool]

        continuous_mode : typing.Optional[bool]

        parsing_instruction : typing.Optional[str]

        fast_mode : typing.Optional[bool]

        formatting_instruction : typing.Optional[str]

        hide_headers : typing.Optional[bool]

        hide_footers : typing.Optional[bool]

        page_header_prefix : typing.Optional[str]

        page_header_suffix : typing.Optional[str]

        page_footer_prefix : typing.Optional[str]

        page_footer_suffix : typing.Optional[str]

        remove_hidden_text : typing.Optional[bool]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJob]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/parsing/upload",
            method="POST",
            params={
                "organization_id": organization_id,
                "project_id": project_id,
            },
            data={
                "adaptive_long_table": adaptive_long_table,
                "annotate_links": annotate_links,
                "auto_mode": auto_mode,
                "auto_mode_trigger_on_image_in_page": auto_mode_trigger_on_image_in_page,
                "auto_mode_trigger_on_table_in_page": auto_mode_trigger_on_table_in_page,
                "auto_mode_trigger_on_text_in_page": auto_mode_trigger_on_text_in_page,
                "auto_mode_trigger_on_regexp_in_page": auto_mode_trigger_on_regexp_in_page,
                "auto_mode_configuration_json": auto_mode_configuration_json,
                "azure_openai_api_version": azure_openai_api_version,
                "azure_openai_deployment_name": azure_openai_deployment_name,
                "azure_openai_endpoint": azure_openai_endpoint,
                "azure_openai_key": azure_openai_key,
                "bbox_bottom": bbox_bottom,
                "bbox_left": bbox_left,
                "bbox_right": bbox_right,
                "bbox_top": bbox_top,
                "compact_markdown_table": compact_markdown_table,
                "disable_ocr": disable_ocr,
                "disable_reconstruction": disable_reconstruction,
                "disable_image_extraction": disable_image_extraction,
                "do_not_cache": do_not_cache,
                "do_not_unroll_columns": do_not_unroll_columns,
                "extract_charts": extract_charts,
                "guess_xlsx_sheet_name": guess_xlsx_sheet_name,
                "high_res_ocr": high_res_ocr,
                "html_make_all_elements_visible": html_make_all_elements_visible,
                "layout_aware": layout_aware,
                "specialized_chart_parsing_agentic": specialized_chart_parsing_agentic,
                "specialized_chart_parsing_plus": specialized_chart_parsing_plus,
                "specialized_chart_parsing_efficient": specialized_chart_parsing_efficient,
                "specialized_image_parsing": specialized_image_parsing,
                "precise_bounding_box": precise_bounding_box,
                "html_remove_fixed_elements": html_remove_fixed_elements,
                "html_remove_navigation_elements": html_remove_navigation_elements,
                "http_proxy": http_proxy,
                "input_s3_path": input_s_3_path,
                "input_s3_region": input_s_3_region,
                "input_url": input_url,
                "invalidate_cache": invalidate_cache,
                "language": language,
                "extract_layout": extract_layout,
                "max_pages": max_pages,
                "merge_tables_across_pages_in_markdown": merge_tables_across_pages_in_markdown,
                "outlined_table_extraction": outlined_table_extraction,
                "aggressive_table_extraction": aggressive_table_extraction,
                "output_pdf_of_document": output_pdf_of_document,
                "output_s3_path_prefix": output_s_3_path_prefix,
                "output_s3_region": output_s_3_region,
                "page_prefix": page_prefix,
                "page_separator": page_separator,
                "page_suffix": page_suffix,
                "preserve_layout_alignment_across_pages": preserve_layout_alignment_across_pages,
                "preserve_very_small_text": preserve_very_small_text,
                "skip_diagonal_text": skip_diagonal_text,
                "spreadsheet_extract_sub_tables": spreadsheet_extract_sub_tables,
                "spreadsheet_force_formula_computation": spreadsheet_force_formula_computation,
                "inline_images_in_markdown": inline_images_in_markdown,
                "structured_output": structured_output,
                "structured_output_json_schema": structured_output_json_schema,
                "structured_output_json_schema_name": structured_output_json_schema_name,
                "take_screenshot": take_screenshot,
                "target_pages": target_pages,
                "vendor_multimodal_api_key": vendor_multimodal_api_key,
                "vendor_multimodal_model_name": vendor_multimodal_model_name,
                "model": model,
                "webhook_url": webhook_url,
                "webhook_configurations": webhook_configurations,
                "preset": preset,
                "parse_mode": parse_mode,
                "page_error_tolerance": page_error_tolerance,
                "replace_failed_page_mode": replace_failed_page_mode,
                "replace_failed_page_with_error_message_prefix": replace_failed_page_with_error_message_prefix,
                "replace_failed_page_with_error_message_suffix": replace_failed_page_with_error_message_suffix,
                "system_prompt": system_prompt,
                "system_prompt_append": system_prompt_append,
                "user_prompt": user_prompt,
                "job_timeout_in_seconds": job_timeout_in_seconds,
                "job_timeout_extra_time_per_page_in_seconds": job_timeout_extra_time_per_page_in_seconds,
                "strict_mode_image_extraction": strict_mode_image_extraction,
                "strict_mode_image_ocr": strict_mode_image_ocr,
                "strict_mode_reconstruction": strict_mode_reconstruction,
                "strict_mode_buggy_font": strict_mode_buggy_font,
                "save_images": save_images,
                "ignore_document_elements_for_layout_detection": ignore_document_elements_for_layout_detection,
                "output_tables_as_HTML": output_tables_as_html,
                "markdown_table_multiline_header_separator": markdown_table_multiline_header_separator,
                "use_vendor_multimodal_model": use_vendor_multimodal_model,
                "bounding_box": bounding_box,
                "gpt4o_mode": gpt_4_o_mode,
                "gpt4o_api_key": gpt_4_o_api_key,
                "complemental_formatting_instruction": complemental_formatting_instruction,
                "content_guideline_instruction": content_guideline_instruction,
                "premium_mode": premium_mode,
                "is_formatting_instruction": is_formatting_instruction,
                "continuous_mode": continuous_mode,
                "parsing_instruction": parsing_instruction,
                "fast_mode": fast_mode,
                "formatting_instruction": formatting_instruction,
                "hide_headers": hide_headers,
                "hide_footers": hide_footers,
                "page_header_prefix": page_header_prefix,
                "page_header_suffix": page_header_suffix,
                "page_footer_prefix": page_footer_prefix,
                "page_footer_suffix": page_footer_suffix,
                "remove_hidden_text": remove_hidden_text,
            },
            files={
                "file": file,
            },
            request_options=request_options,
            omit=OMIT,
            force_multipart=True,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJob,
                    construct_type(
                        type_=ParsingJob,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[ParsingJob]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJob]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJob,
                    construct_type(
                        type_=ParsingJob,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_parameters(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/parameters",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_parsing_job_details(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/details",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_text_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ParsingJobTextResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJobTextResult]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/text",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobTextResult,
                    construct_type(
                        type_=ParsingJobTextResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_text_result_raw(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/text",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_text_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/pdf",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_text_result_raw_pdf(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/pdf",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_structured_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ParsingJobStructuredResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJobStructuredResult]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/structured",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobStructuredResult,
                    construct_type(
                        type_=ParsingJobStructuredResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_structured_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/structured",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_xlsx_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/xlsx",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_xlsx_result_raw(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/xlsx",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ParsingJobMarkdownResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJobMarkdownResult]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/markdown",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobMarkdownResult,
                    construct_type(
                        type_=ParsingJobMarkdownResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_raw_md_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/markdown",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_json_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ParsingJobJsonResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ParsingJobJsonResult]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/json",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobJsonResult,
                    construct_type(
                        type_=ParsingJobJsonResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_job_json_raw_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/json",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return HttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get_parsing_history_result(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.List[ParsingHistoryItem]]:
        """
        Get parsing history for user

        This endpoint is deprecated.
        Use /api/v1/jobs/?job_name=parsing&project_id=YOUR_PROJECT_ID instead.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.List[ParsingHistoryItem]]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            "api/parsing/history",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[ParsingHistoryItem],
                    construct_type(
                        type_=typing.List[ParsingHistoryItem],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def generate_presigned_url(
        self, job_id: str, filename: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[PresignedUrl]:
        """
        Generate a presigned URL for a job

        Parameters
        ----------
        job_id : str

        filename : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[PresignedUrl]
            Successful Response
        """
        _response = self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/read/{jsonable_encoder(filename)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PresignedUrl,
                    construct_type(
                        type_=PresignedUrl,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)


class AsyncRawDeprecatedClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    @contextlib.asynccontextmanager
    async def get_job_image_result(
        self, job_id: str, name: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        name : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.

        Returns
        -------
        typing.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]
            Successful Response
        """
        async with self._client_wrapper.httpx_client.stream(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/image/{jsonable_encoder(name)}",
            method="GET",
            request_options=request_options,
        ) as _response:

            async def _stream() -> AsyncHttpResponse[typing.AsyncIterator[bytes]]:
                try:
                    if 200 <= _response.status_code < 300:
                        _chunk_size = request_options.get("chunk_size", None) if request_options is not None else None
                        return AsyncHttpResponse(
                            response=_response,
                            data=(_chunk async for _chunk in _response.aiter_bytes(chunk_size=_chunk_size)),
                        )
                    await _response.aread()
                    if _response.status_code == 422:
                        raise UnprocessableEntityError(
                            headers=dict(_response.headers),
                            body=typing.cast(
                                HttpValidationError,
                                construct_type(
                                    type_=HttpValidationError,  # type: ignore
                                    object_=_response.json(),
                                ),
                            ),
                        )
                    _response_json = _response.json()
                except JSONDecodeError:
                    raise ApiError(
                        status_code=_response.status_code, headers=dict(_response.headers), body=_response.text
                    )
                raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

            yield await _stream()

    async def get_supported_file_extensions(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.List[LlamaParseSupportedFileExtensions]]:
        """
        Get a list of supported file extensions

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.List[LlamaParseSupportedFileExtensions]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/parsing/supported_file_extensions",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[LlamaParseSupportedFileExtensions],
                    construct_type(
                        type_=typing.List[LlamaParseSupportedFileExtensions],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def screenshot(
        self,
        *,
        file: core.File,
        organization_id: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        do_not_cache: typing.Optional[bool] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_s_3_path: typing.Optional[str] = OMIT,
        input_s_3_region: typing.Optional[str] = OMIT,
        input_url: typing.Optional[str] = OMIT,
        invalidate_cache: typing.Optional[bool] = OMIT,
        max_pages: typing.Optional[int] = OMIT,
        output_s_3_path_prefix: typing.Optional[str] = OMIT,
        output_s_3_region: typing.Optional[str] = OMIT,
        target_pages: typing.Optional[str] = OMIT,
        webhook_url: typing.Optional[str] = OMIT,
        webhook_configurations: typing.Optional[str] = OMIT,
        job_timeout_in_seconds: typing.Optional[float] = OMIT,
        job_timeout_extra_time_per_page_in_seconds: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ParsingJob]:
        """
        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        organization_id : typing.Optional[str]

        project_id : typing.Optional[str]

        do_not_cache : typing.Optional[bool]

        http_proxy : typing.Optional[str]

        input_s_3_path : typing.Optional[str]

        input_s_3_region : typing.Optional[str]

        input_url : typing.Optional[str]

        invalidate_cache : typing.Optional[bool]

        max_pages : typing.Optional[int]

        output_s_3_path_prefix : typing.Optional[str]

        output_s_3_region : typing.Optional[str]

        target_pages : typing.Optional[str]

        webhook_url : typing.Optional[str]

        webhook_configurations : typing.Optional[str]

        job_timeout_in_seconds : typing.Optional[float]

        job_timeout_extra_time_per_page_in_seconds : typing.Optional[float]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJob]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/parsing/screenshot",
            method="POST",
            params={
                "organization_id": organization_id,
                "project_id": project_id,
            },
            data={
                "do_not_cache": do_not_cache,
                "http_proxy": http_proxy,
                "input_s3_path": input_s_3_path,
                "input_s3_region": input_s_3_region,
                "input_url": input_url,
                "invalidate_cache": invalidate_cache,
                "max_pages": max_pages,
                "output_s3_path_prefix": output_s_3_path_prefix,
                "output_s3_region": output_s_3_region,
                "target_pages": target_pages,
                "webhook_url": webhook_url,
                "webhook_configurations": webhook_configurations,
                "job_timeout_in_seconds": job_timeout_in_seconds,
                "job_timeout_extra_time_per_page_in_seconds": job_timeout_extra_time_per_page_in_seconds,
            },
            files={
                "file": file,
            },
            request_options=request_options,
            omit=OMIT,
            force_multipart=True,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJob,
                    construct_type(
                        type_=ParsingJob,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def upload_file(
        self,
        *,
        file: core.File,
        organization_id: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        adaptive_long_table: typing.Optional[bool] = OMIT,
        annotate_links: typing.Optional[bool] = OMIT,
        auto_mode: typing.Optional[bool] = OMIT,
        auto_mode_trigger_on_image_in_page: typing.Optional[bool] = OMIT,
        auto_mode_trigger_on_table_in_page: typing.Optional[bool] = OMIT,
        auto_mode_trigger_on_text_in_page: typing.Optional[str] = OMIT,
        auto_mode_trigger_on_regexp_in_page: typing.Optional[str] = OMIT,
        auto_mode_configuration_json: typing.Optional[str] = OMIT,
        azure_openai_api_version: typing.Optional[str] = OMIT,
        azure_openai_deployment_name: typing.Optional[str] = OMIT,
        azure_openai_endpoint: typing.Optional[str] = OMIT,
        azure_openai_key: typing.Optional[str] = OMIT,
        bbox_bottom: typing.Optional[float] = OMIT,
        bbox_left: typing.Optional[float] = OMIT,
        bbox_right: typing.Optional[float] = OMIT,
        bbox_top: typing.Optional[float] = OMIT,
        compact_markdown_table: typing.Optional[bool] = OMIT,
        disable_ocr: typing.Optional[bool] = OMIT,
        disable_reconstruction: typing.Optional[bool] = OMIT,
        disable_image_extraction: typing.Optional[bool] = OMIT,
        do_not_cache: typing.Optional[bool] = OMIT,
        do_not_unroll_columns: typing.Optional[bool] = OMIT,
        extract_charts: typing.Optional[bool] = OMIT,
        guess_xlsx_sheet_name: typing.Optional[bool] = OMIT,
        high_res_ocr: typing.Optional[bool] = OMIT,
        html_make_all_elements_visible: typing.Optional[bool] = OMIT,
        layout_aware: typing.Optional[bool] = OMIT,
        specialized_chart_parsing_agentic: typing.Optional[bool] = OMIT,
        specialized_chart_parsing_plus: typing.Optional[bool] = OMIT,
        specialized_chart_parsing_efficient: typing.Optional[bool] = OMIT,
        specialized_image_parsing: typing.Optional[bool] = OMIT,
        precise_bounding_box: typing.Optional[bool] = OMIT,
        html_remove_fixed_elements: typing.Optional[bool] = OMIT,
        html_remove_navigation_elements: typing.Optional[bool] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_s_3_path: typing.Optional[str] = OMIT,
        input_s_3_region: typing.Optional[str] = OMIT,
        input_url: typing.Optional[str] = OMIT,
        invalidate_cache: typing.Optional[bool] = OMIT,
        language: typing.Optional[typing.List[ParserLanguages]] = OMIT,
        extract_layout: typing.Optional[bool] = OMIT,
        max_pages: typing.Optional[int] = OMIT,
        merge_tables_across_pages_in_markdown: typing.Optional[bool] = OMIT,
        outlined_table_extraction: typing.Optional[bool] = OMIT,
        aggressive_table_extraction: typing.Optional[bool] = OMIT,
        output_pdf_of_document: typing.Optional[bool] = OMIT,
        output_s_3_path_prefix: typing.Optional[str] = OMIT,
        output_s_3_region: typing.Optional[str] = OMIT,
        page_prefix: typing.Optional[str] = OMIT,
        page_separator: typing.Optional[str] = OMIT,
        page_suffix: typing.Optional[str] = OMIT,
        preserve_layout_alignment_across_pages: typing.Optional[bool] = OMIT,
        preserve_very_small_text: typing.Optional[bool] = OMIT,
        skip_diagonal_text: typing.Optional[bool] = OMIT,
        spreadsheet_extract_sub_tables: typing.Optional[bool] = OMIT,
        spreadsheet_force_formula_computation: typing.Optional[bool] = OMIT,
        inline_images_in_markdown: typing.Optional[bool] = OMIT,
        structured_output: typing.Optional[bool] = OMIT,
        structured_output_json_schema: typing.Optional[str] = OMIT,
        structured_output_json_schema_name: typing.Optional[str] = OMIT,
        take_screenshot: typing.Optional[bool] = OMIT,
        target_pages: typing.Optional[str] = OMIT,
        vendor_multimodal_api_key: typing.Optional[str] = OMIT,
        vendor_multimodal_model_name: typing.Optional[str] = OMIT,
        model: typing.Optional[str] = OMIT,
        webhook_url: typing.Optional[str] = OMIT,
        webhook_configurations: typing.Optional[str] = OMIT,
        preset: typing.Optional[str] = OMIT,
        parse_mode: typing.Optional[ParsingMode] = OMIT,
        page_error_tolerance: typing.Optional[float] = OMIT,
        replace_failed_page_mode: typing.Optional[FailPageMode] = OMIT,
        replace_failed_page_with_error_message_prefix: typing.Optional[str] = OMIT,
        replace_failed_page_with_error_message_suffix: typing.Optional[str] = OMIT,
        system_prompt: typing.Optional[str] = OMIT,
        system_prompt_append: typing.Optional[str] = OMIT,
        user_prompt: typing.Optional[str] = OMIT,
        job_timeout_in_seconds: typing.Optional[float] = OMIT,
        job_timeout_extra_time_per_page_in_seconds: typing.Optional[float] = OMIT,
        strict_mode_image_extraction: typing.Optional[bool] = OMIT,
        strict_mode_image_ocr: typing.Optional[bool] = OMIT,
        strict_mode_reconstruction: typing.Optional[bool] = OMIT,
        strict_mode_buggy_font: typing.Optional[bool] = OMIT,
        save_images: typing.Optional[bool] = OMIT,
        ignore_document_elements_for_layout_detection: typing.Optional[bool] = OMIT,
        output_tables_as_html: typing.Optional[bool] = OMIT,
        markdown_table_multiline_header_separator: typing.Optional[str] = OMIT,
        use_vendor_multimodal_model: typing.Optional[bool] = OMIT,
        bounding_box: typing.Optional[str] = OMIT,
        gpt_4_o_mode: typing.Optional[bool] = OMIT,
        gpt_4_o_api_key: typing.Optional[str] = OMIT,
        complemental_formatting_instruction: typing.Optional[str] = OMIT,
        content_guideline_instruction: typing.Optional[str] = OMIT,
        premium_mode: typing.Optional[bool] = OMIT,
        is_formatting_instruction: typing.Optional[bool] = OMIT,
        continuous_mode: typing.Optional[bool] = OMIT,
        parsing_instruction: typing.Optional[str] = OMIT,
        fast_mode: typing.Optional[bool] = OMIT,
        formatting_instruction: typing.Optional[str] = OMIT,
        hide_headers: typing.Optional[bool] = OMIT,
        hide_footers: typing.Optional[bool] = OMIT,
        page_header_prefix: typing.Optional[str] = OMIT,
        page_header_suffix: typing.Optional[str] = OMIT,
        page_footer_prefix: typing.Optional[str] = OMIT,
        page_footer_suffix: typing.Optional[str] = OMIT,
        remove_hidden_text: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ParsingJob]:
        """
        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        organization_id : typing.Optional[str]

        project_id : typing.Optional[str]

        adaptive_long_table : typing.Optional[bool]

        annotate_links : typing.Optional[bool]

        auto_mode : typing.Optional[bool]

        auto_mode_trigger_on_image_in_page : typing.Optional[bool]

        auto_mode_trigger_on_table_in_page : typing.Optional[bool]

        auto_mode_trigger_on_text_in_page : typing.Optional[str]

        auto_mode_trigger_on_regexp_in_page : typing.Optional[str]

        auto_mode_configuration_json : typing.Optional[str]

        azure_openai_api_version : typing.Optional[str]

        azure_openai_deployment_name : typing.Optional[str]

        azure_openai_endpoint : typing.Optional[str]

        azure_openai_key : typing.Optional[str]

        bbox_bottom : typing.Optional[float]

        bbox_left : typing.Optional[float]

        bbox_right : typing.Optional[float]

        bbox_top : typing.Optional[float]

        compact_markdown_table : typing.Optional[bool]

        disable_ocr : typing.Optional[bool]

        disable_reconstruction : typing.Optional[bool]

        disable_image_extraction : typing.Optional[bool]

        do_not_cache : typing.Optional[bool]

        do_not_unroll_columns : typing.Optional[bool]

        extract_charts : typing.Optional[bool]

        guess_xlsx_sheet_name : typing.Optional[bool]

        high_res_ocr : typing.Optional[bool]

        html_make_all_elements_visible : typing.Optional[bool]

        layout_aware : typing.Optional[bool]

        specialized_chart_parsing_agentic : typing.Optional[bool]

        specialized_chart_parsing_plus : typing.Optional[bool]

        specialized_chart_parsing_efficient : typing.Optional[bool]

        specialized_image_parsing : typing.Optional[bool]

        precise_bounding_box : typing.Optional[bool]

        html_remove_fixed_elements : typing.Optional[bool]

        html_remove_navigation_elements : typing.Optional[bool]

        http_proxy : typing.Optional[str]

        input_s_3_path : typing.Optional[str]

        input_s_3_region : typing.Optional[str]

        input_url : typing.Optional[str]

        invalidate_cache : typing.Optional[bool]

        language : typing.Optional[typing.List[ParserLanguages]]

        extract_layout : typing.Optional[bool]

        max_pages : typing.Optional[int]

        merge_tables_across_pages_in_markdown : typing.Optional[bool]

        outlined_table_extraction : typing.Optional[bool]

        aggressive_table_extraction : typing.Optional[bool]

        output_pdf_of_document : typing.Optional[bool]

        output_s_3_path_prefix : typing.Optional[str]

        output_s_3_region : typing.Optional[str]

        page_prefix : typing.Optional[str]

        page_separator : typing.Optional[str]

        page_suffix : typing.Optional[str]

        preserve_layout_alignment_across_pages : typing.Optional[bool]

        preserve_very_small_text : typing.Optional[bool]

        skip_diagonal_text : typing.Optional[bool]

        spreadsheet_extract_sub_tables : typing.Optional[bool]

        spreadsheet_force_formula_computation : typing.Optional[bool]

        inline_images_in_markdown : typing.Optional[bool]

        structured_output : typing.Optional[bool]

        structured_output_json_schema : typing.Optional[str]

        structured_output_json_schema_name : typing.Optional[str]

        take_screenshot : typing.Optional[bool]

        target_pages : typing.Optional[str]

        vendor_multimodal_api_key : typing.Optional[str]

        vendor_multimodal_model_name : typing.Optional[str]

        model : typing.Optional[str]

        webhook_url : typing.Optional[str]

        webhook_configurations : typing.Optional[str]

        preset : typing.Optional[str]

        parse_mode : typing.Optional[ParsingMode]

        page_error_tolerance : typing.Optional[float]

        replace_failed_page_mode : typing.Optional[FailPageMode]

        replace_failed_page_with_error_message_prefix : typing.Optional[str]

        replace_failed_page_with_error_message_suffix : typing.Optional[str]

        system_prompt : typing.Optional[str]

        system_prompt_append : typing.Optional[str]

        user_prompt : typing.Optional[str]

        job_timeout_in_seconds : typing.Optional[float]

        job_timeout_extra_time_per_page_in_seconds : typing.Optional[float]

        strict_mode_image_extraction : typing.Optional[bool]

        strict_mode_image_ocr : typing.Optional[bool]

        strict_mode_reconstruction : typing.Optional[bool]

        strict_mode_buggy_font : typing.Optional[bool]

        save_images : typing.Optional[bool]

        ignore_document_elements_for_layout_detection : typing.Optional[bool]

        output_tables_as_html : typing.Optional[bool]

        markdown_table_multiline_header_separator : typing.Optional[str]

        use_vendor_multimodal_model : typing.Optional[bool]

        bounding_box : typing.Optional[str]

        gpt_4_o_mode : typing.Optional[bool]

        gpt_4_o_api_key : typing.Optional[str]

        complemental_formatting_instruction : typing.Optional[str]

        content_guideline_instruction : typing.Optional[str]

        premium_mode : typing.Optional[bool]

        is_formatting_instruction : typing.Optional[bool]

        continuous_mode : typing.Optional[bool]

        parsing_instruction : typing.Optional[str]

        fast_mode : typing.Optional[bool]

        formatting_instruction : typing.Optional[str]

        hide_headers : typing.Optional[bool]

        hide_footers : typing.Optional[bool]

        page_header_prefix : typing.Optional[str]

        page_header_suffix : typing.Optional[str]

        page_footer_prefix : typing.Optional[str]

        page_footer_suffix : typing.Optional[str]

        remove_hidden_text : typing.Optional[bool]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJob]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/parsing/upload",
            method="POST",
            params={
                "organization_id": organization_id,
                "project_id": project_id,
            },
            data={
                "adaptive_long_table": adaptive_long_table,
                "annotate_links": annotate_links,
                "auto_mode": auto_mode,
                "auto_mode_trigger_on_image_in_page": auto_mode_trigger_on_image_in_page,
                "auto_mode_trigger_on_table_in_page": auto_mode_trigger_on_table_in_page,
                "auto_mode_trigger_on_text_in_page": auto_mode_trigger_on_text_in_page,
                "auto_mode_trigger_on_regexp_in_page": auto_mode_trigger_on_regexp_in_page,
                "auto_mode_configuration_json": auto_mode_configuration_json,
                "azure_openai_api_version": azure_openai_api_version,
                "azure_openai_deployment_name": azure_openai_deployment_name,
                "azure_openai_endpoint": azure_openai_endpoint,
                "azure_openai_key": azure_openai_key,
                "bbox_bottom": bbox_bottom,
                "bbox_left": bbox_left,
                "bbox_right": bbox_right,
                "bbox_top": bbox_top,
                "compact_markdown_table": compact_markdown_table,
                "disable_ocr": disable_ocr,
                "disable_reconstruction": disable_reconstruction,
                "disable_image_extraction": disable_image_extraction,
                "do_not_cache": do_not_cache,
                "do_not_unroll_columns": do_not_unroll_columns,
                "extract_charts": extract_charts,
                "guess_xlsx_sheet_name": guess_xlsx_sheet_name,
                "high_res_ocr": high_res_ocr,
                "html_make_all_elements_visible": html_make_all_elements_visible,
                "layout_aware": layout_aware,
                "specialized_chart_parsing_agentic": specialized_chart_parsing_agentic,
                "specialized_chart_parsing_plus": specialized_chart_parsing_plus,
                "specialized_chart_parsing_efficient": specialized_chart_parsing_efficient,
                "specialized_image_parsing": specialized_image_parsing,
                "precise_bounding_box": precise_bounding_box,
                "html_remove_fixed_elements": html_remove_fixed_elements,
                "html_remove_navigation_elements": html_remove_navigation_elements,
                "http_proxy": http_proxy,
                "input_s3_path": input_s_3_path,
                "input_s3_region": input_s_3_region,
                "input_url": input_url,
                "invalidate_cache": invalidate_cache,
                "language": language,
                "extract_layout": extract_layout,
                "max_pages": max_pages,
                "merge_tables_across_pages_in_markdown": merge_tables_across_pages_in_markdown,
                "outlined_table_extraction": outlined_table_extraction,
                "aggressive_table_extraction": aggressive_table_extraction,
                "output_pdf_of_document": output_pdf_of_document,
                "output_s3_path_prefix": output_s_3_path_prefix,
                "output_s3_region": output_s_3_region,
                "page_prefix": page_prefix,
                "page_separator": page_separator,
                "page_suffix": page_suffix,
                "preserve_layout_alignment_across_pages": preserve_layout_alignment_across_pages,
                "preserve_very_small_text": preserve_very_small_text,
                "skip_diagonal_text": skip_diagonal_text,
                "spreadsheet_extract_sub_tables": spreadsheet_extract_sub_tables,
                "spreadsheet_force_formula_computation": spreadsheet_force_formula_computation,
                "inline_images_in_markdown": inline_images_in_markdown,
                "structured_output": structured_output,
                "structured_output_json_schema": structured_output_json_schema,
                "structured_output_json_schema_name": structured_output_json_schema_name,
                "take_screenshot": take_screenshot,
                "target_pages": target_pages,
                "vendor_multimodal_api_key": vendor_multimodal_api_key,
                "vendor_multimodal_model_name": vendor_multimodal_model_name,
                "model": model,
                "webhook_url": webhook_url,
                "webhook_configurations": webhook_configurations,
                "preset": preset,
                "parse_mode": parse_mode,
                "page_error_tolerance": page_error_tolerance,
                "replace_failed_page_mode": replace_failed_page_mode,
                "replace_failed_page_with_error_message_prefix": replace_failed_page_with_error_message_prefix,
                "replace_failed_page_with_error_message_suffix": replace_failed_page_with_error_message_suffix,
                "system_prompt": system_prompt,
                "system_prompt_append": system_prompt_append,
                "user_prompt": user_prompt,
                "job_timeout_in_seconds": job_timeout_in_seconds,
                "job_timeout_extra_time_per_page_in_seconds": job_timeout_extra_time_per_page_in_seconds,
                "strict_mode_image_extraction": strict_mode_image_extraction,
                "strict_mode_image_ocr": strict_mode_image_ocr,
                "strict_mode_reconstruction": strict_mode_reconstruction,
                "strict_mode_buggy_font": strict_mode_buggy_font,
                "save_images": save_images,
                "ignore_document_elements_for_layout_detection": ignore_document_elements_for_layout_detection,
                "output_tables_as_HTML": output_tables_as_html,
                "markdown_table_multiline_header_separator": markdown_table_multiline_header_separator,
                "use_vendor_multimodal_model": use_vendor_multimodal_model,
                "bounding_box": bounding_box,
                "gpt4o_mode": gpt_4_o_mode,
                "gpt4o_api_key": gpt_4_o_api_key,
                "complemental_formatting_instruction": complemental_formatting_instruction,
                "content_guideline_instruction": content_guideline_instruction,
                "premium_mode": premium_mode,
                "is_formatting_instruction": is_formatting_instruction,
                "continuous_mode": continuous_mode,
                "parsing_instruction": parsing_instruction,
                "fast_mode": fast_mode,
                "formatting_instruction": formatting_instruction,
                "hide_headers": hide_headers,
                "hide_footers": hide_footers,
                "page_header_prefix": page_header_prefix,
                "page_header_suffix": page_header_suffix,
                "page_footer_prefix": page_footer_prefix,
                "page_footer_suffix": page_footer_suffix,
                "remove_hidden_text": remove_hidden_text,
            },
            files={
                "file": file,
            },
            request_options=request_options,
            omit=OMIT,
            force_multipart=True,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJob,
                    construct_type(
                        type_=ParsingJob,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[ParsingJob]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJob]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJob,
                    construct_type(
                        type_=ParsingJob,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_parameters(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/parameters",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_parsing_job_details(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/details",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_text_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ParsingJobTextResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJobTextResult]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/text",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobTextResult,
                    construct_type(
                        type_=ParsingJobTextResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_text_result_raw(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/text",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_text_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/pdf",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_text_result_raw_pdf(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/pdf",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_structured_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ParsingJobStructuredResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJobStructuredResult]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/structured",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobStructuredResult,
                    construct_type(
                        type_=ParsingJobStructuredResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_structured_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/structured",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_xlsx_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/xlsx",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_xlsx_result_raw(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/xlsx",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ParsingJobMarkdownResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJobMarkdownResult]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/markdown",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobMarkdownResult,
                    construct_type(
                        type_=ParsingJobMarkdownResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_raw_md_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/markdown",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_json_result(
        self,
        job_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ParsingJobJsonResult]:
        """
        Get a job by id

        Note: The 'credits_used' and 'job_credits_usage' fields in the response metadata are deprecated
        and will be removed in a future release.

        Parameters
        ----------
        job_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ParsingJobJsonResult]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/json",
            method="GET",
            params={
                "organization_id": organization_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ParsingJobJsonResult,
                    construct_type(
                        type_=ParsingJobJsonResult,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_job_json_raw_result(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.Optional[typing.Any]]:
        """
        Get a job by id

        Parameters
        ----------
        job_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.Optional[typing.Any]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/result/raw/json",
            method="GET",
            request_options=request_options,
        )
        try:
            if _response is None or not _response.text.strip():
                return AsyncHttpResponse(response=_response, data=None)
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get_parsing_history_result(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.List[ParsingHistoryItem]]:
        """
        Get parsing history for user

        This endpoint is deprecated.
        Use /api/v1/jobs/?job_name=parsing&project_id=YOUR_PROJECT_ID instead.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.List[ParsingHistoryItem]]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            "api/parsing/history",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[ParsingHistoryItem],
                    construct_type(
                        type_=typing.List[ParsingHistoryItem],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def generate_presigned_url(
        self, job_id: str, filename: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[PresignedUrl]:
        """
        Generate a presigned URL for a job

        Parameters
        ----------
        job_id : str

        filename : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[PresignedUrl]
            Successful Response
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"api/parsing/job/{jsonable_encoder(job_id)}/read/{jsonable_encoder(filename)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    PresignedUrl,
                    construct_type(
                        type_=PresignedUrl,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)
