# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.agent_data import AgentData
from ..types.api_key import ApiKey
from ..types.api_key_query_response import ApiKeyQueryResponse
from ..types.api_key_type import ApiKeyType
from ..types.batch import Batch
from ..types.batch_paginated_list import BatchPaginatedList
from ..types.batch_public_output import BatchPublicOutput
from ..types.delete_response import DeleteResponse
from ..types.file import File
from ..types.file_create_permission_info_value import FileCreatePermissionInfoValue
from ..types.file_create_resource_info_value import FileCreateResourceInfoValue
from ..types.file_filter import FileFilter
from ..types.file_query_response import FileQueryResponse
from ..types.filter_operation import FilterOperation
from ..types.llama_parse_parameters import LlamaParseParameters
from ..types.paginated_response_agent_data import PaginatedResponseAgentData
from ..types.paginated_response_aggregate_group import PaginatedResponseAggregateGroup
from ..types.paginated_response_quota_configuration import PaginatedResponseQuotaConfiguration
from ..types.paginated_response_spreadsheet_job import PaginatedResponseSpreadsheetJob
from ..types.parse_configuration import ParseConfiguration
from ..types.parse_configuration_filter import ParseConfigurationFilter
from ..types.parse_configuration_query_response import ParseConfigurationQueryResponse
from ..types.presigned_url import PresignedUrl
from ..types.spreadsheet_job import SpreadsheetJob
from ..types.spreadsheet_parsing_config import SpreadsheetParsingConfig
from ..types.spreadsheet_result_type import SpreadsheetResultType
from .raw_client import AsyncRawBetaClient, RawBetaClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class BetaClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawBetaClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawBetaClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawBetaClient
        """
        return self._raw_client

    def list_api_keys(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        key_type: typing.Optional[ApiKeyType] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ApiKeyQueryResponse:
        """
        List API keys.

        If project_id is provided, validates user has access to that project.
        If project_id is not provided, scopes results to the current user.

        Args:
            user: Current user
            db: Database session
            page_size: Number of items per page
            page_token: Token for pagination
            name: Filter by API key name
            project_id: Filter by project ID
            key_type: Filter by key type

        Returns:
            Paginated response with API keys

        Parameters
        ----------
        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        name : typing.Optional[str]

        project_id : typing.Optional[str]

        key_type : typing.Optional[ApiKeyType]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ApiKeyQueryResponse
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.list_api_keys(
            page_size=1,
            page_token="page_token",
            name="name",
            project_id="project_id",
            key_type="user",
        )
        """
        _response = self._raw_client.list_api_keys(
            page_size=page_size,
            page_token=page_token,
            name=name,
            project_id=project_id,
            key_type=key_type,
            request_options=request_options,
        )
        return _response.data

    def create_api_key(
        self,
        *,
        name: typing.Optional[str] = OMIT,
        project_id: typing.Optional[str] = OMIT,
        key_type: typing.Optional[ApiKeyType] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ApiKey:
        """
        Create a new API key.

        If project_id is specified, validates user has admin permissions for that project.

        Args:
            api_key_create: API key creation data
            user: Current user
            db: Database session

        Returns:
            The created API key with the secret key visible in redacted_api_key field

        Parameters
        ----------
        name : typing.Optional[str]

        project_id : typing.Optional[str]
            The project ID to associate with the API key.

        key_type : typing.Optional[ApiKeyType]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ApiKey
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.create_api_key()
        """
        _response = self._raw_client.create_api_key(
            name=name, project_id=project_id, key_type=key_type, request_options=request_options
        )
        return _response.data

    def get_api_key(self, api_key_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> ApiKey:
        """
        Get an API key by ID.

        Args:
            api_key_id: The ID of the API key
            user: Current user
            db: Database session

        Returns:
            The API key

        Parameters
        ----------
        api_key_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ApiKey
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_api_key(
            api_key_id="api_key_id",
        )
        """
        _response = self._raw_client.get_api_key(api_key_id, request_options=request_options)
        return _response.data

    def delete_api_key(self, api_key_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete an API key.

        If the API key belongs to a project, validates user has admin permissions for that project.
        If the API key has no project, validates it belongs to the current user.

        Args:
            api_key_id: The ID of the API key to delete
            user: Current user
            db: Database session

        Parameters
        ----------
        api_key_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.delete_api_key(
            api_key_id="api_key_id",
        )
        """
        _response = self._raw_client.delete_api_key(api_key_id, request_options=request_options)
        return _response.data

    def list_batches(
        self,
        *,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchPaginatedList:
        """
        Parameters
        ----------
        limit : typing.Optional[int]

        offset : typing.Optional[int]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchPaginatedList
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.list_batches(
            limit=1,
            offset=1,
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.list_batches(
            limit=limit,
            offset=offset,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data

    def create_batch(
        self,
        *,
        tool: str,
        input_type: str,
        input_id: str,
        external_id: str,
        organization_id: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        tool_data: typing.Optional[LlamaParseParameters] = OMIT,
        output_type: typing.Optional[str] = OMIT,
        output_id: typing.Optional[str] = OMIT,
        completion_window: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Batch:
        """
        Parameters
        ----------
        tool : str
            The tool to be used for all requests in the batch.

        input_type : str
            The type of input file. Currently only 'datasource' is supported.

        input_id : str
            The ID of the input file for the batch.

        external_id : str
            A developer-provided ID for the batch. This ID will be returned in the response.

        organization_id : typing.Optional[str]

        project_id : typing.Optional[str]

        tool_data : typing.Optional[LlamaParseParameters]
            The data to be used for the tool.

        output_type : typing.Optional[str]
            The type of output file. Currently only 'datasource' is supported.

        output_id : typing.Optional[str]
            The ID of the output file for the batch.

        completion_window : typing.Optional[int]
            The time frame within which the batch should be processed. Currently only 24h is supported.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Batch
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.create_batch(
            organization_id="organization_id",
            project_id="project_id",
            tool="tool",
            input_type="input_type",
            input_id="input_id",
            external_id="external_id",
        )
        """
        _response = self._raw_client.create_batch(
            tool=tool,
            input_type=input_type,
            input_id=input_id,
            external_id=external_id,
            organization_id=organization_id,
            project_id=project_id,
            tool_data=tool_data,
            output_type=output_type,
            output_id=output_id,
            completion_window=completion_window,
            request_options=request_options,
        )
        return _response.data

    def get_batch(
        self,
        batch_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchPublicOutput:
        """
        Parameters
        ----------
        batch_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchPublicOutput
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_batch(
            batch_id="batch_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_batch(
            batch_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def get_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentData:
        """
        Get agent data by ID.

        Parameters
        ----------
        item_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentData
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_agent_data(
            item_id="item_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_agent_data(
            item_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def update_agent_data(
        self,
        item_id: str,
        *,
        data: typing.Dict[str, typing.Optional[typing.Any]],
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentData:
        """
        Update agent data by ID (overwrites).

        Parameters
        ----------
        item_id : str

        data : typing.Dict[str, typing.Optional[typing.Any]]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentData
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.update_agent_data(
            item_id="item_id",
            project_id="project_id",
            organization_id="organization_id",
            data={"key": "value"},
        )
        """
        _response = self._raw_client.update_agent_data(
            item_id, data=data, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def delete_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Dict[str, str]:
        """
        Delete agent data by ID.

        Parameters
        ----------
        item_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Dict[str, str]
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.delete_agent_data(
            item_id="item_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.delete_agent_data(
            item_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def create_agent_data(
        self,
        *,
        deployment_name: str,
        data: typing.Dict[str, typing.Optional[typing.Any]],
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentData:
        """
        Create new agent data.

        Parameters
        ----------
        deployment_name : str

        data : typing.Dict[str, typing.Optional[typing.Any]]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        collection : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentData
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.create_agent_data(
            project_id="project_id",
            organization_id="organization_id",
            deployment_name="deployment_name",
            data={"key": "value"},
        )
        """
        _response = self._raw_client.create_agent_data(
            deployment_name=deployment_name,
            data=data,
            project_id=project_id,
            organization_id=organization_id,
            collection=collection,
            request_options=request_options,
        )
        return _response.data

    def search_agent_data_api_v_1_beta_agent_data_search_post(
        self,
        *,
        deployment_name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        collection: typing.Optional[str] = OMIT,
        include_total: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseAgentData:
        """
        Search agent data with filtering, sorting, and pagination.

        Parameters
        ----------
        deployment_name : str
            The agent deployment's name to search within

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        collection : typing.Optional[str]
            The logical agent data collection to search within

        include_total : typing.Optional[bool]
            Whether to include the total number of items in the response

        offset : typing.Optional[int]
            The offset to start from. If not provided, the first page is returned

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseAgentData
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.search_agent_data_api_v_1_beta_agent_data_search_post(
            project_id="project_id",
            organization_id="organization_id",
            deployment_name="deployment_name",
        )
        """
        _response = self._raw_client.search_agent_data_api_v_1_beta_agent_data_search_post(
            deployment_name=deployment_name,
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            collection=collection,
            include_total=include_total,
            offset=offset,
            request_options=request_options,
        )
        return _response.data

    def aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
        self,
        *,
        deployment_name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        collection: typing.Optional[str] = OMIT,
        group_by: typing.Optional[typing.Sequence[str]] = OMIT,
        count: typing.Optional[bool] = OMIT,
        first: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseAggregateGroup:
        """
        Aggregate agent data with grouping and optional counting/first item retrieval.

        Parameters
        ----------
        deployment_name : str
            The agent deployment's name to aggregate data for

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        collection : typing.Optional[str]
            The logical agent data collection to aggregate data for

        group_by : typing.Optional[typing.Sequence[str]]
            The fields to group by. If empty, the entire dataset is grouped on. e.g. if left out, can be used for simple count operations

        count : typing.Optional[bool]
            Whether to count the number of items in each group

        first : typing.Optional[bool]
            Whether to return the first item in each group (Sorted by created_at)

        offset : typing.Optional[int]
            The offset to start from. If not provided, the first page is returned

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseAggregateGroup
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            project_id="project_id",
            organization_id="organization_id",
            deployment_name="deployment_name",
        )
        """
        _response = self._raw_client.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            deployment_name=deployment_name,
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            collection=collection,
            group_by=group_by,
            count=count,
            first=first,
            offset=offset,
            request_options=request_options,
        )
        return _response.data

    def delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
        self,
        *,
        deployment_name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DeleteResponse:
        """
        Bulk delete agent data by query (deployment_name, collection, optional filters).

        Parameters
        ----------
        deployment_name : str
            The agent deployment's name to delete data for

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        collection : typing.Optional[str]
            The logical agent data collection to delete from

        filter : typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]]
            Optional filters to select which items to delete

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DeleteResponse
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            project_id="project_id",
            organization_id="organization_id",
            deployment_name="deployment_name",
        )
        """
        _response = self._raw_client.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            deployment_name=deployment_name,
            project_id=project_id,
            organization_id=organization_id,
            collection=collection,
            filter=filter,
            request_options=request_options,
        )
        return _response.data

    def list_quota_configurations(
        self,
        *,
        source_id: str,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseQuotaConfiguration:
        """
        Retrieve a paginated list of quota configurations with optional filtering.

        Parameters
        ----------
        source_id : str

        page : typing.Optional[int]

        page_size : typing.Optional[int]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseQuotaConfiguration
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.list_quota_configurations(
            source_id="source_id",
            page=1,
            page_size=1,
        )
        """
        _response = self._raw_client.list_quota_configurations(
            source_id=source_id, page=page, page_size=page_size, request_options=request_options
        )
        return _response.data

    def create_file(
        self,
        *,
        name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = OMIT,
        file_size: typing.Optional[int] = OMIT,
        last_modified_at: typing.Optional[dt.datetime] = OMIT,
        resource_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]] = OMIT,
        permission_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]] = OMIT,
        data_source_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> File:
        """
        Create a new file in the project.

        Args:
            file_create: File creation data
            project: Validated project from dependency
            db: Database session

        Returns:
            The created file

        Parameters
        ----------
        name : str
            Name that will be used for created file. If possible, always include the file extension in the name.

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        external_file_id : typing.Optional[str]
            The ID of the file in the external system

        file_size : typing.Optional[int]
            Size of the file in bytes

        last_modified_at : typing.Optional[dt.datetime]
            The last modified time of the file

        resource_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]]
            Resource information for the file

        permission_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]]
            Permission information for the file

        data_source_id : typing.Optional[str]
            The ID of the data source that the file belongs to

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        File
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.create_file(
            project_id="project_id",
            organization_id="organization_id",
            name="name",
        )
        """
        _response = self._raw_client.create_file(
            name=name,
            project_id=project_id,
            organization_id=organization_id,
            external_file_id=external_file_id,
            file_size=file_size,
            last_modified_at=last_modified_at,
            resource_info=resource_info,
            permission_info=permission_info,
            data_source_id=data_source_id,
            request_options=request_options,
        )
        return _response.data

    def upsert_file(
        self,
        *,
        name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = OMIT,
        file_size: typing.Optional[int] = OMIT,
        last_modified_at: typing.Optional[dt.datetime] = OMIT,
        resource_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]] = OMIT,
        permission_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]] = OMIT,
        data_source_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> File:
        """
        Upsert a file (create or update if exists) in the project.

        Args:
            file_create: File creation/update data
            project: Validated project from dependency
            db: Database session

        Returns:
            The upserted file

        Parameters
        ----------
        name : str
            Name that will be used for created file. If possible, always include the file extension in the name.

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        external_file_id : typing.Optional[str]
            The ID of the file in the external system

        file_size : typing.Optional[int]
            Size of the file in bytes

        last_modified_at : typing.Optional[dt.datetime]
            The last modified time of the file

        resource_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]]
            Resource information for the file

        permission_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]]
            Permission information for the file

        data_source_id : typing.Optional[str]
            The ID of the data source that the file belongs to

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        File
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.upsert_file(
            project_id="project_id",
            organization_id="organization_id",
            name="name",
        )
        """
        _response = self._raw_client.upsert_file(
            name=name,
            project_id=project_id,
            organization_id=organization_id,
            external_file_id=external_file_id,
            file_size=file_size,
            last_modified_at=last_modified_at,
            resource_info=resource_info,
            permission_info=permission_info,
            data_source_id=data_source_id,
            request_options=request_options,
        )
        return _response.data

    def query_files(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[FileFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> FileQueryResponse:
        """
        Query files with flexible filtering and pagination.

        Args:
            request: The query request with filters and pagination
            project: Validated project from dependency
            db: Database session

        Returns:
            Paginated response with files

        Parameters
        ----------
        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[FileFilter]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FileQueryResponse
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.query_files(
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.query_files(
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            request_options=request_options,
        )
        return _response.data

    def delete_file(
        self,
        file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Delete a single file from the project.

        Args:
            file_id: The ID of the file to delete
            project: Validated project from dependency
            db: Database session

        Returns:
            None (204 No Content on success)

        Parameters
        ----------
        file_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.delete_file(
            file_id="file_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.delete_file(
            file_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def list_parse_configurations(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        creator: typing.Optional[str] = None,
        version: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        List parse configurations for the current project.

        Args:
            project: Validated project from dependency
            user: Current user
            db: Database session
            page_size: Number of items per page
            page_token: Token for pagination
            name: Filter by configuration name
            creator: Filter by creator
            version: Filter by version

        Returns:
            Paginated response with parse configurations

        Parameters
        ----------
        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        name : typing.Optional[str]

        creator : typing.Optional[str]

        version : typing.Optional[str]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfigurationQueryResponse
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.list_parse_configurations(
            page_size=1,
            page_token="page_token",
            name="name",
            creator="creator",
            version="version",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.list_parse_configurations(
            page_size=page_size,
            page_token=page_token,
            name=name,
            creator=creator,
            version=version,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data

    def create_parse_configuration(
        self,
        *,
        name: str,
        version: str,
        parameters: LlamaParseParameters,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        source_type: typing.Optional[str] = OMIT,
        source_id: typing.Optional[str] = OMIT,
        creator: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Create a new parse configuration.

        Args:
            config_create: Parse configuration creation data
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The created parse configuration

        Parameters
        ----------
        name : str
            Name of the parse configuration

        version : str
            Version of the configuration

        parameters : LlamaParseParameters
            LlamaParseParameters configuration

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        source_type : typing.Optional[str]
            Type of the source (e.g., 'project')

        source_id : typing.Optional[str]
            ID of the source

        creator : typing.Optional[str]
            Creator of the configuration

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud, LlamaParseParameters

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.create_parse_configuration(
            project_id="project_id",
            organization_id="organization_id",
            name="name",
            version="version",
            parameters=LlamaParseParameters(),
        )
        """
        _response = self._raw_client.create_parse_configuration(
            name=name,
            version=version,
            parameters=parameters,
            project_id=project_id,
            organization_id=organization_id,
            source_type=source_type,
            source_id=source_id,
            creator=creator,
            request_options=request_options,
        )
        return _response.data

    def upsert_parse_configuration(
        self,
        *,
        name: str,
        version: str,
        parameters: LlamaParseParameters,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        source_type: typing.Optional[str] = OMIT,
        source_id: typing.Optional[str] = OMIT,
        creator: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Create or update a parse configuration by name.

        Args:
            config_create: Parse configuration creation data
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The created or updated parse configuration

        Parameters
        ----------
        name : str
            Name of the parse configuration

        version : str
            Version of the configuration

        parameters : LlamaParseParameters
            LlamaParseParameters configuration

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        source_type : typing.Optional[str]
            Type of the source (e.g., 'project')

        source_id : typing.Optional[str]
            ID of the source

        creator : typing.Optional[str]
            Creator of the configuration

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud, LlamaParseParameters

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.upsert_parse_configuration(
            project_id="project_id",
            organization_id="organization_id",
            name="name",
            version="version",
            parameters=LlamaParseParameters(),
        )
        """
        _response = self._raw_client.upsert_parse_configuration(
            name=name,
            version=version,
            parameters=parameters,
            project_id=project_id,
            organization_id=organization_id,
            source_type=source_type,
            source_id=source_id,
            creator=creator,
            request_options=request_options,
        )
        return _response.data

    def get_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Get a parse configuration by ID.

        Args:
            config_id: The ID of the parse configuration
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The parse configuration

        Parameters
        ----------
        config_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_parse_configuration(
            config_id="config_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_parse_configuration(
            config_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def update_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parameters: typing.Optional[LlamaParseParameters] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Update a parse configuration.

        Args:
            config_id: The ID of the parse configuration to update
            config_update: Update data
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The updated parse configuration

        Parameters
        ----------
        config_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        parameters : typing.Optional[LlamaParseParameters]
            Updated LlamaParseParameters configuration

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.update_parse_configuration(
            config_id="config_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.update_parse_configuration(
            config_id,
            project_id=project_id,
            organization_id=organization_id,
            parameters=parameters,
            request_options=request_options,
        )
        return _response.data

    def delete_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Delete a parse configuration.

        Args:
            config_id: The ID of the parse configuration to delete
            project: Validated project from dependency
            user: Current user
            db: Database session

        Parameters
        ----------
        config_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.delete_parse_configuration(
            config_id="config_id",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.delete_parse_configuration(
            config_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def query_parse_configurations(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[ParseConfigurationFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        Query parse configurations with filtering and pagination.

        Args:
            query_request: Query request with filters and pagination
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            Paginated response with parse configurations

        Parameters
        ----------
        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[ParseConfigurationFilter]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfigurationQueryResponse
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.query_parse_configurations(
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.query_parse_configurations(
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            request_options=request_options,
        )
        return _response.data

    def get_latest_parse_configuration(
        self,
        *,
        creator: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[ParseConfiguration]:
        """
        Get the latest parse configuration for the current project.

        Args:
            project: Validated project from dependency
            user: Current user
            db: Database session
            creator: Optional creator filter

        Returns:
            The latest parse configuration or None if not found

        Parameters
        ----------
        creator : typing.Optional[str]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[ParseConfiguration]
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_latest_parse_configuration(
            creator="creator",
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_latest_parse_configuration(
            creator=creator, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    def list_spreadsheet_jobs(
        self,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseSpreadsheetJob:
        """
        List spreadsheet parsing jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        include_results : typing.Optional[bool]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseSpreadsheetJob
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.list_spreadsheet_jobs(
            include_results=True,
            project_id="project_id",
            organization_id="organization_id",
            page_size=1,
            page_token="page_token",
        )
        """
        _response = self._raw_client.list_spreadsheet_jobs(
            include_results=include_results,
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            request_options=request_options,
        )
        return _response.data

    def create_spreadsheet_job(
        self,
        *,
        file_id: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        config: typing.Optional[SpreadsheetParsingConfig] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SpreadsheetJob:
        """
        Create a spreadsheet parsing job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        file_id : str
            The ID of the file to parse

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        config : typing.Optional[SpreadsheetParsingConfig]
            Configuration for the parsing job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SpreadsheetJob
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.create_spreadsheet_job(
            project_id="project_id",
            organization_id="organization_id",
            file_id="file_id",
        )
        """
        _response = self._raw_client.create_spreadsheet_job(
            file_id=file_id,
            project_id=project_id,
            organization_id=organization_id,
            config=config,
            request_options=request_options,
        )
        return _response.data

    def get_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SpreadsheetJob:
        """
        Get a spreadsheet parsing job.

        When include_results=True (default), the response will include extracted tables and results
        if the job is complete, eliminating the need for a separate /results call.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        spreadsheet_job_id : str

        include_results : typing.Optional[bool]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SpreadsheetJob
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_spreadsheet_job(
            spreadsheet_job_id="spreadsheet_job_id",
            include_results=True,
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_spreadsheet_job(
            spreadsheet_job_id,
            include_results=include_results,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data

    def get_result_table(
        self,
        spreadsheet_job_id: str,
        table_id: str,
        table_type: SpreadsheetResultType,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PresignedUrl:
        """
        Generate a presigned URL to download a specific extracted table.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        spreadsheet_job_id : str

        table_id : str

        table_type : SpreadsheetResultType

        expires_at_seconds : typing.Optional[int]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PresignedUrl
            Successful Response

        Examples
        --------
        from llamaindex_test import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )
        client.beta.get_result_table(
            spreadsheet_job_id="spreadsheet_job_id",
            table_id="table_id",
            table_type="table",
            expires_at_seconds=1,
            project_id="project_id",
            organization_id="organization_id",
        )
        """
        _response = self._raw_client.get_result_table(
            spreadsheet_job_id,
            table_id,
            table_type,
            expires_at_seconds=expires_at_seconds,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data


class AsyncBetaClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawBetaClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawBetaClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawBetaClient
        """
        return self._raw_client

    async def list_api_keys(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        key_type: typing.Optional[ApiKeyType] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ApiKeyQueryResponse:
        """
        List API keys.

        If project_id is provided, validates user has access to that project.
        If project_id is not provided, scopes results to the current user.

        Args:
            user: Current user
            db: Database session
            page_size: Number of items per page
            page_token: Token for pagination
            name: Filter by API key name
            project_id: Filter by project ID
            key_type: Filter by key type

        Returns:
            Paginated response with API keys

        Parameters
        ----------
        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        name : typing.Optional[str]

        project_id : typing.Optional[str]

        key_type : typing.Optional[ApiKeyType]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ApiKeyQueryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.list_api_keys(
                page_size=1,
                page_token="page_token",
                name="name",
                project_id="project_id",
                key_type="user",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list_api_keys(
            page_size=page_size,
            page_token=page_token,
            name=name,
            project_id=project_id,
            key_type=key_type,
            request_options=request_options,
        )
        return _response.data

    async def create_api_key(
        self,
        *,
        name: typing.Optional[str] = OMIT,
        project_id: typing.Optional[str] = OMIT,
        key_type: typing.Optional[ApiKeyType] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ApiKey:
        """
        Create a new API key.

        If project_id is specified, validates user has admin permissions for that project.

        Args:
            api_key_create: API key creation data
            user: Current user
            db: Database session

        Returns:
            The created API key with the secret key visible in redacted_api_key field

        Parameters
        ----------
        name : typing.Optional[str]

        project_id : typing.Optional[str]
            The project ID to associate with the API key.

        key_type : typing.Optional[ApiKeyType]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ApiKey
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.create_api_key()


        asyncio.run(main())
        """
        _response = await self._raw_client.create_api_key(
            name=name, project_id=project_id, key_type=key_type, request_options=request_options
        )
        return _response.data

    async def get_api_key(self, api_key_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> ApiKey:
        """
        Get an API key by ID.

        Args:
            api_key_id: The ID of the API key
            user: Current user
            db: Database session

        Returns:
            The API key

        Parameters
        ----------
        api_key_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ApiKey
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_api_key(
                api_key_id="api_key_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_api_key(api_key_id, request_options=request_options)
        return _response.data

    async def delete_api_key(self, api_key_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete an API key.

        If the API key belongs to a project, validates user has admin permissions for that project.
        If the API key has no project, validates it belongs to the current user.

        Args:
            api_key_id: The ID of the API key to delete
            user: Current user
            db: Database session

        Parameters
        ----------
        api_key_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.delete_api_key(
                api_key_id="api_key_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete_api_key(api_key_id, request_options=request_options)
        return _response.data

    async def list_batches(
        self,
        *,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchPaginatedList:
        """
        Parameters
        ----------
        limit : typing.Optional[int]

        offset : typing.Optional[int]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchPaginatedList
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.list_batches(
                limit=1,
                offset=1,
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list_batches(
            limit=limit,
            offset=offset,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data

    async def create_batch(
        self,
        *,
        tool: str,
        input_type: str,
        input_id: str,
        external_id: str,
        organization_id: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        tool_data: typing.Optional[LlamaParseParameters] = OMIT,
        output_type: typing.Optional[str] = OMIT,
        output_id: typing.Optional[str] = OMIT,
        completion_window: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Batch:
        """
        Parameters
        ----------
        tool : str
            The tool to be used for all requests in the batch.

        input_type : str
            The type of input file. Currently only 'datasource' is supported.

        input_id : str
            The ID of the input file for the batch.

        external_id : str
            A developer-provided ID for the batch. This ID will be returned in the response.

        organization_id : typing.Optional[str]

        project_id : typing.Optional[str]

        tool_data : typing.Optional[LlamaParseParameters]
            The data to be used for the tool.

        output_type : typing.Optional[str]
            The type of output file. Currently only 'datasource' is supported.

        output_id : typing.Optional[str]
            The ID of the output file for the batch.

        completion_window : typing.Optional[int]
            The time frame within which the batch should be processed. Currently only 24h is supported.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Batch
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.create_batch(
                organization_id="organization_id",
                project_id="project_id",
                tool="tool",
                input_type="input_type",
                input_id="input_id",
                external_id="external_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_batch(
            tool=tool,
            input_type=input_type,
            input_id=input_id,
            external_id=external_id,
            organization_id=organization_id,
            project_id=project_id,
            tool_data=tool_data,
            output_type=output_type,
            output_id=output_id,
            completion_window=completion_window,
            request_options=request_options,
        )
        return _response.data

    async def get_batch(
        self,
        batch_id: str,
        *,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> BatchPublicOutput:
        """
        Parameters
        ----------
        batch_id : str

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BatchPublicOutput
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_batch(
                batch_id="batch_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_batch(
            batch_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def get_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentData:
        """
        Get agent data by ID.

        Parameters
        ----------
        item_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentData
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_agent_data(
                item_id="item_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_agent_data(
            item_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def update_agent_data(
        self,
        item_id: str,
        *,
        data: typing.Dict[str, typing.Optional[typing.Any]],
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentData:
        """
        Update agent data by ID (overwrites).

        Parameters
        ----------
        item_id : str

        data : typing.Dict[str, typing.Optional[typing.Any]]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentData
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.update_agent_data(
                item_id="item_id",
                project_id="project_id",
                organization_id="organization_id",
                data={"key": "value"},
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.update_agent_data(
            item_id, data=data, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def delete_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Dict[str, str]:
        """
        Delete agent data by ID.

        Parameters
        ----------
        item_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Dict[str, str]
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.delete_agent_data(
                item_id="item_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete_agent_data(
            item_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def create_agent_data(
        self,
        *,
        deployment_name: str,
        data: typing.Dict[str, typing.Optional[typing.Any]],
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentData:
        """
        Create new agent data.

        Parameters
        ----------
        deployment_name : str

        data : typing.Dict[str, typing.Optional[typing.Any]]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        collection : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentData
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.create_agent_data(
                project_id="project_id",
                organization_id="organization_id",
                deployment_name="deployment_name",
                data={"key": "value"},
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_agent_data(
            deployment_name=deployment_name,
            data=data,
            project_id=project_id,
            organization_id=organization_id,
            collection=collection,
            request_options=request_options,
        )
        return _response.data

    async def search_agent_data_api_v_1_beta_agent_data_search_post(
        self,
        *,
        deployment_name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        collection: typing.Optional[str] = OMIT,
        include_total: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseAgentData:
        """
        Search agent data with filtering, sorting, and pagination.

        Parameters
        ----------
        deployment_name : str
            The agent deployment's name to search within

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        collection : typing.Optional[str]
            The logical agent data collection to search within

        include_total : typing.Optional[bool]
            Whether to include the total number of items in the response

        offset : typing.Optional[int]
            The offset to start from. If not provided, the first page is returned

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseAgentData
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.search_agent_data_api_v_1_beta_agent_data_search_post(
                project_id="project_id",
                organization_id="organization_id",
                deployment_name="deployment_name",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.search_agent_data_api_v_1_beta_agent_data_search_post(
            deployment_name=deployment_name,
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            collection=collection,
            include_total=include_total,
            offset=offset,
            request_options=request_options,
        )
        return _response.data

    async def aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
        self,
        *,
        deployment_name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        collection: typing.Optional[str] = OMIT,
        group_by: typing.Optional[typing.Sequence[str]] = OMIT,
        count: typing.Optional[bool] = OMIT,
        first: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseAggregateGroup:
        """
        Aggregate agent data with grouping and optional counting/first item retrieval.

        Parameters
        ----------
        deployment_name : str
            The agent deployment's name to aggregate data for

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        collection : typing.Optional[str]
            The logical agent data collection to aggregate data for

        group_by : typing.Optional[typing.Sequence[str]]
            The fields to group by. If empty, the entire dataset is grouped on. e.g. if left out, can be used for simple count operations

        count : typing.Optional[bool]
            Whether to count the number of items in each group

        first : typing.Optional[bool]
            Whether to return the first item in each group (Sorted by created_at)

        offset : typing.Optional[int]
            The offset to start from. If not provided, the first page is returned

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseAggregateGroup
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
                project_id="project_id",
                organization_id="organization_id",
                deployment_name="deployment_name",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            deployment_name=deployment_name,
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            collection=collection,
            group_by=group_by,
            count=count,
            first=first,
            offset=offset,
            request_options=request_options,
        )
        return _response.data

    async def delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
        self,
        *,
        deployment_name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DeleteResponse:
        """
        Bulk delete agent data by query (deployment_name, collection, optional filters).

        Parameters
        ----------
        deployment_name : str
            The agent deployment's name to delete data for

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        collection : typing.Optional[str]
            The logical agent data collection to delete from

        filter : typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]]
            Optional filters to select which items to delete

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DeleteResponse
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
                project_id="project_id",
                organization_id="organization_id",
                deployment_name="deployment_name",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            deployment_name=deployment_name,
            project_id=project_id,
            organization_id=organization_id,
            collection=collection,
            filter=filter,
            request_options=request_options,
        )
        return _response.data

    async def list_quota_configurations(
        self,
        *,
        source_id: str,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseQuotaConfiguration:
        """
        Retrieve a paginated list of quota configurations with optional filtering.

        Parameters
        ----------
        source_id : str

        page : typing.Optional[int]

        page_size : typing.Optional[int]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseQuotaConfiguration
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.list_quota_configurations(
                source_id="source_id",
                page=1,
                page_size=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list_quota_configurations(
            source_id=source_id, page=page, page_size=page_size, request_options=request_options
        )
        return _response.data

    async def create_file(
        self,
        *,
        name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = OMIT,
        file_size: typing.Optional[int] = OMIT,
        last_modified_at: typing.Optional[dt.datetime] = OMIT,
        resource_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]] = OMIT,
        permission_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]] = OMIT,
        data_source_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> File:
        """
        Create a new file in the project.

        Args:
            file_create: File creation data
            project: Validated project from dependency
            db: Database session

        Returns:
            The created file

        Parameters
        ----------
        name : str
            Name that will be used for created file. If possible, always include the file extension in the name.

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        external_file_id : typing.Optional[str]
            The ID of the file in the external system

        file_size : typing.Optional[int]
            Size of the file in bytes

        last_modified_at : typing.Optional[dt.datetime]
            The last modified time of the file

        resource_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]]
            Resource information for the file

        permission_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]]
            Permission information for the file

        data_source_id : typing.Optional[str]
            The ID of the data source that the file belongs to

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        File
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.create_file(
                project_id="project_id",
                organization_id="organization_id",
                name="name",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_file(
            name=name,
            project_id=project_id,
            organization_id=organization_id,
            external_file_id=external_file_id,
            file_size=file_size,
            last_modified_at=last_modified_at,
            resource_info=resource_info,
            permission_info=permission_info,
            data_source_id=data_source_id,
            request_options=request_options,
        )
        return _response.data

    async def upsert_file(
        self,
        *,
        name: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        external_file_id: typing.Optional[str] = OMIT,
        file_size: typing.Optional[int] = OMIT,
        last_modified_at: typing.Optional[dt.datetime] = OMIT,
        resource_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]] = OMIT,
        permission_info: typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]] = OMIT,
        data_source_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> File:
        """
        Upsert a file (create or update if exists) in the project.

        Args:
            file_create: File creation/update data
            project: Validated project from dependency
            db: Database session

        Returns:
            The upserted file

        Parameters
        ----------
        name : str
            Name that will be used for created file. If possible, always include the file extension in the name.

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        external_file_id : typing.Optional[str]
            The ID of the file in the external system

        file_size : typing.Optional[int]
            Size of the file in bytes

        last_modified_at : typing.Optional[dt.datetime]
            The last modified time of the file

        resource_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreateResourceInfoValue]]]
            Resource information for the file

        permission_info : typing.Optional[typing.Dict[str, typing.Optional[FileCreatePermissionInfoValue]]]
            Permission information for the file

        data_source_id : typing.Optional[str]
            The ID of the data source that the file belongs to

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        File
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.upsert_file(
                project_id="project_id",
                organization_id="organization_id",
                name="name",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.upsert_file(
            name=name,
            project_id=project_id,
            organization_id=organization_id,
            external_file_id=external_file_id,
            file_size=file_size,
            last_modified_at=last_modified_at,
            resource_info=resource_info,
            permission_info=permission_info,
            data_source_id=data_source_id,
            request_options=request_options,
        )
        return _response.data

    async def query_files(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[FileFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> FileQueryResponse:
        """
        Query files with flexible filtering and pagination.

        Args:
            request: The query request with filters and pagination
            project: Validated project from dependency
            db: Database session

        Returns:
            Paginated response with files

        Parameters
        ----------
        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[FileFilter]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FileQueryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.query_files(
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.query_files(
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            request_options=request_options,
        )
        return _response.data

    async def delete_file(
        self,
        file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Delete a single file from the project.

        Args:
            file_id: The ID of the file to delete
            project: Validated project from dependency
            db: Database session

        Returns:
            None (204 No Content on success)

        Parameters
        ----------
        file_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.delete_file(
                file_id="file_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete_file(
            file_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def list_parse_configurations(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        creator: typing.Optional[str] = None,
        version: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        List parse configurations for the current project.

        Args:
            project: Validated project from dependency
            user: Current user
            db: Database session
            page_size: Number of items per page
            page_token: Token for pagination
            name: Filter by configuration name
            creator: Filter by creator
            version: Filter by version

        Returns:
            Paginated response with parse configurations

        Parameters
        ----------
        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        name : typing.Optional[str]

        creator : typing.Optional[str]

        version : typing.Optional[str]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfigurationQueryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.list_parse_configurations(
                page_size=1,
                page_token="page_token",
                name="name",
                creator="creator",
                version="version",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list_parse_configurations(
            page_size=page_size,
            page_token=page_token,
            name=name,
            creator=creator,
            version=version,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data

    async def create_parse_configuration(
        self,
        *,
        name: str,
        version: str,
        parameters: LlamaParseParameters,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        source_type: typing.Optional[str] = OMIT,
        source_id: typing.Optional[str] = OMIT,
        creator: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Create a new parse configuration.

        Args:
            config_create: Parse configuration creation data
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The created parse configuration

        Parameters
        ----------
        name : str
            Name of the parse configuration

        version : str
            Version of the configuration

        parameters : LlamaParseParameters
            LlamaParseParameters configuration

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        source_type : typing.Optional[str]
            Type of the source (e.g., 'project')

        source_id : typing.Optional[str]
            ID of the source

        creator : typing.Optional[str]
            Creator of the configuration

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud, LlamaParseParameters

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.create_parse_configuration(
                project_id="project_id",
                organization_id="organization_id",
                name="name",
                version="version",
                parameters=LlamaParseParameters(),
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_parse_configuration(
            name=name,
            version=version,
            parameters=parameters,
            project_id=project_id,
            organization_id=organization_id,
            source_type=source_type,
            source_id=source_id,
            creator=creator,
            request_options=request_options,
        )
        return _response.data

    async def upsert_parse_configuration(
        self,
        *,
        name: str,
        version: str,
        parameters: LlamaParseParameters,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        source_type: typing.Optional[str] = OMIT,
        source_id: typing.Optional[str] = OMIT,
        creator: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Create or update a parse configuration by name.

        Args:
            config_create: Parse configuration creation data
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The created or updated parse configuration

        Parameters
        ----------
        name : str
            Name of the parse configuration

        version : str
            Version of the configuration

        parameters : LlamaParseParameters
            LlamaParseParameters configuration

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        source_type : typing.Optional[str]
            Type of the source (e.g., 'project')

        source_id : typing.Optional[str]
            ID of the source

        creator : typing.Optional[str]
            Creator of the configuration

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud, LlamaParseParameters

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.upsert_parse_configuration(
                project_id="project_id",
                organization_id="organization_id",
                name="name",
                version="version",
                parameters=LlamaParseParameters(),
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.upsert_parse_configuration(
            name=name,
            version=version,
            parameters=parameters,
            project_id=project_id,
            organization_id=organization_id,
            source_type=source_type,
            source_id=source_id,
            creator=creator,
            request_options=request_options,
        )
        return _response.data

    async def get_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Get a parse configuration by ID.

        Args:
            config_id: The ID of the parse configuration
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The parse configuration

        Parameters
        ----------
        config_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_parse_configuration(
                config_id="config_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_parse_configuration(
            config_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def update_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parameters: typing.Optional[LlamaParseParameters] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfiguration:
        """
        Update a parse configuration.

        Args:
            config_id: The ID of the parse configuration to update
            config_update: Update data
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            The updated parse configuration

        Parameters
        ----------
        config_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        parameters : typing.Optional[LlamaParseParameters]
            Updated LlamaParseParameters configuration

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfiguration
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.update_parse_configuration(
                config_id="config_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.update_parse_configuration(
            config_id,
            project_id=project_id,
            organization_id=organization_id,
            parameters=parameters,
            request_options=request_options,
        )
        return _response.data

    async def delete_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Delete a parse configuration.

        Args:
            config_id: The ID of the parse configuration to delete
            project: Validated project from dependency
            user: Current user
            db: Database session

        Parameters
        ----------
        config_id : str

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.delete_parse_configuration(
                config_id="config_id",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete_parse_configuration(
            config_id, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def query_parse_configurations(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
        filter: typing.Optional[ParseConfigurationFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        Query parse configurations with filtering and pagination.

        Args:
            query_request: Query request with filters and pagination
            project: Validated project from dependency
            user: Current user
            db: Database session

        Returns:
            Paginated response with parse configurations

        Parameters
        ----------
        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]
            The maximum number of items to return. The service may return fewer than this value. If unspecified, a default page size will be used. The maximum value is typically 1000; values above this will be coerced to the maximum.

        page_token : typing.Optional[str]
            A page token, received from a previous list call. Provide this to retrieve the subsequent page.

        filter : typing.Optional[ParseConfigurationFilter]
            A filter object or expression that filters resources listed in the response.

        order_by : typing.Optional[str]
            A comma-separated list of fields to order by, sorted in ascending order. Use 'field_name desc' to specify descending order.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ParseConfigurationQueryResponse
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.query_parse_configurations(
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.query_parse_configurations(
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            filter=filter,
            order_by=order_by,
            request_options=request_options,
        )
        return _response.data

    async def get_latest_parse_configuration(
        self,
        *,
        creator: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Optional[ParseConfiguration]:
        """
        Get the latest parse configuration for the current project.

        Args:
            project: Validated project from dependency
            user: Current user
            db: Database session
            creator: Optional creator filter

        Returns:
            The latest parse configuration or None if not found

        Parameters
        ----------
        creator : typing.Optional[str]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[ParseConfiguration]
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_latest_parse_configuration(
                creator="creator",
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_latest_parse_configuration(
            creator=creator, project_id=project_id, organization_id=organization_id, request_options=request_options
        )
        return _response.data

    async def list_spreadsheet_jobs(
        self,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedResponseSpreadsheetJob:
        """
        List spreadsheet parsing jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        include_results : typing.Optional[bool]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        page_size : typing.Optional[int]

        page_token : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedResponseSpreadsheetJob
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.list_spreadsheet_jobs(
                include_results=True,
                project_id="project_id",
                organization_id="organization_id",
                page_size=1,
                page_token="page_token",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list_spreadsheet_jobs(
            include_results=include_results,
            project_id=project_id,
            organization_id=organization_id,
            page_size=page_size,
            page_token=page_token,
            request_options=request_options,
        )
        return _response.data

    async def create_spreadsheet_job(
        self,
        *,
        file_id: str,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        config: typing.Optional[SpreadsheetParsingConfig] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SpreadsheetJob:
        """
        Create a spreadsheet parsing job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        file_id : str
            The ID of the file to parse

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        config : typing.Optional[SpreadsheetParsingConfig]
            Configuration for the parsing job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SpreadsheetJob
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.create_spreadsheet_job(
                project_id="project_id",
                organization_id="organization_id",
                file_id="file_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_spreadsheet_job(
            file_id=file_id,
            project_id=project_id,
            organization_id=organization_id,
            config=config,
            request_options=request_options,
        )
        return _response.data

    async def get_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SpreadsheetJob:
        """
        Get a spreadsheet parsing job.

        When include_results=True (default), the response will include extracted tables and results
        if the job is complete, eliminating the need for a separate /results call.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        spreadsheet_job_id : str

        include_results : typing.Optional[bool]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SpreadsheetJob
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_spreadsheet_job(
                spreadsheet_job_id="spreadsheet_job_id",
                include_results=True,
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_spreadsheet_job(
            spreadsheet_job_id,
            include_results=include_results,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data

    async def get_result_table(
        self,
        spreadsheet_job_id: str,
        table_id: str,
        table_type: SpreadsheetResultType,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PresignedUrl:
        """
        Generate a presigned URL to download a specific extracted table.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters
        ----------
        spreadsheet_job_id : str

        table_id : str

        table_type : SpreadsheetResultType

        expires_at_seconds : typing.Optional[int]

        project_id : typing.Optional[str]

        organization_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PresignedUrl
            Successful Response

        Examples
        --------
        import asyncio

        from llamaindex_test import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.beta.get_result_table(
                spreadsheet_job_id="spreadsheet_job_id",
                table_id="table_id",
                table_type="table",
                expires_at_seconds=1,
                project_id="project_id",
                organization_id="organization_id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_result_table(
            spreadsheet_job_id,
            table_id,
            table_type,
            expires_at_seconds=expires_at_seconds,
            project_id=project_id,
            organization_id=organization_id,
            request_options=request_options,
        )
        return _response.data
