{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ae913d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Learn the code - Part 2\n",
    "\n",
    "---\n",
    "**Purpose:** Learn how to measure snow depth levels with gnssrefl using GNSS data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458d0d1",
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gnssrefl.utils import check_environment, set_environment, get_sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Making sure environment variables are set - this is required to run the gnssrefl code\n",
    "notebook_dir = Path.cwd().parents[0]\n",
    "\n",
    "exists = check_environment()\n",
    "if exists == False:\n",
    "    #If you are running this locally - make sure the items in the exe folder have execution permissions\n",
    "    set_environment(refl_code=str(notebook_dir),\n",
    "                    orbits=str(notebook_dir / \"orbits\"),\n",
    "                    exe=str(notebook_dir / \"exe\"))\n",
    "\n",
    "# Set local variable of refl_code location\n",
    "refl_code_loc = os.environ['REFL_CODE']\n",
    "print(\"refl_code location:\", refl_code_loc)\n",
    "\n",
    "# import gnssrefl functions\n",
    "from gnssrefl.rinex2snr_cl import rinex2snr\n",
    "from gnssrefl.quickLook_cl import quicklook\n",
    "from gnssrefl.make_json_input import make_json\n",
    "from gnssrefl.gnssir_cl import gnssir\n",
    "from gnssrefl.daily_avg_cl import daily_avg\n",
    "from gnssrefl.installexe_cl import installexe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88ea6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import the crx2rnx file which is dependant on your working OS - this is required to run the gnssrefl code\n",
    "try:\n",
    "    os.environ['DOCKER']\n",
    "except KeyError:\n",
    "    sys = get_sys()\n",
    "    installexe(sys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a2131a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Station:**\n",
    "We will be using station **gls1**.\n",
    "gls1 was installed at [Dye2](http://greenlandtoday.com/dye-2-a-relic-from-a-not-so-distant-past/?lang=en) on the Greenland Ice Sheet in 2011. \n",
    "The antenna is mounted on a long pole; approximately 3.5-meter of the pole was above the ice at the time of installation. \n",
    "A detailed discussion of the monument and \n",
    "data from the station can be found in [Larson, MacFerrin, and Nylen (2020)](https://tc.copernicus.org/articles/14/1985/2020/tc-14-1985-2020.pdf). \n",
    "The latest position time series for gls1 can be retrieved \n",
    "from the [Nevada Geodetic Laboratory](http://geodesy.unr.edu/gps_timeseries/tenv3/IGS14/GLS1.tenv3). \n",
    "\n",
    "As gls1 is on an ice sheet and the ice surface is relatively smooth in all directions, it \n",
    "is unlikely that a complicated azimuth mask will be required.\n",
    "\n",
    "gls1 was originally installed with an elevation mask of 7 degrees, which is suboptimal for reflections research.\n",
    "Even though the mask was later removed, we will use 7 degrees as the minimum elevation angle for all our analysis.\n",
    "Similarly, even though the site managers later changed to enable L2C tracking, to ensure that \n",
    "a consistent dataset is being used, we will only use L1 data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e8303",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the cell below (starts with %%html) to view the gnss-reflections webapp geoid functionality to get an idea of its surroundings. You can enter the station coordinates by hand if you know them, but since gls1 is part of a public archive known to geodesists, coordinates have been stored in the webapp. Just type in gls1 for the station name. Make a note of the station latitude, longitude, and ellipsoidal height that is returned by the webapp because you will need it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd4875",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "station = 'gls1'\n",
    "\n",
    "# fill in values here from the web app in the cell below\n",
    "lat = 66.47939127\n",
    "long = -46.31015275\n",
    "height = 2148.578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a2e5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://gnss-reflections.org/geoid\" width=\"800\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424367dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Using gnssrefl**\n",
    "\n",
    "Our ultimate goal in this use case is to analyze one year of data. We have chosen the year 2012 because there was a large melt event on the ice sheet. In order to set the proper quality control parameters, we will use quickLook for one day. First we need to translate one day of RINEX data using rinex2snr. We will use day of year 100:\n",
    "\n",
    "We need to pick up a RINEX file and strip out the SNR data.  We use the <code>rinex2snr</code> for this purpose. \n",
    "The only required inputs are the station name (gls1), the year (2012) and day of year (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125405a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell to check out the parameters and default values\n",
    "rinex2snr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e4d0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "year = 2012\n",
    "doy = 100\n",
    "# if you would like to pick an archive then you can \n",
    "# archive = 'unavco'\n",
    "# archive = 'sopac'\n",
    "\n",
    "# if you choose to use an archive then you must add the parameter archive example:\n",
    "# rinex2snr(station, year, doy, archive=archive)\n",
    "\n",
    "# otherwise, the only required parameters are station, year, and doy\n",
    "rinex2snr(station, year, doy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0579fcf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "Once you have successfully created a SNR file, run <code>quickLook</code>.\n",
    "\n",
    "There are two ways to view the quicklook plots in the jupyter notebook version:\n",
    "\n",
    "* The first way is to set the parameter plt to True (`plt=True`). This will print out the plots that the gnssrefl code makes.\n",
    "\n",
    "* The second way is to make the plot ourselves so we can better view these plots. In that case we set `plt=False` - which is also the default. Both options are provided in the cells below.\n",
    "\n",
    "The quicklook plots consist of two graphical representations of the data. The first is\n",
    "periodograms for the four geographic quadrants (northwest, northeast, and so on).\n",
    "You are looking for nice clean (and colorful) peaks. Color means they have\n",
    "passed Quality Control (QC). Gray lines are satellite tracks that failed QC. The second plot summarizes the\n",
    "RH retrievals and how the QC metrics look compared to\n",
    "the defaults. In this case the x-axis is azimuth in degrees.\n",
    "[For more details on quicklook output](https://github.com/kristinemlarson/gnssrefl/blob/master/docs/quickLook_desc.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9bdb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting using plt=True\n",
    "values, metrics = quicklook(station, year, doy=doy, plt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675184e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the quicklook graph periodograms\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(12, 10), sharex=True)\n",
    "fig.suptitle(f'QuickLook: {station}', size=16)\n",
    "\n",
    "quadrants = ['NW', 'NE', 'SW', 'SE']\n",
    "quadrant_labels = ['Northwest', 'Northeast', 'Southwest', 'Southeast']\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    quad = quadrants[i]\n",
    "    for fail_satellite in values[f'f{quad}']:\n",
    "        g = sns.lineplot(x=values[f'f{quad}'][fail_satellite][0],\n",
    "                         y=values[f'f{quad}'][fail_satellite][1],\n",
    "                         ax=ax, color='lightgrey')\n",
    "    for satellite in values[quad]:\n",
    "        g = sns.lineplot(x=values[quad][satellite][0],\n",
    "                         y=values[quad][satellite][1],\n",
    "                         ax=ax)\n",
    "    g.set_title(quadrant_labels[i])\n",
    "    g.set_ylabel('volts/volts')\n",
    "    g.set_xlabel('reflector height (m)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768035a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the qc metrics graphs\n",
    "success, fail = gnssrefl_helpers.quicklook_metrics(metrics)\n",
    "fig, axes = plt.subplots(ncols=1, nrows=3, figsize=(10, 10), sharex=True)\n",
    "fig.suptitle(f'QuickLook Retrieval Metrics: {station} GPS L1', size=16)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    g = sns.scatterplot(x='Azimuth', y=success.columns[i + 1], data=success, ax=ax, label='good')\n",
    "    g = sns.scatterplot(x='Azimuth', y=fail.columns[i + 1], data=fail, ax=ax, color='lightgrey', label='bad')\n",
    "\n",
    "axes[0].legend(loc='upper right')\n",
    "\n",
    "avg_rh = np.mean(success['Reflector Height'])\n",
    "print(f'Average reflector height value: {avg_rh:.1f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08317c35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looking at the metrics plots, do you have some ideas on how to change the azimuth mask angles?\n",
    "\n",
    "Use whichever quicklook plotting method to compare the above to its level when the site was installed in the year 2011 in the cell provided below (run rinex2snr and then quicklook similar to what was shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f9574",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# place code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31399d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, lets make SNR files for the whole year 2012: We will use the 'weekly' parameter that will make just one day of the week over the period we give it. This is in the interest of saving time. It should take ~5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089ce92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rinex2snr(station, year, 1, doy_end=366, weekly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc38b4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will next analyze a year of L1 GPS reflection data from this site. We will use the default minimum and maximum\n",
    "reflector height values (0.5 and 6 meters). But for the reasons previously stated, we will set a minimum elevation angle of 7 degrees. We also specify that we only want to use the L1 data. We use the utility make_json_input to set and store these analysis settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2474a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell to view the available parameters and current defaults\n",
    "make_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d36926",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We decided the best values for these using the QC metric plots above. Do these make sense based on those plots above?\n",
    "min_elevation_angle = 7\n",
    "peak_to_noise = 3\n",
    "amplitude = 8\n",
    "make_json(station, lat, long, height, e1=min_elevation_angle, peak2noise=peak_to_noise, ampl=amplitude, l1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ca3a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is the json file we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ce79a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is the json file that was created with the defaults/parameters you set above\n",
    "json_file = f'{refl_code_loc}/input/{station}.json'\n",
    "with open(json_file, \"r\") as myfile:\n",
    "    file = json.load(myfile)\n",
    "\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff11720",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are going to hand edit the azimuths to between 40 and 330 degrees. Was this close to your estimate using the QC plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6ec1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now lets edit the json file\n",
    "with open(json_file, \"r\") as myfile:\n",
    "    file = json.load(myfile)\n",
    "\n",
    "# Here is where we can 'hand edit' values in the json file\n",
    "# lets edit the azimuths. We set these values by looking at the metrics qc plot above\n",
    "file['azval'] = [40, 90, 90, 180, 180, 270, 270, 330]\n",
    "os.remove(json_file)\n",
    "\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(file, f, indent=4)\n",
    "\n",
    "# now lets view it again and note the difference\n",
    "with open(json_file, \"r\") as myfile:\n",
    "    file = json.load(myfile)\n",
    "\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8fd6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that you have SNR files and json inputs, you can go ahead and estimate reflector heights for the year 2012:\n",
    "\n",
    "*note that it will be normal to see 'Could not read the first SNR file:' results - this is because we used the weekly setting when downloading the snr files. We are setting gnssir to run for every day of the year but if the snr file doesn't exist, it will continue on - in this case we only have one snr file per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118ba40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gnssir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e19acf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "year = 2012\n",
    "doy = 1\n",
    "doy_end = 366\n",
    "gnssir(station, year, doy, doy_end=doy_end, screenstats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd411c7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we can use the daily_avg tool to compute a daily average reflector height. A median filter is set to 0.25 meters \n",
    "and 30 individual tracks are required in order to recover a daily average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55515f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "daily_avg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d75e8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "daily_avg(station, medfilter=.25, ReqTracks=30, plt=False, txtfile=f'{station}-dailyavg.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331db37",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This will create a daily file that contains the daily averages. Let's plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb0008",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filepath = f'{refl_code_loc}/Files/{station}-dailyavg.txt'\n",
    "\n",
    "# I have provided  a function that will read the file for you.\n",
    "data = gnssrefl_helpers.read_rh_files(filepath)\n",
    "df = pd.DataFrame(data, index=None, columns=['dates', 'rh'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6d725",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "g = sns.scatterplot(x='dates', y='rh', data=df, legend=False)\n",
    "# here we flip the axis so its low reflector height (higher snow) to higher reflector height (lower snow)\n",
    "g.set_ylim(3.6, 2.3)\n",
    "g.set_ylabel('Reflector Height (m)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7f9c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data in this plot show you long-term accumulation as well as relatively small snow accumulation events. The overall plot is dominated by the large melt event in the summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80c07e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnssrefl_jupyter",
   "language": "python",
   "name": "gnssrefl_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
