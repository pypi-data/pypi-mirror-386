Metadata-Version: 2.4
Name: aigroup-quant-mcp
Version: 1.0.6
Summary: AI Group Quantitative Analysis MCP Service
Author-email: AI Group <ai.group@example.com>
License-Expression: MIT
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Financial and Insurance Industry
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Office/Business :: Financial :: Investment
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Operating System :: OS Independent
Classifier: Natural Language :: English
Classifier: Natural Language :: Chinese (Simplified)
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pandas>=2.0.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: scipy>=1.10.0
Requires-Dist: lightgbm>=4.0.0
Requires-Dist: xgboost>=2.0.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: torch>=2.0.0
Requires-Dist: mcp>=1.0.0
Provides-Extra: viz
Requires-Dist: matplotlib>=3.7.0; extra == "viz"
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Dynamic: license-file

# QuantAnalyzer - é‡åŒ–åˆ†æå·¥å…·åŒ… v2.0

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> å‚è€ƒQlibæ¶æ„çš„è½»é‡çº§é‡åŒ–åˆ†æPythonåŒ…ï¼Œæ”¯æŒAlpha158å› å­åº“å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹

## ğŸŒŸ v2.0 æ–°ç‰¹æ€§

### ğŸ“Š Alpha158å› å­åº“
- âœ¨ **158ä¸ªæŠ€æœ¯æŒ‡æ ‡å› å­** - å®Œæ•´çš„Qlibçº§å› å­åº“
- ğŸ¯ Kçº¿å½¢æ€ï¼ˆ9ä¸ªï¼‰+ ä»·æ ¼ï¼ˆ5ä¸ªï¼‰+ æˆäº¤é‡ï¼ˆ5ä¸ªï¼‰+ æ»šåŠ¨ç»Ÿè®¡ï¼ˆ139ä¸ªï¼‰
- ğŸ”§ çµæ´»é…ç½®ï¼Œæ”¯æŒè‡ªå®šä¹‰çª—å£

### ğŸ¤– æ·±åº¦å­¦ä¹ æ¨¡å‹
- ğŸš€ **LSTM** - é•¿æœŸä¾èµ–å»ºæ¨¡
- âš¡ **GRU** - é«˜æ•ˆåºåˆ—å­¦ä¹ 
- ğŸ¨ **Transformer** - å¹¶è¡Œæ³¨æ„åŠ›æœºåˆ¶

### ğŸ› ï¸ æ‰©å±•MCPæœåŠ¡
- ğŸ“ˆ ä»5ä¸ªå·¥å…·æ‰©å±•åˆ°**11ä¸ªä¸“ä¸šé‡åŒ–å·¥å…·**
- ğŸ”Œ å®Œæ•´çš„å› å­ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹æµç¨‹
- ğŸ’¡ å³æ’å³ç”¨çš„Roo-Codeé›†æˆ

---

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# ä½¿ç”¨pipå®‰è£…
pip install aigroup-quant-mcp

# æˆ–è€…ä½¿ç”¨uvå®‰è£…
uv pip install aigroup-quant-mcp
```

### åŸºç¡€ä½¿ç”¨

```python
from quantanalyzer.data import DataLoader
from quantanalyzer.factor import Alpha158Generator
from quantanalyzer.model import LSTMModel

# 1. åŠ è½½æ•°æ®
loader = DataLoader()
data = loader.load_from_csv("your_data.csv")

# 2. ç”ŸæˆAlpha158å› å­
generator = Alpha158Generator(data)
factors = generator.generate_all(rolling_windows=[5, 10, 20])

# 3. è®­ç»ƒLSTMæ¨¡å‹
model = LSTMModel(d_feat=factors.shape[1], n_epochs=50)
history = model.fit(X_train, y_train, X_valid, y_valid)

# 4. é¢„æµ‹
predictions = model.predict(X_test)
```

### ä½¿ç”¨MCPæœåŠ¡

```bash
# ä½¿ç”¨pythonç›´æ¥è¿è¡Œ
python -m quantanalyzer.mcp

# æˆ–è€…ä½¿ç”¨uvxè¿è¡Œï¼ˆæ¨èï¼‰
uvx aigroup-quant-mcp

# æˆ–è€…å®‰è£…åç›´æ¥è¿è¡Œ
aigroup-quant-mcp
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1ï¸âƒ£ æ•°æ®å¤„ç†

```python
from quantanalyzer.data import DataLoader, DataProcessor

# åŠ è½½CSV
loader = DataLoader()
data = loader.load_from_csv("stock_data.csv")

# æ•°æ®é¢„å¤„ç†
processor = DataProcessor()
processed = processor.fillna(data)
normalized = processor.normalize(processed)
```

### 2ï¸âƒ£ å› å­è®¡ç®—

#### åŸºç¡€å› å­åº“ï¼ˆv1.0ï¼‰
```python
from quantanalyzer.factor import FactorLibrary

library = FactorLibrary()

# 6ä¸ªåŸºç¡€å› å­
momentum = library.momentum(data, period=20)
volatility = library.volatility(data, period=20)
volume_ratio = library.volume_ratio(data, period=20)
rsi = library.rsi(data, period=14)
macd = library.macd(data)
bb = library.bollinger_bands(data, period=20)
```

#### Alpha158å› å­åº“ï¼ˆv2.0 æ–°å¢ï¼‰
```python
from quantanalyzer.factor import Alpha158Generator

# ç”Ÿæˆ158ä¸ªæŠ€æœ¯æŒ‡æ ‡
generator = Alpha158Generator(data)

# å®Œæ•´å› å­é›†
alpha158_full = generator.generate_all()

# è‡ªå®šä¹‰é…ç½®
alpha158_custom = generator.generate_all(
    kbar=True,                    # Kçº¿å½¢æ€ï¼ˆ9ä¸ªï¼‰
    price=True,                   # ä»·æ ¼ï¼ˆ5ä¸ªï¼‰
    volume=True,                  # æˆäº¤é‡ï¼ˆ5ä¸ªï¼‰
    rolling=True,                 # æ»šåŠ¨ç»Ÿè®¡ï¼ˆ139ä¸ªï¼‰
    rolling_windows=[5, 10, 20]   # è‡ªå®šä¹‰çª—å£
)

# ä»…Kçº¿å› å­
kbar_only = generator.generate_all(
    kbar=True, price=False, volume=False, rolling=False
)
```

### 3ï¸âƒ£ å› å­è¯„ä¼°

```python
from quantanalyzer.factor import FactorEvaluator

# è®¡ç®—æ”¶ç›Šç‡
returns = data['close'].groupby(level=1).pct_change(1).shift(-1)

# è¯„ä¼°IC
evaluator = FactorEvaluator(factor, returns)
ic_metrics = evaluator.calculate_ic(method='spearman')

print(f"ICå‡å€¼: {ic_metrics['ic_mean']:.4f}")
print(f"ICIR: {ic_metrics['icir']:.4f}")
```

### 4ï¸âƒ£ æ¨¡å‹è®­ç»ƒ

#### ä¼ ç»Ÿæ¨¡å‹ï¼ˆv1.0ï¼‰
```python
from quantanalyzer.model import ModelTrainer

# LightGBM/XGBoost/Linear
trainer = ModelTrainer(model_type='lightgbm')
trainer.fit(X_train, y_train)
predictions = trainer.predict(X_test)
```

#### æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆv2.0 æ–°å¢ï¼‰
```python
from quantanalyzer.model import LSTMModel, GRUModel, TransformerModel

# LSTM
lstm = LSTMModel(d_feat=158, hidden_size=64, n_epochs=100)
lstm_history = lstm.fit(X_train, y_train, X_valid, y_valid)
lstm_pred = lstm.predict(X_test)

# GRU
gru = GRUModel(d_feat=158, hidden_size=64)
gru_history = gru.fit(X_train, y_train, X_valid, y_valid)

# Transformer
transformer = TransformerModel(d_feat=158, d_model=64, nhead=4)
transformer_history = transformer.fit(X_train, y_train, X_valid, y_valid)
```

### 5ï¸âƒ£ å›æµ‹å¼•æ“

```python
from quantanalyzer.backtest import BacktestEngine

# TopKç­–ç•¥å›æµ‹
engine = BacktestEngine(
    data=data,
    predictions=predictions,
    top_k=10,
    commission=0.0015,
    slippage=0.001
)

result = engine.run()
print(f"æ€»æ”¶ç›Š: {result['total_return']:.2%}")
print(f"å¤æ™®æ¯”ç‡: {result['sharpe_ratio']:.2f}")
```

---

## ğŸ”Œ MCPæœåŠ¡

### å¯åŠ¨MCPæœåŠ¡

MCPæœåŠ¡æ”¯æŒå¤šç§å¯åŠ¨æ–¹å¼ï¼š

#### ä½¿ç”¨uvxï¼ˆæ¨èï¼‰
```bash
# ç›´æ¥è¿è¡Œï¼Œæ— éœ€å®‰è£…
uvx aigroup-quant-mcp

# æŒ‡å®šç‰ˆæœ¬è¿è¡Œ
uvx aigroup-quant-mcp==1.0.0
```

#### ä½¿ç”¨Pythonç›´æ¥è¿è¡Œ
```bash
# å…‹éš†é¡¹ç›®åç›´æ¥è¿è¡Œ
python -m quantanalyzer.mcp

# æˆ–è€…
python mcp_server.py
```

#### å®‰è£…åè¿è¡Œ
```bash
# å®‰è£…
pip install aigroup-quant-mcp

# è¿è¡Œ
aigroup-quant-mcp
```

MCPæœåŠ¡å·²è‡ªåŠ¨é…ç½®åˆ°Roo-Codeï¼ŒåŒ…å«**11ä¸ªä¸“ä¸šé‡åŒ–å·¥å…·**ï¼š

#### æ•°æ®å·¥å…·
1. `load_csv_data` - åŠ è½½CSVæ•°æ®

#### å› å­å·¥å…·
2. `calculate_factor` - è®¡ç®—åŸºç¡€å› å­ï¼ˆ6ç§ï¼‰
3. `generate_alpha158` - ç”ŸæˆAlpha158å› å­é›†ï¼ˆ158ä¸ªï¼‰
4. `evaluate_factor_ic` - è¯„ä¼°å› å­IC

#### æ¨¡å‹å·¥å…·
5. `train_lstm_model` - è®­ç»ƒLSTMæ¨¡å‹
6. `train_gru_model` - è®­ç»ƒGRUæ¨¡å‹
7. `train_transformer_model` - è®­ç»ƒTransformeræ¨¡å‹
8. `predict_with_model` - æ¨¡å‹é¢„æµ‹

#### ä¿¡æ¯å·¥å…·
9. `get_data_info` - æ•°æ®ä¿¡æ¯
10. `list_factors` - å› å­åˆ—è¡¨
11. `list_models` - æ¨¡å‹åˆ—è¡¨

### MCPä½¿ç”¨æµç¨‹

```bash
# ä½¿ç”¨uvxå¯åŠ¨æœåŠ¡åï¼Œå¯é€šè¿‡MCPå·¥å…·è¿›è¡Œå®Œæ•´åˆ†ææµç¨‹ï¼š

1. load_csv_data          # åŠ è½½æ•°æ®
2. generate_alpha158      # ç”Ÿæˆå› å­
3. train_lstm_model       # è®­ç»ƒæ¨¡å‹
4. predict_with_model     # é¢„æµ‹
5. evaluate_factor_ic     # è¯„ä¼°
```

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
quantanalyzer-project/
â”œâ”€â”€ quantanalyzer/              # æ ¸å¿ƒåŒ…
â”‚   â”œâ”€â”€ data/                   # æ•°æ®å±‚
â”‚   â”‚   â”œâ”€â”€ loader.py          # æ•°æ®åŠ è½½
â”‚   â”‚   â””â”€â”€ processor.py       # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ factor/                 # å› å­å±‚
â”‚   â”‚   â”œâ”€â”€ library.py         # åŸºç¡€å› å­åº“ï¼ˆ6ä¸ªï¼‰
â”‚   â”‚   â”œâ”€â”€ alpha158.py        # â­ Alpha158å› å­ï¼ˆ158ä¸ªï¼‰
â”‚   â”‚   â””â”€â”€ evaluator.py       # å› å­è¯„ä¼°
â”‚   â”œâ”€â”€ model/                  # æ¨¡å‹å±‚
â”‚   â”‚   â”œâ”€â”€ trainer.py         # ä¼ ç»Ÿæ¨¡å‹
â”‚   â”‚   â””â”€â”€ deep_models.py     # â­ æ·±åº¦å­¦ä¹ æ¨¡å‹
â”‚   â””â”€â”€ backtest/               # å›æµ‹å±‚
â”‚       â””â”€â”€ engine.py          # å›æµ‹å¼•æ“
â”œâ”€â”€ examples/                   # ç¤ºä¾‹è„šæœ¬
â”‚   â”œâ”€â”€ test_basic_functions.py
â”‚   â”œâ”€â”€ complete_workflow.py
â”‚   â”œâ”€â”€ analyze_real_data.py
â”‚   â””â”€â”€ test_alpha158_and_dl.py  # â­ æ–°å¢
â”œâ”€â”€ quantanalyzer/mcp.py       # â­ MCPæœåŠ¡å™¨ï¼ˆ11å·¥å…·ï¼‰
â”œâ”€â”€ pyproject.toml             # â­ é¡¹ç›®é…ç½®ï¼ˆæ”¯æŒuv/uvxï¼‰
â”œâ”€â”€ setup.py                   # â­ å®‰è£…é…ç½®
â””â”€â”€ åŠŸèƒ½æ‰©å±•è¯´æ˜.md            # â­ æ–°å¢æ–‡æ¡£
```

---

## â–¶ï¸ æµ‹è¯•è¿è¡Œè¯´æ˜

### è¿è¡Œå®Œæ•´æµ‹è¯•

é¡¹ç›®åŒ…å«å®Œæ•´çš„æµ‹è¯•è„šæœ¬ï¼Œç”¨äºéªŒè¯æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼š

```bash
# è¿è¡ŒAlpha158å› å­å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•
python examples/test_alpha158_and_dl.py
```

### é¢„æœŸè¾“å‡º

**Alpha158å› å­æµ‹è¯•ç»“æœ**ï¼ˆ44æ¡çœŸå®è¡Œæƒ…æ•°æ®ï¼‰ï¼š
- âœ… Kçº¿å½¢æ€å› å­ï¼š9ä¸ªï¼Œæ­£å¸¸
- âœ… Alpha158å› å­ï¼š72ä¸ªï¼ˆå°çª—å£ï¼‰ï¼Œæ­£å¸¸
- âœ… ç©ºå€¼ç‡ï¼š~8.1%ï¼ˆç¬¦åˆé¢„æœŸï¼‰

**æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½å¯¹æ¯”**ï¼š

| æ¨¡å‹ | è®­ç»ƒè½®æ¬¡ | éªŒè¯æŸå¤± | æµ‹è¯•ç›¸å…³æ€§ | æ¨è |
|------|---------|----------|-----------|------|
| **LSTM** | 20è½®æ—©åœ | 1049.49 | **0.8655** | â­â­â­ |
| GRU | 20è½®æ—©åœ | 1048.97 | -0.3271 | âš ï¸ éœ€æ›´å¤šæ•°æ® |
| Transformer | 20è½®æ—©åœ | 1045.70 | -0.5907 | âš ï¸ éœ€æ›´å¤šæ•°æ® |

> **æç¤º**ï¼šåœ¨å°æ ·æœ¬æ•°æ®ä¸Šï¼ŒLSTMè¡¨ç°æœ€ä½³ã€‚å¦‚éœ€æå‡GRUå’ŒTransformeræ€§èƒ½ï¼Œå»ºè®®ä½¿ç”¨æ›´å¤§è§„æ¨¡çš„æ•°æ®é›†ã€‚

### å…¶ä»–æµ‹è¯•ç¤ºä¾‹

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python examples/test_basic_functions.py

# å®Œæ•´å·¥ä½œæµæµ‹è¯•
python examples/complete_workflow.py

# çœŸå®æ•°æ®åˆ†ææµ‹è¯•
python examples/analyze_real_data.py
```

### æµ‹è¯•ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0+
- pandas, numpy, scikit-learn
- matplotlib (å¯è§†åŒ–)

### æ•…éšœæ’é™¤

å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š
1. ä¾èµ–åŒ…æ˜¯å¦å®Œæ•´å®‰è£…
2. æ•°æ®æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
3. GPUå¯ç”¨æ€§ï¼ˆå¦‚ä½¿ç”¨CUDAï¼‰
4. å†…å­˜æ˜¯å¦å……è¶³

---

## ğŸ“Š åŠŸèƒ½éªŒè¯

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æ¨¡å‹ | è®­ç»ƒè½®æ¬¡ | éªŒè¯æŸå¤± | æµ‹è¯•ç›¸å…³æ€§ | æ¨è |
|------|---------|----------|-----------|------|
| **LSTM** | 20è½®æ—©åœ | 1049.49 | **0.8655** | â­â­â­ |
| GRU | 20è½®æ—©åœ | 1048.97 | -0.3271 | âš ï¸ éœ€æ›´å¤šæ•°æ® |
| Transformer | 20è½®æ—©åœ | 1045.70 | -0.5907 | âš ï¸ éœ€æ›´å¤šæ•°æ® |

**ç»“è®º**ï¼šLSTMåœ¨å°æ ·æœ¬ä¸‹è¡¨ç°æœ€ä½³ã€‚

---

## ğŸ“ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šAlphaå› å­æŒ–æ˜

```python
# ç”ŸæˆAlpha158å› å­
generator = Alpha158Generator(data)
factors = generator.generate_all()

# è¯„ä¼°æ¯ä¸ªå› å­
for factor_name in factors.columns:
    evaluator = FactorEvaluator(factors[factor_name], returns)
    ic_metrics = evaluator.calculate_ic()
    print(f"{factor_name}: IC={ic_metrics['ic_mean']:.4f}")

# é€‰æ‹©é«˜ICå› å­æ„å»ºç»„åˆ
```

### åœºæ™¯2ï¼šæœºå™¨å­¦ä¹ é€‰è‚¡

```python
# ä½¿ç”¨Alpha158å› å­è®­ç»ƒæ¨¡å‹
X, y = factors, returns
model = LSTMModel(d_feat=X.shape[1])
model.fit(X_train, y_train, X_valid, y_valid)

# é¢„æµ‹æœªæ¥æ”¶ç›Š
predictions = model.predict(X_test)

# æ„å»ºæŠ•èµ„ç»„åˆ
top_stocks = predictions.nlargest(10)
```

### åœºæ™¯3ï¼šç­–ç•¥å›æµ‹

```python
# åŸºäºé¢„æµ‹ç»“æœè¿›è¡Œå›æµ‹
engine = BacktestEngine(
    data=test_data,
    predictions=predictions,
    top_k=20,
    commission=0.001
)

results = engine.run()
print(f"å¹´åŒ–æ”¶ç›Š: {results['annual_return']:.2%}")
print(f"æœ€å¤§å›æ’¤: {results['max_drawdown']:.2%}")
```

---

## ğŸ”§ é…ç½®å‚æ•°

### Alpha158ç”Ÿæˆé…ç½®

```python
config = {
    'kbar': True,                    # Kçº¿å½¢æ€å› å­
    'price': True,                   # ä»·æ ¼å› å­
    'volume': True,                  # æˆäº¤é‡å› å­
    'rolling': True,                 # æ»šåŠ¨ç»Ÿè®¡å› å­
    'rolling_windows': [5, 10, 20, 30, 60]  # çª—å£å¤§å°
}
```

### æ·±åº¦å­¦ä¹ æ¨¡å‹é…ç½®

#### LSTMé…ç½®
```python
lstm_config = {
    'd_feat': 158,          # è¾“å…¥ç‰¹å¾ç»´åº¦
    'hidden_size': 64,      # éšè—å±‚å¤§å°
    'num_layers': 2,        # LSTMå±‚æ•°
    'dropout': 0.1,         # Dropoutç‡
    'n_epochs': 100,        # è®­ç»ƒè½®æ•°
    'lr': 0.001,            # å­¦ä¹ ç‡
    'batch_size': 800,      # æ‰¹æ¬¡å¤§å°
    'early_stop': 20,       # æ—©åœè½®æ•°
    'device': 'cuda'        # ä½¿ç”¨GPU
}
```

#### Transformeré…ç½®
```python
transformer_config = {
    'd_feat': 158,          # è¾“å…¥ç‰¹å¾ç»´åº¦
    'd_model': 64,          # Transformerç»´åº¦
    'nhead': 4,             # æ³¨æ„åŠ›å¤´æ•°
    'num_layers': 2,        # Transformerå±‚æ•°
    'dropout': 0.1,
    'n_epochs': 100,
    'lr': 0.001,
    'batch_size': 800,
    'early_stop': 20
}
```

---

## ğŸ“š æ–‡æ¡£

### æ ¸å¿ƒæ–‡æ¡£
- [åŠŸèƒ½æ‰©å±•è¯´æ˜.md](åŠŸèƒ½æ‰©å±•è¯´æ˜.md) - v2.0æ–°åŠŸèƒ½è¯¦ç»†è¯´æ˜
- [MCP_ä½¿ç”¨è¯´æ˜.md](MCP_ä½¿ç”¨è¯´æ˜.md) - MCPæœåŠ¡ä½¿ç”¨æŒ‡å—
- [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) - é¡¹ç›®æ€»ç»“

### ç¤ºä¾‹ä»£ç 
- `examples/test_basic_functions.py` - åŸºç¡€åŠŸèƒ½æµ‹è¯•
- `examples/complete_workflow.py` - å®Œæ•´å·¥ä½œæµ
- `examples/analyze_real_data.py` - çœŸå®æ•°æ®åˆ†æ
- `examples/test_alpha158_and_dl.py` - Alpha158å’Œæ·±åº¦å­¦ä¹ æµ‹è¯•

---

## ğŸ¯ æ ¸å¿ƒæ¨¡å—

### æ•°æ®æ¨¡å— (`quantanalyzer.data`)
- `DataLoader` - CSVæ•°æ®åŠ è½½
- `DataProcessor` - æ•°æ®é¢„å¤„ç†ï¼ˆå¡«å……ã€æ ‡å‡†åŒ–ã€å¼‚å¸¸å€¼ï¼‰

### å› å­æ¨¡å— (`quantanalyzer.factor`)
- `FactorLibrary` - 6ä¸ªåŸºç¡€å› å­
- `Alpha158Generator` - 158ä¸ªAlphaå› å­ â­ v2.0
- `FactorEvaluator` - IC/ICIRè¯„ä¼°

### æ¨¡å‹æ¨¡å— (`quantanalyzer.model`)
- `ModelTrainer` - ä¼ ç»ŸMLæ¨¡å‹ï¼ˆLightGBM/XGBoost/Linearï¼‰
- `LSTMModel` - LSTMæ·±åº¦å­¦ä¹  â­ v2.0
- `GRUModel` - GRUæ·±åº¦å­¦ä¹  â­ v2.0
- `TransformerModel` - Transformer â­ v2.0

### å›æµ‹æ¨¡å— (`quantanalyzer.backtest`)
- `BacktestEngine` - TopKç­–ç•¥å›æµ‹

---

## ğŸ”¬ æŠ€æœ¯è§„æ ¼

### æ”¯æŒçš„å› å­ç±»å‹

| ç±»åˆ« | æ•°é‡ | ç¤ºä¾‹ |
|------|------|------|
| Kçº¿å½¢æ€ | 9 | KMID, KLEN, KUP, KLOW |
| ä»·æ ¼ | 5 | OPEN0, HIGH0, LOW0, CLOSE0 |
| æˆäº¤é‡ | 5 | VOLUME0-4 |
| è¶‹åŠ¿ | 30+ | ROC, MA, BETA, RSQR |
| æ³¢åŠ¨ | 10+ | STD, RESI |
| æå€¼ | 20+ | MAX, MIN, QTLU, QTLD |
| ä½ç½® | 15+ | RANK, RSV, IMAX, IMIN |
| ç›¸å…³ | 10+ | CORR, CORD |
| ç»Ÿè®¡ | 40+ | CNTP, SUMP, VMA, WVMA |

### æ¨¡å‹æ¶æ„å¯¹æ¯”

| ç‰¹æ€§ | LSTM | GRU | Transformer |
|------|------|-----|-------------|
| å‚æ•°é‡ | ä¸­ | å° | å¤§ |
| è®­ç»ƒé€Ÿåº¦ | æ…¢ | å¿« | ä¸­ |
| é•¿æœŸè®°å¿† | å¼º | ä¸­ | å¼º |
| å¹¶è¡ŒåŒ– | å¦ | å¦ | æ˜¯ |
| å°æ ·æœ¬ | â­â­â­ | â­â­ | â­ |
| å¤§æ ·æœ¬ | â­â­ | â­â­ | â­â­â­ |

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### GPUåŠ é€Ÿ

```python
# å¯ç”¨GPUè®­ç»ƒ
model = LSTMModel(
    d_feat=158,
    device='cuda'  # ä½¿ç”¨GPU
)

# æˆ–è‡ªåŠ¨æ£€æµ‹
import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = LSTMModel(d_feat=158, device=device)
```

### æ‰¹å¤„ç†ä¼˜åŒ–

```python
# å¤§æ•°æ®é›†å»ºè®®å¢åŠ æ‰¹æ¬¡å¤§å°
model = LSTMModel(
    d_feat=158,
    batch_size=2000,  # å¢å¤§æ‰¹æ¬¡
    n_epochs=50       # å‡å°‘è½®æ•°
)
```

---

## ğŸ“ˆ å®é™…åº”ç”¨

### åº”ç”¨æ¡ˆä¾‹1ï¼šé€‰è‚¡ç­–ç•¥

```python
# 1. ç”ŸæˆAlpha158å› å­
factors = Alpha158Generator(data).generate_all()

# 2. è®­ç»ƒLSTMé€‰è‚¡æ¨¡å‹
model = LSTMModel(d_feat=158, n_epochs=100)
model.fit(X_train, y_train, X_valid, y_valid)

# 3. é¢„æµ‹æœªæ¥æ”¶ç›Š
predictions = model.predict(X_test)

# 4. TopKå›æµ‹
from quantanalyzer.backtest import BacktestEngine
engine = BacktestEngine(data, predictions, top_k=20)
result = engine.run()
```

### åº”ç”¨æ¡ˆä¾‹2ï¼šå› å­æŒ–æ˜

```python
# ç”Ÿæˆæ‰€æœ‰å› å­
alpha158 = Alpha158Generator(data).generate_all()

# è¯„ä¼°æ¯ä¸ªå› å­
results = []
for col in alpha158.columns:
    evaluator = FactorEvaluator(alpha158[col], returns)
    ic = evaluator.calculate_ic()
    results.append({
        'factor': col,
        'ic_mean': ic['ic_mean'],
        'icir': ic['icir']
    })

# é€‰æ‹©Topå› å­
top_factors = sorted(results, key=lambda x: abs(x['icir']), reverse=True)[:20]
```



---

## ğŸ§ª æµ‹è¯•

é¡¹ç›®åŒ…å«å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿å„æ¨¡å—åŠŸèƒ½æ­£å¸¸ã€‚

### è¿è¡Œæµ‹è¯•

```bash
# ä½¿ç”¨Python unittestè¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m unittest discover tests

# æˆ–è€…è¿è¡Œç‰¹å®šæ¨¡å—çš„æµ‹è¯•
python -m unittest tests.test_data
python -m unittest tests.test_factor
python -m unittest tests.test_model
```

### æµ‹è¯•è¦†ç›–ç‡

```bash
# ä½¿ç”¨coverage.pyè¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pip install coverage
coverage run -m unittest discover tests
coverage report
coverage html  # ç”ŸæˆHTMLæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ã€‚

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

---

## ğŸ™ é¸£è°¢

- [Qlib](https://github.com/microsoft/qlib) - å‚è€ƒæ¶æ„
- [MCP](https://github.com/microsoft/mcp) - å·¥å…·åè®®
- [PyTorch](https://pytorch.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶
```

```

```

```
