"""
æ•°æ®æ ¼å¼è½¬æ¢å™¨
ç”¨äºå°†ä¸åŒæ¥æºçš„è‚¡ç¥¨æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼

åŠŸèƒ½ç‰¹æ€§ï¼š
1. æ™ºèƒ½åˆ—åè¯†åˆ« - è‡ªåŠ¨è¯†åˆ«å¤šç§åˆ—åå˜ä½“ï¼ˆä¸­è‹±æ–‡ã€å¤§å°å†™ç­‰ï¼‰
2. è‡ªåŠ¨åˆ é™¤ç©ºåˆ— - è½¬æ¢è¿‡ç¨‹ä¸­è‡ªåŠ¨ç§»é™¤å®Œå…¨ä¸ºç©ºçš„åˆ—ï¼ˆå¦‚ç©ºçš„æŒä»“é‡åˆ—ï¼‰
3. å¤šç¼–ç æ”¯æŒ - è‡ªåŠ¨å°è¯• UTF-8ã€GBKã€GB18030 ç­‰ç¼–ç 
4. çµæ´»çš„æ—¥æœŸæ ¼å¼ - æ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼è‡ªåŠ¨è½¬æ¢
"""

import pandas as pd
import numpy as np
from typing import Union, Dict, Optional, Tuple
from pathlib import Path


class DataFormatConverter:
    """æ•°æ®æ ¼å¼è½¬æ¢å™¨"""

    # æ”¯æŒçš„æ•°æ®æºæ ¼å¼æ˜ å°„
    SOURCE_FORMATS = {
        'aigroup_market': {
            'date_column': 'äº¤æ˜“æ—¥æœŸ',
            'open_column': 'å¼€ç›˜',
            'close_column': 'æ”¶ç›˜',
            'high_column': 'æœ€é«˜',
            'low_column': 'æœ€ä½',
            'volume_column': 'æˆäº¤é‡',
            'amount_column': 'æˆäº¤é¢',  # å…¼å®¹'æˆäº¤é¢'å’Œ'æˆäº¤é¢(ä¸‡å…ƒ)'
            'symbol_column': 'è‚¡ç¥¨ä»£ç ',
            'date_format': '%Y%m%d',
            'amount_unit': 'ä¸‡å…ƒ'
        },
        'standard': {
            'date_column': 'datetime',
            'open_column': 'open',
            'close_column': 'close',
            'high_column': 'high',
            'low_column': 'low',
            'volume_column': 'volume',
            'amount_column': 'amount',
            'symbol_column': 'symbol',
            'date_format': '%Y-%m-%d',
            'amount_unit': 'å…ƒ'
        }
    }
    
    # åˆ—åæ˜ å°„è¡¨ - æ”¯æŒå¤šç§å˜ä½“çš„åˆ—åè‡ªåŠ¨è¯†åˆ«
    COLUMN_NAME_VARIANTS = {
        'datetime': ['äº¤æ˜“æ—¥æœŸ', 'æ—¥æœŸ', 'date', 'datetime', 'time', 'æ—¶é—´', 'trade_date', 'trading_date'],
        'symbol': ['è‚¡ç¥¨ä»£ç ', 'ä»£ç ', 'symbol', 'code', 'stock_code', 'ts_code', 'åˆçº¦ä»£ç ', 'contract_code', 'instrument'],
        'open': ['å¼€ç›˜', 'å¼€ç›˜ä»·', 'open', 'Open', 'OPEN', 'open_price', 'å¼€'],
        'high': ['æœ€é«˜', 'æœ€é«˜ä»·', 'high', 'High', 'HIGH', 'high_price', 'é«˜'],
        'low': ['æœ€ä½', 'æœ€ä½ä»·', 'low', 'Low', 'LOW', 'low_price', 'ä½'],
        'close': ['æ”¶ç›˜', 'æ”¶ç›˜ä»·', 'close', 'Close', 'CLOSE', 'close_price', 'æ”¶'],
        'volume': ['æˆäº¤é‡', 'é‡', 'volume', 'Volume', 'VOLUME', 'vol', 'Vol', 'VOL', 'trade_volume'],
        'amount': ['æˆäº¤é¢', 'æˆäº¤é¢(ä¸‡å…ƒ)', 'é¢', 'amount', 'Amount', 'AMOUNT', 'turnover', 'trade_amount']
    }

    def __init__(self):
        self.detected_format = None
        self._build_reverse_mapping()
    
    def _build_reverse_mapping(self):
        """æ„å»ºåå‘æ˜ å°„è¡¨ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾æ ‡å‡†åˆ—å"""
        self.reverse_mapping = {}
        for standard_name, variants in self.COLUMN_NAME_VARIANTS.items():
            for variant in variants:
                # å­˜å‚¨åŸå§‹åç§°
                self.reverse_mapping[variant] = standard_name
                # å­˜å‚¨å»é™¤ç©ºæ ¼åçš„åç§°
                self.reverse_mapping[variant.strip()] = standard_name
                # å­˜å‚¨å°å†™ç‰ˆæœ¬
                self.reverse_mapping[variant.lower().strip()] = standard_name

    def _normalize_column_name(self, col_name: str) -> str:
        """
        æ ‡å‡†åŒ–åˆ—åï¼Œå»é™¤ç©ºæ ¼å¹¶è½¬å°å†™
        
        Args:
            col_name: åŸå§‹åˆ—å
            
        Returns:
            æ ‡å‡†åŒ–åçš„åˆ—å
        """
        return col_name.strip().lower() if isinstance(col_name, str) else str(col_name)
    
    def _find_standard_column(self, columns: list, standard_name: str) -> Optional[str]:
        """
        ä»åˆ—ååˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”æ ‡å‡†åç§°çš„åˆ—
        
        Args:
            columns: åˆ—ååˆ—è¡¨
            standard_name: æ ‡å‡†åˆ—åï¼ˆå¦‚'open', 'close'ç­‰ï¼‰
            
        Returns:
            æ‰¾åˆ°çš„åŸå§‹åˆ—åï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        variants = self.COLUMN_NAME_VARIANTS.get(standard_name, [])
        
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        for col in columns:
            if col in variants:
                return col
        
        # ç„¶åå°è¯•å»ç©ºæ ¼åŒ¹é…
        for col in columns:
            col_stripped = col.strip()
            if col_stripped in variants:
                return col
        
        # æœ€åå°è¯•ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
        for col in columns:
            col_normalized = self._normalize_column_name(col)
            if col_normalized in [self._normalize_column_name(v) for v in variants]:
                return col
        
        return None
    
    def detect_data_format(self, df: pd.DataFrame) -> str:
        """
        è‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¼å¼ï¼ˆæ”¯æŒæ™ºèƒ½åˆ—åè¯†åˆ«ï¼‰

        Args:
            df: è¾“å…¥çš„DataFrame

        Returns:
            æ£€æµ‹åˆ°çš„æ ¼å¼åç§°
        """
        columns = df.columns.tolist()
        
        # å°è¯•æ™ºèƒ½è¯†åˆ«å¿…éœ€çš„åˆ—
        required_columns = ['datetime', 'open', 'high', 'low', 'close', 'volume']
        found_columns = {}
        
        for required_col in required_columns:
            found_col = self._find_standard_column(columns, required_col)
            if found_col:
                found_columns[required_col] = found_col
        
        # å¦‚æœæ‰¾åˆ°äº†æ‰€æœ‰å¿…éœ€åˆ—ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºæ ‡å‡†æ ¼å¼æˆ–éœ€è¦è½¬æ¢çš„æ ¼å¼
        if len(found_columns) == len(required_columns):
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ ‡å‡†æ ¼å¼
            standard_columns = ['datetime', 'symbol', 'open', 'high', 'low', 'close', 'volume']
            if all(col in columns for col in standard_columns):
                return 'standard'
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡åˆ—åï¼ˆè¯´æ˜æ˜¯aigroup_marketæ ¼å¼æˆ–ç±»ä¼¼æ ¼å¼ï¼‰
            has_chinese = any(
                any('\u4e00' <= char <= '\u9fff' for char in str(col))
                for col in found_columns.values()
            )
            
            if has_chinese:
                return 'aigroup_market'
            else:
                # è‹±æ–‡åˆ—åä½†ä¸æ˜¯æ ‡å‡†æ ¼å¼ï¼Œä¹Ÿå½’ç±»ä¸ºéœ€è¦è½¬æ¢çš„æ ¼å¼
                return 'aigroup_market'  # ä½¿ç”¨ç›¸åŒçš„è½¬æ¢é€»è¾‘
        
        # æ— æ³•è¯†åˆ«çš„æ ¼å¼
        return 'unknown'

    def convert_to_standard_format(
        self,
        df: Union[pd.DataFrame, str, Path],
        source_format: Optional[str] = None,
        target_symbol: Optional[str] = None,
        **kwargs
    ) -> pd.DataFrame:
        """
        è½¬æ¢æ•°æ®åˆ°æ ‡å‡†æ ¼å¼

        Args:
            df: è¾“å…¥æ•°æ®ï¼ˆDataFrameæˆ–æ–‡ä»¶è·¯å¾„ï¼‰
            source_format: æºæ•°æ®æ ¼å¼ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹
            target_symbol: ç›®æ ‡è‚¡ç¥¨ä»£ç ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä»æ•°æ®ä¸­è·å–
            **kwargs: å…¶ä»–è½¬æ¢å‚æ•°

        Returns:
            è½¬æ¢åçš„DataFrameï¼ˆæ ‡å‡†æ ¼å¼ï¼‰
        """
        # åŠ è½½æ•°æ®ï¼Œå°è¯•å¤šç§ç¼–ç 
        if isinstance(df, (str, Path)):
            try:
                df = pd.read_csv(df, **kwargs)
            except UnicodeDecodeError:
                # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•GBKç¼–ç ï¼ˆå¸¸ç”¨äºä¸­æ–‡æ–‡ä»¶ï¼‰
                try:
                    df = pd.read_csv(df, encoding='gbk', **kwargs)
                except UnicodeDecodeError:
                    # å¦‚æœGBKä¹Ÿå¤±è´¥ï¼Œå°è¯•gb18030ç¼–ç 
                    df = pd.read_csv(df, encoding='gb18030', **kwargs)

        df = df.copy()

        # æ£€æµ‹æ•°æ®æ ¼å¼
        if source_format is None:
            source_format = self.detect_data_format(df)

        if source_format == 'unknown':
            raise ValueError("æ— æ³•è¯†åˆ«çš„æ•°æ®æ ¼å¼ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šsource_formatå‚æ•°")

        # è·å–æ ¼å¼é…ç½®
        format_config = self.SOURCE_FORMATS.get(source_format)
        if not format_config:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {source_format}")

        # æ‰§è¡Œè½¬æ¢
        converted_df = self._convert_format(df, format_config, target_symbol)

        return converted_df

    def _convert_format(
        self,
        df: pd.DataFrame,
        format_config: Dict,
        target_symbol: Optional[str] = None
    ) -> pd.DataFrame:
        """
        æ‰§è¡Œæ ¼å¼è½¬æ¢ï¼ˆä½¿ç”¨æ™ºèƒ½åˆ—åè¯†åˆ«ï¼‰

        Args:
            df: åŸå§‹æ•°æ®
            format_config: æ ¼å¼é…ç½®
            target_symbol: ç›®æ ‡è‚¡ç¥¨ä»£ç 

        Returns:
            è½¬æ¢åçš„DataFrame
        """
        df = df.copy()
        
        # ğŸ”¥ æ–°å¢ï¼šè‡ªåŠ¨åˆ é™¤å®Œå…¨ä¸ºç©ºçš„åˆ—
        # æ£€æµ‹æ¯åˆ—çš„ç©ºå€¼æƒ…å†µ
        empty_columns = []
        for col in df.columns:
            # æ£€æŸ¥åˆ—æ˜¯å¦å®Œå…¨ä¸ºç©ºï¼ˆå…¨æ˜¯NaNæˆ–ç©ºå­—ç¬¦ä¸²ï¼‰
            if df[col].isna().all() or (df[col].astype(str).str.strip() == '').all():
                empty_columns.append(col)
        
        # åˆ é™¤ç©ºåˆ—
        if empty_columns:
            df = df.drop(columns=empty_columns)
        
        columns = df.columns.tolist()
        
        # ä½¿ç”¨æ™ºèƒ½åˆ—åè¯†åˆ«æ„å»ºæ˜ å°„
        column_mapping = {}
        
        # å¿…éœ€çš„åˆ—
        required_standards = ['datetime', 'open', 'high', 'low', 'close', 'volume']
        for standard_name in required_standards:
            found_col = self._find_standard_column(columns, standard_name)
            if found_col:
                column_mapping[found_col] = standard_name
            else:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {standard_name} (æœªæ‰¾åˆ°å¯¹åº”çš„åˆ—åå˜ä½“)")
        
        # å¯é€‰çš„è‚¡ç¥¨ä»£ç åˆ—
        symbol_col = self._find_standard_column(columns, 'symbol')
        if symbol_col:
            column_mapping[symbol_col] = 'symbol'
        
        # å¯é€‰çš„æˆäº¤é¢åˆ—
        amount_col = self._find_standard_column(columns, 'amount')
        if amount_col:
            column_mapping[amount_col] = 'amount'
        
        # é‡å‘½ååˆ—
        df = df.rename(columns=column_mapping)
        
        # å¤„ç†è‚¡ç¥¨ä»£ç 
        if target_symbol:
            df['symbol'] = target_symbol
        elif 'symbol' not in df.columns:
            # å¦‚æœæ²¡æœ‰è‚¡ç¥¨ä»£ç åˆ—ï¼Œä½¿ç”¨é»˜è®¤å€¼
            df['symbol'] = 'DEFAULT'
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼ - å°è¯•å¤šç§æ ¼å¼
        try:
            # é¦–å…ˆå°è¯•é…ç½®çš„æ ¼å¼
            df['datetime'] = pd.to_datetime(df['datetime'], format=format_config.get('date_format', '%Y%m%d'))
        except:
            # å¦‚æœå¤±è´¥ï¼Œè®©pandasè‡ªåŠ¨æ¨æ–­
            df['datetime'] = pd.to_datetime(df['datetime'])
        
        # è½¬æ¢æ•°æ®ç±»å‹
        numeric_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # å¤„ç†æˆäº¤é¢åˆ—
        if 'amount' in df.columns:
            df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
            # å¦‚æœæºæ ¼å¼æ˜¯ä¸‡å…ƒï¼Œéœ€è¦è½¬æ¢ä¸ºå…ƒ
            if format_config.get('amount_unit') == 'ä¸‡å…ƒ':
                df['amount'] = df['amount'] * 10000
        # ğŸ”¥ ä¿®æ”¹ï¼šä¸å†åˆ›å»ºå…¨æ˜¯NaNçš„amountåˆ—
        
        # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œåªä¿ç•™å®é™…å­˜åœ¨çš„åˆ—
        final_columns = ['datetime', 'symbol', 'open', 'high', 'low', 'close', 'volume', 'amount']
        existing_columns = [col for col in final_columns if col in df.columns]
        df = df[existing_columns]
        
        # ğŸ”¥ æ–°å¢ï¼šåˆ é™¤è½¬æ¢åä»ç„¶å…¨æ˜¯NaNçš„åˆ—ï¼ˆäºŒæ¬¡æ¸…ç†ï¼‰
        columns_to_drop = []
        for col in df.columns:
            if col not in ['datetime', 'symbol'] and df[col].isna().all():
                columns_to_drop.append(col)
        
        if columns_to_drop:
            df = df.drop(columns=columns_to_drop)
        
        # æ’åº
        df = df.sort_values(['datetime', 'symbol']).reset_index(drop=True)
        
        return df

    def validate_converted_data(self, df: pd.DataFrame) -> Dict:
        """
        éªŒè¯è½¬æ¢åçš„æ•°æ®è´¨é‡

        Args:
            df: è½¬æ¢åçš„DataFrame

        Returns:
            éªŒè¯æŠ¥å‘Š
        """
        report = {
            'shape': df.shape,
            'missing_values': df.isnull().sum().to_dict(),
            'data_types': df.dtypes.to_dict(),
            'date_range': {
                'start': df['datetime'].min() if 'datetime' in df.columns else None,
                'end': df['datetime'].max() if 'datetime' in df.columns else None
            },
            'symbols': df['symbol'].unique().tolist() if 'symbol' in df.columns else [],
            'price_range': {
                'open_min': df['open'].min() if 'open' in df.columns else None,
                'open_max': df['open'].max() if 'open' in df.columns else None,
                'close_min': df['close'].min() if 'close' in df.columns else None,
                'close_max': df['close'].max() if 'close' in df.columns else None,
            }
        }

        return report

    def get_supported_formats(self) -> Dict:
        """
        è·å–æ”¯æŒçš„æ•°æ®æ ¼å¼è¯´æ˜

        Returns:
            æ ¼å¼è¯´æ˜å­—å…¸
        """
        return {
            'aigroup_market': {
                'description': 'aigroup-market-mcpä¸‹è½½çš„CSVæ ¼å¼',
                'columns': self.SOURCE_FORMATS['aigroup_market'],
                'features': ['ä¸­æ–‡åˆ—å', 'ä¸‡å…ƒå•ä½æˆäº¤é¢', 'YYYYMMDDæ—¥æœŸæ ¼å¼']
            },
            'standard': {
                'description': 'aigroup-quant-mcpæ ‡å‡†æ ¼å¼',
                'columns': self.SOURCE_FORMATS['standard'],
                'features': ['è‹±æ–‡åˆ—å', 'å…ƒå•ä½æˆäº¤é¢', 'YYYY-MM-DDæ—¥æœŸæ ¼å¼']
            }
        }