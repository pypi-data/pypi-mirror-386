<!-- saved from url=(0036)https://www.cs.columbia.edu/~zhouyu/ -->
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <link rel="stylesheet" href="./www.cs.columbia.edu_files/css">
    <link rel="stylesheet" type="text/css" data-href="dynamic-stylesheet" href="./www.cs.columbia.edu_files/main.css">
    <style type="text/css">
        <!--
        body {
            font: 100%/1.4 Verdana, Arial, Helvetica, sans-serif;

            /*background: #42413C;*/
            margin: 0;
            padding: 0;
            color: #000;
            /*background-color: #069;*/
        }

        #app {
            height: 100vh;
        }

        #app {

            /* ~~ 元素/标签选择器 ~~ */
            ul,
            ol,
            dl {
                /* 由于浏览器之间的差异，最佳做法是在列表中将填充和边距都设置为零。 */
                padding: 0;
                margin: 0;
            }

            h1,
            h2,
            h3,
            h4,
            h5,
            h6,
            p {
                margin-top: 10px;
                /* 删除上边距可以解决边距会超出其包含的 div 的问题。 */
                padding-right: 50px;
                padding-left: 100px;
                /* 向 div 内的元素侧边添加填充可避免使用任何方框模型数学。 */
            }

            a img {
                /* 此选择器将删除某些浏览器中显示在图像周围的默认蓝色边框 */
                border: none;
            }

            /* ~~ 站点链接的样式必须保持此顺序，包括用于创建悬停效果的选择器组在内。 ~~ */
            a:link {
                color: #42413C;
                text-decoration: underline;
            }

            a:visited {
                color: #6E6C64;
                text-decoration: underline;
            }

            a:hover,
            a:active,
            a:focus {
                /* 此组选择器将为键盘导航者提供与鼠标使用者相同的悬停体验。 */
                text-decoration: none;
            }

            /* ~~ 此固定宽度容器包含所有其它 div ~~ */
            .container {
                width: 1000px;
                background: #FFF;
                margin: 0 auto;
                overflow: hidden;
            }

            /* ~~ 以下是此布局的列。 ~~ */
            .content {
                padding: 0px 0;
                width: 1000px;
                float: middle;
            }

            /* ~~ 此分组的选择器为 .content 区域中的列表提供了空间 ~~ */
            .content ul,
            .content ol {
                padding: 0 15px 15px 40px;
            }

            /* ~~ 导航列表样式 ~~ */
            ul.nav {
                list-style: none;
                border-top: 1px solid #666;
                margin-bottom: 15px;
            }

            ul.nav li {
                border-bottom: 1px solid #666;
            }

            ul.nav a,
            ul.nav a:visited {
                padding: 5px 5px 5px 15px;
                display: block;
                width: 120px;
                text-decoration: none;
                background: #C6D580;
            }

            ul.nav a:hover,
            ul.nav a:active,
            ul.nav a:focus {
                background: #ADB96E;
                color: #FFF;
            }

            /* ~~ 其它浮动/清除类 ~~ */
            .fltrt {
                float: right;
                margin-left: 10px;
            }

            .fltlft {
                float: left;
                margin-right: 0px;
            }

            .clearfloat {
                clear: both;
                height: 0;
                font-size: 1px;
                line-height: 0px;
            }

            .papertitle {
                color: #000080;
            }
        }
        -->

    </style>
    <script charset="utf-8" src="./www.cs.columbia.edu_files/button.856debeac157d9669cf51e73a08fbc93.js"></script>
</head>


<body>

    <div id="app">
        <div class="container">
            <div class="content">
                <table border="0" cellpadding="0" cellspacing="0">
                    <tbody>
                        <tr>
                            <td width="250" align="middle">
                                <p class="style2"><img alt="" height="343.3" src="./www.cs.columbia.edu_files/007.jpg"
                                        width="344.9"></p>
                            </td>
                            <td width="450" height="240" align="left">
                                <h2>Zhou Yu &nbsp; 俞舟</h2>
                                <p>Zhou (pronunced similar to Jo)</p>
                                <p></p>
                                <p>Associate Professor</p>
                                <p>Computer Science Department</p>
                                <p>Columbia University</p>
                                <p>Address:</p>
                                <p>Schapiro CEPSR 723</p>
                                <p>530 West 120th Street, New York, NY 10027</p>
                                <p>Email: <a href="mailto:zy2461@columbia.edu">zy2461@columbia.edu</a></p>
                                <p><a href="https://www.linkedin.com/in/zhou-jo-yu-95327378" target="_blank">
                                        <img src="./www.cs.columbia.edu_files/LinkedIn_logo_initials.png"
                                            alt="LinkedIn Profile" width="40" height="40">
                                    </a></p>
                                <p><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true"
                                        allowfullscreen="true"
                                        class="twitter-follow-button twitter-follow-button-rendered"
                                        title="Twitter Follow Button"
                                        src="./www.cs.columbia.edu_files/follow_button.2f70fb173b9000da126c79afe2098f02.en.html"
                                        style="position: static; visibility: visible; width: 156px; height: 20px;"
                                        data-screen-name="Zhou_Yu_AI"></iframe>
                                    <script async="" src="./www.cs.columbia.edu_files/widgets.js"
                                        charset="utf-8"></script>
                                </p>
                                <p>CV <a
                                        href="https://drive.google.com/file/d/10-nTl4BJzbo9yoyKbT6cR9lih-1P74tE/view?usp=sharing">[pdf]</a>
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>
                <hr>

                <h3>
                    <font color="orange">Welcome </font>
                </h3>

                <p>I am an Associate Professor at the Computer Science Department, Columbia University. I am also a
                    co-founder of <a href="https://www.arklex.ai/">Arklex.ai</a> that centers its efforts on harnessing
                    the power of AI Agents to empower and shape the future landscape of the workspace. Before that I was
                    an Assistant Professor at UC Davis. I received my PhD at Language Technology Institute under School
                    of Computer Science, Carnegie Mellon University 2017, working with <a
                        href="http://www.cs.cmu.edu/~awb/"> Prof. Alan W Black </a> and <a
                        href="http://www.cs.cmu.edu/~air/"> Prof. Alexander I. Rudnicky</a>. 2015 summer and 2016
                    summer, I interned with <a href="http://suendermann.com/su/index.htm/l">Prof. David Suendermann-Oeft
                    </a> at ETS San Francisco Office on cloud based multimodal dialog systems. 2014 Fall, I interned
                    with <a href="http://research.microsoft.com/en-us/um/people/dbohus/">Dan Bohus </a> and <a
                        href="http://research.microsoft.com/en-us/um/people/horvitz/"> Eric Horvitz </a> at Microsoft
                    Research on situated multimodal dialogue systems. I was featured on Forbes 30 under 30 in Science in
                    2018. My team also won the 2018 Amazon Alexa Socialbot Competition. Our work on Persuasive Dialog
                    Systems also won ACL 2019 best paper nomination.</p>
                <p>Prior to CMU, I received a B.S. in Computer Science and a B.A. in Linguistics under English Language
                    Major from Zhejiang University in 2011. I worked with Prof. Xiaofei He and Prof. Deng Cai on Machine
                    Learning and Computer Vision. I also worked with Prof. Yunhua Qu on Machine Translation.</p>
                <hr>
                <h3>
                    <font color="orange">Research Interests</font>
                </h3>
                <!--/*<p>My research aims to leverage automatic obtainable multimodal information with machine learning methods to make conversations more nature and effective. The dynamics of both verbal and nonverbal behaviors of the conversational parties contribute to the process and outcome of the conversation. In order to understand human-human and human-dialog system interactions and improve the underlying model of the system, I design methods to predict conversation partners' attention and engagement in real time using both verbal and nonverbal behaviors, such as gaze and smiles. Then I leverage these signals to change system's conversatioanl strategies on the fly to accomendate users.</p>*/-->
                <p>I design algorithms for real-time <b>intelligent interactive systems </b> that coordinate with user
                    actions that are beyond spoken languages, including non-verbal behaviors to achieve effective and
                    natural communications. In particular, I optimize human-machine communication via studies of
                    <b>multimodal sensing and analysis</b>, <b>speech and natural language processing</b>, <b>machine
                        learning</b> and <b>human-computer interaction</b>. The central focus of my dissertation
                    research is to bring together all the areas above to design, implement and deploy end-to-end
                    real-time interactive intelligent systems that are able to plan globally considering interaction
                    history and current user actions to achieve better user experience and task performance. Meanwhile,
                    I enjoy collaborating with researchers with different backgrounds on interdisciplinary research in
                    all area of science, such as health care, education and robotics.
                </p>

                <hr>
                <h3>
                    <font color="orange"> Talks </font>
                </h3>
                <p>This is the teaching material of my COM 4705 Introduction to Natural Language Processing 2024 Fall <a
                        href="https://docs.google.com/document/d/1hBrfzdk6Xjp_7ct-1M23tkm0IbPi9x_z5RvuHGPaEEM/edit?tab=t.0">Webpage</a>
                </p>
                <p>I generally recruite PhDs and interns every year, so don't send me generic email to ask about it. If
                    you don't have much experience, please follow this <a
                        href="https://www.linkedin.com/posts/zhou-jo-yu-95327378_this-is-the-time-of-year-when-my-inboxes-activity-7273367390971641857-Ex3O?utm_source=share&amp;utm_medium=member_desktop">
                        LinkedIn post</a> to get in contact.</p>
                <p>We just released our Open-Source AI Agent framework with features such as mixed-control, task
                    composition, human-intervention and continual learning, want to know more, please check <a
                        href="https://arklexai.github.io/Agent-First-Organization/">here</a></p>
                <p>Our recent work, <a href="https://agent-e3.github.io/ExACT/">ExACT</a> on AI Agent planning is the
                    top entry on various AI Agent Benchmark. Check it our, open source code coming soon </p>
                <p>Slides from my rescent talk: AI Agents beyond ChatGPT <a
                        href="https://docs.google.com/presentation/d/1mFA4fVSX1viMO0sq-YHeihTQN46PELGok2m-ibzwEiY/edit#slide=id.g2d63de434db_0_0">slides</a>
                </p>
                <p>Our lab received one outstanding paper in ACL 2024 and another in NAACL 2024</p>
                <p>Thanks Columbia University for the Provost's Junior Faculty Award 2023</p>
                <p>Thanks Sony for the 2023 Faculty Award</p>
                <p>Thanks Walmart AI lab for the 2023 Research Award</p>
                <p>Thanks Cisco for the 2022 Faculty Award</p>
                <p>Thanks IBM for the 2021 IBM Faculty Award</p>
                <p>Thanks Adobe for the 2021 Adobe Faculty Award</p>
                <p>Thanks Tencent for the 2021 Tencent Faculty Award</p>
                <p>Please try our dialog data collection and evaluation tool kit LEGOEval <a
                        href="https://t.co/0PH9ZwSIiD?amp=1">code</a> <a
                        href="https://arxiv.org/pdf/2105.01992.pdf">paper</a> <a
                        href="https://t.co/JMI1YCw9Ph?amp=1">demo</a></p>
                <p>I created the first Conversational AI course at Columbia 2021, Here is all the reading materials and
                    corresponding slides.<a
                        href="https://docs.google.com/spreadsheets/d/1nSKcnM5r9x82BdyPgn-obN1sRUlLC7zZ082a0132Igk/edit#gid=1523499517">link</a>
                </p>
                <p> Recent talk at USC ISI, Teaching machines with natural language. <a
                        href="https://www.youtube.com/watch?v=rNyOspG27Xs&amp;t=2230s">video</a> </p>
                <p>New WeCNLP invited talk video on Builidng Dialog Systems with Less Supervsion <a
                        href="https://youtu.be/cenK4hwjSPs">video</a></p>
                <p>
                </p>
                <p>Recent talk: Building Dialog Systems with Less Supervision <a
                        href="https://drive.google.com/file/d/1QPAjOO_Ap8odxnint-YXM2bWQZNsEZcT/view?usp=sharing">slides</a>
                </p>
                <p>
                </p>
                <p>Recent talk: Gunrock, 2018 Amazon Alexa Socialbot Winner <a
                        href="https://drive.google.com/file/d/1TUnU-iVmxS-lr5n6_vpMOgOBB5LrPHdE/view?usp=sharing">slides</a>
                </p>
                <p>Recent talk: Grounding Reinforcement Learning with Real-World Dialog Applications <a
                        href="https://drive.google.com/open?id=1HtCj9K4qatc1yJDOdidZV_UTSDDslcNm">slides</a></p>
                <!--<p> Here is a YouTube video on Multimodal Dialog Systems at AI2 (Thanks AI2 for the recording) <a href="https://www.youtube.com/watch?v=39T9ukI9HnQ">video</a><p>-->
                <p> Here is a Chinese verison of Multimodal Dialog Systems talk that targets to general public. <a
                        href="https://www.youtube.com/watch?v=RrWSetIOR2Q&amp;t=1874s"> video</a></p>
                <h3>
                    <font color="orange">News</font>
                </h3>
                <p> I designed a Conversational AI course in Columbia, here are the reading materials and slides<a
                        href="https://docs.google.com/spreadsheets/d/1nSKcnM5r9x82BdyPgn-obN1sRUlLC7zZ082a0132Igk/edit?fbclid=IwAR1tX8eztqZ4Kn4NNPUvkkGKCurikWtv-wcSnRyDRg4M544dQtSXTTb3vfM#gid=1523499517">[link]</a>
                </p>
                <p><iframe width="560" height="315" src="./www.cs.columbia.edu_files/jIvDJHpi_Lw.html" frameborder="0"
                        allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen=""></iframe></p>

                <p> Our paper Persuasion For Good was nominated for ACL 2019 best paper.</p>
                <p> We won Amazon Alexa Prize with $500,000 <a
                        href="https://developer.amazon.com/alexaprize">webpage</a> Please refer to our system report <a
                        href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Gunrock.pdf">[pdf]</a>
                </p>
                <p> I was featured on Forbes 30 under 30 in Science <a
                        href="https://www.forbes.com/30-under-30/2018/science/zhou-yu/0">webpage</a> If you want to try
                    our chatbot, just say "Alexa Let's chat!" to any Alexa device or download the App Amazon Alexa on
                    your phone.</p>
                <p> If you want to do a PhD with me, please read Mor's advice <a
                        href="https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf">Applying PhD</a>. </p>
                <hr>

                <h3>
                    <font color="orange"> PhD Students </font>
                </h3>
                <p><a href="https://www.linkedin.com/in/mingyang-zhou-9b174650/">Mingyang Zhou</a>, graduated 2022, Now
                    Researcher at Capital One</p>
                <p><a href="https://www.linkedin.com/in/dianbyu/">Dian Yu</a>, graduated 2022, Now Researcher at Google
                    Deepmind</p>
                <p><a href="https://wyshi.github.io/">Weiyan Shi</a>, graduated 2023, Now Faculty at Northeastern </p>
                <p><a href="https://www.linkedin.com/in/sam-davidson-nlp/">Sam Davidson</a>, graduated 2024, Now Applied
                    Scientist at Amazon AWS</p>
                <p><a href-"https:="" www.linkedin.com="" in="" qingyang-wu-2497a0110="" "="">Qingyang Wu</a>, graduated 2024, Now Researcher at Together.ai</p>
<p><a href=" https://www.linkedin.com/in/kun-qian-6b01b113a/">Kun Qian </a>, graduated 2024, Now Scientist at Apple</p>
                <p><a href="https://www.linkedin.com/in/yanda-chen-03455a16a/">Yanda Chen</a>, graduated 2024, Now
                    Researcher at Anthropic </p>
                <p><a href="https://yooli23.github.io/"> Yu Li</a> joined 2020 </p>
                <p><a href="https://max.imillian.com/"> Max Chen</a>, joined 2021, Graduate Fellowship for STEM
                    Diversity </p>
                <p><a href="https://skywang.me/">Sky Wang</a>, joined 2021, NSF Graduate Fellowship </p>
                <p><a href="https://www.matoles.com/">Matthew Toles</a>, joined 2022, NSF Graduate Fellowship </p>
                <p><a href="https://zacharyhorvitz.github.io/">Zachary Horvitz</a>, joined 2023, Amazon Fellowship </p>
                <p><a href="https://siyan-sylvia-li.com/">Siyan(Sylvia) Li</a>, joined 2023 </p>
                <p><a href="https://billyzhang24kobe.github.io/">Xuanming Zhang</a>, joined 2023</p>
                <p><a href="https://jasonyux.com/">Xiao Yu</a>, joined 2023</p>
                <p><a href="https://scholar.google.com/citations?user=S0vGr-gAAAAJ&amp;hl=en">Yunan(Lucy) Lu</a>, joined
                    2024 </p>

                <h3>
                    <font color="orange">Selected Publications </font>
                </h3>
                <p>ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning, Xiao Yu, Baolin
                    Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, Zhou Yu, arxiv 2024 <a
                        href="https://agent-e3.github.io/ExACT/">website</a></p>
                <p>Xiao Yu, Jinzhong Zhang, Zhou Yu ConFit: Improving Resume-Job Matching using Data Augmentation and
                    Contrastive Learning, RecSys 2024</p>
                <p>Xiao Yu, Qingyang Wu, Yu Li, Zhou Yu, LIONs: An Empirically Optimized Approach to Align Language
                    Models, EMNLP 2024</p>
                <p>Xuanming Zhang, Anthony Diaz, Zixun Chen, Qingyang Wu, Kun Qian, Erik Voss, Zhou Yu, DECOR: Improving
                    Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and
                    Rewriting, EMNLP 2024</p>
                <p>Ryan Shea, Aymen Kallala, Xin Lucy Liu, Michael W. Morris, Zhou Yu, ACE: A LLM-based Negotiation
                    Coaching System, EMNLP 2024</p>
                <p>Ryan Shea, Zhou Yu, A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies,
                    EMNLP 2024</p>
                <p>Zachary Horvitz, Ajay Patel, Kanishk Singh, Chris Callison-Burch, Kathleen McKeown, Zhou Yu,
                    TinyStyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings, EMNLP 2024 Findings
                </p>
                <p>Kun Qian, Shunji Wan, Claudia Tang, Youzhi Wang, Xuanming Zhang, Maximillian Chen, Zhou Yu, VarBench:
                    Robust Language Model Benchmarking Through Dynamic Variable Perturbation, EMNLP 2024 Findings</p>
                <p>Siyan Li, Teresa Shao, Zhou Yu, Julia Hirschberg, EDEN: Empathetic Dialogues for English Learning,
                    EMNLP 2024 Findings</p>
                <p>Yu Li, Shang Qu, Jili Shen, Shangchao Min, Zhou Yu, Curriculum-Driven Edubot: A Framework for
                    Developing Language Learning Chatbots Through Synthesizing Conversational Data SIGDIAL 2024</p>
                <p>Yu-Wen Chen, Zhou Yu, Julia Hirschberg, MultiPA: A Multi-task Speech Pronunciation Assessment Model
                    for Open Response Scenarios, INTERSPEECH 2024</p>
                <p>Yanda Chen, Ruiqi Zhong, Narutatsu Ri, Chen Zhao, He He, Jacob Steinhardt, Zhou Yu, Kathleen McKeown,
                    Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations, ICML
                    2024</p>
                <p>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, He He, Parallel Structures in Pre-training Data
                    Yield In-Context Learning, ACL 2024</p>
                <p>Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen
                    McKeown, Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models,
                    ACL 2024, Outstanding paper</p>
                <p>Xuanming Zhang, Zixun Chen, Zhou Yu, ProLex: A Benchmark for Language Proficiency-oriented Lexical
                    Substitution, ACL 2024 Findings</p>
                <p>Myeongseob Ko · Feiyang Kang · Weiyan Shi · Ming Jin · Zhou Yu · Ruoxi Jia, The Mirrored Influence
                    Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes, CVPR 2024</p>
                <p>Xiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, Zhou Yu, Teaching Language Models to Self-Improve
                    through Interactive Demonstrations, NAACL 2024, Outstanding paper </p>
                <p>Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu, Kathleen McKeown, ParaGuide: Guided
                    Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer, AAAI 2024</p>
                <p>Jianguo Zhang, Kun Qian, Zhiwei Liu, Shelby Heinecke, Rui Meng, Ye Liu, Zhou Yu, Silvio Savarese,
                    Caiming Xiong, DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for
                    Conversational AI, arxiv 2023</p>
                <p>Ryan Shea, Zhou Yu, Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning
                    EMNLP 2023</p>
                <p>Xiao Yu, Qingyang Wu, Kun Qian, Zhou Yu, KRLS: Improving End-to-End Response Generation in Task
                    Oriented Dialog with Reinforced Keywords Learning, EMNLP 2023</p>
                <p>Libo Qin, Wenbo Pan, Qiguang Chen, Lizi Liao, Zhou Yu, Yue Zhang, Wanxiang Che, Min Li, End-to-end
                    Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions, EMNLP 2023</p>
                <p>Xiao Yu, Maximillian Chen, Zhou YuPrompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue
                    Policy Planning, EMNLP 2023</p>
                <p>Sky CH-Wang, Arkadiy Saakyan, Oliver Li, Zhou Yu, Smaranda Muresan, Sociocultural Norm Similarities
                    and Differences via Situational Alignment and Explainable Textual Entailment, EMNLP 2023</p>
                <p>Rahul Goel, Waleed Ammar, Aditya Gupta, Siddharth Vashishtha, Motoki Sano, Faiz Surani, Max Chang,
                    HyunJeong Choe, David Greene, Chuan He, Rattima Nitisaroj, Anna Trukhina, Shachi Paul, Pararth Shah,
                    Rushin Shah, Zhou Yu, PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs,
                    EMNLP 2023</p>
                <p>Weiyan Shi, Emily Dinan, Adi Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis,
                    AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies EMNLP 2023 Findings</p>
                <p>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, He He, On the Relation between Sensitivity and
                    Accuracy in In-context Learning, EMNLP 2023 Findings</p>
                <p>Yukun Huang, Yanda Chen, Zhou Yu, Kathleen McKeown, In-context Learning Distillation: Transferring
                    Few-shot Learning Ability of Pre-trained Language Models AACL 2023</p>
                <p>Yohei Hayamizu, Zhou Yu, and Shiqi Zhang, Learning Joint Policies for Human-Robot Dialog and
                    Co-Navigation, IEEE/RSJ International Conference on Intelligent Robots (IROS), 2023 </p>
                <p>Qingyang Wu, Zhou Yu, Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling, arxiv
                    2023, <a href="https://arxiv.org/pdf/2209.07634.pdf">[pdf]</a></p>
                <p>Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, Zhou Yu, Mixture of Soft Prompts for Controllable
                    Data Generation, EMNLP 2023 Findings, <a href="https://arxiv.org/pdf/2303.01580.pdf">[pdf]</a> </p>
                <p>Qingyang Wu, Deema Alnuhait, Derek Chen, Zhou Yu, Using Textual Interface to Align External Knowledge
                    for End-to-End Task-Oriented Dialogue Systems,arxiv 2023, <a
                        href="https://arxiv.org/pdf/2305.13710.pdf">[pdf]</a></p>
                <p>Maximillian Chen, Xiao Yu, Weiyan Shi, Urvi Awasthi, Zhou Yu Controllable Mixed-Initiative Dialogue
                    Generation through Prompting ACL 2023, <a href="https://arxiv.org/abs/2305.04147">[pdf]</a></p>
                <p>Yu Li, Baolin Peng, Pengcheng He, Michel Galley, Zhou Yu, Jianfeng Gao, DIONYSUS: A Pre-trained Model
                    for Low-Resource Dialogue Summarization, ACL 2023, <a
                        href="https://arxiv.org/abs/2212.10018">[pdf]</a></p>
                <p>Kun Qian, Ryan Shea, Yu Li, Luke Kutszik Fryer, Zhou Yu, User Adaptive Language Learning Chatbots
                    with a Curriculum, AIED 2023,<a href="https://arxiv.org/pdf/2304.05489.pdf">[pdf]</a></p>
                <p>Yanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown, He He, On the Relation between Sensitivity and
                    Accuracy in In-context Learning, arxiv 2023 <a href="https://arxiv.org/pdf/2209.07661.pdf">[pdf]</a>
                </p>
                <p>Max Chen, Zhou Yu, Pre-Finetuning for Few-Shot Emotional Speech Recognition, Interspeech 2023 <a
                        href="https://arxiv.org/abs/2302.12921">[odf]</a></p>
                <p>Yukun Huang, Yanda Chen, Zhou Yu, Kathleen McKeown, In-context Learning Distillation: Transferring
                    Few-shot Learning Ability of Pre-trained Language Models arxiv 2023, <a
                        href="https://arxiv.org/pdf/2212.10670.pdf">[pdf]</a></p>
                <p>Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden,
                    Zhou Yu, Weizhu Chen, Jianfeng Gao, Check Your Facts and Try Again: Improving Large Language Models
                    with External Knowledge and Automated Feedback, arXiv 2023 <a
                        href="https://arxiv.org/pdf/2302.12813.pdf">[pdf]</a></p>
                <p>Rahul Goel, Waleed Ammar, Aditya Gupta, Siddharth Vashishtha, Motoki Sano, Faiz Surani, Max Chang,
                    HyunJeong Choe, David Greene, Kyle He, Rattima Nitisaroj, Anna Trukhina, Shachi Paul, Pararth Shah,
                    Rushin Shah, Zhou Yu, PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs,
                    arxiv 2023 <a href="https://arxiv.org/pdf/2303.08954.pdf">[pdf]</a></p>
                <p>Maximillian Chen, Caitlyn K. Chen, Xiao Yu and Zhou Yu, FastKASSIM: A Fast Tree Kernel-Based
                    Syntactic Similarity Metric, EACL 2023 <a href="https://arxiv.org/pdf/2203.08299.pdf">[pdf]</a></p>
                <p>Kushal Chawla, Weiyan Shi, Jingwen Zhang, Gale Lucas, Zhou Yu and Jonathan Gratch, Social Influence
                    Dialogue Systems: A Survey of Datasets and Models For Social Influence Tasks, EACL 2023 <a
                        href="https://arxiv.org/pdf/2210.05664.pdf">[pdf]</a></p>
                <p>Derek Chen, Kun Qian and Zhou Yu, Stabilized In-Context Learning with Pre-trained Language Models for
                    Few Shot Dialogue State Tracking, EACL 2023 Findings <a
                        href="https://arxiv.org/pdf/2302.05932.pdf">[pdf]</a></p>
                <p>Maximillian Chen, Alexandros Papangelis, Chenyang Tao, Seokhwan Kim, Andy Rosenbaum, Yang Liu, Zhou
                    Yu and Dilek Hakkani-Tur, PLACES: Prompting Language Models for Social Conversation Synthesis EACL
                    2023 Findings <a href="https://arxiv.org/pdf/2302.03269.pdf">[pdf]</a></p>
                <p>Yingwen Fu, Wenjie Ou, Zhou Yu, and Yue Lin, MIGA: A Unified Multi-task Generation Framework for
                    Conversational Text-to-SQL, AAAI 2023<a href="https://arxiv.org/pdf/2212.09278.pdf">[pdf]</a> </p>
                <p>Weiyan Shi, Ryan Patrick Shea, Si Chen, Chiyuan Zhang, Ruoxi Jia and Zhou Yu, Just Fine-tune Twice:
                    Selective Differential Privacy for Large Language Models, EMNLP 2022 <a
                        href="https://arxiv.org/pdf/2204.07667.pdf">[pdf]</a></p>

                <p>David Gros, Yu Li and Zhou Yu, Robots-Dont-Cry v1: Understanding Falsely Anthropomorphic Utterances
                    in Dialog Systems, EMNLP 2022<a href="https://arxiv.org/pdf/2210.12429.pdf">[pdf]</a></p>
                <p>Sky CH-Wang, Evan Li, Oliver Li, Smaranda Muresan and Zhou Yu, Affective Idiosyncratic Responses to
                    Music, EMNLP 2022 <a href="https://arxiv.org/pdf/2210.09396.pdf">[pdf]</a></p>
                <p>Mingyang Zhou, Grace Luo, Anna Rohrbach and Zhou Yu, Focus! Relevant and Sufficient Context Selection
                    for News Image Captioning, EMNLP 2022 Findings <a
                        href="https://arxiv.org/pdf/2212.00843.pdf">[pdf]</a> </p>
                <p>Maximillian Chen, Weiyan Shi, Feifan Yan, Ryan Hou, Jingwen Zhang, Saurav Sahay and Zhou Yu,
                    Seamlessly Integrating Factual Information and Social Content with Persuasive Dialogue, AACL 2022 <a
                        href="https://arxiv.org/pdf/2203.07657.pdf"> [pdf]</a></p>
                <p>Qingyang Wu, Zhenzhong Lan, Kun Qian, Jing Gu, Alborz Geramifard, Zhou Yu, Memformer: A
                    Memory-Augmented Transformer for Sequence Modeling, AACL Findings 2022 <a
                        href="https://aclanthology.org/2022.findings-aacl.29.pdf">[pdf]</a></p>
                <p>Libo Qin, Qiguang Chen, Tianbao Xie, Qian Liu, Shijue Huang, Wanxiang Che and Zhou Yu,CGIM: A Cycle
                    Guided Interactive Learning Model for Consistency Identification in Task-oriented Dialogue, Coling
                    2022 <a href="https://aclanthology.org/2022.coling-1.37/">[pdf]</a></p>
                <p>Lu Sun, Yuhan Liu, Grace Joseph, Yu Zhou, Steven P. Dow and Haiyi Zhu, Comparing experts and crowds
                    for AI data work: allocating human intelligence to design a conversational agent, HCOMP 2022 <a
                        href="https://ojs.aaai.org/index.php/HCOMP/article/view/21999">[pdf]</a></p>

                <p>Liang Qiu, Yizhou Zhao, Yuan Liang, Pan Lu, Weiyan Shi, Zhou Yu and Song-Chun Zhu, Towards Socially
                    Intelligent Agents with Mental State Transition and Human Value, SIGDIAL 2022 <a
                        href="https://arxiv.org/pdf/2103.07011.pdf">[pdf]</a></p>
                <p>Qingyang Wu, Song Feng, Derek Chen, Sachindra Joshi, Luis Lastras and Zhou Yu, DG2: Data Augmentation
                    Through Document Grounded Dialogue Generation, SIGDIAL 2022</p>
                <p>Baolin Peng, Michel Galley, Pengcheng He, Chris Brockett, Lars Liden, Elnaz Nouri, Zhou Yu, Bill
                    Dolan, Jianfeng Gao, GODEL: Large-Scale Pre-Training for Goal-Directed Dialog <a
                        href="https://arxiv.org/abs/2206.11309">[pdf]</a> <a
                        href="https://huggingface.co/microsoft/GODEL-v1_1-large-seq2seq?text=Hey+my+name+is+Thomas%21+How+are+you%3F">[code]</a>
                    <a
                        href="https://www.microsoft.com/en-us/research/blog/godel-combining-goal-oriented-dialog-with-real-world-conversations/">[blog]</a>
                </p>
                <p>Weiyan Shi, Aiqi Cui, Evan Li, Ruoxi Jia and Zhou Yu, Selective Differential Privacy for Language
                    Models, NAACL 2022 <a href="https://arxiv.org/abs/2108.12944">[pdf]</a><a
                        href="https://github.com/wyshi/lm_privacy">[code]</a></p>
                <p>Yu Li, Baolin Peng, Yelong Shen, Yi Mao, Lars Liden, Zhou Yu, Jianfeng Gao, Knowledge-Grounded
                    Dialogue Generation with a Unified Knowledge Representation, NAACL 2022<a
                        href="https://arxiv.org/abs/2112.07924">[pdf]</a></p>
                <p>Kun Qian, Ahmad Beirami, Satwik Kottur, Shahin Shayandeh, Paul Crook, Alborz Geramifard, Zhou Yu,
                    Chinnadhurai Sankar, Database Search Results Disambiguation for Task-Oriented Dialog Systems, NAACL
                    2022<a href="https://arxiv.org/pdf/2112.08351.pdf">[pdf]</a></p>
                <p>Xun Yuan, Sam Pham, Sam Davidson, Zhou Yu, ErAConD: Error Annotated Conversational Dialog Dataset for
                    Grammatical Error Correction, NAACL 2022<a href="https://arxiv.org/abs/2112.08466">[pdf]</a></p>
                <p>Mingyang Zhou, Licheng Yu, Amanpreet Singh, Mengjiao Wang, Zhou Yu, Ning Zhang, Unsupervised
                    Vision-and-Language Pre-training via Retrieval-based Multi-Granular Alignment, CVPR 2022 <a
                        href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.pdf">[pdf]</a>
                </p>
                <p>Bowen Yang, Cong Han, Yu Li, Lei Zuo, Zhou Yu, Improving Conversational Recommendation Systems’
                    Quality with Context-Aware Item Meta-Information, NAACL 2022 Findings <a
                        href="https://arxiv.org/abs/2112.08140">[pdf]</a></p>
                <p>Yu Li, Chun-Yen Chen, Dian Yu, Sam Davidson, Ryan Hou, Xun Yuan, Yinghua Tan, Derek Pham, Zhou Yu,
                    Using Chatbots to Teach Languages, Learning at Scale, 2022<a
                        href="https://arxiv.org/pdf/2208.00376.pdf">[pdf]</a></p>
                <p>Ying Xu, Dakuo Wang, Mo Yu, Daniel Ritchie, Bingsheng Yao, Tongshuang Wu, Zheng Zhang, Toby Jia-Jun
                    Li, Nora Bradford, Branda Sun, Tran Bao Hoang, Yisi Sang, Yufang Hou, Xiaojuan Ma, Diyi Yang, Nanyun
                    Peng, Zhou Yu, Mark Warschauer, Fantastic Questions and Where to Find Them: FairytaleQA--An
                    Authentic Dataset for Narrative Comprehension, ACL 2022 <a
                        href="https://arxiv.org/abs/2203.13947">[pdf]</a></p>
                <p>Yingwen_Fu, Wenjie Ou, Zhou Yu, Yue Lin, Effective Unsupervised Constrained Text Generation based on
                    Perturbed Masking, ACL 2022 Findings <a
                        href="https://aclanthology.org/2022.findings-acl.111.pdf">[pdf]</a></p>
                <p>Matthew Marge, Carol Espy-Wilson, Nigel G Ward, Abeer Alwan, Yoav Artzi, Mohit Bansal, Gil
                    Blankenship, Joyce Chai, Hal Daumé III, Debadeepta Dey, Mary Harper, Thomas Howard, Casey
                    Kennington, Ivana Kruijff-Korbayová, Dinesh Manocha, Cynthia Matuszek, Ross Mead, Raymond Mooney,
                    Roger K Moore, Mari Ostendorf, Heather Pon-Barry, Alexander I Rudnicky, Matthias Scheutz, Robert St
                    Amant, Tong Sun, Stefanie Tellex, David Traum and Zhou Yu, Spoken language interaction with robots:
                    Recommendations for future research, Computer Speech and Language, 2022 <a
                        href="http://users.umiacs.umd.edu/~hal/docs/daume22spoken.pdf">[pdf]</a></p>
                <p>Derek Chen and Zhou Yu, GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation,
                    EMNLP 2021 <a href="https://arxiv.org/abs/2109.03079">[pdf]</a><a
                        href="https://github.com/asappresearch/gold">[code]</a></p>
                <p>Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul Crook, Bing Liu, Zhou Yu, Eunjoon
                    Cho, Pascale Fung and Zhiguang Wang, Continual Learning in Task-Oriented Dialogue Systems, EMNLP
                    2021 <a href="https://arxiv.org/abs/2012.15504">[pdf]</a></p>
                <p>
                </p>
                <p>Zhaojiang Lin, Bing Liu, Andrea Madotto, Seungwhan Moon, Zhenpeng Zhou, Paul Crook, Zhiguang Wang,
                    Zhou Yu, Eunjoon Cho, Rajen Subba and Pascale Fung, Zero-Shot Dialogue State Tracking via Cross-Task
                    Transfer, EMNLP 2021 <a href="https://arxiv.org/abs/2109.04655">[pdf]</a></p>
                <p>Weiyan Shi, Yu Li, Saurav Sahay and Zhou Yu, Refine and Imitate: Reducing Repetition and
                    Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration, EMNLP 2021
                    Findings <a href="https://arxiv.org/abs/2012.15375">[pdf]</a></p>
                <p>Dian Yu, Zhou Yu and Kenji Sagae, Attribute Alignment: Controlling Text Generation from Pre-trained
                    Language Models, EMNLP 2021 Findings <a href="https://arxiv.org/abs/2103.11070"> [pdf]</a></p>
                <p>Jun Zhang, Yan Yang, Chencai Chen, liang he and Zhou Yu, KERS: A Knowledge-Enhanced Framework for
                    Recommendation Dialog Systems with Multiple Subgoals, EMNLP 2021 Findings <a
                        href="https://aclanthology.org/2021.findings-emnlp.94/">[pdf]</a></p>
                <p>Kai-Hui Liang, Weiyan Shi, Yoojung Oh, Jingwen Zhang, Zhou Yu, Discovering Chatbot's
                    Self-Disclosure's Impact on User Trust, Affinity, and Recommendation Effectiveness, arXiv <a
                        href="https://arxiv.org/abs/2106.01666">[pdf]</a></p>
                <p>Kai-Hui Liang, Patrick Lange, Yoo Jung Oh, Jingwen Zhang, Yoshimi Fukuoka and Zhou Yu, Evaluation of
                    In-Person Counseling Strategies To Develop Physical Activity Chatbot for Women, SIGDIAL 2021 <a
                        href="https://arxiv.org/abs/2107.10410">[pdf]</a></p>
                <p>Satwik Kottur, Chinnadhurai Sankar, Zhou Yu and Alborz Geramifard, DialogStitch: Synthetic Deeper and
                    Multi-Context Task-Oriented Dialogs, SIGDIAL 2021 <a
                        href="https://aclanthology.org/2021.sigdial-1.3.pdf">[pdf]</a></p>
                <p>Minh Nguyen and Zhou Yu, Improving Named Entity Recognition in Spoken Dialog Systems by Context and
                    Speech Pattern Modeling, SIGDIAL 2021 <a href="https://aclanthology.org/2021.sigdial-1.6/">[pdf]</a>
                </p>
                <p>Lu Pan, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan Liang, and
                    Song-Chun Zhu, IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language
                    Reasoning. NeurIPS 2021, Datasets and Benchmarks Track.<a
                        href="https://openreview.net/pdf?id=uXa9oBDZ9V1">[pdf]</a></p>
                <p>Kun Qian, Ahmad Beirami, Zhouhan Lin, Ankita De, Alborz Geramifard, Zhou Yu and Chinnadhurai Sankar,
                    Annotation Inconsistency and Entity Bias in MultiWOZ, SIGDIAL 2021 <a
                        href="https://arxiv.org/abs/2105.14150">[pdf]</a></p>
                <p>Jing Gu, Qingyang Wu, Chongruo Wu, Weiyan Shi and Zhou Yu, PRAL: A Tailored Pre-Training Model for
                    Task-Oriented Dialog Generation, ACL 2021 <a href="https://arxiv.org/pdf/2004.13835.pdf">[pdf]</a><a
                        href="https://github.com/qywu/PRAL">[code]</a></p>
                <p>Vojtěch Hudeček, Ondřej Dušek and Zhou Yu, Discovering Dialogue Slots with Weak Supervision, ACL 2021
                    <a href="https://aclanthology.org/2021.acl-long.189.pdf">[pdf]</a>
                </p>
                <p>Weixin Liang, Kai-Hui Liang and Zhou Yu, HERALD: An Annotation Efficient Method to Detect User
                    Disengagement in Social Conversations, ACL 2021 <a
                        href="https://arxiv.org/pdf/2106.00162.pdf">[pdf]</a><a
                        href="https://github.com/Weixin-Liang/HERALD/">[code and data]</a><a
                        href="https://drive.google.com/file/d/1xjNUrkmSm-eBEQLBR2UXl2YpXkvz54-2/view?usp=sharing">[video]</a>
                </p>
                <p>David Gros, Yu Li and Zhou Yu, The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting
                    User Questions About Human or Non-Human Identity, ACL 2021 <a
                        href="https://arxiv.org/pdf/2106.02692.pdf">[pdf]</a><a
                        href="https://github.com/DNGros/R-U-A-Robot">[code and data]</a></p>
                <p>Siyang Liu, Chujie Zheng, Orianna Demasi, Sahand Sabour, Yu Li, Zhou Yu, Yong Jiang and Minlie Huang,
                    Towards Emotional Support Dialogue Systems, ACL 2021 <a
                        href="https://arxiv.org/abs/2106.01144">[pdf]</a></p>
                <p>Liang Qiu, Yuan Liang, Yizhou Zhao, Pan Lu, Baolin Peng, Zhou Yu, Ying Nian Wu and Song-Chun Zhu,
                    SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues, ACL 2021 <a
                        href="https://arxiv.org/pdf/2106.01006.pdf">[pdf]</a> <a
                        href="https://github.com/Liang-Qiu/SocAoG-dialogues">[code]</a></p>
                <p>Meng Zhou, Zechen Li, Bowen Tan, Guangtao Zeng, Wenmian Yang, Xuehai He, Zeqian Ju, Subrato
                    Chakravorty, Shu Chen, Xingyi Yang, Yichen Zhang, Qingyang Wu, Zhou Yu, Kun Xu, Eric Xing and
                    Pengtao Xie, On the Generation of Medical Dialogs for COVID-19, ACL 2021 <a
                        href="https://arxiv.org/pdf/2005.05442.pdf">[pdf]</a> <a
                        href="https://github.com/UCSD-AI4H/COVID-Dialogue">[code and data]</a></p>
                <p> Derek Chen, Howard Chen, Yi Yang, Alexander Lin and Zhou Yu, Action-Based Conversations Dataset:A
                    Corpus for Building More In-Depth Task-Oriented Dialogue Systems, NAACL 2021 <a
                        href="https://arxiv.org/pdf/2104.00783.pdf">[pdf]</a> <a
                        href="https://github.com/asappresearch/abcd">[code and data]</a></p>
                <p>Zhaojiang Lin, Bing Liu, Seungwhan Moon, Paul Crook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu, Andrea
                    Madotto, Eunjoon Cho, Rajen Subba, Leveraging Slot Descriptions for Zero-Shot Cross-Domain Dialogue
                    State Tracking, NAACL 2021 <a href="https://arxiv.org/pdf/2105.04222.pdf">[pdf]</a> </p>
                <p>Mingyang Zhou, Luowei Zhou, Yu Cheng, Linjie Li, Zhou Yu, Jingjing Liu, UC2: Universal Cross-lingual
                    Cross-modal Vision-and-Language Pretraining, CVPR 2021 <a
                        href="https://arxiv.org/pdf/2104.00332.pdf">[pdf]</a> <a
                        href="https://drive.google.com/file/d/1tWWA_dXOtywgcKiwn4CTxEwers6NN_hW/view?usp=sharing">[video]</a><a
                        href="https://github.com/zmykevin/UC2">[code and data]</a></p>
                <p>Qingyang Wu, Lei Li and Zhou Yu, TextGAIL: Generative Adversarial Imitation Learning for Text
                    Generation, AAAI 2021 <a href="https://arxiv.org/pdf/2004.13796.pdf">[pdf]</a><a
                        href="https://github.com/qywu/TextGAIL">[code]</a></p>
                <p>Jing Gu, Qingyang Wu and Zhou Yu, Perception Score: A Learned Metric for Open-ended Text Generation
                    Evaluation, AAAI 2021<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17526">[pdf]</a><a
                        href="https://github.com/g-jing/perception-score"></a></p>
                <p>Kun Qian, Wei Wei and Zhou Yu, A Student-Teacher Architecture for Dialog Domain Adaptation under the
                    Meta-Learning Setting. AAAI 2021<a href="https://arxiv.org/pdf/2104.02689.pdf">[pdf]</a><a
                        href="https://github.com/qbetterk/LossAttention">[code]</a></p>
                <p>Jing Gu, Mostafa Mirshekari, Zhou Yu and Aaron Sisto, ChainCQG: Flow-Aware Conversational Question
                    Generation, EACL 2021 <a href="https://arxiv.org/pdf/2102.02864.pdf">[pdf]</a><a
                        href="https://github.com/g-jing/Chain-CQG">[code]</a></p>
                <p>Qingyang Wu, Yichi Zhang, Yu Li and Zhou Yu, Alternating Recurrent Dialog Model with Large-scale
                    Pre-trained Language Models, EACL 2021 <a
                        href="https://www.aclweb.org/anthology/2021.eacl-main.110.pdf">[pdf]</a><a
                        href="https://github.com/qywu/ARDM">[code]</a></p>
                <p>Dian Yu and Zhou Yu, MIDAS: A Dialog Act Annotation Scheme for Open Domain Human Machine Spoken
                    Conversations, EACL 2021 <a href="https://arxiv.org/pdf/1908.10023.pdf">[pdf]</a><a
                        href="https://github.com/DianDYu/MIDAS_dialog_act">[code]</a></p>
                <p>David Gros, Hariharan Sezhiyan, Prem Devanbu, Zhou Yu, Code to Comment "Translation": Data, Metrics,
                    Baselining &amp; Evaluation, ASE 2020 <a
                        href="https://www.cs.ucdavis.edu/~devanbu/code_comm_trans.pdf">[pdf]</a> </p>
                <p>Shirley Anugrah Hayati, Dongyeop Kang, Qingxiaoyang Zhu, Weiyan Shi and Zhou Yu, INSPIRED: Toward
                    Sociable Recommendation Dialog Systems. EMNLP 2020 <a
                        href="https://arxiv.org/abs/2009.14306">[pdf]</a><a
                        href="https://github.com/sweetpeach/Inspired">[code and data]</a></p>
                <p>Liang Qiu, Yizhou Zhao, Weiyan Shi, Yuan Liang, Feng Shi, Tao Yuan, Zhou Yu, Song-Chun Zhu,
                    Structured Attention for Unsupervised Dialogue Structure Induction, EMNLP 2020 <a
                        href="https://arxiv.org/abs/2009.08552">[pdf]</a></p>
                <p>Orianna Demasi, Yu Li, Zhou Yu, A Multi-Persona Chatbot for Hotline Counselor Training, Findings in
                    EMNLP 2020, <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.324.pdf">[pdf]</a></p>
                <p>Weixin Liang, James Zou and Zhou Yu, ALICE: Active Learning with Contrastive Natural Language
                    Explanations, EMNLP 2020 <a href="https://arxiv.org/abs/2009.10259">[pdf]</a></p>
                <p>Weixin Liang, James Zou and Zhou Yu, Beyond User Self-Reported Likert Scale Ratings: A Comparison
                    Model for Automatic Dialog Evaluation, ACL 2020 <a
                        href="https://www.aclweb.org/anthology/2020.acl-main.126.pdf">[pdf]</a></p>
                <p>Silin Gao, Yichi Zhang, Zhijian Ou and Zhou Yu, Paraphrase Augmented Task-Oriented Dialog Generation,
                    ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.60.pdf">[pdf]</a></p>
                <p>Jiaying Hu, Yan Yang, Chencai Chen, Liang He and Zhou Yu, SAS: Dialogue State Tracking via Slot
                    Attention and Slot Information Sharing, ACL 2020 <a
                        href="https://www.aclweb.org/anthology/2020.acl-main.567.pdf">[pdf]</a></p>
                <p>Yiheng Zhou, Yulia Tsvetkov, Alan Black, and Zhou Yu, Augmenting Non-Collaborative Dialog Systems
                    with Explicit Semantic and Strategic Dialog History, ICLR 2020, <a
                        href="https://arxiv.org/abs/1909.13425">[pdf]</a></p>
                <p>Weiyan Shi, Yoo Jung Oh, Xuewei Wang, Saurav Sahay, Jingwen Zhang, and Zhou Yu, Effects of Persuasive
                    Dialogues: Testing Bot Identities and Inquiry Strategies, CHI 2020 <a
                        href="https://arxiv.org/pdf/2001.04564.pdf">[pdf]</a></p>
                <p>Qingyang Wu, Lei Li, Hao Zhou, Ying Zeng and Zhou Yu, Importance-Aware Learning for Neural Headline
                    Editing, AAAI 2020 <a href="https://arxiv.org/pdf/1912.01114.pdf">[pdf]</a></p>
                <p>Yu Li, Kun Qian, Weiyan Shi and Zhou Yu, End-to-End Trainable Non-Collaborative Dialog System, AAAI
                    2020 <a href="https://arxiv.org/pdf/1911.10742.pdf">[pdf]</a></p>
                <p>Xiyuan Zhang, Chenxi Li, Sam Davidson, Dian Yu and Zhou Yu, Filling Conversation Ellipsis for Better
                    Social Dialog Understanding, AAAI 2020 <a href="https://arxiv.org/pdf/1911.10776.pdf">[pdf]</a></p>
                <p>Weixin Liang, Youzhi Tian, Chengcai Chen and Zhou Yu, MOSS: End-to-End Dialog System Framework with
                    Modular Supervision, AAAI 2020 <a href="https://arxiv.org/abs/1909.05528">[pdf]</a></p>
                <p>Yichi Zhang, Zhijian Ou and Zhou Yu, Task-Oriented Dialog Systems that Consider Multiple Appropriate
                    Responses under the Same Context, AAAI 2020 <a href="https://arxiv.org/pdf/1911.10484.pdf">[pdf]</a>
                    <a href="https://gitlab.com/ucdavisnlp/damd-multiwoz">[code]</a>
                </p>
                <p>Dian Yu &amp; Zhou Yu, MIDAS: A Dialog Act Annotation Scheme for Open Domain Human Machine Spoken
                    Conversations, arXiv <a href="https://arxiv.org/abs/1908.10023">[pdf]</a></p>
                <p>Mingyang Zhou, Joshua Arnold, Zhou Yu, Building Task-Oriented Visual Dialog Systems Through
                    Alternative Optimization Between Dialog Policy and Language Generation, EMNLP 2019 <a
                        href="https://arxiv.org/abs/1909.05365">[pdf]</a></p>
                <p>Weiyan Shi, Kun Qian, Xuewei Wang, Zhou Yu, How to Build User Simulators to Train RL-based Dialog
                    Systems, EMNLP 2019 <a href="http://arxiv.org/abs/1909.01388">[pdf]</a></p>
                <p>Sam Davidson, Dian Yu, Zhou Yu, Dependency Parsing for Spoken Dialog Systems, EMNLP 2019 <a
                        href="http://arxiv.org/abs/1909.03317">[pdf]</a></p>
                <p>Dian Yu, et al., Gunrock: A Social Bot for Complex and Engaging Long Conversations, EMNLP 2019 demo
                    <a href="https://arxiv.org/pdf/1910.03042.pdf">[pdf]</a>
                </p>
                <p>Michelle Cohn, Chun-Yen Chen and Zhou Yu, A Large-Scale User Study of an Alexa Prize Chatbot: Effect
                    of TTS Dynamism on Perceived Quality of Social Dialog, SIGDIAL 2019 <a
                        href="https://www.researchgate.net/publication/336241774_A_Large-Scale_User_Study_of_an_Alexa_Prize_Chatbot_Effect_of_TTS_Dynamism_on_Perceived_Quality_of_Social_Dialog">[pdf]</a>
                </p>
                <p>Kun Qian &amp; Zhou Yu, Domain Adaptive Dialog Generation via Meta Learning, ACL 2019 <a
                        href="https://arxiv.org/pdf/1906.03520.pdf">[pdf]</a></p>
                <p>Xuewei Wang, Weiyan Shi, Richard Kim, Yoo Jung Oh, Sijia Yang, Jingwen Zhang, Zhou Yu, Persuasion for
                    Good: Towards a Personalized Persuasive Dialogue System for Social Good, ACL 2019<a
                        href="https://arxiv.org/pdf/1906.06725.pdf">[pdf]</a>, <a
                        href="https://gitlab.com/ucdavisnlp/persuasionforgood">[data and code]</a> ** best paper
                    nomination</p>
                <p>Weiyan Shi, Tiancheng Zhao, Zhou Yu, Unsupervised Dialog Structure Learning, NAACL 2019 <a
                        href="https://ariv.org/pdf/1904.03736.pdf">[pdf]</a></p>
                <p>Chen et al., Gunrock: Building A Human-Like Social Bot By Leveraging Large Scale Real User Data <a
                        href="https://m.media-amazon.com/images/G/01/mobile-apps/dex/alexa/alexaprize/assets/pdf/2018/Gunrock.pdf">[pdf]</a>
                </p>

                <p>Jiaao Chen, Jianshu Chen and Zhou Yu, Incorporating Structured Commonsense Knowledge in Story
                    Completion, AAAI 2019 <a href="http://arxiv.org/abs/1811.00625">[pdf]</a></p>
                <p>Youzhi Tian, Zhiting Hu and Zhou Yu, Structured Content Preservation for Unsupervised Text Style
                    Transfer, arXiv 2018 <a href="https://arxiv.org/abs/1810.06526">[pdf]</a></p>
                <p>Zijie Zhu, Xuewei Wang, Aakaash Kapoor, Tingrui Pan and Zhou Yu, EIS: A Wearable Device for Epidermal
                    American Sign Language Recognition, IMWUT 2018 (Ubicomp 2019)<a
                        href="https://dl.acm.org/citation.cfm?id=3287080">[pdf]</a></p>
                <p>
                </p>
                <p>Mingyang Zhou, Runxiang Cheng, Yong Jae Lee and Zhou Yu, A Visual Attention Grounding Neural Model
                    for Multimodal Machine Translation, EMNLP 2018 <a
                        href="http://aclweb.org/anthology/D18-1400">[pdf]</a><a
                        href="https://github.com/sampalomad/IKEA-Dataset">[data]</a></p>
                <p>Weiming Wen, Songwen Su and Zhou Yu, Cross-Lingual Cross-Platform Rumor Verification Pivoting on
                    Multimedia Content, EMNLP 2018 <a href="http://aclweb.org/anthology/D18-1385">[pdf]</a> <a
                        href="https://github.com/WeimingWen/CCRV">[code&amp;data]</a></p>
                <p>Jiaping Zhang, Tiancheng Zhao and Zhou Yu, Multimodal Hierarchical Reinforcement Learning Policy for
                    Task-Oriented Visual Dialog, SIGDIAL 2018 <a href="https://arxiv.org/abs/1805.03257">[pdf]</a></p>
                <p>Weiyan Shi and Zhou Yu, Sentiment Adaptive End-to-End Dialog Systems, ACL 2018 <a
                        href="https://arxiv.org/abs/1804.10731">[pdf]</a></p>
                <p>Ryant et al., Enhancement and Analysis of Conversational Speech: JSALT 2017, ICAASP 2018 <a
                        href="http://languagelog.ldc.upenn.edu/myl/ICASSP_JSALT_2018.pdf">[pdf]</a></p>
                <p>Zhou Yu, Alan W Black and Alexander I. Rudnicky, Learning Conversational Systems that Interleave Task
                    and Non-Task Content, IJCAI 2017 <a href="https://arxiv.org/abs/1703.00099">[pdf]</a></p>
                <!--p>-Zhou Yu, Xinrui He, Alan W Black and Alexander I. Rudnicky, User Engagement Modeling in Virtual Agents Under Different Cultural Contexts, IVA 2016. </p>-->
                <p>Zhou Yu, Vikram Ramanarayanan, Patrick Lange, and David Suendermann-Oeft. An open-source multimodal
                    dialog system with real-time engagement tracking for job interview trainingapplications.In IWSDS,
                    2017 <a
                        href="https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.iwsds2017/papers/IWSDS2017_paper_30.pdf">[pdf]</a>
                </p>
                <p>Zhou Yu, Ziyu Xu, Alan W Black and Alexander Rudnicky, Strategy and Policy Learning for
                    Non-Task-Oriented Conversational Systems, SIGDIAL 2016. <a
                        href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial_2016.pdf">[pdf]</a></p>
                <p>Zhou Yu, Leah Nicolich-Henkin, Alan W Black and Alexander Rudnicky, A Wizard-of-Oz Study on A
                    Non-Task-Oriented Dialog Systems that Reacts to User Engagement, SIGDIAL 2016. <a
                        href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial_2016_2.pdf">[pdf]</a></p>
                <!--p>Zhou Yu, Ziyu Xu, Alan W Black and Alexander Rudnicky, Chatbot evaluation and database expansion via crowdsourcing, In Proceedings of the RE-WOCHAT workshop of LREC, 2016. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/LREC.pdf">[pdf]</a></p>-->
                <p>Sean Andrist, Dan Bohus, Zhou Yu, Eric Horvitz, Are You Messing with Me?: Querying about the
                    Sincerity of Interactions in the Open World. HRI 2016. <a
                        href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/HRI2015.pdf">[pdf]</a></p>
                <!--<p>Zhou Yu, Vikram Ramanarayanan, Robert Mundkowsky, Patrick Lange, Alan Black, Alexei Ivanov, David Suendermann-Oeft, Multimodal HALEF: An Open-Source Modular Web-Based Multimodal HAL, IWSDS 2016. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/IWSDS_ZHOU.pdf">[pdf]</a><p> 
<p>Alexei Ivanov, Patrick Lange, David Suendermann-Oeft, Vikram Ramanarayanan, Yao Qian, Zhou Yu and Jidong Tao, Speed vs. Accuracy: Designing an Optimal ASR System for Spontaneous Non-Native Speech in a Real-Time Application, IWSDS 2016. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/IWSDS_ALEX.pdf">[pdf]</a></p>    
<p>Zhou Yu, Vikram Ramanarayanan, David Suendermann-Oeft, Xinhao Wang, Klaus Zechner, Lei Chen, Jidong Tao and Yao Qian, Using Bidirectional LSTM Recurrent Neural Networks to Learn High-Level Abstractions of Sequential Features for Automated Scoring of Non-Native Spontaneous Speech, ASRU 2015. <a href = "http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/ASRU.pdf">[pdf]</a></p>-->
                <p>Zhou Yu, Dan Bohus and Eric Horvitz, Incremental Coordination: Attention-Centric Speech Production in
                    a Physically Situated Conversational Agent, SIGDIAL 2015. <a
                        href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/sigdial2015_camera_Zhou_et_al.pdf">[pdf]</a>
                </p>
                <p>
                    <!--<p>Zhou Yu, Alexandros Papangelis, Alexander Rudnicky, TickTock: Engagement Awareness in a non-Goal-Oriented Multimodal Dialogue System, AAAI Spring Symposium on Turn-taking and Coordination in Human-Machine Interaction 2015. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/TickTock.pdf">[pdf]</a><a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/AAAI_slides.pptx">[slides]</a> <p>
<p>Zhou Yu, Stefan Scherer, David Devault, Jonathan Gratch, Giota Stratou, Louis-Philippe Morency and Justine Cassell, Multimodal Prediction of Psychological Disorder: Learning Verbal and Nonverbal Commonality in Adjacency Pairs, SEMDIAL 2013. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/semdial_2013_zhou.pdf">[pdf]</a> <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SEMDIAL_slides.pptx">[slides]</a> <p>
<P>Zhou Yu, David Gerritsen, Amy Ogan, Alan W Black, Justine Cassell, Automatic Prediction of Friendship via Multi-model Dyadic Features, SIGDIAL, 2013. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/Sigdial2013.pdf">[pdf]</a><p>-->
                    <!---<p>- Zhou Yu, Deng Cai, Xiaofei He, Error-correcting Output Hashing in Fast Similar Search, <b>Best paper</b> in The Second International Conference on Internet Multimedia Computing and Service, ICIMCS  Harbin, China,Dec.2010. <a href="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/p7-yu.pdf">[pdf]</a>  </p>-->

                </p>
                <hr>
                <h3>
                    <font color="orange">Demo Videos </font>
                </h3>
                <p><b>
                        <font color="#01A9DB">TickTock: a multimodal chatbot with user engagement coordination </font>
                    </b>
                    <br><em> - below is a demo of using automatically generated conversational strategy to improve user
                        engagement.</em>
                </p>
                <p> <video style="border-color:black;border-style:solid;border-width:thin" width="500" height="400"
                        controls="" poster="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/Engaged.png">
                        <source src="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/Engaged.mp4" type="video/mp4">
                    </video></p>
                <p><b>
                        <font color="#01A9DB">Direction-giving Robot: a direction-giving humanoid robot with user
                            attention coordination </font>
                    </b>
                    <br><em> - below is a demo and some real user cases of people interacting with the robot.</em>
                </p>
                <p> <video style="border-color:black;border-style:solid;border-width:thin" width="640" height="338"
                        controls="" poster="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial2015_full.jpg">
                        <source src="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/SigDial2015_full.mp4"
                            type="video/mp4">
                    </video></p>
                <p><b>
                        <font color="#01A9DB">HALEF: a distributed web-based multimodal dialog system with user
                            engagement coordination</font>
                    </b>
                    <br><em> - below is a demo of a Amazon Turker interacting with our job interview training
                        application via a web browser. It live-streams videos from usrs' local webcam to the server.
                    </em>
                </p>
                <p> <video style="border-color:black;border-style:solid;border-width:thin" width="640" height="480"
                        controls="" poster="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/EngTask.png">
                        <source src="http://www.cs.cmu.edu/afs/cs/user/zhouyu/www/EngTask.mp4" type="video/mp4">
                    </video></p>
                <hr>
            </div>
        </div>
    </div>
    <!--
<div
    id="chat-window"
    botID="NY3C2t6RxmEsMKX3jWCvUmL"
    version="v1alpha1"
    institutionID="richtech"
></div>
-->

    <script defer="">
        const link = document.querySelector('link[data-href="dynamic-stylesheet"]');
        link.href = 'https://d24t34cstvp7ab.cloudfront.net/qa-js-prod/main.css' + '?v=' + Date.now();
        var script = document.createElement('script');
        script.onerror = function () {
            alert('Could not load ' + this.src);
        };
        script.defer = true;
        script.src = 'https://d24t34cstvp7ab.cloudfront.net/qa-js-prod/main.js' + '?v=' + Date.now();
        document.body.appendChild(script);
    </script>
    <script defer="" src="./www.cs.columbia.edu_files/main.js"></script>


    <iframe scrolling="no" frameborder="0" allowtransparency="true"
        src="./www.cs.columbia.edu_files/widget_iframe.2f70fb173b9000da126c79afe2098f02.html"
        title="Twitter settings iframe" style="display: none;"></iframe><iframe id="rufous-sandbox" scrolling="no"
        frameborder="0" allowtransparency="true" allowfullscreen="true"
        style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;"
        title="Twitter analytics iframe" src="./www.cs.columbia.edu_files/saved_resource.html"></iframe>
</body>

</html>