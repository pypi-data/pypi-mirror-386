{"guide": {"name": "queuing", "category": "additional-features", "pretty_category": "Additional Features", "guide_index": 1, "absolute_index": 14, "pretty_name": "Queuing", "content": "# Queuing\n\nEvery Gradio app comes with a built-in queuing system that can scale to thousands of concurrent users. Because many of your event listeners may involve heavy processing, Gradio automatically creates a queue to handle every event listener in the backend. Every event listener in your app automatically has a queue to process incoming events.\n\n## Configuring the Queue\n\nBy default, each event listener has its own queue, which handles one request at a time. This can be configured via two arguments:\n\n- `concurrency_limit`: This sets the maximum number of concurrent executions for an event listener. By default, the limit is 1 unless configured otherwise in `Blocks.queue()`. You can also set it to `None` for no limit (i.e., an unlimited number of concurrent executions). For example:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    prompt = gr.Textbox()\n    image = gr.Image()\n    generate_btn = gr.Button(\"Generate Image\")\n    generate_btn.click(image_gen, prompt, image, concurrency_limit=5)\n```\n\nIn the code above, up to 5 requests can be processed simultaneously for this event listener. Additional requests will be queued until a slot becomes available.\n\nIf you want to manage multiple event listeners using a shared queue, you can use the `concurrency_id` argument:\n\n- `concurrency_id`: This allows event listeners to share a queue by assigning them the same ID. For example, if your setup has only 2 GPUs but multiple functions require GPU access, you can create a shared queue for all those functions. Here's how that might look:\n\n```python\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    prompt = gr.Textbox()\n    image = gr.Image()\n    generate_btn_1 = gr.Button(\"Generate Image via model 1\")\n    generate_btn_2 = gr.Button(\"Generate Image via model 2\")\n    generate_btn_3 = gr.Button(\"Generate Image via model 3\")\n    generate_btn_1.click(image_gen_1, prompt, image, concurrency_limit=2, concurrency_id=\"gpu_queue\")\n    generate_btn_2.click(image_gen_2, prompt, image, concurrency_id=\"gpu_queue\")\n    generate_btn_3.click(image_gen_3, prompt, image, concurrency_id=\"gpu_queue\")\n```\n\nIn this example, all three event listeners share a queue identified by `\"gpu_queue\"`. The queue can handle up to 2 concurrent requests at a time, as defined by the `concurrency_limit`.\n\n### Notes\n\n- To ensure unlimited concurrency for an event listener, set `concurrency_limit=None`.  This is useful if your function is calling e.g. an external API which handles the rate limiting of requests itself.\n- The default concurrency limit for all queues can be set globally using the `default_concurrency_limit` parameter in `Blocks.queue()`. \n\nThese configurations make it easy to manage the queuing behavior of your Gradio app.\n", "tags": [], "spaces": [], "url": "/guides/queuing/", "contributor": null}}