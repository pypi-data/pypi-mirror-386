{"guide": {"name": "create-immersive-demo", "category": "other-tutorials", "pretty_category": "Other Tutorials", "guide_index": null, "absolute_index": 69, "pretty_name": "Create Immersive Demo", "content": "# Create a Real-Time Immersive Audio + Video Demo with FastRTC\n\n\n\nFastRTC is a library that lets you build low-latency real-time apps over WebRTC. In this guide, you\u2019ll implement a fun demo where Gemini is an art critic and will critique your uploaded artwork:\n- Streams your webcam and microphone to a Gemini real-time session\n- Sends periodic video frames (and an optional uploaded image) to the model\n- Streams back the model\u2019s audio responses in real time\n- Creates a polished full-screen Gradio `WebRTC` UI\n\n### What you\u2019ll build\n<video autoplay loop>\n  <source src=\"https://github.com/gradio-app/gradio/blob/main/guides/assets/art-critic.mp4?raw=true\" type=\"video/mp4\" />\n</video>\n\n### Prerequisites\n- Python 3.10+\n- A Gemini API key: `GEMINI_API_KEY`\n\nInstall the dependencies:\n\n```bash\npip install \"fastrtc[vad, tts]\" gradio google-genai python-dotenv websockets pillow\n```\n\n## 1) Encoders for audio and images\nEncoder functions to send audio as base64-encoded data and images as base64-encoded JPEG.\n\n```python\nimport base64\nimport numpy as np\nfrom io import BytesIO\nfrom PIL import Image\n\ndef encode_audio(data: np.ndarray) -> dict:\n    \"\"\"Encode audio data (int16 mono) for Gemini.\"\"\"\n    return {\n        \"mime_type\": \"audio/pcm\",\n        \"data\": base64.b64encode(data.tobytes()).decode(\"UTF-8\"),\n    }\n\ndef encode_image(data: np.ndarray) -> dict:\n    with BytesIO() as output_bytes:\n        pil_image = Image.fromarray(data)\n        pil_image.save(output_bytes, \"JPEG\")\n        bytes_data = output_bytes.getvalue()\n    base64_str = str(base64.b64encode(bytes_data), \"utf-8\")\n    return {\"mime_type\": \"image/jpeg\", \"data\": base64_str}\n```\n\n\n## 2) Implement the Gemini audio-video handler\nThis handler:\n- Opens a Gemini Live session on startup\n- Receives streaming audio from Gemini and yields it back to the client\n- Sends microphone audio as it arrives\n- Sends a video frame at most once per second (to avoid flooding the API)\n- Optionally sends an uploaded image (`gr.Image`) alongside the webcam frame\n\n```python\nimport asyncio\nimport os\nimport time\nimport numpy as np\nimport websockets\nfrom dotenv import load_dotenv\nfrom google import genai\nfrom fastrtc import AsyncAudioVideoStreamHandler, wait_for_item, WebRTCError\n\nload_dotenv()\n\nclass GeminiHandler(AsyncAudioVideoStreamHandler):\n    def __init__(self) -> None:\n        super().__init__(\n            \"mono\",\n            output_sample_rate=24000,\n            input_sample_rate=16000,\n        )\n        self.audio_queue = asyncio.Queue()\n        self.video_queue = asyncio.Queue()\n        self.session = None\n        self.last_frame_time = 0.0\n        self.quit = asyncio.Event()\n\n    def copy(self) -> \"GeminiHandler\":\n        return GeminiHandler()\n\n    async def start_up(self):\n        await self.wait_for_args()\n        api_key = self.latest_args[3]\n        hf_token = self.latest_args[4]\n        if hf_token is None or hf_token == \"\":\n            raise WebRTCError(\"HF Token is required\")\n        os.environ[\"HF_TOKEN\"] = hf_token\n        client = genai.Client(\n            api_key=api_key, http_options={\"api_version\": \"v1alpha\"}\n        )\n        config = {\"response_modalities\": [\"AUDIO\"], \"system_instruction\": \"You are an art critic that will critique the artwork passed in as an image to the user. Critique the artwork in a funny and lighthearted way. Be concise and to the point. Be friendly and engaging. Be helpful and informative. Be funny and lighthearted.\"}\n        async with client.aio.live.connect(\n            model=\"gemini-2.0-flash-exp\",\n            config=config,\n        ) as session:\n            self.session = session\n            while not self.quit.is_set():\n                turn = self.session.receive()\n                try:\n                    async for response in turn:\n                        if data := response.data:\n                            audio = np.frombuffer(data, dtype=np.int16).reshape(1, -1)\n                        self.audio_queue.put_nowait(audio)\n                except websockets.exceptions.ConnectionClosedOK:\n                    print(\"connection closed\")\n                    break\n\n    # Video: receive and (optionally) send frames to Gemini\n    async def video_receive(self, frame: np.ndarray):\n        self.video_queue.put_nowait(frame)\n        if self.session and (time.time() - self.last_frame_time > 1.0):\n            self.last_frame_time = time.time()\n            await self.session.send(input=encode_image(frame))\n            # If there is an uploaded image passed alongside the WebRTC component,\n            # it will be available in latest_args[2]\n            if self.latest_args[2] is not None:\n                await self.session.send(input=encode_image(self.latest_args[2]))\n\n    async def video_emit(self) -> np.ndarray:\n        frame = await wait_for_item(self.video_queue, 0.01)\n        if frame is not None:\n            return frame\n        # Fallback while waiting for first frame\n        return np.zeros((100, 100, 3), dtype=np.uint8)\n\n    # Audio: forward microphone audio to Gemini\n    async def receive(self, frame: tuple[int, np.ndarray]) -> None:\n        _, array = frame\n        array = array.squeeze()  # (num_samples,)\n        audio_message = encode_audio(array)\n        if self.session:\n            await self.session.send(input=audio_message)\n\n    # Audio: emit Gemini\u2019s audio back to the client\n    async def emit(self):\n        array = await wait_for_item(self.audio_queue, 0.01)\n        if array is not None:\n            return (self.output_sample_rate, array)\n        return array\n\n    async def shutdown(self) -> None:\n        if self.session:\n            self.quit.set()\n            await self.session.close()\n            self.quit.clear()\n```\n\n\n## 3) Setup Stream and Gradio UI\nWe\u2019ll add an optional `gr.Image` input alongside the `WebRTC` component. The handler will access this in `self.latest_args[1]` when sending frames to Gemini.\n\n```python\nimport gradio as gr\nfrom fastrtc import Stream, WebRTC, get_hf_turn_credentials\n\n\nstream = Stream(\n    handler=GeminiHandler(),\n    modality=\"audio-video\",\n    mode=\"send-receive\",\n    server_rtc_configuration=get_hf_turn_credentials(ttl=600*10000),\n    rtc_configuration=get_hf_turn_credentials(),\n    additional_inputs=[\n        gr.Markdown(\n            \"## \ud83c\udfa8 Art Critic\\n\\n\"\n            \"Provide an image of your artwork or hold it up to the webcam, and Gemini will critique it for you.\"\n            \"To get a Gemini API key, please visit the [Gemini API Key](https://aistudio.google.com/apikey) page.\"\n            \"To get an HF Token, please visit the [HF Token](https://huggingface.co/settings/tokens) page.\"\n        ),\n        gr.Image(label=\"Artwork\", value=\"mona_lisa.jpg\", type=\"numpy\", sources=[\"upload\", \"clipboard\"]),\n        gr.Textbox(label=\"Gemini API Key\", type=\"password\"),\n        gr.Textbox(label=\"HF Token\", type=\"password\"),\n    ],\n    ui_args={\n        \"icon\": \"https://www.gstatic.com/lamda/images/gemini_favicon_f069958c85030456e93de685481c559f160ea06b.png\",\n        \"pulse_color\": \"rgb(255, 255, 255)\",\n        \"icon_button_color\": \"rgb(255, 255, 255)\",\n        \"title\": \"Gemini Audio Video Chat\",\n    },\n    time_limit=90,\n    concurrency_limit=5,\n)\n\nif __name__ == \"__main__\":\n    stream.ui.launch()\n\n```\n\n### References\n- Gemini Audio Video Chat reference code: [Hugging Face Space](https://huggingface.co/spaces/gradio/gemini-audio-video/blob/main/app.py)\n- FastRTC docs: `https://fastrtc.org`\n- Audio + video user guide: `https://fastrtc.org/userguide/audio-video/`\n- Gradio component integration: `https://fastrtc.org/userguide/gradio/`\n- Cookbook (live demos + code): `https://fastrtc.org/cookbook/`\n", "tags": ["REAL-TIME", "IMMERSIVE", "FASTRTC", "VIDEO", "AUDIO", "STREAMING", "GEMINI", "WEBRTC"], "spaces": [], "url": "/guides/create-immersive-demo/", "contributor": null}}