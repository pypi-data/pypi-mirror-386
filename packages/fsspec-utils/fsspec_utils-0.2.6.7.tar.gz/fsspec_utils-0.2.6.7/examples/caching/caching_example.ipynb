{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Caching with fsspec-utils\n",
    "\n",
    "This example demonstrates how to use the caching functionality in fsspec-utils \n",
    "to improve performance for repeated file operations.\n",
    "\n",
    "The example shows:\n",
    "1. Creating a filesystem with caching enabled\n",
    "2. Performing file operations that populate the cache\n",
    "3. Demonstrating improved performance on subsequent reads\n",
    "4. Showing how cached files can be accessed even when the original source is unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Import fsspec-utils filesystem function\n",
    "from fsspec_utils import filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory and file for our demonstration\n",
    "tmpdir = tempfile.mkdtemp()\n",
    "print(f\"Created temporary directory: {tmpdir}\")\n",
    "\n",
    "# Create a sample JSON file\n",
    "sample_file = os.path.join(tmpdir, \"sample_data.json\")\n",
    "sample_data = {\n",
    "    \"name\": \"fsspec-utils caching example\",\n",
    "    \"timestamp\": time.time(),\n",
    "    \"items\": [{\"id\": i, \"value\": f\"item_{i}\"} for i in range(1000)]  # Larger dataset for better demo\n",
    "}\n",
    "\n",
    "# Write the sample data to our file\n",
    "with open(sample_file, 'w') as f:\n",
    "    json.dump(sample_data, f)\n",
    "\n",
    "print(f\"Created sample file: {sample_file}\")\n",
    "\n",
    "# Create a cache directory\n",
    "cache_dir = os.path.join(tmpdir, \"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Filesystem with Caching Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filesystem with caching enabled\n",
    "print(\"\\n=== Creating filesystem with caching ===\")\n",
    "fs = filesystem(\n",
    "    protocol_or_path=\"file\",\n",
    "    cached=True,\n",
    "    cache_storage=cache_dir,\n",
    "    verbose=True  # Enable verbose logging to see cache operations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Read - Populating the Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read - this should populate the cache\n",
    "print(\"\\n=== First read (populating cache) ===\")\n",
    "start_time = time.time()\n",
    "data1 = fs.read_json(sample_file)\n",
    "first_read_time = time.time() - start_time\n",
    "print(f\"First read completed in {first_read_time:.4f} seconds\")\n",
    "print(f\"Data keys: {list(data1.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Cache Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cache files were created\n",
    "cache_files = []\n",
    "if os.path.exists(cache_dir):\n",
    "    for root, dirs, files in os.walk(cache_dir):\n",
    "        for file in files:\n",
    "            cache_files.append(os.path.join(root, file))\n",
    "print(f\"Cache files created: {len(cache_files)} files\")\n",
    "for file in cache_files[:5]:  # Show first 5 cache files\n",
    "    print(f\"  - {file}\")\n",
    "if len(cache_files) > 5:\n",
    "    print(f\"  ... and {len(cache_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Read - Using the Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second read - this should use the cache\n",
    "print(\"\\n=== Second read (using cache) ===\")\n",
    "start_time = time.time()\n",
    "data2 = fs.read_json(sample_file)\n",
    "second_read_time = time.time() - start_time\n",
    "print(f\"Second read completed in {second_read_time:.4f} seconds\")\n",
    "print(f\"Data keys: {list(data2.keys())}\")\n",
    "\n",
    "# Verify data is the same\n",
    "assert data1 == data2, \"Data from first and second reads should be identical\"\n",
    "print(\"✓ Data from both reads is identical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating Cache Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate cache effectiveness by removing original file\n",
    "print(\"\\n=== Demonstrating cache effectiveness ===\")\n",
    "print(\"Removing original file...\")\n",
    "os.remove(sample_file)\n",
    "print(f\"Original file exists: {os.path.exists(sample_file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Read - From Cache Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third read - this should still work from cache\n",
    "print(\"\\n=== Third read (from cache only) ===\")\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    data3 = fs.read_json(sample_file)\n",
    "    third_read_time = time.time() - start_time\n",
    "    print(f\"Third read completed in {third_read_time:.4f} seconds\")\n",
    "    print(f\"Data keys: {list(data3.keys())}\")\n",
    "    \n",
    "    # Verify data is still the same\n",
    "    assert data1 == data3, \"Data from cache should be identical to original\"\n",
    "    print(\"✓ Successfully read from cache even after original file was removed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading from cache: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "print(\"\\n=== Performance Comparison ===\")\n",
    "print(f\"First read (from disk): {first_read_time:.4f} seconds\")\n",
    "print(f\"Second read (from cache): {second_read_time:.4f} seconds\")\n",
    "print(f\"Third read (from cache): {third_read_time:.4f} seconds\")\n",
    "\n",
    "if second_read_time < first_read_time:\n",
    "    improvement = ((first_read_time - second_read_time) / first_read_time) * 100\n",
    "    print(f\"Cache improvement: {improvement:.1f}% faster\")\n",
    "else:\n",
    "    print(\"Note: Cache read wasn't faster in this small example, but would be with larger files or remote storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary directory\n",
    "import shutil\n",
    "shutil.rmtree(tmpdir)\n",
    "print(f\"\\nCleaned up temporary directory: {tmpdir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}