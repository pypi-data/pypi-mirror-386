{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing with fsspec-utils\n",
    "\n",
    "This example demonstrates how to perform batch processing operations with \n",
    "different file formats using fsspec-utils.\n",
    "\n",
    "The example shows:\n",
    "1. Creating sample data files in different formats (Parquet, CSV, JSON)\n",
    "2. Reading files in batches using the `batch_size` parameter\n",
    "3. Processing batches of data efficiently\n",
    "4. Demonstrating the differences between batch processing for different file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Import fsspec-utils\n",
    "from fsspec_utils import filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(temp_dir):\n",
    "    \"\"\"Create sample Parquet, CSV, and JSON files for demonstration.\"\"\"\n",
    "    print(f\"Creating sample data in {temp_dir}\")\n",
    "    \n",
    "    # Create sample data\n",
    "    sample_data = [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"age\": 30, \"city\": \"London\"},\n",
    "        {\"id\": 3, \"name\": \"Charlie\", \"age\": 35, \"city\": \"Paris\"},\n",
    "        {\"id\": 4, \"name\": \"Diana\", \"age\": 28, \"city\": \"Tokyo\"},\n",
    "        {\"id\": 5, \"name\": \"Eve\", \"age\": 32, \"city\": \"Berlin\"},\n",
    "        {\"id\": 6, \"name\": \"Frank\", \"age\": 27, \"city\": \"Sydney\"},\n",
    "        {\"id\": 7, \"name\": \"Grace\", \"age\": 29, \"city\": \"Toronto\"},\n",
    "        {\"id\": 8, \"name\": \"Henry\", \"age\": 31, \"city\": \"Moscow\"},\n",
    "    ]\n",
    "    \n",
    "    # Create Parquet files\n",
    "    for i in range(3):\n",
    "        file_path = os.path.join(temp_dir, f\"data_{i+1}.parquet\")\n",
    "        df = pl.DataFrame(sample_data[i*2:(i+1)*2])\n",
    "        df.write_parquet(file_path)\n",
    "        print(f\"Created Parquet file: {file_path}\")\n",
    "    \n",
    "    # Create CSV files\n",
    "    for i in range(3):\n",
    "        file_path = os.path.join(temp_dir, f\"data_{i+1}.csv\")\n",
    "        df = pl.DataFrame(sample_data[i*2:(i+1)*2])\n",
    "        df.write_csv(file_path)\n",
    "        print(f\"Created CSV file: {file_path}\")\n",
    "    \n",
    "    # Create JSON files\n",
    "    for i in range(3):\n",
    "        file_path = os.path.join(temp_dir, f\"data_{i+1}.json\")\n",
    "        with open(file_path, 'w') as f:\n",
    "            import json\n",
    "            json.dump(sample_data[i*2:(i+1)*2], f)\n",
    "        print(f\"Created JSON file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_parquet_batch_reading(temp_dir):\n",
    "    \"\"\"Demonstrate batch reading of Parquet files.\"\"\"\n",
    "    print(\"\\n=== Parquet Batch Reading ===\")\n",
    "    \n",
    "    # Get filesystem\n",
    "    fs = filesystem(\"file\")\n",
    "    \n",
    "    # Define the path pattern for Parquet files\n",
    "    parquet_path = os.path.join(temp_dir, \"*.parquet\")\n",
    "    \n",
    "    # Example 1: Read Parquet files in batches\n",
    "    print(\"\\n1. Reading Parquet files in batches (batch_size=2):\")\n",
    "    for i, batch in enumerate(fs.read_parquet(parquet_path, batch_size=2)):\n",
    "        print(f\"   Batch {i+1}:\")\n",
    "        print(f\"   - Type: {type(batch)}\")\n",
    "        print(f\"   - Number of rows: {batch.num_rows}\")\n",
    "        print(f\"   - Columns: {batch.column_names}\")\n",
    "        print(f\"   - Data preview: {batch.to_pandas().head(1).to_dict('records')}\")\n",
    "    \n",
    "    # Example 2: Read Parquet files with include_file_path=True\n",
    "    print(\"\\n2. Reading Parquet files with include_file_path=True:\")\n",
    "    for i, batch in enumerate(fs.read_parquet(parquet_path, batch_size=2, include_file_path=True)):\n",
    "        print(f\"   Batch {i+1}:\")\n",
    "        print(f\"   - Type: {type(batch)}\")\n",
    "        print(f\"   - Number of rows: {batch.num_rows}\")\n",
    "        print(f\"   - Columns: {batch.column_names}\")\n",
    "        if 'file_path' in batch.column_names:\n",
    "            file_paths = batch.column('file_path').to_pylist()\n",
    "            print(f\"   - File paths: {set(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_csv_batch_reading(temp_dir):\n",
    "    \"\"\"Demonstrate batch reading of CSV files.\"\"\"\n",
    "    print(\"\\n=== CSV Batch Reading ===\")\n",
    "    \n",
    "    # Get filesystem\n",
    "    fs = filesystem(\"file\")\n",
    "    \n",
    "    # Define the path pattern for CSV files\n",
    "    csv_path = os.path.join(temp_dir, \"*.csv\")\n",
    "    \n",
    "    # Example 1: Read CSV files in batches\n",
    "    print(\"\\n1. Reading CSV files in batches (batch_size=2):\")\n",
    "    for i, batch in enumerate(fs.read_csv(csv_path, batch_size=2)):\n",
    "        print(f\"   Batch {i+1}:\")\n",
    "        print(f\"   - Type: {type(batch)}\")\n",
    "        print(f\"   - Shape: {batch.shape}\")\n",
    "        print(f\"   - Columns: {batch.columns}\")\n",
    "        print(f\"   - Data preview: {batch.head(1).to_dicts()}\")\n",
    "    \n",
    "    # Example 2: Read CSV files with include_file_path=True\n",
    "    print(\"\\n2. Reading CSV files with include_file_path=True:\")\n",
    "    for i, batch in enumerate(fs.read_csv(csv_path, batch_size=2, include_file_path=True)):\n",
    "        print(f\"   Batch {i+1}:\")\n",
    "        print(f\"   - Type: {type(batch)}\")\n",
    "        print(f\"   - Shape: {batch.shape}\")\n",
    "        print(f\"   - Columns: {batch.columns}\")\n",
    "        if 'file_path' in batch.columns:\n",
    "            file_paths = batch['file_path'].unique().to_list()\n",
    "            print(f\"   - File paths: {file_paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_json_batch_reading(temp_dir):\n",
    "    \"\"\"Demonstrate batch reading of JSON files.\"\"\"\n",
    "    print(\"\\n=== JSON Batch Reading ===\")\n",
    "    \n",
    "    # Get filesystem\n",
    "    fs = filesystem(\"file\")\n",
    "    \n",
    "    # Define the path pattern for JSON files\n",
    "    json_path = os.path.join(temp_dir, \"*.json\")\n",
    "    \n",
    "    # Example 1: Read JSON files in batches\n",
    "    print(\"\\n1. Reading JSON files in batches (batch_size=2):\")\n",
    "    for i, batch in enumerate(fs.read_json(json_path, batch_size=2)):\n",
    "        print(f\"   Batch {i+1}:\")\n",
    "        print(f\"   - Type: {type(batch)}\")\n",
    "        print(f\"   - Shape: {batch.shape}\")\n",
    "        print(f\"   - Columns: {batch.columns}\")\n",
    "        print(f\"   - Data preview: {batch.head(1).to_dicts()}\")\n",
    "    \n",
    "    # Example 2: Read JSON files with include_file_path=True\n",
    "    print(\"\\n2. Reading JSON files with include_file_path=True:\")\n",
    "    for i, batch in enumerate(fs.read_json(json_path, batch_size=2, include_file_path=True)):\n",
    "        print(f\"   Batch {i+1}:\")\n",
    "        print(f\"   - Type: {type(batch)}\")\n",
    "        print(f\"   - Shape: {batch.shape}\")\n",
    "        print(f\"   - Columns: {batch.columns}\")\n",
    "        if 'file_path' in batch.columns:\n",
    "            file_paths = batch['file_path'].unique().to_list()\n",
    "            print(f\"   - File paths: {file_paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Created temporary directory: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "create_sample_data(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate batch reading for each format\n",
    "demonstrate_parquet_batch_reading(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_csv_batch_reading(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_json_batch_reading(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary directory\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"\\nCleaned up temporary directory: {temp_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}