<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>advanced – fsspec-utils</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-bc185b5c5bdbcb35c2eb49d8a876ef70.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b487cddad83ce73ad93f1328ce7d9f7a.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-c35703f27e2ef84e2c700e09dd0c80cb.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-b487cddad83ce73ad93f1328ce7d9f7a.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">fsspec-utils</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./quickstart.html"> 
<span class="menu-text">Quickstart</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./installation.html"> 
<span class="menu-text">Installation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./advanced.html" aria-current="page"> 
<span class="menu-text">Advanced</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./architecture.html"> 
<span class="menu-text">Architecture</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./contributing.html"> 
<span class="menu-text">Contributing</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-api-reference" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">API Reference</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-api-reference">    
        <li class="dropdown-header">Core</li>
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.core.base.html">
 <span class="dropdown-text">fsspec_utils.core.base</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.core.ext.html">
 <span class="dropdown-text">fsspec_utils.core.ext</span></a>
  </li>  
        <li class="dropdown-header">Storage Options</li>
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.storage_options.base.html">
 <span class="dropdown-text">fsspec_utils.storage_options.base</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.storage_options.cloud.html">
 <span class="dropdown-text">fsspec_utils.storage_options.cloud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.storage_options.core.html">
 <span class="dropdown-text">fsspec_utils.storage_options.core</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.storage_options.git.html">
 <span class="dropdown-text">fsspec_utils.storage_options.git</span></a>
  </li>  
        <li class="dropdown-header">Utils</li>
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.datetime.html">
 <span class="dropdown-text">fsspec_utils.utils.datetime</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.logging.html">
 <span class="dropdown-text">fsspec_utils.utils.logging</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.misc.html">
 <span class="dropdown-text">fsspec_utils.utils.misc</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.polars.html">
 <span class="dropdown-text">fsspec_utils.utils.polars</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.pyarrow.html">
 <span class="dropdown-text">fsspec_utils.utils.pyarrow</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.sql.html">
 <span class="dropdown-text">fsspec_utils.utils.sql</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./api/fsspec_utils.utils.types.html">
 <span class="dropdown-text">fsspec_utils.utils.types</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/legout/fsspec-utils"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text">GitHub</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://pypi.org/project/fsspec-utils/"> <i class="bi bi-box-arrow-down" role="img">
</i> 
<span class="menu-text">PyPI</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#advanced-usage" id="toc-advanced-usage" class="nav-link active" data-scroll-target="#advanced-usage">Advanced Usage</a>
  <ul class="collapse">
  <li><a href="#unified-filesystem-creation-with-filesystem" id="toc-unified-filesystem-creation-with-filesystem" class="nav-link" data-scroll-target="#unified-filesystem-creation-with-filesystem">Unified Filesystem Creation with <code>filesystem</code></a>
  <ul class="collapse">
  <li><a href="#detailed-caching-for-improved-performance" id="toc-detailed-caching-for-improved-performance" class="nav-link" data-scroll-target="#detailed-caching-for-improved-performance">Detailed Caching for Improved Performance</a></li>
  </ul></li>
  <li><a href="#custom-filesystem-implementations" id="toc-custom-filesystem-implementations" class="nav-link" data-scroll-target="#custom-filesystem-implementations">Custom Filesystem Implementations</a>
  <ul class="collapse">
  <li><a href="#gitlab-filesystem-gitlabfilesystem" id="toc-gitlab-filesystem-gitlabfilesystem" class="nav-link" data-scroll-target="#gitlab-filesystem-gitlabfilesystem">GitLab Filesystem (<code>GitLabFileSystem</code>)</a></li>
  </ul></li>
  <li><a href="#advanced-data-reading-and-writing-read_files-write_files" id="toc-advanced-data-reading-and-writing-read_files-write_files" class="nav-link" data-scroll-target="#advanced-data-reading-and-writing-read_files-write_files">Advanced Data Reading and Writing (<code>read_files</code>, <code>write_files</code>)</a>
  <ul class="collapse">
  <li><a href="#universal-read_files" id="toc-universal-read_files" class="nav-link" data-scroll-target="#universal-read_files">Universal <code>read_files</code></a></li>
  <li><a href="#reading-and-processing-multiple-files-pyarrow-tables-batch-processing" id="toc-reading-and-processing-multiple-files-pyarrow-tables-batch-processing" class="nav-link" data-scroll-target="#reading-and-processing-multiple-files-pyarrow-tables-batch-processing">Reading and Processing Multiple Files (PyArrow Tables, Batch Processing)</a></li>
  <li><a href="#advanced-parquet-handling-and-delta-lake-integration" id="toc-advanced-parquet-handling-and-delta-lake-integration" class="nav-link" data-scroll-target="#advanced-parquet-handling-and-delta-lake-integration">Advanced Parquet Handling and Delta Lake Integration</a></li>
  </ul></li>
  <li><a href="#storage-options-management" id="toc-storage-options-management" class="nav-link" data-scroll-target="#storage-options-management">Storage Options Management</a>
  <ul class="collapse">
  <li><a href="#loading-from-environment-variables" id="toc-loading-from-environment-variables" class="nav-link" data-scroll-target="#loading-from-environment-variables">Loading from Environment Variables</a></li>
  <li><a href="#merging-storage-options" id="toc-merging-storage-options" class="nav-link" data-scroll-target="#merging-storage-options">Merging Storage Options</a></li>
  <li><a href="#note-on-github-examples" id="toc-note-on-github-examples" class="nav-link" data-scroll-target="#note-on-github-examples">Note on GitHub Examples</a></li>
  </ul></li>
  <li><a href="#performance-tips" id="toc-performance-tips" class="nav-link" data-scroll-target="#performance-tips">Performance Tips</a></li>
  <li><a href="#flexible-storage-configuration" id="toc-flexible-storage-configuration" class="nav-link" data-scroll-target="#flexible-storage-configuration">Flexible Storage Configuration</a>
  <ul class="collapse">
  <li><a href="#local-storage-example" id="toc-local-storage-example" class="nav-link" data-scroll-target="#local-storage-example">Local Storage Example</a></li>
  <li><a href="#conceptual-aws-s3-configuration" id="toc-conceptual-aws-s3-configuration" class="nav-link" data-scroll-target="#conceptual-aws-s3-configuration">Conceptual AWS S3 Configuration</a></li>
  <li><a href="#conceptual-azure-configuration" id="toc-conceptual-azure-configuration" class="nav-link" data-scroll-target="#conceptual-azure-configuration">Conceptual Azure Configuration</a></li>
  <li><a href="#conceptual-gcs-configuration" id="toc-conceptual-gcs-configuration" class="nav-link" data-scroll-target="#conceptual-gcs-configuration">Conceptual GCS Configuration</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>





<section id="advanced-usage" class="level1">
<h1>Advanced Usage</h1>
<p><code>fsspec-utils</code> extends the capabilities of <code>fsspec</code> to provide a more robust and feature-rich experience for handling diverse file systems and data formats. This section delves into advanced features, configurations, and performance tips to help you get the most out of the library.</p>
<section id="unified-filesystem-creation-with-filesystem" class="level2">
<h2 class="anchored" data-anchor-id="unified-filesystem-creation-with-filesystem">Unified Filesystem Creation with <code>filesystem</code></h2>
<p>The <code>fsspec_utils.core.filesystem</code> function offers a centralized and enhanced way to instantiate <code>fsspec</code> filesystem objects. It supports:</p>
<ul>
<li><strong>Intelligent Caching</strong>: Automatically wraps filesystems with <code>MonitoredSimpleCacheFileSystem</code> for improved performance and verbose logging of cache operations.</li>
<li><strong>Structured Storage Options</strong>: Integrates seamlessly with <code>fsspec_utils.storage_options</code> classes, allowing for type-safe and organized configuration of cloud and Git-based storage.</li>
<li><strong>Protocol Inference</strong>: Can infer the filesystem protocol directly from a URI or path, reducing boilerplate.</li>
</ul>
<p><strong>Example: Cached S3 Filesystem with Structured Options</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.core <span class="im">import</span> filesystem</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> AwsStorageOptions</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure S3 options using the structured class</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>s3_opts <span class="op">=</span> AwsStorageOptions(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    region<span class="op">=</span><span class="st">"us-east-1"</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    access_key_id<span class="op">=</span><span class="st">"YOUR_ACCESS_KEY"</span>,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    secret_access_key<span class="op">=</span><span class="st">"YOUR_SECRET_KEY"</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a cached S3 filesystem using the 'filesystem' helper</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"s3"</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    storage_options<span class="op">=</span>s3_opts,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    cached<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    cache_storage<span class="op">=</span><span class="st">"/tmp/s3_cache"</span>, <span class="co"># Optional: specify cache directory</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span> <span class="co"># Enable verbose cache logging</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the filesystem as usual</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(fs.ls(<span class="st">"s3://your-bucket/"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="detailed-caching-for-improved-performance" class="level3">
<h3 class="anchored" data-anchor-id="detailed-caching-for-improved-performance">Detailed Caching for Improved Performance</h3>
<p><code>fsspec-utils</code> provides an enhanced caching mechanism that improves performance for repeated file operations, especially useful for remote filesystems.</p>
<p>This example demonstrates how caching improves read performance. The first read populates the cache, while subsequent reads retrieve data directly from the cache, significantly reducing access time. It also shows that data can still be retrieved from the cache even if the original source becomes unavailable.</p>
<p><strong>Caching in fsspec-utils</strong> is an enhanced mechanism that improves performance for repeated file operations, especially useful for remote filesystems where network latency can significantly impact performance.</p>
<p>The <code>filesystem()</code> function provides several parameters for configuring caching:</p>
<ul>
<li><code>cached</code>: When set to <code>True</code>, enables caching for all read operations</li>
<li><code>cache_storage</code>: Specifies the directory where cached files will be stored</li>
<li><code>verbose</code>: When set to <code>True</code>, provides detailed logging about cache operations</li>
</ul>
<p><strong>Step-by-step walkthrough:</strong></p>
<ol type="1">
<li><p><strong>First read (populating cache)</strong>: When reading a file for the first time, the data is retrieved from the source (disk, network, etc.) and stored in the cache directory. This takes longer than subsequent reads because it involves both reading from the source and writing to the cache.</p></li>
<li><p><strong>Second read (using cache)</strong>: When the same file is read again, the data is retrieved directly from the cache instead of the source. This is significantly faster because it avoids network latency or disk I/O.</p></li>
<li><p><strong>Demonstrating cache effectiveness</strong>: Even after the original file is removed, the cached version can still be accessed. This demonstrates that the cache acts as a persistent copy of the data, independent of the source file.</p></li>
<li><p><strong>Performance comparison</strong>: The timing results clearly show the performance benefits of caching, with subsequent reads being orders of magnitude faster than the initial read.</p></li>
</ol>
<p>This caching mechanism is particularly valuable when working with:</p>
<ul>
<li>Remote filesystems (S3, GCS, Azure) where network latency is a bottleneck</li>
<li>Frequently accessed files that don’t change often</li>
<li>Applications that read the same data multiple times</li>
<li>Environments with unreliable network connections</li>
</ul>
<section id="setup-and-first-read-populating-cache" class="level4">
<h4 class="anchored" data-anchor-id="setup-and-first-read-populating-cache">Setup and First Read (Populating Cache)</h4>
<p>In this step, we create a sample JSON file and initialize the <code>fsspec-utils</code> filesystem with caching enabled. The first read operation retrieves data from the source and populates the cache.</p>
<p><strong>Setup steps:</strong></p>
<ol type="1">
<li>Create a temporary directory for our example</li>
<li>Create sample data file</li>
<li>Configure filesystem with caching</li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils <span class="im">import</span> filesystem</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> examples.caching.setup_data <span class="im">import</span> create_sample_data_file</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>tmpdir <span class="op">=</span> tempfile.mkdtemp()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created temporary directory: </span><span class="sc">{</span>tmpdir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>sample_file <span class="op">=</span> create_sample_data_file(tmpdir)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>cache_dir <span class="op">=</span> os.path.join(tmpdir, <span class="st">"cache"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    protocol_or_path<span class="op">=</span><span class="st">"file"</span>,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    cached<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    cache_storage<span class="op">=</span>cache_dir,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== First read (populating cache) ==="</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>data1 <span class="op">=</span> fs.read_json(sample_file)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>first_read_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First read completed in </span><span class="sc">{</span>first_read_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="second-read-using-cache" class="level4">
<h4 class="anchored" data-anchor-id="second-read-using-cache">Second Read (Using Cache)</h4>
<p>Now, let’s read the same file again to see the performance improvement from using the cache.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Second read (using cache) ==="</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>data2 <span class="op">=</span> fs.read_json(sample_file)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>second_read_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Second read completed in </span><span class="sc">{</span>second_read_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The second read retrieves data directly from the cache, which is significantly faster than reading from the source again.</p>
</section>
<section id="reading-from-cache-after-deletion" class="level4">
<h4 class="anchored" data-anchor-id="reading-from-cache-after-deletion">Reading from Cache after Deletion</h4>
<p>To demonstrate that the cache is persistent, we’ll remove the original file and try to read it again.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Demonstrating cache effectiveness ==="</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Removing original file..."</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>os.remove(sample_file)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original file exists: </span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>exists(sample_file)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Third read (from cache only) ==="</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>data3 <span class="op">=</span> fs.read_json(sample_file)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>third_read_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Third read completed in </span><span class="sc">{</span>third_read_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Successfully read from cache even after original file was removed"</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Performance Comparison ==="</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First read (from disk): </span><span class="sc">{</span>first_read_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Second read (from cache): </span><span class="sc">{</span>second_read_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Third read (from cache): </span><span class="sc">{</span>third_read_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>shutil.rmtree(tmpdir)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cleaned up temporary directory: </span><span class="sc">{</span>tmpdir<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This step proves that the cache acts as a persistent copy of the data, allowing access even if the original source is unavailable.</p>
</section>
</section>
</section>
<section id="custom-filesystem-implementations" class="level2">
<h2 class="anchored" data-anchor-id="custom-filesystem-implementations">Custom Filesystem Implementations</h2>
<p><code>fsspec-utils</code> provides specialized filesystem implementations for unique use cases:</p>
<section id="gitlab-filesystem-gitlabfilesystem" class="level3">
<h3 class="anchored" data-anchor-id="gitlab-filesystem-gitlabfilesystem">GitLab Filesystem (<code>GitLabFileSystem</code>)</h3>
<p>Access files directly from GitLab repositories. This is particularly useful for configuration files, datasets, or code stored in private or public GitLab instances.</p>
<p><strong>Example: Reading from a GitLab Repository</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.core <span class="im">import</span> filesystem</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate a GitLab filesystem</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>gitlab_fs <span class="op">=</span> filesystem(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gitlab"</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    storage_options<span class="op">=</span>{</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"project_name"</span>: <span class="st">"your-group/your-project"</span>, <span class="co"># Or "project_id": 12345</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"ref"</span>: <span class="st">"main"</span>, <span class="co"># Branch, tag, or commit SHA</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"token"</span>: <span class="st">"glpat_YOUR_PRIVATE_TOKEN"</span> <span class="co"># Required for private repos</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># List files in the repository root</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(gitlab_fs.ls(<span class="st">"/"</span>))</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Read a specific file</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>content <span class="op">=</span> gitlab_fs.cat(<span class="st">"README.md"</span>).decode(<span class="st">"utf-8"</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(content[:<span class="dv">200</span>]) <span class="co"># Print first 200 characters</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="advanced-data-reading-and-writing-read_files-write_files" class="level2">
<h2 class="anchored" data-anchor-id="advanced-data-reading-and-writing-read_files-write_files">Advanced Data Reading and Writing (<code>read_files</code>, <code>write_files</code>)</h2>
<p>The <code>fsspec_utils.core.ext</code> module (exposed via <code>AbstractFileSystem</code> extensions) provides powerful functions for reading and writing various data formats (JSON, CSV, Parquet) with advanced features like:</p>
<ul>
<li><strong>Batch Processing</strong>: Efficiently handle large datasets by processing files in configurable batches.</li>
<li><strong>Parallel Processing</strong>: Leverage multi-threading to speed up file I/O operations.</li>
<li><strong>Schema Unification &amp; Optimization</strong>: Automatically unifies schemas when concatenating multiple files and optimizes data types for memory efficiency (e.g., using Polars’ <code>opt_dtypes</code> or PyArrow’s schema casting).</li>
<li><strong>File Path Tracking</strong>: Optionally include the source file path as a column in the resulting DataFrame/Table.</li>
</ul>
<section id="universal-read_files" class="level3">
<h3 class="anchored" data-anchor-id="universal-read_files">Universal <code>read_files</code></h3>
<p>The <code>read_files</code> function acts as a universal reader, delegating to format-specific readers (JSON, CSV, Parquet) while maintaining consistent options.</p>
<p><strong>Example: Reading CSVs in Batches with Parallelism</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.core <span class="im">import</span> filesystem</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming you have multiple CSV files like 'data/part_0.csv', 'data/part_1.csv', etc.</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># on your local filesystem</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(<span class="st">"file"</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Read CSV files in batches of 10, using multiple threads, and including file path</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_df <span class="kw">in</span> fs.read_files(</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data/*.csv"</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    include_file_path<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    use_threads<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Processed batch with </span><span class="sc">{</span><span class="bu">len</span>(batch_df)<span class="sc">}</span><span class="ss"> rows. Columns: </span><span class="sc">{</span>batch_df<span class="sc">.</span>columns<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(batch_df.head(<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="reading-and-processing-multiple-files-pyarrow-tables-batch-processing" class="level3">
<h3 class="anchored" data-anchor-id="reading-and-processing-multiple-files-pyarrow-tables-batch-processing">Reading and Processing Multiple Files (PyArrow Tables, Batch Processing)</h3>
<p><code>fsspec-utils</code> simplifies reading multiple files of various formats (Parquet, CSV, JSON) from a folder into a single PyArrow Table or Polars DataFrame.</p>
<p><strong>Reading multiple files into a single table</strong> is a powerful feature that allows you to efficiently process data distributed across multiple files. This is particularly useful when dealing with large datasets that are split into smaller files for better organization or parallel processing.</p>
<p><strong>Key concepts demonstrated:</strong></p>
<ol type="1">
<li><p><strong>Glob patterns</strong>: The <code>**/*.parquet</code>, <code>**/*.csv</code>, and <code>**/*.json</code> patterns are used to select files recursively from the directory and its subdirectories. The <code>**</code> pattern matches any directories, allowing the function to find files in nested directories.</p></li>
<li><p><strong>Concat parameter</strong>: The <code>concat=True</code> parameter tells the function to combine data from multiple files into a single table or DataFrame. When set to <code>False</code>, the function would return a list of individual tables/DataFrames.</p></li>
<li><p><strong>Format flexibility</strong>: The same interface can be used to read different file formats (Parquet, CSV, JSON), making it easy to work with heterogeneous data sources.</p></li>
</ol>
<p><strong>Step-by-step explanation:</strong></p>
<ol type="1">
<li><p><strong>Creating sample data</strong>: We create two subdirectories and populate them with sample data in three different formats (Parquet, CSV, JSON). Each format contains the same structured data but in different serialization formats.</p></li>
<li><p><strong>Reading Parquet files</strong>: Using <code>fs.read_parquet("**/*.parquet", concat=True)</code>, we read all Parquet files recursively and combine them into a single PyArrow Table. Parquet is a columnar storage format that is highly efficient for analytical workloads.</p></li>
<li><p><strong>Reading CSV files</strong>: Using <code>fs.read_csv("**/*.csv", concat=True)</code>, we read all CSV files and combine them into a Polars DataFrame, which we then convert to a PyArrow Table for consistency.</p></li>
<li><p><strong>Reading JSON files</strong>: Using <code>fs.read_json("**/*.json", as_dataframe=True, concat=True)</code>, we read all JSON files and combine them into a Polars DataFrame, then convert it to a PyArrow Table.</p></li>
<li><p><strong>Verification</strong>: Finally, we verify that all three tables have the same number of rows, confirming that the data was correctly read and combined across all files and formats.</p></li>
</ol>
<p>The flexibility of <code>fsspec-utils</code> allows you to use the same approach with different data sources, including remote filesystems like S3, GCS, or Azure Blob Storage, simply by changing the filesystem path.</p>
<section id="setup" class="level4">
<h4 class="anchored" data-anchor-id="setup">Setup</h4>
<p>First, we’ll create a temporary directory with sample data in different formats.</p>
<p><strong>Setup steps:</strong></p>
<ol type="1">
<li>Create a temporary directory for our example</li>
<li>Create sample data in subdirectories</li>
</ol>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> examples.read_folder.create_dataset <span class="im">import</span> create_sample_dataset</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>temp_dir <span class="op">=</span> tempfile.mkdtemp()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>create_sample_dataset(temp_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This step sets up the environment by creating a temporary directory and populating it with sample data files.</p>
</section>
<section id="reading-parquet-files" class="level4">
<h4 class="anchored" data-anchor-id="reading-parquet-files">Reading Parquet Files</h4>
<p>Now, let’s read all the Parquet files from the directory and its subdirectories into a single PyArrow Table.</p>
<p><strong>Reading Parquet files:</strong></p>
<ol type="1">
<li>Read Parquet files using glob pattern</li>
<li>Display table information and sample data</li>
</ol>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Reading Parquet Files ==="</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils <span class="im">import</span> filesystem</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(temp_dir)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>parquet_table <span class="op">=</span> fs.read_parquet(<span class="st">"**/*.parquet"</span>, concat<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Successfully read Parquet files into PyArrow Table"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Table shape: </span><span class="sc">{</span>parquet_table<span class="sc">.</span>num_rows<span class="sc">}</span><span class="ss"> rows x </span><span class="sc">{</span>parquet_table<span class="sc">.</span>num_columns<span class="sc">}</span><span class="ss"> columns"</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 3 rows:"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(parquet_table.<span class="bu">slice</span>(<span class="dv">0</span>, <span class="dv">3</span>).to_pandas())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We use the <code>read_parquet</code> method with a glob pattern <code>**/*.parquet</code> to find all Parquet files recursively. The <code>concat=True</code> parameter combines them into a single table.</p>
</section>
<section id="reading-csv-files" class="level4">
<h4 class="anchored" data-anchor-id="reading-csv-files">Reading CSV Files</h4>
<p>Next, we’ll read all the CSV files into a Polars DataFrame and then convert it to a PyArrow Table.</p>
<p><strong>Reading CSV files:</strong></p>
<ol type="1">
<li>Read CSV files using glob pattern</li>
<li>Display DataFrame information and sample data</li>
<li>Convert to PyArrow Table for consistency</li>
</ol>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Reading CSV Files ==="</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>csv_df <span class="op">=</span> fs.read_csv(<span class="st">"**/*.csv"</span>, concat<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Successfully read CSV files into Polars DataFrame"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DataFrame shape: </span><span class="sc">{</span>csv_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 3 rows:"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(csv_df.head(<span class="dv">3</span>))</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>csv_table <span class="op">=</span> csv_df.to_arrow()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Similarly, we use <code>read_csv</code> with the same glob pattern to read all CSV files.</p>
</section>
<section id="reading-json-files" class="level4">
<h4 class="anchored" data-anchor-id="reading-json-files">Reading JSON Files</h4>
<p>Finally, let’s read all the JSON files.</p>
<p><strong>Reading JSON files:</strong></p>
<ol type="1">
<li>Read JSON files using glob pattern</li>
<li>Display DataFrame information and sample data</li>
<li>Convert to PyArrow Table for consistency</li>
</ol>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Reading JSON Files ==="</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>json_df <span class="op">=</span> fs.read_json(<span class="st">"**/*.json"</span>, as_dataframe<span class="op">=</span><span class="va">True</span>, concat<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Successfully read JSON files into Polars DataFrame"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DataFrame shape: </span><span class="sc">{</span>json_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 3 rows:"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(json_df.head(<span class="dv">3</span>))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>json_table <span class="op">=</span> json_df.to_arrow()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>read_json</code> method is used to read all JSON files. We set <code>as_dataframe=True</code> to get a Polars DataFrame.</p>
</section>
<section id="verification" class="level4">
<h4 class="anchored" data-anchor-id="verification">Verification</h4>
<p>Let’s verify that all the tables have the same number of rows.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Verification ==="</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"All tables have the same number of rows: </span><span class="sc">{</span>parquet_table<span class="sc">.</span>num_rows <span class="op">==</span> csv_table<span class="sc">.</span>num_rows <span class="op">==</span> json_table<span class="sc">.</span>num_rows<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>shutil.rmtree(temp_dir)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cleaned up temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This final step confirms that our data reading and concatenation were successful.</p>
<p>This example shows how to read various file formats from a directory, including subdirectories, into a unified PyArrow Table or Polars DataFrame. It highlights the flexibility of <code>fsspec-utils</code> in handling different data sources and formats.</p>
<p><code>fsspec-utils</code> enables efficient batch processing of large datasets by reading files in smaller, manageable chunks. This is particularly useful for memory-constrained environments or when processing streaming data.</p>
<p><strong>Batch processing</strong> is a technique for handling large datasets by dividing them into smaller, manageable chunks. This is particularly important for:</p>
<ol type="1">
<li><strong>Memory-constrained environments</strong>: When working with datasets that are too large to fit in memory, batch processing allows you to process the data incrementally.</li>
<li><strong>Streaming data</strong>: When data is continuously generated (e.g., from IoT devices or real-time applications), batch processing enables you to process data as it arrives.</li>
<li><strong>Distributed processing</strong>: In distributed computing environments, batch processing allows different nodes to work on different chunks of data simultaneously.</li>
</ol>
<p><strong>The <code>batch_size</code> parameter</strong> controls how many files or records are processed together in each batch. A smaller batch size reduces memory usage but may increase processing overhead, while a larger batch size improves throughput but requires more memory.</p>
<p><strong>Step-by-step walkthrough:</strong></p>
<ol type="1">
<li><p><strong>Creating sample batched data</strong>: We generate sample data and distribute it across multiple files in each format (Parquet, CSV, JSON). Each file contains a subset of the total data, simulating a real-world scenario where data is split across multiple files.</p></li>
<li><p><strong>Reading Parquet files in batches</strong>: Using <code>fs.read_parquet(parquet_path, batch_size=2)</code>, we read all Parquet files in batches of 2 files at a time. Each iteration of the loop processes a batch of files, and the <code>batch</code> variable contains the combined data from those files.</p></li>
<li><p><strong>Reading CSV files in batches</strong>: Similarly, we use <code>fs.read_csv(csv_path, batch_size=2)</code> to read CSV files in batches. The result is a Polars DataFrame for each batch, which we can process individually.</p></li>
<li><p><strong>Reading JSON files in batches</strong>: Finally, we use <code>fs.read_json(json_path, batch_size=2)</code> to read JSON files in batches. The JSON data is automatically converted to Polars DataFrames for easy processing.</p></li>
</ol>
<p><strong>Benefits of batch processing:</strong></p>
<ul>
<li><strong>Reduced memory footprint</strong>: Instead of loading all files into memory at once, you only load the current batch.</li>
<li><strong>Progressive processing</strong>: You can start processing data as soon as the first batch is available, without waiting for all data to be loaded.</li>
<li><strong>Fault tolerance</strong>: If processing fails on one batch, you can restart from that batch without reprocessing all previous batches.</li>
<li><strong>Scalability</strong>: Batch processing scales well with both the size of the dataset and the available computational resources.</li>
</ul>
<p>This approach is particularly valuable when working with large datasets in cloud storage, where downloading the entire dataset would be impractical due to network constraints or memory limitations.</p>
</section>
<section id="setup-1" class="level4">
<h4 class="anchored" data-anchor-id="setup-1">Setup</h4>
<p>First, we’ll create a temporary directory with sample data files.</p>
<p>This step sets up the environment by creating a temporary directory and populating it with sample data files in batches.</p>
<p><strong>Setup steps:</strong></p>
<ol type="1">
<li>Create a temporary directory for our example</li>
<li>Create sample batched data</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> examples.batch_processing.generate_batched_data <span class="im">import</span> create_batched_dataset</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>temp_dir <span class="op">=</span> tempfile.mkdtemp()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>create_batched_dataset(temp_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="batch-reading-parquet-files" class="level4">
<h4 class="anchored" data-anchor-id="batch-reading-parquet-files">Batch Reading Parquet Files</h4>
<p>Now, let’s read the Parquet files in batches.</p>
<p><strong>Reading Parquet files in batches:</strong></p>
<ol type="1">
<li>Initialize filesystem</li>
<li>Set up path pattern for Parquet files</li>
<li>Process files in batches of 2</li>
</ol>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Parquet Batch Reading ==="</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils <span class="im">import</span> filesystem</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(<span class="st">"file"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>parquet_path <span class="op">=</span> os.path.join(temp_dir, <span class="st">"*.parquet"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Reading Parquet files in batches (batch_size=2):"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(fs.read_parquet(parquet_path, batch_size<span class="op">=</span><span class="dv">2</span>)):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Batch </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: rows=</span><span class="sc">{</span>batch<span class="sc">.</span>num_rows<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   - Data preview: </span><span class="sc">{</span>batch<span class="sc">.</span>to_pandas()<span class="sc">.</span>head(<span class="dv">1</span>)<span class="sc">.</span>to_dict(<span class="st">'records'</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="batch-reading-csv-files" class="level4">
<h4 class="anchored" data-anchor-id="batch-reading-csv-files">Batch Reading CSV Files</h4>
<p>Next, we’ll read the CSV files in batches.</p>
<p><strong>Reading CSV files in batches:</strong></p>
<ol type="1">
<li>Set up path pattern for CSV files</li>
<li>Process files in batches of 2</li>
</ol>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== CSV Batch Reading ==="</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>csv_path <span class="op">=</span> os.path.join(temp_dir, <span class="st">"*.csv"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Reading CSV files in batches (batch_size=2):"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(fs.read_csv(csv_path, batch_size<span class="op">=</span><span class="dv">2</span>)):</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Batch </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: shape=</span><span class="sc">{</span>batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   - Data preview: </span><span class="sc">{</span>batch<span class="sc">.</span>head(<span class="dv">1</span>)<span class="sc">.</span>to_dicts()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Similarly, we use <code>read_csv</code> with the same glob pattern to read all CSV files.</p>
</section>
<section id="batch-reading-json-files" class="level4">
<h4 class="anchored" data-anchor-id="batch-reading-json-files">Batch Reading JSON Files</h4>
<p>Finally, let’s read the JSON files in batches.</p>
<p><strong>Reading JSON files in batches:</strong></p>
<ol type="1">
<li>Set up path pattern for JSON files</li>
<li>Process files in batches of 2</li>
<li>Clean up the temporary directory</li>
</ol>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== JSON Batch Reading ==="</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>json_path <span class="op">=</span> os.path.join(temp_dir, <span class="st">"*.json"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Reading JSON files in batches (batch_size=2):"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(fs.read_json(json_path, batch_size<span class="op">=</span><span class="dv">2</span>)):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Batch </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: shape=</span><span class="sc">{</span>batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   - Data preview: </span><span class="sc">{</span>batch<span class="sc">.</span>head(<span class="dv">1</span>)<span class="sc">.</span>to_dicts()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>shutil.rmtree(temp_dir)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cleaned up temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>read_json</code> method is also used with <code>batch_size=2</code> to process JSON files in batches.</p>
<p>This example illustrates how to read Parquet, CSV, and JSON files in batches using the <code>batch_size</code> parameter. This approach allows for processing of large datasets without loading the entire dataset into memory at once.</p>
</section>
</section>
<section id="advanced-parquet-handling-and-delta-lake-integration" class="level3">
<h3 class="anchored" data-anchor-id="advanced-parquet-handling-and-delta-lake-integration">Advanced Parquet Handling and Delta Lake Integration</h3>
<p><code>fsspec-utils</code> enhances Parquet operations with deep integration with PyArrow and Pydala, enabling efficient dataset management, partitioning, and delta lake capabilities.</p>
<ul>
<li><strong><code>pyarrow_dataset</code></strong>: Create PyArrow datasets for optimized querying, partitioning, and predicate pushdown.</li>
<li><strong><code>pyarrow_parquet_dataset</code></strong>: Specialized for Parquet, handling <code>_metadata</code> files for overall dataset schemas.</li>
<li><strong><code>pydala_dataset</code></strong>: Integrates with <code>pydala</code> for advanced features like Delta Lake operations (upserts, schema evolution).</li>
</ul>
<p><strong>Example: Writing to a PyArrow Dataset with Partitioning</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> polars <span class="im">as</span> pl</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.core <span class="im">import</span> filesystem</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(<span class="st">"file"</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>base_path <span class="op">=</span> <span class="st">"output/my_partitioned_data"</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pl.DataFrame({</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>],</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"value"</span>: [<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>, <span class="st">"D"</span>],</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"year"</span>: [<span class="dv">2023</span>, <span class="dv">2023</span>, <span class="dv">2024</span>, <span class="dv">2024</span>],</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"month"</span>: [<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Write data as a partitioned PyArrow dataset</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>fs.write_pyarrow_dataset(</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>data,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    path<span class="op">=</span>base_path,</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    partition_by<span class="op">=</span>[<span class="st">"year"</span>, <span class="st">"month"</span>], <span class="co"># Partition by year and month</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"parquet"</span>,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"zstd"</span>,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"overwrite"</span> <span class="co"># Overwrite if path exists</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Data written to </span><span class="sc">{</span>base_path<span class="sc">}</span><span class="ss"> partitioned by year/month."</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected structure: output/my_partitioned_data/year=2023/month=10/data-*.parquet</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Example: Delta Lake Operations with Pydala Dataset</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> polars <span class="im">as</span> pl</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.core <span class="im">import</span> filesystem</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> filesystem(<span class="st">"file"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>delta_path <span class="op">=</span> <span class="st">"output/my_delta_table"</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial data</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>initial_data <span class="op">=</span> pl.DataFrame({</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"name"</span>: [<span class="st">"Alice"</span>, <span class="st">"Bob"</span>],</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"version"</span>: [<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Write initial data to a Pydala dataset</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>fs.write_pydala_dataset(</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>initial_data,</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    path<span class="op">=</span>delta_path,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"overwrite"</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initial Delta table created."</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co"># New data for an upsert: update Alice, add Charlie</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>new_data <span class="op">=</span> pl.DataFrame({</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: [<span class="dv">1</span>, <span class="dv">3</span>],</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"name"</span>: [<span class="st">"Alicia"</span>, <span class="st">"Charlie"</span>],</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"version"</span>: [<span class="dv">2</span>, <span class="dv">1</span>]</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a delta merge (upsert)</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>fs.write_pydala_dataset(</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>new_data,</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>    path<span class="op">=</span>delta_path,</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"delta"</span>,</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>    delta_subset<span class="op">=</span>[<span class="st">"id"</span>] <span class="co"># Column(s) to use for merging</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Delta merge completed."</span>)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the updated table</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>updated_df <span class="op">=</span> fs.pydala_dataset(delta_path).to_polars()</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated Delta table:"</span>)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(updated_df)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected: id=1 Alicia version=2, id=2 Bob version=1, id=3 Charlie version=1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>fsspec-utils</code> facilitates integration with Delta Lake by providing <code>StorageOptions</code> that can be used to configure <code>deltalake</code>’s <code>DeltaTable</code> for various storage backends.</p>
<p>This example demonstrates how to use <code>LocalStorageOptions</code> with <code>deltalake</code>’s <code>DeltaTable</code>. It shows how to initialize a <code>DeltaTable</code> instance by passing the <code>fsspec-utils</code> storage options, enabling seamless interaction with Delta Lake tables across different storage types.</p>
<p><strong>Step-by-step walkthrough:</strong></p>
<ol type="1">
<li>Create a temporary directory for our example</li>
<li>Create a simple Polars DataFrame</li>
<li>Write initial data to create the Delta table</li>
<li>Create a LocalStorageOptions object for the temporary directory</li>
<li>Create a DeltaTable instance, passing storage options
<ul>
<li>Note: deltalake expects storage_options as a dict, which to_object_store_kwargs provides</li>
</ul></li>
<li>Read data from the DeltaTable</li>
<li>Clean up the temporary directory</li>
</ol>
<p><strong>Delta Lake</strong> is an open-source storage layer that brings ACID transactions to Apache Spark and big data workloads. It provides a reliable, scalable, and performant way to work with data lakes, combining the benefits of data lakes (low cost, flexibility) with data warehouses (reliability, performance).</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deltalake <span class="im">import</span> DeltaTable</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> LocalStorageOptions</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> polars <span class="im">as</span> pl</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>temp_dir <span class="op">=</span> tempfile.mkdtemp()</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>delta_table_path <span class="op">=</span> os.path.join(temp_dir, <span class="st">"my_delta_table"</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Creating a dummy Delta table at: </span><span class="sc">{</span>delta_table_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pl.DataFrame({</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"value"</span>: [<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>]</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>data.write_delta(delta_table_path, mode<span class="op">=</span><span class="st">"overwrite"</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Initial data written to Delta table."</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>local_options <span class="op">=</span> LocalStorageOptions(path<span class="op">=</span>temp_dir)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>dt <span class="op">=</span> DeltaTable(delta_table_path, storage_options<span class="op">=</span>local_options.to_object_store_kwargs())</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Successfully created DeltaTable instance from: </span><span class="sc">{</span>delta_table_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DeltaTable version: </span><span class="sc">{</span>dt<span class="sc">.</span>version()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DeltaTable files: </span><span class="sc">{</span>dt<span class="sc">.</span>files()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>table_data <span class="op">=</span> dt.to_pyarrow_table()</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Data read from DeltaTable:"</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(table_data.to_pandas())</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>shutil.rmtree(temp_dir)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cleaned up temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Key features of Delta Lake:</strong></p>
<ul>
<li>ACID transactions: Ensures data integrity even with concurrent operations</li>
<li>Time travel: Allows querying data as it existed at any point in time</li>
<li>Schema enforcement: Maintains data consistency with schema validation</li>
<li>Scalable metadata: Handles billions of files efficiently</li>
<li>Unified analytics: Supports both batch and streaming workloads</li>
</ul>
<p><strong>Integrating fsspec-utils with Delta Lake:</strong></p>
<p>The <code>fsspec-utils</code> <code>StorageOptions</code> classes can be used to configure <code>deltalake</code>’s <code>DeltaTable</code> for various storage backends. This integration allows you to:</p>
<ol type="1">
<li>Use consistent configuration patterns across different storage systems</li>
<li>Leverage the benefits of fsspec’s unified filesystem interface</li>
<li>Seamlessly switch between local and cloud storage without changing your Delta Lake code</li>
</ol>
<p><strong>The <code>to_object_store_kwargs()</code> method</strong> converts <code>fsspec-utils</code> storage options into a dictionary format that <code>deltalake</code> expects for its <code>storage_options</code> parameter. This is necessary because <code>deltalake</code> requires storage options as a dictionary, while <code>fsspec-utils</code> provides them as structured objects.</p>
<p><strong>Step-by-step walkthrough:</strong></p>
<ol type="1">
<li><p><strong>Creating a temporary directory</strong>: We create a temporary directory to store our Delta table, ensuring the example is self-contained and doesn’t leave artifacts on your system.</p></li>
<li><p><strong>Creating sample data</strong>: We create a simple Polars DataFrame with sample data that will be written to our Delta table.</p></li>
<li><p><strong>Writing to Delta table</strong>: Using the <code>write_delta</code> method, we convert our DataFrame into a Delta table. This creates the necessary Delta Lake metadata alongside the data files.</p></li>
<li><p><strong>Configuring storage options</strong>: We create a <code>LocalStorageOptions</code> object that points to our temporary directory. This object contains all the information needed to access the Delta table.</p></li>
<li><p><strong>Initializing DeltaTable</strong>: We create a <code>DeltaTable</code> instance by passing the table path and the storage options converted to a dictionary via <code>to_object_store_kwargs()</code>. This allows <code>deltalake</code> to locate and access the Delta table files.</p></li>
<li><p><strong>Verifying the DeltaTable</strong>: We check the version and files of our Delta table to confirm it was created correctly. Delta tables maintain version history, allowing you to track changes over time.</p></li>
<li><p><strong>Reading data</strong>: Finally, we read the data from our Delta table back into a PyArrow Table, demonstrating that we can successfully interact with the Delta Lake table using the fsspec-utils configuration.</p></li>
</ol>
<p>This integration is particularly valuable when working with Delta Lake in cloud environments, as it allows you to use the same configuration approach for local development and production deployments across different cloud providers.</p>
</section>
</section>
<section id="storage-options-management" class="level2">
<h2 class="anchored" data-anchor-id="storage-options-management">Storage Options Management</h2>
<p><code>fsspec-utils</code> provides a robust system for managing storage configurations, simplifying credential handling and environment setup.</p>
<section id="loading-from-environment-variables" class="level3">
<h3 class="anchored" data-anchor-id="loading-from-environment-variables">Loading from Environment Variables</h3>
<p>Instead of hardcoding credentials, you can load storage options directly from environment variables.</p>
<p><strong>Example: Loading AWS S3 Configuration from Environment</strong></p>
<p>Set these environment variables before running your script:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">AWS_ACCESS_KEY_ID</span><span class="op">=</span><span class="st">"YOUR_ACCESS_KEY"</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">AWS_SECRET_ACCESS_KEY</span><span class="op">=</span><span class="st">"YOUR_SECRET_KEY"</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">AWS_DEFAULT_REGION</span><span class="op">=</span><span class="st">"us-west-2"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then in Python:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> AwsStorageOptions</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load AWS options directly from environment variables</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>aws_opts <span class="op">=</span> AwsStorageOptions.from_env()</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded AWS region: </span><span class="sc">{</span>aws_opts<span class="sc">.</span>region<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use it to create a filesystem</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># fs = aws_opts.to_filesystem()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="merging-storage-options" class="level3">
<h3 class="anchored" data-anchor-id="merging-storage-options">Merging Storage Options</h3>
<p>Combine multiple storage option configurations, useful for layering default settings with user-specific overrides.</p>
<p><strong>Example: Merging S3 Options</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> AwsStorageOptions, merge_storage_options</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Base configuration</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>base_opts <span class="op">=</span> AwsStorageOptions(</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    protocol<span class="op">=</span><span class="st">"s3"</span>,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    region<span class="op">=</span><span class="st">"us-east-1"</span>,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    access_key_id<span class="op">=</span><span class="st">"DEFAULT_KEY"</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># User-provided overrides</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>user_overrides <span class="op">=</span> {</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"access_key_id"</span>: <span class="st">"USER_KEY"</span>,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"allow_http"</span>: <span class="va">True</span> <span class="co"># New setting</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge, with user_overrides taking precedence</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>merged_opts <span class="op">=</span> merge_storage_options(base_opts, user_overrides, overwrite<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Merged Access Key ID: </span><span class="sc">{</span>merged_opts<span class="sc">.</span>access_key_id<span class="sc">}</span><span class="ss">"</span>) <span class="co"># USER_KEY</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Merged Region: </span><span class="sc">{</span>merged_opts<span class="sc">.</span>region<span class="sc">}</span><span class="ss">"</span>) <span class="co"># us-east-1</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Allow HTTP: </span><span class="sc">{</span>merged_opts<span class="sc">.</span>allow_http<span class="sc">}</span><span class="ss">"</span>) <span class="co"># True</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="note-on-github-examples" class="level3">
<h3 class="anchored" data-anchor-id="note-on-github-examples">Note on GitHub Examples</h3>
<p>For a comprehensive collection of executable examples demonstrating various functionalities and advanced patterns of <code>fsspec-utils</code>, including those discussed in this document, please refer to the <a href="https://github.com/legout/fsspec-utils/tree/main/examples">examples directory on GitHub</a>. Each example is designed to be runnable and provides detailed insights into practical usage.</p>
</section>
</section>
<section id="performance-tips" class="level2">
<h2 class="anchored" data-anchor-id="performance-tips">Performance Tips</h2>
<ul>
<li><strong>Caching</strong>: Always consider using <code>cached=True</code> with the <code>filesystem</code> function, especially for remote filesystems, to minimize repeated downloads.</li>
<li><strong>Parallel Reading</strong>: For multiple files, set <code>use_threads=True</code> in <code>read_json</code>, <code>read_csv</code>, and <code>read_parquet</code> to leverage concurrent I/O.</li>
<li><strong>Batch Processing</strong>: When dealing with a very large number of files or extremely large individual files, use the <code>batch_size</code> parameter in reading functions to process data in chunks, reducing memory footprint.</li>
<li><strong><code>opt_dtypes</code></strong>: Utilize <code>opt_dtypes=True</code> in reading functions when converting to Polars or PyArrow to automatically optimize column data types, leading to more efficient memory usage and faster subsequent operations.</li>
<li><strong>Parquet Datasets</strong>: For large, partitioned Parquet datasets, use <code>pyarrow_dataset</code> or <code>pydala_dataset</code>. These leverage PyArrow’s dataset API for efficient metadata handling, partition pruning, and predicate pushdown, reading only the necessary data.</li>
<li><strong>Compression</strong>: When writing Parquet files, choose an appropriate compression codec (e.g., <code>zstd</code>, <code>snappy</code>) to reduce file size and improve I/O performance. <code>zstd</code> often provides a good balance of compression ratio and speed.</li>
</ul>
</section>
<section id="flexible-storage-configuration" class="level2">
<h2 class="anchored" data-anchor-id="flexible-storage-configuration">Flexible Storage Configuration</h2>
<p><code>fsspec-utils</code> simplifies configuring connections to various storage systems, including local filesystems, AWS S3, Azure Storage, and Google Cloud Storage, using <code>StorageOptions</code> classes. These options can then be converted into <code>fsspec</code> filesystems.</p>
<section id="local-storage-example" class="level3">
<h3 class="anchored" data-anchor-id="local-storage-example">Local Storage Example</h3>
<p>This example demonstrates how to initialize <code>LocalStorageOptions</code> and use it to interact with the local filesystem.</p>
<p><strong>Step-by-step walkthrough:</strong></p>
<ol type="1">
<li>Create a temporary directory for our test</li>
<li>Create a test file and write content to it</li>
<li>List files in the directory to verify our file was created</li>
<li>Read the content back to verify it was written correctly</li>
<li>Clean up the temporary directory</li>
</ol>
<p><strong>StorageOptions classes</strong> simplify configuration for different storage systems and provide a consistent interface for creating fsspec filesystem objects.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> LocalStorageOptions</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"=== LocalStorageOptions Example ===</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>local_options <span class="op">=</span> LocalStorageOptions(auto_mkdir<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>local_fs <span class="op">=</span> local_options.to_filesystem()</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>temp_dir <span class="op">=</span> tempfile.mkdtemp()</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Working in temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>temp_file <span class="op">=</span> os.path.join(temp_dir, <span class="st">"test_file.txt"</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> local_fs.<span class="bu">open</span>(temp_file, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    f.write(<span class="st">"Hello, LocalStorageOptions!"</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created test file: </span><span class="sc">{</span>temp_file<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>files <span class="op">=</span> local_fs.ls(temp_dir)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Files in </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>[os.path.basename(f) <span class="cf">for</span> f <span class="kw">in</span> files]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> local_fs.<span class="bu">open</span>(temp_file, <span class="st">"r"</span>) <span class="im">as</span> f:</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    content <span class="op">=</span> f.read()</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"File content: '</span><span class="sc">{</span>content<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>shutil.rmtree(temp_dir)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cleaned up temporary directory: </span><span class="sc">{</span>temp_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Local storage example completed.</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="conceptual-aws-s3-configuration" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-aws-s3-configuration">Conceptual AWS S3 Configuration</h3>
<p>This example demonstrates the configuration pattern for <code>AwsStorageOptions</code>. It is expected to fail when attempting to connect to actual cloud services because it uses dummy credentials.</p>
<p><strong>Note:</strong> The <code>to_filesystem()</code> method converts StorageOptions into fsspec-compatible objects, allowing seamless integration with any fsspec-compatible library.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> AwsStorageOptions</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"=== Conceptual AwsStorageOptions Example (using a dummy endpoint) ===</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>aws_options <span class="op">=</span> AwsStorageOptions(</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    endpoint_url<span class="op">=</span><span class="st">"http://s3.dummy-endpoint.com"</span>,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    access_key_id<span class="op">=</span><span class="st">"DUMMY_KEY"</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    secret_access_key<span class="op">=</span><span class="st">"DUMMY_SECRET"</span>,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    allow_http<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    region<span class="op">=</span><span class="st">"us-east-1"</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>aws_fs <span class="op">=</span> aws_options.to_filesystem()</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created fsspec filesystem for S3: </span><span class="sc">{</span><span class="bu">type</span>(aws_fs)<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AWS storage example completed.</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="conceptual-azure-configuration" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-azure-configuration">Conceptual Azure Configuration</h3>
<p>This example shows how to configure <code>AzureStorageOptions</code>. It is expected to fail when attempting to connect to actual cloud services because it uses dummy credentials.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fsspec_utils.storage_options <span class="im">import</span> AzureStorageOptions</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"=== Conceptual AzureStorageOptions Example (using a dummy connection string) ===</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>azure_options <span class="op">=</span> AzureStorageOptions(</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    protocol<span class="op">=</span><span class="st">"az"</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    account_name<span class="op">=</span><span class="st">"demoaccount"</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    connection_string<span class="op">=</span><span class="st">"DefaultEndpointsProtocol=https;AccountName=demoaccount;AccountKey=demokey==;EndpointSuffix=core.windows.net"</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>azure_fs <span class="op">=</span> azure_options.to_filesystem()</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Created fsspec filesystem for Azure: </span><span class="sc">{</span><span class="bu">type</span>(azure_fs)<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Azure storage example completed.</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="conceptual-gcs-configuration" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-gcs-configuration">Conceptual GCS Configuration</h3>
<p>This example shows how to configure <code>GcsStorageOptions</code>. It is expected to fail when attempting to connect to actual cloud services because it uses dummy credentials.</p>
<p><strong>StorageOptions classes</strong> provide a simplified, consistent interface for configuring connections to various storage systems. They abstract away the complexity of different storage backends and provide a unified way to create fsspec filesystem objects.</p>
<p>The <code>to_filesystem()</code> method converts these options into <code>fsspec</code> compatible objects, enabling seamless integration with any fsspec-compatible library or tool.</p>
<p><strong>Important Note</strong>: The AWS, Azure, and GCS examples use dummy credentials and are for illustrative purposes only. These examples are expected to fail when attempting to connect to actual cloud services because:</p>
<ol type="1">
<li>The endpoint URLs are not real service endpoints</li>
<li>The credentials are placeholder values that don’t correspond to actual accounts</li>
<li>The connection strings and tokens are examples, not valid credentials</li>
</ol>
<p>This approach allows you to understand the configuration pattern without needing actual cloud credentials. When using these examples in production, you would replace the dummy values with your real credentials and service endpoints.</p>
<p>```python from fsspec_utils.storage_options import GcsStorageOptions</p>
<p>print(“=== Conceptual GcsStorageOptions Example (using a dummy token path) ===”) gcs_options = GcsStorageOptions( protocol=“gs”, project=“demo-project”, token=“path/to/dummy-service-account.json” )</p>
<p>gcs_fs = gcs_options.to_filesystem() print(f”Created fsspec filesystem for GCS: {type(gcs_fs).__name__}“) print(”GCS storage example completed.“)</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>2025 © fsspec-utils</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>