<p align="center">
 <img src="docs/figure/logo.png" alt="FlowLLM Logo" width="50%">
</p>

<p align="center">
  <strong>FlowLLM: A Flexible Framework for Building LLM-Powered Flows</strong><br>
  <em>Flow with Intelligence, Build with Simplicity.</em>
</p>

<p align="center">
  <a href="https://pypi.org/project/flowllm/"><img src="https://img.shields.io/badge/python-3.12+-blue" alt="Python Version"></a>
  <a href="https://pypi.org/project/flowllm/"><img src="https://img.shields.io/badge/pypi-v0.1.10-blue?logo=pypi" alt="PyPI Version"></a>
  <a href="./LICENSE"><img src="https://img.shields.io/badge/license-Apache--2.0-black" alt="License"></a>
</p>

---

FlowLLM is a **configuration-driven** framework for building LLM-powered applications. Write operations once, compose them via YAML configuration, and automatically get HTTP APIs and MCP toolsâ€”no boilerplate code needed.

## ğŸ“– Table of Contents

- [Why FlowLLM?](#-why-flowllm)
- [Getting Started](#-getting-started)
- [Core Workflow](#-core-workflow)
- [Architecture](#-architecture)
- [Features](#-features)
- [Resources](#-resources)

---

## ğŸ’¡ Why FlowLLM?

**The Problem**: Building LLM services traditionally requires writing boilerplate routes, validation, documentation, and orchestration code for each endpoint.

**The Solution**: FlowLLM's configuration-driven approach lets you:

- âœ… **Write Operations Once** - Focus on business logic in reusable Python ops
- âœ… **Configure, Don't Code** - Compose workflows using YAML configuration
- âœ… **Auto-Generate Services** - HTTP and MCP endpoints created automatically
- âœ… **Built-in Orchestration** - Sequential (`>>`), parallel (`|`), and nested flows
- âœ… **Zero Boilerplate** - No routes, validators, or service code needed

| Feature | Traditional Approach | FlowLLM Approach |
|---------|---------------------|------------------|
| **Service Creation** | Write FastAPI/Flask routes, handlers, validation | Write YAML config - auto-registers HTTP + MCP |
| **API Documentation** | Manually write OpenAPI specs | Auto-generated from config |
| **Workflow Changes** | Modify Python code, test, redeploy | Update config, restart service |
| **Orchestration** | Write custom coordination code | Use expressions: `>>`, `\|`, `()` |

**Perfect For**: Rapid prototyping, microservices, AI agent tools, data pipelines, enterprise AI applications.

---

## ğŸš€ Getting Started

### Installation

```bash
pip install flowllm
```

For detailed setup instructions, see the [Installation Guide](INSTALLATION.md).

### Quick Start

See the [Quick Start Guide](QUICKSTART.md) to build your first LLM service in 30 seconds.

---

## ğŸ¯ Core Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Build Ops     â”‚      â”‚  Configure YAML  â”‚      â”‚    Auto-Register         â”‚
â”‚   (Python)      â”‚  â†’   â”‚   (Workflows)    â”‚  â†’   â”‚    Services              â”‚
â”‚                 â”‚      â”‚                  â”‚      â”‚                          â”‚
â”‚  â€¢ BaseOp       â”‚      â”‚  flow:           â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â€¢ BaseAsyncOp  â”‚      â”‚    workflow:     â”‚      â”‚  â”‚  HTTP Service      â”‚  â”‚
â”‚  â€¢ BaseMcpOp    â”‚      â”‚      description â”‚      â”‚  â”‚  POST /workflow    â”‚  â”‚
â”‚  â€¢ BaseRayOp    â”‚      â”‚      flow_contentâ”‚      â”‚  â”‚  OpenAPI docs      â”‚  â”‚
â”‚                 â”‚      â”‚      tool:       â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚      â”‚        parametersâ”‚      â”‚                          â”‚
â”‚                 â”‚      â”‚                  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                 â”‚      â”‚  backend: http   â”‚      â”‚  â”‚  MCP Service       â”‚  â”‚
â”‚                 â”‚      â”‚     or mcp       â”‚      â”‚  â”‚  Tool: workflow    â”‚  â”‚
â”‚                 â”‚      â”‚                  â”‚      â”‚  â”‚  Auto-discovered   â”‚  â”‚
â”‚                 â”‚      â”‚                  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Three Simple Steps:**

1. **Create an Op** - Write a Python class implementing your business logic
2. **Configure in YAML** - Define workflow and service endpoints
3. **Launch** - Run one command to start your HTTP or MCP service

**No manual routing, no endpoint definitions, no service code - just configuration!**

---

## âœ¨ Architecture

FlowLLM adopts a **three-layer configuration-driven architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Service Layer (å¤–å±‚)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ HTTP Service â”‚  â”‚  MCP Service â”‚  â”‚  CMD Service â”‚              â”‚
â”‚  â”‚   FastAPI    â”‚  â”‚   FastMCP    â”‚  â”‚  Command Lineâ”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                 Auto-Register from Configuration                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Flow Layer (ä¸­å±‚)                            â”‚
â”‚  â€¢ Sequential: op1 >> op2 >> op3                                    â”‚
â”‚  â€¢ Parallel: (op1 | op2 | op3)                                      â”‚
â”‚  â€¢ Nested: op1 >> (op2 | op3) >> op4                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Foundation Layer (åº•å±‚)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Op Lib   â”‚  â”‚ LLM Lib  â”‚  â”‚Embedding â”‚  â”‚ Storage  â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚ BaseOp   â”‚  â”‚ OpenAI   â”‚  â”‚ OpenAI   â”‚  â”‚ElasticS. â”‚            â”‚
â”‚  â”‚BaseAsync â”‚  â”‚ LiteLLM  â”‚  â”‚Compatibleâ”‚  â”‚ChromaDB  â”‚            â”‚
â”‚  â”‚BaseTool  â”‚  â”‚DashScope â”‚  â”‚          â”‚  â”‚  Local   â”‚            â”‚
â”‚  â”‚BaseMcpOp â”‚  â”‚  Custom  â”‚  â”‚  Custom  â”‚  â”‚  Cache   â”‚            â”‚
â”‚  â”‚BaseRayOp â”‚  â”‚          â”‚  â”‚          â”‚  â”‚          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Design Principles

1. **Separation of Concerns** - Ops (business logic), Flows (orchestration), Services (protocol handling)
2. **Configuration over Code** - Ops in Python, Flows in YAML, Services auto-generated
3. **Dependency Injection** - ServiceContext manages shared resources (LLM, VectorStore, etc.)
4. **Registry Pattern** - Dynamic loading and discovery based on configuration

### Complete Data Flow

```
Request â†’ Service Layer (HTTP/MCP)
       â†“
Flow Layer (Parse expression â†’ Build DAG)
       â†“
Foundation Layer (Execute ops with context)
       â†“
Response (JSON/MCP result)
```

---

## ğŸ¯ Features

### ğŸ“¦ Pre-built Operations

**Gallery Ops**: `SimpleLLMOp`, `ReactLLMOp`, `ExecuteCodeOp`, `TranslateCodeOp`  
**Search Ops**: `TavilySearchOp`, `DashScopeSearchOp`, `McpSearchOp`  
**Research Ops**: `DashScopeDeepResearchOp`, `LangChainDeepResearchOp`  
**Data Ops**: Various extraction and processing operations

### ğŸ”§ Advanced Capabilities

- **Multi-LLM Support** - OpenAI, LiteLLM (100+ providers), DashScope, custom providers
- **Vector Storage** - Elasticsearch, ChromaDB, local file-based, in-memory
- **Async/Streaming** - Full async support with SSE streaming responses
- **Distributed Computing** - Ray integration for scaling operations
- **Caching** - Intelligent caching with TTL and automatic serialization
- **Web Crawling** - Integrated `crawl4ai` for content extraction

### ğŸ§ª Workflow Patterns

- **Simple LLM Chat** - Direct model interaction
- **Multi-Step Research** - Sequential search, summarization, validation
- **Parallel Processing** - Concurrent sentiment analysis, keyword extraction
- **Complex Pipelines** - Nested sequential and parallel operations

---

## ğŸ“š Resources

### Documentation

- **[Installation Guide](INSTALLATION.md)** - Setup and environment configuration
- **[Quick Start Guide](QUICKSTART.md)** - Build your first service
- **Specialized Guides** in `doc/`:
  - [Deep Research Guide](docs/deep_research.md)
  - [Financial Supply Guide](docs/fin_supply_readme.md)
  - [Vector Store Guide](docs/vector_store.md)

### Examples & Configuration

- **Examples**: `test/` directory for practical examples
- **Configuration**: `flowllm/config/` for sample configs

### Latest Updates

- **[2025-10]** FlowLLM v0.1.10 - Enhanced async support and stability
- **[2025-09]** Financial data modules with 26+ pre-built flows
- **[2025-09]** Deep research with multiple search backends
- **[2025-08]** MCP (Model Context Protocol) support
- **[2025-06]** Multi-backend vector storage

---


## âš–ï¸ License

Apache License 2.0 - see [LICENSE](./LICENSE) file for details.

---

## ğŸŒŸ Star History

If you find FlowLLM useful, please consider giving it a star!
