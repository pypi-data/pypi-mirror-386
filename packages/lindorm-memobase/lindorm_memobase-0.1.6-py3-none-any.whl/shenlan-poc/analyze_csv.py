#!/usr/bin/env python3
"""
åˆ†æå¹¶æ‰“å°CSVæ–‡ä»¶çš„ç»“æ„
"""
import csv
import json
from typing import Dict, Any
from datetime import datetime


def analyze_csv_structure(csv_file_path: str):
    """åˆ†æCSVæ–‡ä»¶ç»“æ„å¹¶æ‰“å°è¯¦ç»†ä¿¡æ¯"""
    
    print("=" * 80)
    print(f"CSVæ–‡ä»¶ç»“æ„åˆ†æ: {csv_file_path}")
    print("=" * 80)
    
    try:
        with open(csv_file_path, 'r', encoding='utf-8') as file:
            reader = csv.reader(file)
            
            # è¯»å–è¡¨å¤´
            header = next(reader)
            print(f"\nğŸ“‹ è¡¨å¤´ä¿¡æ¯:")
            print(f"åˆ—æ•°: {len(header)}")
            for i, col in enumerate(header):
                print(f"  [{i}] {col}")
            
            # åˆ†æå‰å‡ è¡Œæ•°æ®
            print(f"\nğŸ” æ•°æ®æ ·æœ¬åˆ†æ (å‰5è¡Œ):")
            print("-" * 80)
            
            sample_rows = []
            for row_num, row in enumerate(reader, start=2):
                if row_num > 20:
                    break
                sample_rows.append(row)
            
            for i, row in enumerate(sample_rows):
                print(f"\nç¬¬ {i+2} è¡Œæ•°æ®:")
                print(f"åˆ—æ•°: {len(row)}")
                
                for j, (col_name, value) in enumerate(zip(header, row)):
                    print(f"  [{j}] {col_name}: {repr(value)}")
                
                print("-" * 40)
            
            # ç»Ÿè®¡æ€»ä½“ä¿¡æ¯
            file.seek(0)
            reader = csv.reader(file)
            next(reader)  # è·³è¿‡è¡¨å¤´
            
            total_rows = 0
            valid_rows = 0
            error_rows = 0
            
            for row in reader:
                total_rows += 1
                if len(row) >= 6:
                    response = row[5]
                    if response and not response.startswith('ERROR:') and 'Method Not Allowed' not in response:
                        valid_rows += 1
                    else:
                        error_rows += 1
                
                # åªç»Ÿè®¡å‰1000è¡Œï¼Œé¿å…å¤ªæ…¢
                if total_rows >= 1000:
                    print("  (ä»…ç»Ÿè®¡å‰1000è¡Œ)")
                    break
            
            print(f"  æ€»è¡Œæ•°: {total_rows}")
            print(f"  æœ‰æ•ˆè¡Œæ•°: {valid_rows}")
            print(f"  é”™è¯¯è¡Œæ•°: {error_rows}")
            print(f"  æœ‰æ•ˆç‡: {valid_rows/total_rows*100:.1f}%")
            
            # å­—æ®µç±»å‹åˆ†æ
            print(f"\nğŸ·ï¸  å­—æ®µè¯¦ç»†è¯´æ˜:")
            field_descriptions = [
                ("__source__", "æ¥æºIPåœ°å€"),
                ("__time__", "æ—¶é—´æˆ³"),
                ("__topic__", "ä¸»é¢˜æ ‡è¯†"),
                ("request", "è¯·æ±‚å†…å®¹ (JSONæ ¼å¼)"),
                ("request_ts", "è¯·æ±‚æ—¶é—´æˆ³ (æ¯«ç§’)"),
                ("response", "å“åº”å†…å®¹ (æ–‡æœ¬)"),
                ("response_ts", "å“åº”æ—¶é—´æˆ³ (æ¯«ç§’)"),
                ("stream_id", "æµID")
            ]
            
            for i, (field, desc) in enumerate(field_descriptions):
                if i < len(header):
                    print(f"  [{i}] {field}: {desc}")
    
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    csv_file_path = "./data/shenlandata_converted.csv"
    analyze_csv_structure(csv_file_path)


if __name__ == "__main__":
    main()