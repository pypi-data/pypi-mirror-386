import os
import sys
import re
import time
import json
import requests
import warnings
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.cookie_validator import CookieValidator

# è§£å†³SSLç‰ˆæœ¬è­¦å‘Š
try:
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
except:
    pass
warnings.filterwarnings('ignore')

# åŠ è½½.envæ–‡ä»¶ä¸­çš„æ‰€æœ‰éšç§é…ç½®ï¼ˆCookieã€è·¯å¾„ç­‰ï¼‰
load_dotenv()

# -------------------------- é…ç½®å‚æ•°ï¼ˆéœ€æ ¹æ®æŠ“åŒ…ç»“æœä¿®æ”¹ï¼‰ --------------------------
# 1. ä».envè¯»å–éšç§é…ç½®
OBSIDIAN_NOTES_PATH = os.getenv("OBSIDIAN_PATH", "")
MANUAL_COOKIES = {
    "csrftoken": os.getenv("LEETCODE_CSRFTOKEN", ""),
    "slsession": os.getenv("LEETCODE_SLSSESSION", ""),
    "session": os.getenv("LEETCODE_SESSION", "")
}

# 2. LeetCode GraphQLæ¥å£ï¼ˆé€šå¸¸æ— éœ€ä¿®æ”¹ï¼ŒLeetCodeé€šç”¨ï¼‰
GRAPHQL_API = "https://leetcode.cn/graphql/"

# 3. è¯·æ±‚é—´éš”ï¼ˆé¿å…åçˆ¬ï¼‰
REQUEST_DELAY = 2

# 4. GraphQLæŸ¥è¯¢è¯­å¥ï¼ˆä»æŠ“åŒ…Payloadå¤åˆ¶ï¼Œç¡®ä¿ä¸LeetCodeä¸€è‡´ï¼‰
# ç¬”è®°åˆ—è¡¨æŸ¥è¯¢ - ä½¿ç”¨çœŸå®çš„noteAggregateNoteæŸ¥è¯¢
NOTES_LIST_QUERY = """
query noteAggregateNote($aggregateType: AggregateNoteEnum!, $keyword: String, $orderBy: AggregateNoteSortingOrderEnum, $limit: Int = 100, $skip: Int = 0) {
  noteAggregateNote(aggregateType: $aggregateType, keyword: $keyword, orderBy: $orderBy, limit: $limit, skip: $skip) {
    count
    userNotes {
      config
      content
      id
      noteType
      status
      summary
      targetId
      updatedAt
      ... on NoteAggregateLeetbookNoteNode {
        notePage {
          bookTitle
          coverImg
          linkTemplate
          parentTitle
          title
          __typename
        }
        __typename
      }
      ... on NoteAggregateQuestionNoteNode {
        noteQuestion {
          linkTemplate
          questionFrontendId
          questionId
          title
          translatedTitle
          __typename
        }
        __typename
      }
      __typename
    }
    __typename
  }
}
"""

# ç¬”è®°å†…å®¹æŸ¥è¯¢ï¼ˆå†…å®¹å·²ç»åœ¨åˆ—è¡¨ä¸­è¿”å›äº†ï¼Œä½†ä¿ç•™æ­¤æŸ¥è¯¢ä»¥å¤‡ç”¨ï¼‰
NOTE_CONTENT_QUERY = """
query noteDetail($uuid: String!) {
    note(uuid: $uuid) {
        uuid
        content
        question {
            questionId
            questionFrontendId
            title
            titleSlug
        }
    }
}
"""
# ------------------------------------------------------------------------------

def clean_content(content):
    """æ¸…æ´—å†…å®¹ç”¨äºæ›´æ–°å¯¹æ¯”"""
    return "".join(content.split())

def get_note_problems(session):
    """é€šè¿‡GraphQLæ¥å£è·å–ç¬”è®°åˆ—è¡¨"""
    print("\nğŸ“‹ æ­£åœ¨é€šè¿‡GraphQL APIçˆ¬å–ç¬”è®°é¢˜ç›®åˆ—è¡¨...")
    
    # å°è¯•ä¸åŒç±»å‹çš„ç¬”è®°
    note_types = ["QUESTION_NOTE", "LEETBOOK_NOTE", "ALL"]
    all_problems = []
    
    for note_type in note_types:
        print(f"\nğŸ” å°è¯•è·å–ç±»å‹: {note_type}")
        try:
            skip = 0
            limit = 100  # æ¯æ¬¡è·å–100æ¡
            type_notes = []
            
            while True:
                print(f"   è¯·æ±‚ä¸­ï¼ˆå·²è·å–: {skip}ï¼‰...")
                
                # æ„é€ è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿæµè§ˆå™¨ï¼‰
                headers = {
                    "Content-Type": "application/json",
                    "X-CSRFToken": MANUAL_COOKIES["csrftoken"],
                    "Referer": "https://leetcode.cn/notes/my-notes/",
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
                    "Cookie": f"csrftoken={MANUAL_COOKIES['csrftoken']}; sl-session={MANUAL_COOKIES['slsession']}; LEETCODE_SESSION={MANUAL_COOKIES['session']}"
                }
                
                # æ„é€ GraphQLè¯·æ±‚ä½“
                payload = {
                    "operationName": "noteAggregateNote",
                    "query": NOTES_LIST_QUERY.strip(),
                    "variables": {
                        "aggregateType": note_type,
                        "limit": limit,
                        "skip": skip,
                        "orderBy": "DESCENDING"
                    }
                }
                
                # å‘é€è¯·æ±‚
                response = session.post(
                    GRAPHQL_API,
                    json=payload,
                    headers=headers,
                    timeout=15
                )
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code != 200:
                    print(f"   âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
                    break
                
                # è§£æJSONå“åº”
                try:
                    data = response.json()
                except json.JSONDecodeError:
                    print("   âŒ å“åº”ä¸æ˜¯JSONæ ¼å¼")
                    break
                
                # å¤„ç†GraphQLé”™è¯¯
                if "errors" in data:
                    print(f"   âŒ GraphQLé”™è¯¯ï¼š{data['errors'][0]['message'][:100] if data['errors'] else 'Unknown'}")
                    break
                
                # æå–ç¬”è®°åˆ—è¡¨
                note_data = data.get("data", {}).get("noteAggregateNote", {})
                notes = note_data.get("userNotes", [])
                total = note_data.get("count", 0)
                
                print(f"   ğŸ“ˆ å½“å‰ç±»å‹å…± {total} æ¡ç¬”è®°")
                
                if not notes:
                    break
                
                type_notes.extend(notes)
                print(f"   ç´¯è®¡è·å– {len(type_notes)}/{total} æ¡")
                
                # åˆ¤æ–­æ˜¯å¦ç»§ç»­åˆ†é¡µ
                if len(type_notes) >= total:
                    break
                skip = len(type_notes)  # ä½¿ç”¨å·²è·å–çš„æ•°é‡ä½œä¸ºä¸‹ä¸€æ¬¡çš„skip
                time.sleep(REQUEST_DELAY)
            
            # æå–æœ‰æ•ˆé¢˜ç›®ä¿¡æ¯
            for note in type_notes:
                # å¤„ç†é¢˜ç›®ç¬”è®°
                if note.get("__typename") == "NoteAggregateQuestionNoteNode":
                    question = note.get("noteQuestion", {})
                    if not question:
                        continue
                    
                    # æå–æ ¸å¿ƒå­—æ®µ
                    problem_id = question.get("questionFrontendId")
                    problem_title = question.get("translatedTitle") or question.get("title")
                    # ä» linkTemplate æå– slugï¼Œä¾‹å¦‚: "/problems/two-sum/"
                    link_template = question.get("linkTemplate", "")
                    problem_slug = link_template.strip("/").split("/")[-1] if link_template else ""
                    
                    # ç¬”è®°IDå’Œå†…å®¹
                    note_id = note.get("id")
                    note_content = note.get("content", "")
                    
                    if not (problem_id and problem_title and problem_slug and note_id):
                        print(f"   âš ï¸ è·³è¿‡ä¿¡æ¯ä¸å®Œæ•´çš„ç¬”è®°")
                        continue
                    
                    all_problems.append({
                        "id": str(problem_id),
                        "title": problem_title,
                        "slug": problem_slug,
                        "note_id": str(note_id),
                        "content": note_content
                    })
                    print(f"   ğŸ“Œ å·²è¯†åˆ«ï¼š{problem_id}. {problem_title}")
        
        except Exception as e:
            print(f"   âŒ è·å–{note_type}ç±»å‹ç¬”è®°å¤±è´¥ï¼š{str(e)[:100]}")
            continue
    
    print(f"\nâœ… å…±çˆ¬å–åˆ° {len(all_problems)} ä¸ªæœ‰æ•ˆç¬”è®°é¢˜ç›®")
    return all_problems

def get_note_content(session, note_id):
    """é€šè¿‡GraphQLæ¥å£è·å–å•æ¡ç¬”è®°å†…å®¹"""
    try:
        print(f"ğŸ” æ­£åœ¨è·å–ç¬”è®°{note_id}å†…å®¹...")
        
        headers = {
            "Content-Type": "application/json",
            "X-CSRFToken": MANUAL_COOKIES["csrftoken"],
            "Referer": f"https://leetcode.cn/notes/{note_id}/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/119.0.0.0 Safari/537.36",
            "Cookie": f"csrftoken={MANUAL_COOKIES['csrftoken']}; slsession={MANUAL_COOKIES['slsession']}"
        }
        
        # æ„é€ è¯·æ±‚ä½“
        payload = {
            "query": NOTE_CONTENT_QUERY.strip(),
            "variables": {"uuid": note_id}
        }
        
        # å‘é€è¯·æ±‚
        response = session.post(
            GRAPHQL_API,
            json=payload,
            headers=headers,
            timeout=15
        )
        response.raise_for_status()
        data = response.json()
        
        # å¤„ç†GraphQLé”™è¯¯
        if "errors" in data:
            print(f"âš ï¸ ç¬”è®°å†…å®¹è¯·æ±‚é”™è¯¯ï¼š{data['errors']}")
            return ""
        
        # æå–ç¬”è®°å†…å®¹ï¼ˆä¸å“åº”å­—æ®µå¯¹åº”ï¼‰
        content = data.get("data", {}).get("note", {}).get("content", "").strip()
        return content
    
    except Exception as e:
        print(f"âš ï¸ è·å–ç¬”è®°{note_id}å†…å®¹å¤±è´¥ï¼š{str(e)[:100]}")
        return ""

def crawl_leetcode_notes():
    # éªŒè¯éšç§é…ç½®
    if not OBSIDIAN_NOTES_PATH:
        print("âŒ æœªè¯»å–åˆ°Obsidianè·¯å¾„ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ ï¼š")
        print("   OBSIDIAN_PATH='ä½ çš„ç¬”è®°è·¯å¾„'")
        return
    
    if not (MANUAL_COOKIES["csrftoken"] and MANUAL_COOKIES["slsession"]):
        print("âŒ æœªè¯»å–åˆ°Cookieï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ ï¼š")
        print("   LEETCODE_CSRFTOKEN='ä½ çš„csrftoken'")
        print("   LEETCODE_SLSSESSION='ä½ çš„slsession'")
        return
    
    # ğŸ” éªŒè¯ Cookie æœ‰æ•ˆæ€§ï¼ˆæ–°å¢ï¼‰
    print("\nğŸ” å¼€å§‹éªŒè¯ Cookie æœ‰æ•ˆæ€§...")
    validator = CookieValidator()
    validation_result = validator.validate(verbose=False)
    
    if not validation_result["valid"]:
        print("\n" + "=" * 60)
        print(validation_result["message"])
        print("=" * 60)
        print("\nğŸ”§ å¦‚ä½•æ›´æ–° Cookieï¼š")
        print("   1. æ‰“å¼€æµè§ˆå™¨æ— ç—•æ¨¡å¼")
        print("   2. è®¿é—® https://leetcode.cn/notes/my-notes/")
        print("   3. ç™»å½•ä½ çš„è´¦å·")
        print("   4. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·ï¼Œåˆ‡æ¢åˆ° Network æ ‡ç­¾")
        print("   5. åˆ·æ–°é¡µé¢ï¼Œæ‰¾åˆ° graphql è¯·æ±‚")
        print("   6. å¤åˆ¶ Request Headers ä¸­çš„ Cookie å­—æ®µ")
        print("   7. æ›´æ–° .env æ–‡ä»¶ä¸­çš„å¯¹åº”å€¼\n")
        print("ğŸ“– è¯¦ç»†æ­¥éª¤è¯·å‚è€ƒã€ŠæŠ“åŒ…æŒ‡å—.mdã€‹\n")
        return
    
    print(f"âœ… Cookie éªŒè¯é€šè¿‡ï¼å½“å‰ç”¨æˆ·: {validation_result['user_info']['username']}")
    
    # æ£€æŸ¥ç¬”è®°è®¿é—®æƒé™
    notes_check = validator.check_notes_access(verbose=False)
    if not notes_check["accessible"]:
        print(f"\nâŒ {notes_check['message']}")
        print("è¯·ç¡®è®¤ Cookie å¯¹åº”çš„è´¦å·æœ‰è®¿é—®æƒé™\n")
        return
    
    if notes_check['notes_count'] == 0:
        print(f"âš ï¸ {notes_check['message']}")
        print("å¦‚æœä½ çš„è´¦å·æœ‰ç¬”è®°ä½†è¿™é‡Œæ˜¾ç¤º0æ¡ï¼Œè¯·æ£€æŸ¥ Cookie æ˜¯å¦å¯¹åº”æ­£ç¡®çš„è´¦å·\n")
    else:
        print(f"âœ… ç¬”è®°è®¿é—®æ­£å¸¸ï¼Œæ£€æµ‹åˆ° {notes_check['notes_count']} æ¡ç¬”è®°\n")
    
    # éªŒè¯å¹¶åˆ›å»ºç¬”è®°ç›®å½•
    if not os.path.exists(OBSIDIAN_NOTES_PATH):
        try:
            os.makedirs(OBSIDIAN_NOTES_PATH)
            print(f"âœ… åˆ›å»ºç¬”è®°æ–‡ä»¶å¤¹ï¼š{OBSIDIAN_NOTES_PATH}")
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ›å»ºç¬”è®°æ–‡ä»¶å¤¹ï¼š{e}")
            return
    
    # åˆå§‹åŒ–ä¼šè¯
    session = requests.Session()
    print("âœ… éšç§é…ç½®åŠ è½½å®Œæˆï¼Œå¼€å§‹çˆ¬å–...")

    # è·å–ç¬”è®°åˆ—è¡¨
    problems = get_note_problems(session)
    if not problems:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç¬”è®°ï¼Œç¨‹åºé€€å‡º")
        return

    # åŒæ­¥ç¬”è®°å†…å®¹åˆ°Obsidian
    for i, problem in enumerate(problems):
        problem_id = problem["id"]
        problem_title = problem["title"]
        problem_slug = problem["slug"]
        note_id = problem["note_id"]
        markdown_text = problem.get("content", "")  # å†…å®¹å·²ç»åœ¨åˆ—è¡¨ä¸­è¿”å›
        
        print(f"\nğŸ“ å¤„ç†ç¬¬ {i+1}/{len(problems)} ä¸ªï¼š{problem_id}. {problem_title}")

        # æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…åçˆ¬ï¼ˆè™½ç„¶ä¸å†éœ€è¦è¯·æ±‚ï¼Œä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€ï¼‰
        if i > 0 and i % 10 == 0:
            time.sleep(1)

        # æ£€æŸ¥ç¬”è®°å†…å®¹
        if not markdown_text:
            print(f"âŒ è·³è¿‡ï¼šæœªè·å–åˆ°ç¬”è®°å†…å®¹")
            continue

        # æ„å»ºMarkdownå†…å®¹ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰
        metadata = f"""---
id: {problem_id}
title: {problem_title}
source: https://leetcode.cn/problems/{problem_slug}/
tags: [LeetCode, ç®—æ³•]
---

"""
        new_content = metadata
        new_content += f"# {problem_id}. {problem_title}\n\n"
        new_content += f"## é¢˜ç›®é“¾æ¥\n[{problem_title}](https://leetcode.cn/problems/{problem_slug}/)\n\n"
        new_content += f"## è§£é¢˜ç¬”è®°\n{markdown_text}\n"

        # ä¿å­˜/æ›´æ–°æ–‡ä»¶
        filename = f"{problem_id}. {problem_title}.md"
        filepath = os.path.join(OBSIDIAN_NOTES_PATH, filename)

        if os.path.exists(filepath):
            with open(filepath, "r", encoding="utf-8") as f:
                old_content = f.read()
            if clean_content(new_content) == clean_content(old_content):
                print(f"âœ… æ— æ›´æ–°ï¼Œè·³è¿‡")
                continue
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(new_content)
            print(f"âœ… å·²æ›´æ–°")
        else:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(new_content)
            print(f"âœ… å·²åˆ›å»º")

    print("\nğŸ‰ æ‰€æœ‰ç¬”è®°åŒæ­¥å®Œæˆï¼")

if __name__ == "__main__":
    crawl_leetcode_notes()