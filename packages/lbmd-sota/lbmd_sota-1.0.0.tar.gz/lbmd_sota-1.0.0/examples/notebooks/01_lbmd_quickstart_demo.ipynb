{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBMD SOTA Framework - Interactive Quickstart Demo\n",
    "\n",
    "Welcome to the **Latent Boundary Manifold Decomposition (LBMD)** interactive demonstration! This notebook provides a hands-on introduction to LBMD's core capabilities for mechanistic interpretability in instance segmentation.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "- **Core LBMD Concepts**: Boundary manifolds, neuron responsiveness, and transition analysis\n",
    "- **Practical Usage**: How to analyze your own models and datasets\n",
    "- **Visualization Tools**: Interactive exploration of boundary structures\n",
    "- **Interpretation**: Understanding what LBMD reveals about your models\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- LBMD SOTA Framework installed\n",
    "- 8GB RAM (16GB recommended)\n",
    "- GPU optional but recommended\n",
    "\n",
    "## üöÄ Let's Get Started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LBMD imports\n",
    "from lbmd_sota.core import LBMDConfig\n",
    "from lbmd_sota.empirical_validation import MultiDatasetEvaluator\n",
    "from lbmd_sota.visualization import InteractiveManifoldExplorer\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}  
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 1: Configuration Setup\n",
    "\n",
    "Let's start by setting up the LBMD configuration. This defines how the analysis will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LBMD configuration\n",
    "config_dict = {\n",
    "    'datasets': {\n",
    "        'data_dir': './data',\n",
    "        'cache_dir': './cache',\n",
    "        'batch_size': 4\n",
    "    },\n",
    "    'models': {\n",
    "        'architecture': 'maskrcnn_r50_fpn',\n",
    "        'checkpoint_dir': './models'\n",
    "    },\n",
    "    'lbmd_parameters': {\n",
    "        'k_neurons': 20,        # Top-k boundary-responsive neurons\n",
    "        'epsilon': 0.1,         # Boundary detection threshold\n",
    "        'tau': 0.5,            # Transition strength threshold\n",
    "        'manifold_method': 'umap'  # Manifold learning method\n",
    "    },\n",
    "    'visualization': {\n",
    "        'output_dir': './demo_results',\n",
    "        'interactive': True,\n",
    "        'figure_format': 'png'\n",
    "    },\n",
    "    'computation': {\n",
    "        'device': 'auto',\n",
    "        'mixed_precision': False\n",
    "    }\n",
    "}\n",
    "\n",
    "config = LBMDConfig(config_dict)\n",
    "print(\"‚úÖ Configuration created successfully!\")\n",
    "print(f\"üìä Analysis parameters: k={config.lbmd_parameters.k_neurons}, Œµ={config.lbmd_parameters.epsilon}, œÑ={config.lbmd_parameters.tau}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 2: Load Sample Data\n",
    "\n",
    "For this demo, we'll create synthetic data that mimics real instance segmentation scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_segmentation_data(num_images=3, image_size=224):\n",
    "    \"\"\"Create synthetic segmentation data for demonstration.\"\"\"\n",
    "    synthetic_data = []\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Create base image with gradient background\n",
    "        x, y = np.meshgrid(np.linspace(0, 1, image_size), np.linspace(0, 1, image_size))\n",
    "        \n",
    "        # Create colorful background\n",
    "        image = np.zeros((image_size, image_size, 3))\n",
    "        image[:, :, 0] = 0.3 + 0.4 * x  # Red channel\n",
    "        image[:, :, 1] = 0.2 + 0.5 * y  # Green channel\n",
    "        image[:, :, 2] = 0.4 + 0.3 * (x + y) / 2  # Blue channel\n",
    "        \n",
    "        # Add some noise\n",
    "        noise = np.random.normal(0, 0.05, image.shape)\n",
    "        image = np.clip(image + noise, 0, 1)\n",
    "        \n",
    "        # Create instance mask with multiple objects\n",
    "        mask = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        # Add circular objects\n",
    "        num_objects = np.random.randint(2, 5)\n",
    "        for obj_id in range(1, num_objects + 1):\n",
    "            center_x = np.random.randint(40, image_size - 40)\n",
    "            center_y = np.random.randint(40, image_size - 40)\n",
    "            radius = np.random.randint(15, 35)\n",
    "            \n",
    "            # Create circular mask\n",
    "            yy, xx = np.ogrid[:image_size, :image_size]\n",
    "            circle_mask = (xx - center_x)**2 + (yy - center_y)**2 <= radius**2\n",
    "            mask[circle_mask] = obj_id\n",
    "            \n",
    "            # Add object to image with distinct color\n",
    "            obj_color = np.random.rand(3)\n",
    "            for c in range(3):\n",
    "                image[circle_mask, c] = 0.7 * obj_color[c] + 0.3 * image[circle_mask, c]\n",
    "        \n",
    "        # Convert to uint8 for display\n",
    "        image_uint8 = (image * 255).astype(np.uint8)\n",
    "        synthetic_data.append((image_uint8, mask))\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Create sample data\n",
    "sample_data = create_synthetic_segmentation_data(num_images=3)\n",
    "print(f\"‚úÖ Created {len(sample_data)} synthetic images\")\n",
    "\n",
    "# Visualize the sample data\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Synthetic Sample Data', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (image, mask) in enumerate(sample_data):\n",
    "    # Show original image\n",
    "    axes[0, i].imshow(image)\n",
    "    axes[0, i].set_title(f'Image {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Show instance mask\n",
    "    axes[1, i].imshow(mask, cmap='tab10')\n",
    "    axes[1, i].set_title(f'Instance Mask {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Data statistics:\")\n",
    "for i, (image, mask) in enumerate(sample_data):\n",
    "    num_instances = len(np.unique(mask)) - 1  # Subtract background\n",
    "    print(f\"  Image {i+1}: {num_instances} instances, shape {image.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Step 3: Create Demonstration Model\n",
    "\n",
    "We'll create a simple CNN model to demonstrate LBMD analysis. In practice, you would use pre-trained models like Mask R-CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DemoSegmentationModel(nn.Module):\n",
    "    \"\"\"Simple segmentation model for LBMD demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=80):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone layers\n",
    "        self.backbone = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(3, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Layer 3 - This will be our target layer for LBMD analysis\n",
    "            nn.Conv2d(128, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(256, 512, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Segmentation head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        features = self.backbone(x)\n",
    "        output = self.head(features)\n",
    "        \n",
    "        # Upsample to input resolution\n",
    "        output = F.interpolate(output, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return output\n",
    "\n",
    "# Create and initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DemoSegmentationModel(num_classes=80)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Demo model created and moved to {device}\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Target layer for LBMD analysis: backbone[6] (256 channels)\")\n",
    "\n",
    "# Test model with sample input\n",
    "sample_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(sample_input)\n",
    "print(f\"‚úÖ Model test successful: input {sample_input.shape} ‚Üí output {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 4: Run LBMD Analysis\n",
    "\n",
    "Now let's run the core LBMD analysis to identify boundary-responsive neurons and construct boundary manifolds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbmd_sota.core.data_models import LBMDResults\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_lbmd_analysis(model, image_tensor, target_layer_name='backbone.6'):\n",
    "    \"\"\"Run LBMD analysis on a single image.\"\"\"\n",
    "    \n",
    "    # Hook to capture intermediate features\n",
    "    features = {}\n",
    "    \n",
    "    def hook_fn(name):\n",
    "        def hook(module, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # Register hook on target layer\n",
    "    target_layer = model.backbone[6]  # Conv2d(128, 256, ...)\n",
    "    hook = target_layer.register_forward_hook(hook_fn(target_layer_name))\n",
    "    \n",
    "    try:\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            _ = model(image_tensor)\n",
    "        \n",
    "        # Get features from target layer\n",
    "        layer_features = features[target_layer_name]  # Shape: [1, 256, H, W]\n",
    "        batch_size, num_channels, feat_h, feat_w = layer_features.shape\n",
    "        \n",
    "        # Flatten spatial dimensions\n",
    "        features_flat = layer_features.view(num_channels, -1).cpu().numpy()  # [256, H*W]\n",
    "        \n",
    "        # Step 1: Compute boundary responsiveness scores\n",
    "        # For demo, we'll use activation variance as a proxy for boundary responsiveness\n",
    "        boundary_scores = np.var(features_flat, axis=1)  # Variance across spatial locations\n",
    "        \n",
    "        # Normalize scores\n",
    "        boundary_scores = (boundary_scores - boundary_scores.min()) / (boundary_scores.max() - boundary_scores.min())\n",
    "        \n",
    "        # Step 2: Select top-k boundary-responsive neurons\n",
    "        k = config.lbmd_parameters.k_neurons\n",
    "        top_k_indices = np.argsort(boundary_scores)[-k:]\n",
    "        top_k_features = features_flat[top_k_indices]  # [k, H*W]\n",
    "        \n",
    "        # Step 3: Create boundary mask\n",
    "        # Use high-activation regions as boundary proxy\n",
    "        activation_map = np.mean(top_k_features, axis=0).reshape(feat_h, feat_w)\n",
    "        threshold = np.percentile(activation_map, 80)  # Top 20% activations\n",
    "        boundary_mask_small = activation_map > threshold\n",
    "        \n",
    "        # Upsample boundary mask to original image size\n",
    "        boundary_mask = np.kron(boundary_mask_small, np.ones((8, 8)))  # Simple upsampling\n",
    "        if boundary_mask.shape[0] > 224:\n",
    "            boundary_mask = boundary_mask[:224, :224]\n",
    "        elif boundary_mask.shape[0] < 224:\n",
    "            pad_h = 224 - boundary_mask.shape[0]\n",
    "            pad_w = 224 - boundary_mask.shape[1]\n",
    "            boundary_mask = np.pad(boundary_mask, ((0, pad_h), (0, pad_w)), mode='constant')\n",
    "        \n",
    "        # Step 4: Manifold learning\n",
    "        # Sample points for manifold construction\n",
    "        n_sample_points = min(1000, top_k_features.shape[1])\n",
    "        sample_indices = np.random.choice(top_k_features.shape[1], n_sample_points, replace=False)\n",
    "        sampled_features = top_k_features[:, sample_indices].T  # [n_sample_points, k]\n",
    "        \n",
    "        # Apply t-SNE for 2D manifold\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, n_sample_points-1))\n",
    "        manifold_coords = tsne.fit_transform(sampled_features)\n",
    "        \n",
    "        # Step 5: Clustering\n",
    "        n_clusters = min(5, n_sample_points // 50)  # Adaptive number of clusters\n",
    "        if n_clusters < 2:\n",
    "            n_clusters = 2\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(manifold_coords)\n",
    "        \n",
    "        # Step 6: Compute pixel coordinates for sampled points\n",
    "        pixel_coords = np.array([\n",
    "            [idx // feat_w * 8, idx % feat_w * 8]  # Map back to approximate pixel coordinates\n",
    "            for idx in sample_indices\n",
    "        ])\n",
    "        \n",
    "        # Ensure pixel coordinates are within image bounds\n",
    "        pixel_coords = np.clip(pixel_coords, 0, 223)\n",
    "        \n",
    "        # Step 7: Determine boundary flags\n",
    "        is_boundary = np.array([\n",
    "            boundary_mask[coord[0], coord[1]] for coord in pixel_coords\n",
    "        ])\n",
    "        \n",
    "        # Step 8: Compute transition strengths between clusters\n",
    "        transition_strengths = {}\n",
    "        for i in range(n_clusters):\n",
    "            for j in range(i+1, n_clusters):\n",
    "                # Simple distance-based transition strength\n",
    "                cluster_i_points = manifold_coords[clusters == i]\n",
    "                cluster_j_points = manifold_coords[clusters == j]\n",
    "                \n",
    "                if len(cluster_i_points) > 0 and len(cluster_j_points) > 0:\n",
    "                    # Compute minimum distance between clusters\n",
    "                    min_dist = np.inf\n",
    "                    for pi in cluster_i_points:\n",
    "                        for pj in cluster_j_points:\n",
    "                            dist = np.linalg.norm(pi - pj)\n",
    "                            min_dist = min(min_dist, dist)\n",
    "                    \n",
    "                    # Convert distance to strength (closer = stronger transition)\n",
    "                    transition_strength = np.exp(-min_dist / 2.0)\n",
    "                    transition_strengths[(i, j)] = transition_strength\n",
    "        \n",
    "        # Create LBMD results\n",
    "        results = LBMDResults(\n",
    "            layer_name=target_layer_name,\n",
    "            boundary_scores=boundary_scores[top_k_indices],\n",
    "            boundary_mask=boundary_mask,\n",
    "            manifold_coords=manifold_coords,\n",
    "            pixel_coords=pixel_coords,\n",
    "            is_boundary=is_boundary,\n",
    "            clusters=clusters,\n",
    "            transition_strengths=transition_strengths,\n",
    "            cluster_hulls={},  # We'll skip convex hulls for simplicity\n",
    "            statistical_metrics=None,\n",
    "            topological_properties=None\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    finally:\n",
    "        # Remove hook\n",
    "        hook.remove()\n",
    "\n",
    "# Run LBMD analysis on sample images\n",
    "lbmd_results = []\n",
    "\n",
    "print(\"üîç Running LBMD analysis...\")\n",
    "for i, (image, mask) in enumerate(sample_data):\n",
    "    # Convert image to tensor\n",
    "    image_tensor = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Run analysis\n",
    "    results = run_lbmd_analysis(model, image_tensor)\n",
    "    lbmd_results.append(results)\n",
    "    \n",
    "    print(f\"  ‚úÖ Image {i+1}: {len(results.boundary_scores)} boundary neurons, \"\n",
    "          f\"{len(np.unique(results.clusters))} clusters, \"\n",
    "          f\"{np.sum(results.is_boundary)} boundary points\")\n",
    "\n",
    "print(f\"\\n‚úÖ LBMD analysis completed for {len(lbmd_results)} images!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}