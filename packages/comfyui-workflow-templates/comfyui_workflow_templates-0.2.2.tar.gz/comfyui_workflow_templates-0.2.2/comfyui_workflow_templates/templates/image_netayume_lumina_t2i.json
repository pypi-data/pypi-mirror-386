{
  "id": "9ae6082b-c7f4-433c-9971-7a8f65a3ea65",
  "revision": 0,
  "last_node_id": 21,
  "last_link_id": 18,
  "nodes": [
    {
      "id": 13,
      "type": "EmptySD3LatentImage",
      "pos": [
        70,
        390
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            17
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 17,
      "type": "MarkdownNote",
      "pos": [
        60,
        560
      ],
      "size": [
        340,
        100
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Note: Image size",
      "properties": {},
      "widgets_values": [
        "This model is best at 1024x1024, but you can try higher like 1024x1536"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 11,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        890,
        170
      ],
      "size": [
        310,
        60
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 12
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            13
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "ModelSamplingAuraFlow"
      },
      "widgets_values": [
        4
      ]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        70,
        200
      ],
      "size": [
        315,
        98
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            12
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            3,
            5
          ]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "CheckpointLoaderSimple",
        "models": [
          {
            "name": "NetaYumev35_pretrained_all_in_one.safetensors",
            "url": "https://huggingface.co/duongve/NetaYume-Lumina-Image-2.0/resolve/main/NetaYumev35_pretrained_all_in_one.safetensors",
            "directory": "checkpoints"
          }
        ]
      },
      "widgets_values": [
        "NetaYumev35_pretrained_all_in_one.safetensors"
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        890,
        270
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 13
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            14
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        942500763821827,
        "randomize",
        30,
        4,
        "res_multistep",
        "simple",
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        890,
        580
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 14
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1230,
        170
      ],
      "size": [
        820,
        850
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 16
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64"
      },
      "widgets_values": [
        "NetaYume_Lumina_3.5"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        200
      ],
      "size": [
        423.83001708984375,
        177.11770629882812
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "You are an assistant designed to generate high quality anime images based on textual prompts. <Prompt Start> @comfyanonymous, \"Warm and cheerful digital illustration of a girl standing in the middle of an orange grove, surrounded by lush green leaves and ripe, vibrant oranges hanging from the trees. She has chestnut-brown hair tied in a single loose braid draped over her shoulder, with soft bangs framing her bright, smiling face.\n Her expression is full of joy and sunshineâ€”eyes squinting slightly, mouth open in a wide, carefree smile, radiating pure happiness. She wears a crisp white blouse underneath a black jacket, slightly unbuttoned for a relaxed look. The sunlight filters through the leaves above, casting dappled golden light on her hair and shoulders, creating a warm, inviting atmosphere.\n  A few oranges hang close to her head, and one or two lie on the ground around her feet. The background features soft-focus trees stretching into the distance, with sunlight breaking through the foliage. The art style is painterly and soft, emphasizing the natural setting and the girl's radiant, wholesome charm.\""
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        410
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "You are an assistant designed to generate low-quality images based on textual prompts <Prompt Start> blurry, worst quality, low quality, jpeg artifacts, signature, watermark, username, error, deformed hands, bad anatomy, extra limbs, poorly drawn hands, poorly drawn face, mutation, deformed, extra eyes, extra arms, extra legs, malformed limbs, fused fingers, too many fingers, long neck, cross-eyed, bad proportions, missing arms, missing legs, extra digit, fewer digits, cropped"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 18,
      "type": "MarkdownNote",
      "pos": [
        410,
        0
      ],
      "size": [
        440,
        120
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Note: Prompt",
      "properties": {},
      "widgets_values": [
        "Check the prompt book [here](https://nieta-art.feishu.cn/wiki/RY3GwpT59icIQlkWXEfcCqIMnQd)\n\nYou should keep the prefix part fixed until the **Prompt Start** tag\n\n@whatever in the prompt is for artist tags, such as @comfyanonymous\n\nYou can find more artist tags [here](https://gumgum10.github.io/gumgum.github.io/)\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 16,
      "type": "MarkdownNote",
      "pos": [
        -380,
        160
      ],
      "size": [
        420,
        400
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Note: About NetaYume Lumina",
      "properties": {},
      "widgets_values": [
        "## About NetaYume Lumina\n\n[NetaYume Lumina](https://civitai.com/models/1790792) is a **text-to-image** model fine-tuned from [Neta Lumina](https://huggingface.co/neta-art/Neta-Lumina), a high-quality anime-style image generation model developed by [**Neta.art Lab**](https://huggingface.co/neta-art). It builds upon [**Lumina-Image-2.0**,](https://huggingface.co/Alpha-VLLM/Lumina-Image-2.0) an open-source base model released by the [**Alpha-VLLM team**](https://huggingface.co/Alpha-VLLM) at Shanghai AI Laboratory.\n\n\n- [Style Reference Sheet](https://neta-lumina-style.tz03.xyz/)\n- [Prompt book](https://nieta-art.feishu.cn/wiki/RY3GwpT59icIQlkWXEfcCqIMnQd)\n\n\n**Key Features:**\n\n- **High-Quality Anime Generation:** Generates detailed anime-style images with sharp outlines, vibrant colors, and smooth shading.\n- **Improved Character Understanding:** Better captures characters, especially those from the Danbooru dataset, resulting in more coherent and accurate character representations.\n- **Enhanced Fine Details:** Accurately generates accessories, clothing textures, hairstyles, and background elements with greater clarity.\n\n\n## Model link\n\n\nDownload this file: [NetaYumev35_pretrained_all_in_one.safetensors](https://huggingface.co/duongve/NetaYume-Lumina-Image-2.0/resolve/main/NetaYumev35_pretrained_all_in_one.safetensors) \n\nThen place it in the **ComfyUI/models/checkpoints** folder."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 19,
      "type": "MarkdownNote",
      "pos": [
        1240,
        30
      ],
      "size": [
        450,
        88
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Note: Output files",
      "properties": {},
      "widgets_values": [
        "The output image will be saved in the `ComfyUI/outputs` folder.q"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      3,
      4,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      5,
      4,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      8,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      12,
      4,
      0,
      11,
      0,
      "MODEL"
    ],
    [
      13,
      11,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      14,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      16,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      17,
      13,
      0,
      3,
      3,
      "LATENT"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load model",
      "bounding": [
        60,
        130,
        340,
        180
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2 - Image size",
      "bounding": [
        60,
        320,
        340,
        190
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        410,
        130,
        445.27801513671875,
        474.2060852050781
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.587994762372824,
      "offset": [
        450.21032258050616,
        169.58047369730693
      ]
    },
    "frontendVersion": "1.27.10",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}