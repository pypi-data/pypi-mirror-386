[
  {
    "moduleName": "default",
    "isEssential": true,
    "title": "Getting Started",
    "type": "image",
    "templates": [
      {
        "name": "01_qwen_t2i_subgraphed",
        "title": "Text to Image[New]",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from text prompts using the Qwen-Image model",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "tags": ["Text to Image", "Image"],
        "models": ["Qwen-Image"],
        "date": "2025-10-17",
        "size": 29.59
      },
      {
        "name": "02_qwen_Image_edit_subgraphed",
        "title": "Image Editing[New]",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Edit your images with Qwen-Image-Edit, the latest OSS model",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit",
        "tags": ["Image to Image", "Image Edit", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-10-17",
        "size": 29.59
      },
      {
        "name": "03_video_wan2_2_14B_i2v_subgraphed",
        "title": "Image to Video[New]",
        "description": "Generate videos from an input image using Wan2.2 14B",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Image to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-10-17",
        "size": 35.42
      },
      {
        "name": "04_hunyuan_3d_2.1_subgraphed",
        "title": "Image to 3D[New]",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D models from single images using Hunyuan3D 2.1.",
        "tags": ["Image to 3D", "3D"],
        "models": ["Hunyuan3D"],
        "date": "2025-10-17",
        "tutorialUrl": "https://docs.comfy.org/tutorials/3d/hunyuan3D-2",
        "size": 4.59
      },
      {
        "name": "05_audio_ace_step_1_t2a_song_subgraphed",
        "title": "Text to Song[New]",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate songs from text prompts using ACE-Step v1",
        "tags": ["Text to Audio", "Audio"],
        "models": ["ACE-Step"],
        "date": "2025-10-17",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      },
      {
        "name": "default",
        "title": "Image Generation",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from text prompts.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/text-to-image",
        "tags": ["Text to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 1.99,
        "vram": 2.88
      },
      {
        "name": "image2image",
        "title": "Image to Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Transform existing images using text prompts.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/image-to-image",
        "tags": ["Image to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 1.99,
        "vram": 2.88
      },
      {
        "name": "lora",
        "title": "LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with LoRA models for specialized styles or subjects.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Text to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2.27,
        "vram": 2.88
      },
      {
        "name": "lora_multiple",
        "title": "LoRA Multiple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by combining multiple LoRA models.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Text to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2.27,
        "vram": 3.12
      },
      {
        "name": "inpaint_example",
        "title": "Inpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Edit specific parts of images seamlessly.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Inpainting", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 4.86,
        "vram": 3.82
      },
      {
        "name": "inpaint_model_outpainting",
        "title": "Outpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Extend images beyond their original boundaries.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Outpainting", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 4.86,
        "vram": 3.82
      },
      {
        "name": "embedding_example",
        "title": "Embedding",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images using textual inversion for consistent styles.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/",
        "tags": ["Text to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 4.86,
        "vram": 3.84
      },
      {
        "name": "gligen_textbox_example",
        "title": "Gligen Textbox",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with precise object placement using text boxes.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/gligen/",
        "tags": ["Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2.77,
        "vram": 3.8
      },
      {
        "name": "area_composition",
        "title": "Area Composition",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by controlling composition with defined areas.",
        "tags": ["Text to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/",
        "size": 2.3,
        "vram": 5.76
      },
      {
        "name": "area_composition_square_area_for_subject",
        "title": "Area Composition Square Area for Subject",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with consistent subject placement using area composition.",
        "tags": ["Text to Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/#increasing-consistency-of-images-with-area-composition",
        "size": 2.3,
        "vram": 5.52
      },
      {
        "name": "hiresfix_latent_workflow",
        "title": "Upscale",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale images by enhancing quality in latent space.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/",
        "size": 1.99,
        "vram": 3.66
      },
      {
        "name": "esrgan_example",
        "title": "ESRGAN",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale images using ESRGAN models to enhance quality.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/",
        "size": 2.05,
        "vram": 6.0
      },
      {
        "name": "hiresfix_esrgan_workflow",
        "title": "HiresFix ESRGAN Workflow",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale images using ESRGAN models during intermediate generation steps.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#non-latent-upscaling",
        "size": 2.05,
        "vram": 6.0
      },
      {
        "name": "latent_upscale_different_prompt_model",
        "title": "Latent Upscale Different Prompt Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale images while changing prompts across generation passes.",
        "thumbnailVariant": "zoomHover",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#more-examples",
        "size": 3.97,
        "vram": 4.8
      },
      {
        "name": "controlnet_example",
        "title": "Scribble ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by scribble reference images using ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/",
        "size": 2.97,
        "vram": 6.0
      },
      {
        "name": "2_pass_pose_worship",
        "title": "Pose ControlNet 2 Pass",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by pose references using ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#pose-controlnet",
        "size": 4.34,
        "vram": 6.0
      },
      {
        "name": "depth_controlnet",
        "title": "Depth ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by depth information using ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image", "Text to Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets",
        "size": 2.69,
        "vram": 6.0
      },
      {
        "name": "depth_t2i_adapter",
        "title": "Depth T2I Adapter",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by depth information using T2I adapter.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image", "Text to Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets",
        "size": 2.35,
        "vram": 6.0
      },
      {
        "name": "mixing_controlnets",
        "title": "Mixing ControlNets",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by combining multiple ControlNet models.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image", "Text to Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#mixing-controlnets",
        "size": 3.1,
        "vram": 6.0
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--image]",
    "title": "Image",
    "type": "image",
    "templates": [
      {
        "name": "image_qwen_image",
        "title": "Qwen-Image Text to Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with exceptional multilingual text rendering and editing capabilities using Qwen-Image's 20B MMDiT model..",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "tags": ["Text to Image", "Image"],
        "models": ["Qwen-Image"],
        "date": "2025-08-05",
        "size": 29.59
      },
      {
        "name": "image_qwen_image_instantx_controlnet",
        "title": "Qwen-Image InstantX Union ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with Qwen-Image InstantX ControlNet, supporting canny, soft edge, depth, pose",
        "tags": ["Image to Image", "Image", "ControlNet"],
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "models": ["Qwen-Image"],
        "date": "2025-08-23",
        "size": 32.88
      },
      {
        "name": "image_qwen_image_instantx_inpainting_controlnet",
        "title": "Qwen-Image InstantX Inpainting ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Professional inpainting and image editing with Qwen-Image InstantX ControlNet. Supports object replacement, text modification, background changes, and outpainting.",
        "tags": ["Image to Image", "Image", "ControlNet", "Inpainting"],
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "models": ["Qwen-Image"],
        "date": "2025-09-12",
        "size": 33.54
      },
      {
        "name": "image_qwen_image_union_control_lora",
        "title": "Qwen-Image Union Control",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with precise structural control using Qwen-Image's unified ControlNet LoRA. Supports multiple control types including canny, depth, lineart, softedge, normal, and openpose for diverse creative applications.",
        "tags": ["Text to Image", "Image", "ControlNet"],
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "models": ["Qwen-Image"],
        "date": "2025-08-23",
        "size": 30.47
      },
      {
        "name": "image_qwen_image_controlnet_patch",
        "title": "Qwen-Image ControlNet model patch",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Control image generation using Qwen-Image ControlNet models. Supports canny, depth, and inpainting controls through model patching.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "tags": ["Text to Image", "Image", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-08-24",
        "size": 31.7
      },
      {
        "name": "image_qwen_image_edit_2509",
        "title": "Qwen Image Edit 2509",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Advanced image editing with multi-image support, improved consistency, and ControlNet integration.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit",
        "tags": ["Image to Image", "Image Edit", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-09-25",
        "size": 29.59
      },
      {
        "name": "image_qwen_image_edit",
        "title": "Qwen Image Edit",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Edit images with precise bilingual text editing and dual semantic/appearance editing capabilities using Qwen-Image-Edit's 20B MMDiT model.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit",
        "tags": ["Image to Image", "Image Edit"],
        "models": ["Qwen-Image"],
        "date": "2025-08-18",
        "size": 29.59
      },
      {
        "name": "flux_kontext_dev_basic",
        "title": "Flux Kontext Dev Image Edit",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Smart image editing that keeps characters consistent, edits specific parts without affecting others, and preserves original styles.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-kontext-dev",
        "tags": ["Image Edit", "Image to Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-06-26",
        "size": 16.43,
        "vram": 18.0
      },
      {
        "name": "image_chroma1_radiance_text_to_image",
        "title": "Chroma1 Radiance text to image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Chroma1-Radiance works directly with image pixels instead of compressed latents, delivering higher quality images with reduced artifacts and distortion.",
        "tags": ["Text to Image", "Image"],
        "models": ["Chroma"],
        "date": "2025-09-18",
        "size": 22.0,
        "vram": 22.0
      },
      {
        "name": "image_netayume_lumina_t2i",
        "title": "NetaYume Lumina Text to Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "High-quality anime-style image generation with enhanced character understanding and detailed textures. Fine-tuned from Neta Lumina on Danbooru dataset.",
        "tags": ["Text to Image", "Image", "Anime"],
        "models": ["OmniGen"],
        "date": "2025-10-10",
        "size": 9.89
      },
      {
        "name": "image_chroma_text_to_image",
        "title": "Chroma text to image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Chroma - enhanced Flux model with improved image quality and better prompt understanding for stunning text-to-image generation.",
        "tags": ["Text to Image", "Image"],
        "models": ["Chroma", "Flux"],
        "date": "2025-06-04",
        "size": 21.69,
        "vram": 14.5
      },
      {
        "name": "image_flux.1_fill_dev_OneReward",
        "title": "Flux.1 Dev OneReward",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Supports various tasks such as image inpainting, outpainting, and object removal by bytedance-research team",
        "tags": ["Inpainting", "Outpainting"],
        "models": ["Flux", "BFL"],
        "date": "2025-09-21",
        "size": 27.01,
        "vram": 20.0
      },
      {
        "name": "flux_dev_checkpoint_example",
        "title": "Flux Dev fp8",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images using Flux Dev fp8 quantized version. Suitable for devices with limited VRAM, requires only one model file, but image quality is slightly lower than the full version.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Text to Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 16.06,
        "vram": 17.0
      },
      {
        "name": "flux1_dev_uso_reference_image_gen",
        "title": "Flux.1 Dev USO Reference Image Generation",
        "description": "Use reference images to control both style and subject - keep your character's face while changing artistic style, or apply artistic styles to new scenes",
        "thumbnailVariant": "hoverDissolve",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-09-02",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-uso",
        "size": 17.32,
        "vram": 18.5
      },
      {
        "name": "flux_schnell",
        "title": "Flux Schnell fp8",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Quickly generate images with Flux Schnell fp8 quantized version. Ideal for low-end hardware, requires only 4 steps to generate images.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Text to Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 16.05,
        "vram": 17.0
      },
      {
        "name": "flux1_krea_dev",
        "title": "Flux.1 Krea Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "A fine-tuned FLUX model pushing photorealism to the max",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux1-krea-dev",
        "tags": ["Text to Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-07-31",
        "size": 20.74,
        "vram": 21.5
      },
      {
        "name": "flux_dev_full_text_to_image",
        "title": "Flux Dev full text to image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate high-quality images with Flux Dev full version. Requires larger VRAM and multiple model files, but provides the best prompt following capability and image quality.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Text to Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 31.83,
        "vram": 22.0
      },
      {
        "name": "flux_schnell_full_text_to_image",
        "title": "Flux Schnell full text to image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images quickly with Flux Schnell full version. Uses Apache2.0 license, requires only 4 steps to generate images while maintaining good image quality.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Text to Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 31.81
      },
      {
        "name": "flux_fill_inpaint_example",
        "title": "Flux Inpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Fill missing parts of images using Flux inpainting.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-fill-dev",
        "tags": ["Image to Image", "Inpainting", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 9.66
      },
      {
        "name": "flux_fill_outpaint_example",
        "title": "Flux Outpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Extend images beyond boundaries using Flux outpainting.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-fill-dev",
        "tags": ["Outpainting", "Image", "Image to Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 9.66
      },
      {
        "name": "flux_canny_model_example",
        "title": "Flux Canny Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by edge detection using Flux Canny.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image to Image", "ControlNet", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 31.83
      },
      {
        "name": "flux_depth_lora_example",
        "title": "Flux Depth Lora",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by depth information using Flux LoRA.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image to Image", "ControlNet", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 32.98
      },
      {
        "name": "flux_redux_model_example",
        "title": "Flux Redux Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by transferring style from reference images using Flux Redux.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image to Image", "ControlNet", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-03-01",
        "size": 32.74
      },
      {
        "name": "image_omnigen2_t2i",
        "title": "OmniGen2 Text to Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate high-quality images from text prompts using OmniGen2's unified 7B multimodal model with dual-path architecture.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/omnigen/omnigen2",
        "tags": ["Text to Image", "Image"],
        "models": ["OmniGen"],
        "date": "2025-06-30",
        "size": 14.7
      },
      {
        "name": "image_omnigen2_image_edit",
        "title": "OmniGen2 Image Edit",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Edit images with natural language instructions using OmniGen2's advanced image editing capabilities and text rendering support.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/omnigen/omnigen2",
        "tags": ["Image Edit", "Image"],
        "models": ["OmniGen"],
        "date": "2025-06-30",
        "size": 14.7
      },
      {
        "name": "hidream_i1_dev",
        "title": "HiDream I1 Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with HiDream I1 Dev - Balanced version with 28 inference steps, suitable for medium-range hardware.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Text to Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17",
        "size": 31.03
      },
      {
        "name": "hidream_i1_fast",
        "title": "HiDream I1 Fast",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images quickly with HiDream I1 Fast - Lightweight version with 16 inference steps, ideal for rapid previews on lower-end hardware.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Text to Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17",
        "size": 22.57
      },
      {
        "name": "hidream_i1_full",
        "title": "HiDream I1 Full",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with HiDream I1 Full - Complete version with 50 inference steps for highest quality output.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Text to Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17",
        "size": 22.57
      },
      {
        "name": "hidream_e1_1",
        "title": "HiDream E1.1 Image Edit",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Edit images with HiDream E1.1 – it’s better in image quality and editing accuracy than HiDream-E1-Full.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-e1",
        "tags": ["Image Edit", "Image"],
        "models": ["HiDream"],
        "date": "2025-07-21",
        "size": 46.96
      },
      {
        "name": "hidream_e1_full",
        "title": "HiDream E1 Image Edit",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Edit images with HiDream E1 - Professional natural language image editing model.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-e1",
        "tags": ["Image Edit", "Image"],
        "models": ["HiDream"],
        "date": "2025-05-01",
        "size": 31.86
      },
      {
        "name": "sd3.5_simple_example",
        "title": "SD3.5 Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images using SD 3.5.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35",
        "tags": ["Text to Image", "Image"],
        "models": ["SD3.5", "Stability"],
        "date": "2025-03-01",
        "size": 13.91
      },
      {
        "name": "sd3.5_large_canny_controlnet_example",
        "title": "SD3.5 Large Canny ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by edge detection using SD 3.5 Canny ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image to Image", "Image", "ControlNet"],
        "models": ["SD3.5", "Stability"],
        "date": "2025-03-01",
        "size": 21.97
      },
      {
        "name": "sd3.5_large_depth",
        "title": "SD3.5 Large Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by depth information using SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image to Image", "Image", "ControlNet"],
        "models": ["SD3.5", "Stability"],
        "date": "2025-03-01",
        "size": 21.97
      },
      {
        "name": "sd3.5_large_blur",
        "title": "SD3.5 Large Blur",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images guided by blurred reference images using SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image to Image", "Image"],
        "models": ["SD3.5", "Stability"],
        "date": "2025-03-01",
        "size": 21.97
      },
      {
        "name": "sdxl_simple_example",
        "title": "SDXL Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate high-quality images using SDXL.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/",
        "tags": ["Text to Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 12.12
      },
      {
        "name": "sdxl_refiner_prompt_example",
        "title": "SDXL Refiner Prompt",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Enhance SDXL images using refiner models.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/",
        "tags": ["Text to Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 12.12
      },
      {
        "name": "sdxl_revision_text_prompts",
        "title": "SDXL Revision Text Prompts",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by transferring concepts from reference images using SDXL Revision.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/#revision",
        "tags": ["Text to Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 9.9
      },
      {
        "name": "sdxlturbo_example",
        "title": "SDXL Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images in a single step using SDXL Turbo.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/",
        "tags": ["Text to Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 6.46
      },
      {
        "name": "image_lotus_depth_v1_1",
        "title": "Lotus Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Run Lotus Depth in ComfyUI for zero-shot, efficient monocular depth estimation with high detail retention.",
        "tags": ["Image", "Text to Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-05-21",
        "size": 1.93
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "GENERATION TYPE",
    "title": "Video",
    "icon": "icon-[lucide--film]",
    "type": "video",
    "templates": [
      {
        "name": "video_wan2_2_14B_t2v",
        "title": "Wan 2.2 14B Text to Video",
        "description": "Generate high-quality videos from text prompts with cinematic aesthetic control and dynamic motion generation using Wan 2.2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_i2v",
        "title": "Wan 2.2 14B Image to Video",
        "description": "Transform static images into dynamic videos with precise motion control and style preservation using Wan 2.2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Image to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_flf2v",
        "title": "Wan 2.2 14B First-Last Frame to Video",
        "description": "Generate smooth video transitions by defining start and end frames.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["FLF2V", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-02",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_animate",
        "title": "Wan2.2 Animate, character animation and replacement",
        "description": "Unified character animation and replacement framework with precise motion and expression replication.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-animate",
        "tags": ["Video", "Image to Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-09-22",
        "size": 25.535
      },
      {
        "name": "video_wan2_2_14B_s2v",
        "title": "Wan2.2-S2V Audio-Driven Video Generation",
        "description": "Transform static images and audio into dynamic videos with perfect synchronization and minute-level generation.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-s2v",
        "tags": ["Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-02",
        "size": 23.52
      },
      {
        "name": "video_humo",
        "title": "HuMo Video Generation",
        "description": "Generate videos basic on audio, image, and text, keep the character's lip sync.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video"],
        "models": ["HuMo"],
        "date": "2025-09-21",
        "size": 25.98
      },
      {
        "name": "video_wan2_2_14B_fun_inpaint",
        "title": "Wan 2.2 14B Fun Inp",
        "description": "Generate videos from start and end frames using Wan 2.2 Fun Inp.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-inp",
        "tags": ["FLF2V", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-12",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_fun_control",
        "title": "Wan 2.2 14B Fun Control",
        "description": "Generate videos guided by pose, depth, and edge controls using Wan 2.2 Fun Control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-control",
        "tags": ["Video to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-12",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_fun_camera",
        "title": "Wan 2.2 14B Fun Camera Control",
        "description": "Generate videos with camera motion controls including pan, zoom, and rotation using Wan 2.2 Fun Camera Control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-camera",
        "tags": ["Video to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-17",
        "size": 37.3
      },
      {
        "name": "video_wan2_2_5B_ti2v",
        "title": "Wan 2.2 5B Video Generation",
        "description": "Fast text-to-video and image-to-video generation with 5B parameters. Optimized for rapid prototyping and creative exploration.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 16.9
      },
      {
        "name": "video_wan2_2_5B_fun_inpaint",
        "title": "Wan 2.2 5B Fun Inpaint",
        "description": "Efficient video inpainting from start and end frames. 5B model delivers quick iterations for testing workflows.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 16.9
      },
      {
        "name": "video_wan2_2_5B_fun_control",
        "title": "Wan 2.2 5B Fun Control",
        "description": "Multi-condition video control with pose, depth, and edge guidance. Compact 5B size for experimental development.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 16.9
      },
      {
        "name": "video_wan_vace_14B_t2v",
        "title": "Wan2.1 VACE Text to Video",
        "description": "Transform text descriptions into high-quality videos. Supports both 480p and 720p with VACE-14B model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_14B_ref2v",
        "title": "Wan2.1 VACE Reference to Video",
        "description": "Create videos that match the style and content of a reference image. Perfect for style-consistent video generation.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Video", "Image to Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_14B_v2v",
        "title": "Wan2.1 VACE Control Video",
        "description": "Generate videos by controlling input videos and reference images using Wan VACE.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Video to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_outpainting",
        "title": "Wan2.1 VACE Outpainting",
        "description": "Generate extended videos by expanding video size using Wan VACE outpainting.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Outpainting", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_flf2v",
        "title": "Wan2.1 VACE First-Last Frame",
        "description": "Generate smooth video transitions by defining start and end frames. Supports custom keyframe sequences.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["FLF2V", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_inpainting",
        "title": "Wan2.1 VACE Inpainting",
        "description": "Edit specific regions in videos while preserving surrounding content. Great for object removal or replacement.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Inpainting", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan2.1_alpha_t2v_14B",
        "title": "Wan2.1 Alpha T2V",
        "description": "Generate text-to-video with alpha channel support for transparent backgrounds and semi-transparent objects.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-10-06",
        "size": 20.95
      },
      {
        "name": "video_wan_ati",
        "title": "Wan2.1 ATI",
        "description": "Trajectory-controlled video generation.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-ati",
        "tags": ["Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 23.65
      },
      {
        "name": "video_wan2.1_fun_camera_v1.1_1.3B",
        "title": "Wan 2.1 Fun Camera 1.3B",
        "description": "Generate dynamic videos with cinematic camera movements using Wan 2.1 Fun Camera 1.3B model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 10.7
      },
      {
        "name": "video_wan2.1_fun_camera_v1.1_14B",
        "title": "Wan 2.1 Fun Camera 14B",
        "description": "Generate high-quality videos with advanced camera control using the full 14B model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 39.16
      },
      {
        "name": "text_to_video_wan",
        "title": "Wan 2.1 Text to Video",
        "description": "Generate videos from text prompts using Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-video",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-03-01",
        "size": 9.15
      },
      {
        "name": "image_to_video_wan",
        "title": "Wan 2.1 Image to Video",
        "description": "Generate videos from images using Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-video",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-03-01",
        "size": 38.23
      },
      {
        "name": "wan2.1_fun_inp",
        "title": "Wan 2.1 Inpainting",
        "description": "Generate videos from start and end frames using Wan 2.1 inpainting.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-inp",
        "tags": ["Inpainting", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 10.6
      },
      {
        "name": "wan2.1_fun_control",
        "title": "Wan 2.1 ControlNet",
        "description": "Generate videos guided by pose, depth, and edge controls using Wan 2.1 ControlNet.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Video to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 10.6
      },
      {
        "name": "wan2.1_flf2v_720_f16",
        "title": "Wan 2.1 FLF2V 720p F16",
        "description": "Generate videos by controlling first and last frames using Wan 2.1 FLF2V.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-flf",
        "tags": ["FLF2V", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 38.23
      },
      {
        "name": "ltxv_text_to_video",
        "title": "LTXV Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/ltxv",
        "tags": ["Text to Video", "Video"],
        "models": ["LTXV"],
        "date": "2025-03-01",
        "size": 17.84
      },
      {
        "name": "ltxv_image_to_video",
        "title": "LTXV Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from still images.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/ltxv",
        "tags": ["Image to Video", "Video"],
        "models": ["LTXV"],
        "date": "2025-03-01",
        "size": 17.84
      },
      {
        "name": "mochi_text_to_video_example",
        "title": "Mochi Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts using Mochi model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/mochi/",
        "tags": ["Text to Video", "Video"],
        "models": ["Mochi"],
        "date": "2025-03-01",
        "size": 28.65
      },
      {
        "name": "hunyuan_video_text_to_video",
        "title": "Hunyuan Video Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts using Hunyuan model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/",
        "tags": ["Text to Video", "Video"],
        "models": ["Hunyuan Video", "Tencent"],
        "date": "2025-03-01",
        "size": 33.04
      },
      {
        "name": "image_to_video",
        "title": "SVD Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from still images.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Image to Video", "Video"],
        "models": ["SVD", "Stability"],
        "date": "2025-03-01",
        "size": 8.9
      },
      {
        "name": "txt_to_image_to_video",
        "title": "SVD Text to Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos by first creating images from text prompts.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Text to Video", "Video"],
        "models": ["SVD", "Stability"],
        "date": "2025-03-01",
        "size": 15.36
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--volume-2]",
    "title": "Audio",
    "type": "audio",
    "templates": [
      {
        "name": "audio_stable_audio_example",
        "title": "Stable Audio",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate audio from text prompts using Stable Audio.",
        "tags": ["Text to Audio", "Audio"],
        "models": ["Stable Audio", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/audio/",
        "size": 5.35
      },
      {
        "name": "audio_ace_step_1_t2a_instrumentals",
        "title": "ACE-Step v1 Text to Instrumentals Music",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate instrumental music from text prompts using ACE-Step v1.",
        "tags": ["Text to Audio", "Audio"],
        "models": ["ACE-Step"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      },
      {
        "name": "audio_ace_step_1_t2a_song",
        "title": "ACE Step v1 Text to Song",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate songs with vocals from text prompts using ACE-Step v1, supporting multilingual and style customization.",
        "tags": ["Text to Audio", "Audio"],
        "models": ["ACE-Step"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      },
      {
        "name": "audio_ace_step_1_m2m_editing",
        "title": "ACE Step v1 M2M Editing",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Edit existing songs to change style and lyrics using ACE-Step v1 M2M.",
        "tags": ["Audio Editing", "Audio"],
        "models": ["ACE-Step"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--box]",
    "title": "3D Model",
    "type": "3d",
    "templates": [
      {
        "name": "3d_hunyuan3d-v2.1",
        "title": "Hunyuan3D 2.1",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D models from single images using Hunyuan3D 2.0.",
        "tags": ["Image to 3D", "3D"],
        "models": ["Hunyuan3D", "Tencent"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "size": 4.59
      },
      {
        "name": "3d_hunyuan3d_image_to_model",
        "title": "Hunyuan3D 2.0",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D models from single images using Hunyuan3D 2.0.",
        "tags": ["Image to 3D", "3D"],
        "models": ["Hunyuan3D", "Tencent"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "size": 4.59
      },
      {
        "name": "3d_hunyuan3d_multiview_to_model",
        "title": "Hunyuan3D 2.0 MV",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D models from multiple views using Hunyuan3D 2.0 MV.",
        "tags": ["3D", "Image to 3D"],
        "models": ["Hunyuan3D", "Tencent"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "thumbnailVariant": "hoverDissolve",
        "size": 4.59
      },
      {
        "name": "3d_hunyuan3d_multiview_to_model_turbo",
        "title": "Hunyuan3D 2.0 MV Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D models from multiple views using Hunyuan3D 2.0 MV Turbo.",
        "tags": ["Image to 3D", "3D"],
        "models": ["Hunyuan3D", "Tencent"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "thumbnailVariant": "hoverDissolve",
        "size": 4.59
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "CLOSED SOURCE MODELS",
    "title": "Image API",
    "icon": "icon-[lucide--hand-coins]",
    "type": "image",
    "templates": [
      {
        "name": "api_bytedance_seedream4",
        "title": "ByteDance Seedream 4.0",
        "description": "Multi-modal AI model for text-to-image and image editing. Generate 2K images in under 2 seconds with natural language control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image Edit", "Image", "API", "Text to Image"],
        "models": ["Seedream 4.0", "ByteDance"],
        "date": "2025-09-11",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_google_gemini_image",
        "title": "Google Gemini Image",
        "description": "Nano-banana (Gemini-2.5-Flash Image) - image editing with consistency.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image Edit", "Image", "API", "Text to Image"],
        "models": ["Gemini-2.5-Flash", "nano-banana", "Google"],
        "date": "2025-08-27",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_1_kontext_multiple_images_input",
        "title": "BFL Flux.1 Kontext Multiple Image Input",
        "description": "Input multiple images and edit them with Flux.1 Kontext.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Image Edit", "Image"],
        "models": ["Flux", "Kontext", "BFL"],
        "date": "2025-05-29",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_1_kontext_pro_image",
        "title": "BFL Flux.1 Kontext Pro",
        "description": "Edit images with Flux.1 Kontext pro image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Image Edit", "Image"],
        "models": ["Flux", "Kontext", "BFL"],
        "date": "2025-05-29",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_1_kontext_max_image",
        "title": "BFL Flux.1 Kontext Max",
        "description": "Edit images with Flux.1 Kontext max image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Image Edit", "Image"],
        "models": ["Flux", "Kontext", "BFL"],
        "date": "2025-05-29",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_wan_text_to_image",
        "title": "Wan2.5: Text to Image",
        "description": "Generate images with excellent prompt following and visual quality using FLUX.1 Pro.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Wan2.5", "Wan"],
        "date": "2025-09-25",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_pro_t2i",
        "title": "BFL Flux[Pro]: Text to Image",
        "description": "Generate images with excellent prompt following and visual quality using FLUX.1 Pro.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-1-pro-ultra-image",
        "tags": ["Image Edit", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-05-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_photon_i2i",
        "title": "Luma Photon: Image to Image",
        "description": "Guide image generation using a combination of images and prompt.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Image to Image", "Image", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_photon_style_ref",
        "title": "Luma Photon: Style Reference",
        "description": "Generate images by blending style references with precise control using Luma Photon.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_recraft_image_gen_with_color_control",
        "title": "Recraft: Color Control Image Generation",
        "description": "Generate images with custom color palettes and brand-specific visuals using Recraft.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Recraft"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_recraft_image_gen_with_style_control",
        "title": "Recraft: Style Control Image Generation",
        "description": "Control style with visual examples, align positioning, and fine-tune objects. Store and share styles for perfect brand consistency.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Recraft"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_recraft_vector_gen",
        "title": "Recraft: Vector Generation",
        "description": "Generate high-quality vector images from text prompts using Recraft's AI vector generator.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API", "Vector"],
        "models": ["Recraft"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_text_to_image",
        "title": "Runway: Text to Image",
        "description": "Generate high-quality images from text prompts using Runway's AI model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_reference_to_image",
        "title": "Runway: Reference to Image",
        "description": "Generate new images based on reference styles and compositions with Runway's AI.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image to Image", "Image", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_stable_image_ultra_t2i",
        "title": "Stability AI: Stable Image Ultra Text to Image",
        "description": "Generate high quality images with excellent prompt adherence. Perfect for professional GENERATION TYPE at 1 megapixel resolution.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_i2i",
        "title": "Stability AI: Image to Image",
        "description": "Transform images with high-quality generation using Stability AI, perfect for professional editing and style transfer.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image to Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_sd3.5_t2i",
        "title": "Stability AI: SD3.5 Text to Image",
        "description": "Generate high quality images with excellent prompt adherence. Perfect for professional GENERATION TYPE at 1 megapixel resolution.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_sd3.5_i2i",
        "title": "Stability AI: SD3.5 Image to Image",
        "description": "Generate high quality images with excellent prompt adherence. Perfect for professional GENERATION TYPE at 1 megapixel resolution.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image to Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_ideogram_v3_t2i",
        "title": "Ideogram V3: Text to Image",
        "description": "Generate professional-quality images with excellent prompt alignment, photorealism, and text rendering using Ideogram V3.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Ideogram"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_t2i",
        "title": "OpenAI: GPT-Image-1 Text to Image",
        "description": "Generate images from text prompts using OpenAI GPT Image 1 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["GPT-Image-1", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_i2i",
        "title": "OpenAI: GPT-Image-1 Image to Image",
        "description": "Generate images from input images using OpenAI GPT Image 1 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Image to Image", "Image", "API"],
        "models": ["GPT-Image-1", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_inpaint",
        "title": "OpenAI: GPT-Image-1 Inpaint",
        "description": "Edit images using inpainting with OpenAI GPT Image 1 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Inpainting", "Image", "API"],
        "models": ["GPT-Image-1", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_multi_inputs",
        "title": "OpenAI: GPT-Image-1 Multi Inputs",
        "description": "Generate images from multiple inputs using OpenAI GPT Image 1 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["GPT-Image-1", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_dall_e_2_t2i",
        "title": "OpenAI: Dall-E 2 Text to Image",
        "description": "Generate images from text prompts using OpenAI Dall-E 2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Dall-E", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_dall_e_2_inpaint",
        "title": "OpenAI: Dall-E 2 Inpaint",
        "description": "Edit images using inpainting with OpenAI Dall-E 2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Inpainting", "Image", "API"],
        "models": ["Dall-E", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_dall_e_3_t2i",
        "title": "OpenAI: Dall-E 3 Text to Image",
        "description": "Generate images from text prompts using OpenAI Dall-E 3 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Dall-E", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-3",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "CLOSED SOURCE MODELS",
    "title": "Video API",
    "icon": "icon-[lucide--film]",
    "type": "video",
    "templates": [
      {
        "name": "api_openai_sora_video",
        "title": "Sora 2: Text & Image to Video",
        "description": "OpenAI's Sora-2 and Sora-2 Pro video generation with synchronized audio.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Text to Video", "API"],
        "models": ["OpenAI"],
        "date": "2025-10-08",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_wan_text_to_video",
        "title": "Wan2.5: Text to Video",
        "description": "Generate videos with synchronized audio, enhanced motion, and superior quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Wan2.5", "Wan"],
        "date": "2025-09-27",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_wan_image_to_video",
        "title": "Wan2.5: Image to Video",
        "description": "Transform images into videos with synchronized audio, enhanced motion, and superior quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Wan2.5", "Wan"],
        "date": "2025-09-27",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_kling_i2v",
        "title": "Kling: Image to Video",
        "description": "Generate videos with excellent prompt adherence for actions, expressions, and camera movements using Kling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_kling_effects",
        "title": "Kling: Video Effects",
        "description": "Generate dynamic videos by applying visual effects to images using Kling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_kling_flf",
        "title": "Kling: FLF2V",
        "description": "Generate videos through controlling the first and last frames.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "FLF2V"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_text_to_video",
        "title": "Vidu: Text to Video",
        "description": "Generate high-quality 1080p videos from text prompts with adjustable movement amplitude and duration control using Vidu's advanced AI model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_image_to_video",
        "title": "Vidu: Image to Video",
        "description": "Transform static images into dynamic 1080p videos with precise motion control and customizable movement amplitude using Vidu.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_reference_to_video",
        "title": "Vidu: Reference to Video",
        "description": "Generate videos with consistent subjects using multiple reference images (up to 7) for character and style continuity across the video sequence.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "Image to Video", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_start_end_to_video",
        "title": "Vidu: Start End to Video",
        "description": "Create smooth video transitions between defined start and end frames with natural motion interpolation and consistent visual quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "FLF2V"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bytedance_text_to_video",
        "title": "ByteDance: Text to Video",
        "description": "Generate high-quality videos directly from text prompts using ByteDance's Seedance model. Supports multiple resolutions and aspect ratios with natural motion and cinematic quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "Text to Video"],
        "models": ["ByteDance"],
        "date": "2025-10-6",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bytedance_image_to_video",
        "title": "ByteDance: Image to Video",
        "description": "Transform static images into dynamic videos using ByteDance's Seedance model. Analyzes image structure and generates natural motion with consistent visual style and coherent video sequences.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "Image to Video"],
        "models": ["ByteDance"],
        "date": "2025-10-6",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bytedance_flf2v",
        "title": "ByteDance: Start End to Video",
        "description": "Generate cinematic video transitions between start and end frames with fluid motion, scene consistency, and professional polish using ByteDance's Seedance model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "FLF2V"],
        "models": ["ByteDance"],
        "date": "2025-10-6",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_i2v",
        "title": "Luma: Image to Video",
        "description": "Take static images and instantly create magical high quality animations.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_t2v",
        "title": "Luma: Text to Video",
        "description": "High-quality videos can be generated using simple prompts.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_text_to_video",
        "title": "Moonvalley: Text to Video",
        "description": "Generate cinematic, 1080p videos from text prompts through a model trained exclusively on licensed data.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_image_to_video",
        "title": "Moonvalley: Image to Video",
        "description": "Generate cinematic, 1080p videos with an image through a model trained exclusively on licensed data.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_video_to_video_motion_transfer",
        "title": "Moonvalley: Motion Transfer",
        "description": "Apply motion from one video to another.",
        "mediaType": "image",
        "thumbnailVariant": "hoverDissolve",
        "mediaSubtype": "webp",
        "tags": ["Video to Video", "Video", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_video_to_video_pose_control",
        "title": "Moonvalley: Pose Control",
        "description": "Apply human pose and movement from one video to another.",
        "mediaType": "image",
        "thumbnailVariant": "hoverDissolve",
        "mediaSubtype": "webp",
        "tags": ["Video to Video", "Video", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_hailuo_minimax_video",
        "title": "MiniMax: Video",
        "description": "Generate high-quality videos from text prompts with optional first-frame control using MiniMax Hailuo-02 model. Supports multiple resolutions (768P/1080P) and durations (6/10s) with intelligent prompt optimization.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_hailuo_minimax_t2v",
        "title": "MiniMax: Text to Video",
        "description": "Generate high-quality videos directly from text prompts. Explore MiniMax's advanced AI capabilities to create diverse visual narratives with professional CGI effects and stylistic elements to bring your descriptions to life.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_hailuo_minimax_i2v",
        "title": "MiniMax: Image to Video",
        "description": "Generate refined videos from images and text with CGI integration using MiniMax.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pixverse_i2v",
        "title": "PixVerse: Image to Video",
        "description": "Generate dynamic videos from static images with motion and effects using PixVerse.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pixverse_template_i2v",
        "title": "PixVerse Templates: Image to Video",
        "description": "Generate dynamic videos from static images with motion and effects using PixVerse.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pixverse_t2v",
        "title": "PixVerse: Text to Video",
        "description": "Generate videos with accurate prompt interpretation and stunning video dynamics.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_gen3a_turbo_image_to_video",
        "title": "Runway: Gen3a Turbo Image to Video",
        "description": "Generate cinematic videos from static images using Runway Gen3a Turbo.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_gen4_turo_image_to_video",
        "title": "Runway: Gen4 Turbo Image to Video",
        "description": "Generate dynamic videos from images using Runway Gen4 Turbo.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_first_last_frame",
        "title": "Runway: First Last Frame to Video",
        "description": "Generate smooth video transitions between two keyframes with Runway's precision.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "FLF2V"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pika_i2v",
        "title": "Pika: Image to Video",
        "description": "Generate smooth animated videos from single static images using Pika AI.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pika_scene",
        "title": "Pika Scenes: Images to Video",
        "description": "Generate videos that incorporate multiple input images using Pika Scenes.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_veo2_i2v",
        "title": "Veo2: Image to Video",
        "description": "Generate videos from images using Google Veo2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Veo", "Google"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_veo3",
        "title": "Veo3: Image to Video",
        "description": "Generate high-quality 8-second videos from text prompts or images using Google's advanced Veo 3 API. Features audio generation, prompt enhancement, and dual model options for speed or quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Text to Video", "API"],
        "models": ["Veo", "Google"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "CLOSED SOURCE MODELS",
    "title": "3D API",
    "icon": "icon-[lucide--box]",
    "type": "image",
    "templates": [
      {
        "name": "api_rodin_gen2",
        "title": "Rodin: Gen-2 Image to Model",
        "description": "Generate detailed 4X mesh quality 3D models from photos using Rodin Gen2",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to 3D", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-09-27",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_rodin_image_to_model",
        "title": "Rodin: Image to Model",
        "description": "Generate detailed 3D models from single photos using Rodin AI.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to 3D", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_rodin_multiview_to_model",
        "title": "Rodin: Multiview to Model",
        "description": "Sculpt comprehensive 3D models using Rodin's multi-angle reconstruction.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to 3D", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_tripo_text_to_model",
        "title": "Tripo: Text to Model",
        "description": "Craft 3D objects from descriptions with Tripo's text-driven modeling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Model", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_tripo_image_to_model",
        "title": "Tripo: Image to Model",
        "description": "Generate professional 3D assets from 2D images using Tripo engine.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to 3D", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_tripo_multiview_to_model",
        "title": "Tripo: Multiview to Model",
        "description": "Build 3D models from multiple angles with Tripo's advanced scanner.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to 3D", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "CLOSED SOURCE MODELS",
    "title": "Audio API",
    "type": "audio",
    "icon": "icon-[lucide--volume-2]",
    "templates": [
      {
        "name": "api_stability_ai_text_to_audio",
        "title": "Stability AI: Text to Audio",
        "description": "Generate music from text using Stable Audio 2.5. Create minutes-long tracks in seconds.",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "tags": ["Text to Audio", "Audio", "API"],
        "date": "2025-09-09",
        "models": ["Stability", "Stable Audio"],
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_audio_to_audio",
        "title": "Stability AI: Audio to Audio",
        "description": "Transform audio into new compositions using Stable Audio 2.5. Upload audio and AI creates complete tracks.",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "tags": ["Audio to Audio", "Audio", "API"],
        "date": "2025-09-09",
        "models": ["Stability", "Stable Audio"],
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_audio_inpaint",
        "title": "Stability AI: Audio Inpainting",
        "description": "Complete or extend audio tracks using Stable Audio 2.5. Upload audio and AI generates the rest.",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "tags": ["Audio to Audio", "Audio", "API"],
        "date": "2025-09-09",
        "models": ["Stability", "Stable Audio"],
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "CLOSED SOURCE MODELS",
    "title": "LLM API",
    "icon": "icon-[lucide--message-square-text]",
    "type": "image",
    "templates": [
      {
        "name": "api_openai_chat",
        "title": "OpenAI: Chat",
        "description": "Engage with OpenAI's advanced language models for intelligent conversations.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["LLM", "API"],
        "models": ["OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_google_gemini",
        "title": "Google Gemini: Chat",
        "description": "Experience Google's multimodal AI with Gemini's reasoning capabilities.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["LLM", "API"],
        "models": ["Google Gemini", "Google"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  }
]
