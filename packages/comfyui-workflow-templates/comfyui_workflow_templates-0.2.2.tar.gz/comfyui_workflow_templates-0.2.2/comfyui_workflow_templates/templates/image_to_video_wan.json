{
  "id": "469720c1-eccb-42bf-835a-f2976736e0bf",
  "revision": 0,
  "last_node_id": 57,
  "last_link_id": 113,
  "nodes": [
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        20,
        70
      ],
      "size": [
        346.7470703125,
        82
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "wan2.1_i2v_480p_14B_fp16.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": [
        "wan2.1_i2v_480p_14B_fp16.safetensors",
        "default"
      ]
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        20,
        190
      ],
      "size": [
        350,
        110
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            74,
            75
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "wan",
        "default"
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        20,
        350
      ],
      "size": [
        350,
        60
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76,
            99
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "wan_2.1_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "wan_2.1_vae.safetensors"
      ]
    },
    {
      "id": 49,
      "type": "CLIPVisionLoader",
      "pos": [
        20,
        460
      ],
      "size": [
        350,
        60
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "slot_index": 0,
          "links": [
            94
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader",
        "models": [
          {
            "name": "clip_vision_h.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors",
            "directory": "clip_vision"
          }
        ]
      },
      "widgets_values": [
        "clip_vision_h.safetensors"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        410,
        80
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            97
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 54,
      "type": "ModelSamplingSD3",
      "pos": [
        860,
        30
      ],
      "size": [
        290,
        60
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 110
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            111
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingSD3"
      },
      "widgets_values": [
        8
      ]
    },
    {
      "id": 55,
      "type": "CreateVideo",
      "pos": [
        1190,
        30
      ],
      "size": [
        270,
        78
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 112
        },
        {
          "name": "audio",
          "shape": 7,
          "type": "AUDIO",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "VIDEO",
          "type": "VIDEO",
          "links": [
            113
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CreateVideo"
      },
      "widgets_values": [
        16
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        860,
        140
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 111
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 101
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 102
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 103
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            35
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        987948718394761,
        "randomize",
        20,
        6,
        "uni_pc",
        "simple",
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        960,
        450
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 35
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            112
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 56,
      "type": "SaveVideo",
      "pos": [
        1200,
        160
      ],
      "size": [
        740,
        540
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "video",
          "type": "VIDEO",
          "link": 113
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveVideo"
      },
      "widgets_values": [
        "video/ComfyUI",
        "auto",
        "auto"
      ]
    },
    {
      "id": 50,
      "type": "WanImageToVideo",
      "pos": [
        460,
        560
      ],
      "size": [
        320,
        220
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 97
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 98
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 99
        },
        {
          "name": "clip_vision_output",
          "shape": 7,
          "type": "CLIP_VISION_OUTPUT",
          "link": 107
        },
        {
          "name": "start_image",
          "shape": 7,
          "type": "IMAGE",
          "link": 106
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            101
          ]
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "slot_index": 1,
          "links": [
            102
          ]
        },
        {
          "name": "latent",
          "type": "LATENT",
          "slot_index": 2,
          "links": [
            103
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "WanImageToVideo"
      },
      "widgets_values": [
        512,
        512,
        33,
        1
      ]
    },
    {
      "id": 51,
      "type": "CLIPVisionEncode",
      "pos": [
        460,
        860
      ],
      "size": [
        253.60000610351562,
        78
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 94
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 109
        }
      ],
      "outputs": [
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "slot_index": 0,
          "links": [
            107
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionEncode"
      },
      "widgets_values": [
        "none"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        410,
        280
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            98
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 57,
      "type": "MarkdownNote",
      "pos": [
        -600,
        30
      ],
      "size": [
        590,
        430
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "[Tutorial](https://docs.comfy.org/tutorials/video/wan/wan-video)\n\n\n## Model links\n\n**text_encoders**\n\n- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n\n**clip_vision**\n\n- [clip_vision_h.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors)\n\n**diffusion_models**\n\n- [wan2.1_i2v_480p_14B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16.safetensors)\n\n**vae**\n\n- [wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors)\n\n\nModel Storage Location\n\n```\n📂 ComfyUI/\n├── 📂 models/\n│   ├── 📂 text_encoders/\n│   │      └── umt5_xxl_fp8_e4m3fn_scaled.safetensors\n│   ├── 📂 clip_vision/\n│   │      └── clip_vision_h.safetensors\n│   ├── 📂 diffusion_models/\n│   │      └── wan2.1_i2v_480p_14B_fp16.safetensors\n│   └── 📂 vae/\n│          └── wan_2.1_vae.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 52,
      "type": "LoadImage",
      "pos": [
        30,
        620
      ],
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            106,
            109
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "slot_index": 1,
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "image_to_video_wan_start_image.png",
        "image"
      ]
    }
  ],
  "links": [
    [
      35,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      74,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      94,
      49,
      0,
      51,
      0,
      "CLIP_VISION"
    ],
    [
      97,
      6,
      0,
      50,
      0,
      "CONDITIONING"
    ],
    [
      98,
      7,
      0,
      50,
      1,
      "CONDITIONING"
    ],
    [
      99,
      39,
      0,
      50,
      2,
      "VAE"
    ],
    [
      101,
      50,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      102,
      50,
      1,
      3,
      2,
      "CONDITIONING"
    ],
    [
      103,
      50,
      2,
      3,
      3,
      "LATENT"
    ],
    [
      106,
      52,
      0,
      50,
      4,
      "IMAGE"
    ],
    [
      107,
      51,
      0,
      50,
      3,
      "CLIP_VISION_OUTPUT"
    ],
    [
      109,
      52,
      0,
      51,
      1,
      "IMAGE"
    ],
    [
      110,
      37,
      0,
      54,
      0,
      "MODEL"
    ],
    [
      111,
      54,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      112,
      8,
      0,
      55,
      0,
      "IMAGE"
    ],
    [
      113,
      55,
      0,
      56,
      0,
      "VIDEO"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [
        10,
        0,
        370,
        533.5999755859375
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2 - Upload start_image",
      "bounding": [
        10,
        550,
        370,
        400
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step4 - Prompt",
      "bounding": [
        400,
        0,
        445.27801513671875,
        467.2060852050781
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Step3 - Video size",
      "bounding": [
        400,
        480,
        440,
        310
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1.0159611845439778,
      "offset": [
        369.61463579251983,
        -313.38208398559794
      ]
    },
    "frontendVersion": "1.29.2"
  },
  "version": 0.4
}