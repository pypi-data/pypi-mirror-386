"""
This file is automatically generated by TritonParse reproducer.
It contains a smallest testing example for a Triton kernel.
"""

import torch

# {{IR_OVERRIDE_SETUP_PLACEHOLDER}}

# {{KERNEL_SYSPATH_PLACEHOLDER}}

# {{KERNEL_IMPORT_PLACEHOLDER}}

# {{UTILITY_FUNCTIONS_PLACEHOLDER}}


if __name__ == "__main__":
    script_dir = Path(__file__).resolve().parent  # noqa: F821
    json_file = script_dir / "{{JSON_FILE_NAME_PLACEHOLDER}}"
    grid, args_dict = create_args_from_json_file(str(json_file))  # noqa: F821

    print("Generated kernel arguments dictionary:")
    for name, arg in args_dict.items():
        print(f"  {name}: {arg}")
    print(f"Grid: {grid}")

    # {{KERNEL_INVOCATION_PLACEHOLDER}}

    torch.cuda.synchronize()
    print("Kernel execution finished.")
