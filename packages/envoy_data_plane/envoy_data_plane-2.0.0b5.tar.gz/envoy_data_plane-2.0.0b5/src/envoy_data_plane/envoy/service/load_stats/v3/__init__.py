# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: envoy/service/load_stats/v3/lrs.proto
# plugin: python-betterproto2
# This file has been @generated

__all__ = (
    "LoadReportingServiceAsyncStub",
    "LoadReportingServiceBase",
    "LoadReportingServiceSyncStub",
    "LoadStatsRequest",
    "LoadStatsResponse",
)

import datetime
import typing
from collections.abc import AsyncIterable, AsyncIterator, Iterable, Iterator
from typing import TYPE_CHECKING

import betterproto2
import grpc
import grpclib
import pydantic
from betterproto2 import grpclib as betterproto2_grpclib
from pydantic.dataclasses import dataclass

from .....message_pool import default_message_pool

if TYPE_CHECKING:
    import grpclib.server
    from betterproto2.grpclib.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline

_COMPILER_VERSION = "0.9.0"
betterproto2.check_compiler_version(_COMPILER_VERSION)


@dataclass(eq=False, repr=False, config={"extra": "forbid"})
class LoadStatsRequest(betterproto2.Message):
    """
    A load report Envoy sends to the management server.
    """

    node: "___config__core__v3__.Node | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Node identifier for Envoy instance.
    """

    cluster_stats: "list[___config__endpoint__v3__.ClusterStats]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A list of load stats to report.
    """


default_message_pool.register_message(
    "envoy.service.load_stats.v3", "LoadStatsRequest", LoadStatsRequest
)


@dataclass(eq=False, repr=False, config={"extra": "forbid"})
class LoadStatsResponse(betterproto2.Message):
    """
    The management server sends envoy a LoadStatsResponse with all clusters it
    is interested in learning load stats about.
    """

    clusters: "list[typing.Annotated[str, pydantic.AfterValidator(betterproto2.validators.validate_string)]]" = betterproto2.field(
        1, betterproto2.TYPE_STRING, repeated=True
    )
    """
    Clusters to report stats for.
    Not populated if ``send_all_clusters`` is true.
    """

    send_all_clusters: "bool" = betterproto2.field(4, betterproto2.TYPE_BOOL)
    """
    If true, the client should send all clusters it knows about.
    Only clients that advertise the "envoy.lrs.supports_send_all_clusters" capability in their
    :ref:`client_features<envoy_v3_api_field_config.core.v3.Node.client_features>` field will honor this field.
    """

    load_reporting_interval: "datetime.timedelta | None" = betterproto2.field(
        2,
        betterproto2.TYPE_MESSAGE,
        unwrap=lambda: ____google__protobuf__.Duration,
        optional=True,
    )
    """
    The minimum interval of time to collect stats over. This is only a minimum for two reasons:

    1. There may be some delay from when the timer fires until stats sampling occurs.
    2. For clusters that were already feature in the previous ``LoadStatsResponse``, any traffic
       that is observed in between the corresponding previous ``LoadStatsRequest`` and this
       ``LoadStatsResponse`` will also be accumulated and billed to the cluster. This avoids a period
       of inobservability that might otherwise exists between the messages. New clusters are not
       subject to this consideration.
    """

    report_endpoint_granularity: "bool" = betterproto2.field(3, betterproto2.TYPE_BOOL)
    """
    Set to ``true`` if the management server supports endpoint granularity
    report.
    """


default_message_pool.register_message(
    "envoy.service.load_stats.v3", "LoadStatsResponse", LoadStatsResponse
)


class LoadReportingServiceSyncStub:
    """
    [#protodoc-title: Load reporting service (LRS)]

    Load Reporting Service is an Envoy API to emit load reports. Envoy will initiate a bi-directional
    stream with a management server. Upon connecting, the management server can send a
    :ref:`LoadStatsResponse <envoy_v3_api_msg_service.load_stats.v3.LoadStatsResponse>` to a node it is
    interested in getting the load reports for. Envoy in this node will start sending
    :ref:`LoadStatsRequest <envoy_v3_api_msg_service.load_stats.v3.LoadStatsRequest>`. This is done periodically
    based on the :ref:`load reporting interval <envoy_v3_api_field_service.load_stats.v3.LoadStatsResponse.load_reporting_interval>`
    For details, take a look at the :ref:`Load Reporting Service sandbox example <install_sandboxes_load_reporting_service>`.
    """

    def __init__(self, channel: grpc.Channel):
        self._channel = channel

    def stream_load_stats(
        self, messages: "Iterable[LoadStatsRequest]"
    ) -> "Iterator[LoadStatsResponse]":
        """
        Advanced API to allow for multi-dimensional load balancing by remote
        server. For receiving LB assignments, the steps are:
        1, The management server is configured with per cluster/zone/load metric
           capacity configuration. The capacity configuration definition is
           outside of the scope of this document.
        2. Envoy issues a standard {Stream,Fetch}Endpoints request for the clusters
           to balance.

        Independently, Envoy will initiate a StreamLoadStats bidi stream with a
        management server:
        1. Once a connection establishes, the management server publishes a
           LoadStatsResponse for all clusters it is interested in learning load
           stats about.
        2. For each cluster, Envoy load balances incoming traffic to upstream hosts
           based on per-zone weights and/or per-instance weights (if specified)
           based on intra-zone LbPolicy. This information comes from the above
           {Stream,Fetch}Endpoints.
        3. When upstream hosts reply, they optionally add header <define header
           name> with ASCII representation of EndpointLoadMetricStats.
        4. Envoy aggregates load reports over the period of time given to it in
           LoadStatsResponse.load_reporting_interval. This includes aggregation
           stats Envoy maintains by itself (total_requests, rpc_errors etc.) as
           well as load metrics from upstream hosts.
        5. When the timer of load_reporting_interval expires, Envoy sends new
           LoadStatsRequest filled with load reports for each cluster.
        6. The management server uses the load reports from all reported Envoys
           from around the world, computes global assignment and prepares traffic
           assignment destined for each zone Envoys are located in. Goto 2.
        """

        yield from self._channel.stream_stream(
            "/envoy.service.load_stats.v3.LoadReportingService/StreamLoadStats",
            LoadStatsRequest.SerializeToString,
            LoadStatsResponse.FromString,
        )(iter(messages))


class LoadReportingServiceAsyncStub(betterproto2_grpclib.ServiceStub):
    """
    [#protodoc-title: Load reporting service (LRS)]

    Load Reporting Service is an Envoy API to emit load reports. Envoy will initiate a bi-directional
    stream with a management server. Upon connecting, the management server can send a
    :ref:`LoadStatsResponse <envoy_v3_api_msg_service.load_stats.v3.LoadStatsResponse>` to a node it is
    interested in getting the load reports for. Envoy in this node will start sending
    :ref:`LoadStatsRequest <envoy_v3_api_msg_service.load_stats.v3.LoadStatsRequest>`. This is done periodically
    based on the :ref:`load reporting interval <envoy_v3_api_field_service.load_stats.v3.LoadStatsResponse.load_reporting_interval>`
    For details, take a look at the :ref:`Load Reporting Service sandbox example <install_sandboxes_load_reporting_service>`.
    """

    async def stream_load_stats(
        self,
        messages: "AsyncIterable[LoadStatsRequest] | Iterable[LoadStatsRequest]",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "AsyncIterator[LoadStatsResponse]":
        """
        Advanced API to allow for multi-dimensional load balancing by remote
        server. For receiving LB assignments, the steps are:
        1, The management server is configured with per cluster/zone/load metric
           capacity configuration. The capacity configuration definition is
           outside of the scope of this document.
        2. Envoy issues a standard {Stream,Fetch}Endpoints request for the clusters
           to balance.

        Independently, Envoy will initiate a StreamLoadStats bidi stream with a
        management server:
        1. Once a connection establishes, the management server publishes a
           LoadStatsResponse for all clusters it is interested in learning load
           stats about.
        2. For each cluster, Envoy load balances incoming traffic to upstream hosts
           based on per-zone weights and/or per-instance weights (if specified)
           based on intra-zone LbPolicy. This information comes from the above
           {Stream,Fetch}Endpoints.
        3. When upstream hosts reply, they optionally add header <define header
           name> with ASCII representation of EndpointLoadMetricStats.
        4. Envoy aggregates load reports over the period of time given to it in
           LoadStatsResponse.load_reporting_interval. This includes aggregation
           stats Envoy maintains by itself (total_requests, rpc_errors etc.) as
           well as load metrics from upstream hosts.
        5. When the timer of load_reporting_interval expires, Envoy sends new
           LoadStatsRequest filled with load reports for each cluster.
        6. The management server uses the load reports from all reported Envoys
           from around the world, computes global assignment and prepares traffic
           assignment destined for each zone Envoys are located in. Goto 2.
        """

        async for response in self._stream_stream(
            "/envoy.service.load_stats.v3.LoadReportingService/StreamLoadStats",
            messages,
            LoadStatsRequest,
            LoadStatsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        ):
            yield response


from .....google import protobuf as ____google__protobuf__
from ....config.core import v3 as ___config__core__v3__
from ....config.endpoint import v3 as ___config__endpoint__v3__


class LoadReportingServiceBase(betterproto2_grpclib.ServiceBase):
    """
    [#protodoc-title: Load reporting service (LRS)]

    Load Reporting Service is an Envoy API to emit load reports. Envoy will initiate a bi-directional
    stream with a management server. Upon connecting, the management server can send a
    :ref:`LoadStatsResponse <envoy_v3_api_msg_service.load_stats.v3.LoadStatsResponse>` to a node it is
    interested in getting the load reports for. Envoy in this node will start sending
    :ref:`LoadStatsRequest <envoy_v3_api_msg_service.load_stats.v3.LoadStatsRequest>`. This is done periodically
    based on the :ref:`load reporting interval <envoy_v3_api_field_service.load_stats.v3.LoadStatsResponse.load_reporting_interval>`
    For details, take a look at the :ref:`Load Reporting Service sandbox example <install_sandboxes_load_reporting_service>`.
    """

    async def stream_load_stats(
        self, messages: "AsyncIterator[LoadStatsRequest]"
    ) -> "AsyncIterator[LoadStatsResponse]":
        """
        Advanced API to allow for multi-dimensional load balancing by remote
        server. For receiving LB assignments, the steps are:
        1, The management server is configured with per cluster/zone/load metric
           capacity configuration. The capacity configuration definition is
           outside of the scope of this document.
        2. Envoy issues a standard {Stream,Fetch}Endpoints request for the clusters
           to balance.

        Independently, Envoy will initiate a StreamLoadStats bidi stream with a
        management server:
        1. Once a connection establishes, the management server publishes a
           LoadStatsResponse for all clusters it is interested in learning load
           stats about.
        2. For each cluster, Envoy load balances incoming traffic to upstream hosts
           based on per-zone weights and/or per-instance weights (if specified)
           based on intra-zone LbPolicy. This information comes from the above
           {Stream,Fetch}Endpoints.
        3. When upstream hosts reply, they optionally add header <define header
           name> with ASCII representation of EndpointLoadMetricStats.
        4. Envoy aggregates load reports over the period of time given to it in
           LoadStatsResponse.load_reporting_interval. This includes aggregation
           stats Envoy maintains by itself (total_requests, rpc_errors etc.) as
           well as load metrics from upstream hosts.
        5. When the timer of load_reporting_interval expires, Envoy sends new
           LoadStatsRequest filled with load reports for each cluster.
        6. The management server uses the load reports from all reported Envoys
           from around the world, computes global assignment and prepares traffic
           assignment destined for each zone Envoys are located in. Goto 2.
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)
        yield LoadStatsResponse()

    async def __rpc_stream_load_stats(
        self, stream: "grpclib.server.Stream[LoadStatsRequest, LoadStatsResponse]"
    ) -> None:
        request = stream.__aiter__()
        await self._call_rpc_handler_server_stream(
            self.stream_load_stats,
            stream,
            request,
        )

    def __mapping__(self) -> "dict[str, grpclib.const.Handler]":
        return {
            "/envoy.service.load_stats.v3.LoadReportingService/StreamLoadStats": grpclib.const.Handler(
                self.__rpc_stream_load_stats,
                grpclib.const.Cardinality.STREAM_STREAM,
                LoadStatsRequest,
                LoadStatsResponse,
            ),
        }
