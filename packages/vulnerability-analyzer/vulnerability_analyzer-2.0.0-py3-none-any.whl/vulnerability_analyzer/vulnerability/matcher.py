#!/usr/bin/env python3
"""
Vulnerability Matcher - Match network data against vulnerability databases
Uses same simple keyword matching as Analysis/Vulnerability tool
"""

import pandas as pd
import json
from typing import Dict, List, Any, Optional


class VulnerabilityMatcher:
    """
    Match network data against vulnerability databases using simple keyword matching.
    Uses same logic as Analysis/Vulnerability/core/vulnerability_matcher.py
    """
    
    def __init__(self):
        """Initialize vulnerability matcher."""
        pass

    def match_vulnerabilities(self, data: pd.DataFrame, analysis_type: str = "pcap") -> pd.DataFrame:
        """
        Convenience method to match vulnerabilities from DataFrame data.
        
        Args:
            data: DataFrame with extracted data (PCAP or Nmap)
            analysis_type: Type of analysis ("pcap" or "nmap")
        
        Returns:
            DataFrame with vulnerability matches
        """
        # Create temporary CSV file
        import tempfile
        import os
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as temp_file:
            data.to_csv(temp_file.name, index=False)
            temp_csv_path = temp_file.name
        
        try:
            # Use built-in vulnerability database (create a simple one if not exists)
            exploit_csv_path = self._get_or_create_vuln_db()
            
            if analysis_type.lower() == "pcap":
                results = self.match_pcap_to_exploits(temp_csv_path, exploit_csv_path)
            else:  # nmap
                results = self.match_nmap_to_exploits(temp_csv_path, exploit_csv_path)
            
            return results
            
        finally:
            # Clean up temp file
            if os.path.exists(temp_csv_path):
                os.remove(temp_csv_path)
    
    def _get_or_create_vuln_db(self) -> str:
        """Get or create a simple vulnerability database CSV"""
        import tempfile
        
        # Create a comprehensive vulnerability database with multiple ID types
        vuln_data = [
            {"cve_id": "CVE-2024-0001", "description": "tcp port 80 http vulnerability", "severity": "high"},
            {"cve_id": "CVE-2024-0002", "description": "ssh port 22 authentication bypass", "severity": "critical"},
            {"cve_id": "CVE-2024-0003", "description": "dns port 53 amplification attack", "severity": "medium"},
            {"cve_id": "CVE-2024-0004", "description": "ftp port 21 anonymous access", "severity": "high"},
            {"cve_id": "CVE-2024-0005", "description": "telnet port 23 cleartext protocol", "severity": "medium"},
            # NIST National Vulnerability Database entries
            {"cve_id": "NVD-2024-001", "description": "mysql port 3306 sql injection", "severity": "high"},
            {"cve_id": "NVD-2024-002", "description": "postgres port 5432 privilege escalation", "severity": "critical"},
            # OSVDB (Open Source Vulnerability Database) entries
            {"cve_id": "OSVDB-12345", "description": "apache httpd remote code execution", "severity": "critical"},
            {"cve_id": "OSVDB-12346", "description": "nginx buffer overflow", "severity": "high"},
            # Microsoft Security Bulletins
            {"cve_id": "MS24-001", "description": "windows smb port 445 vulnerability", "severity": "critical"},
            {"cve_id": "MS24-002", "description": "rdp port 3389 authentication bypass", "severity": "high"},
            # ExploitDB entries
            {"cve_id": "EDB-50001", "description": "vsftpd backdoor port 21", "severity": "critical"},
            {"cve_id": "EDB-50002", "description": "proftpd mod_copy arbitrary file write", "severity": "high"},
            # Metasploit modules
            {"cve_id": "MSF-001", "description": "samba trans2open overflow", "severity": "critical"},
            {"cve_id": "MSF-002", "description": "distcc daemon command execution", "severity": "high"},
            # CAPEC (Common Attack Pattern Enumeration and Classification)
            {"cve_id": "CAPEC-100", "description": "overflow binary resource file", "severity": "medium"},
            {"cve_id": "CAPEC-101", "description": "buffer overflow via environment variables", "severity": "high"},
        ]
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as temp_file:
            import csv
            writer = csv.DictWriter(temp_file, fieldnames=["cve_id", "description", "severity"])
            writer.writeheader()
            writer.writerows(vuln_data)
            return temp_file.name

    def match_pcap_to_exploits(self, pcap_csv_path: str, exploit_csv_path: str, output_csv_path: str = None, output_json_path: str = None) -> pd.DataFrame:
        """
        Matches extracted PCAP data to known vulnerabilities.
        Same logic as Analysis/Vulnerability/core/vulnerability_matcher.py
        
        Args:
            pcap_csv_path: Path to extracted PCAP CSV
            exploit_csv_path: Path to vulnerability database CSV
            output_csv_path: Optional path to save CSV results
            output_json_path: Optional path to save JSON results
        """
        # Load extracted PCAP data and fill empty values
        pcap_df = pd.read_csv(pcap_csv_path).dropna(how='all', axis=1).fillna("")
        
        # Load known exploits database
        exploit_df = pd.read_csv(exploit_csv_path).fillna("")

        # Normalize strings for case-insensitive matching
        exploit_df['description'] = exploit_df['description'].astype(str).str.lower()
        exploit_df['cve_id'] = exploit_df['cve_id'].astype(str).str.upper()

        # Columns in PCAP likely to contain indicators (hostnames, URLs, protocols, etc.)
        fields_to_match = ['http.host', 'http.user_agent', 'dns.qry.name', '_ws.col.info']

        matches = []

        # Iterate over each row in the PCAP and check for matches in exploit descriptions
        for _, row in pcap_df.iterrows():
            # Combine searchable text from important fields
            search_terms = " ".join(str(row[field]).lower() for field in fields_to_match if field in row and row[field])

            # Use available MAC address from Ethernet or Wi-Fi layer
            src_mac = row.get("eth.src") or row.get("wlan.sa") or ""
            dst_mac = row.get("eth.dst") or row.get("wlan.da") or ""

            # Compare search terms to each known exploit
            for _, exp in exploit_df.iterrows():
                if any(term in search_terms for term in exp['description'].split()):
                    matches.append({
                        "ip.src": row.get("ip.src", ""),
                        "mac.src": src_mac,
                        "ip.dst": row.get("ip.dst", ""),
                        "mac.dst": dst_mac,
                        "matched_info": search_terms,
                        "exploit_description": exp['description'],
                        "cve_id": exp['cve_id']
                    })
                    break  # Stop at first match to avoid duplicates

        # Format and optionally write to CSV/JSON
        matches_df = pd.DataFrame(matches)
        if output_csv_path:
            matches_df.to_csv(output_csv_path, index=False)
        if output_json_path:
            matches_dict = matches_df.to_dict('records')
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'analysis_type': 'pcap_vulnerability_matching',
                    'total_matches': len(matches_dict),
                    'matches': matches_dict
                }, f, indent=2)

        return matches_df

    def match_nmap_to_exploits(self, xml_csv_path: str, exploit_csv_path: str, output_csv_path: str = None, output_json_path: str = None) -> pd.DataFrame:
        """
        Matches extracted Nmap XML service data to known vulnerabilities.
        Same logic as Analysis/Vulnerability/core/vulnerability_matcher.py
        
        Args:
            xml_csv_path: Path to extracted Nmap CSV
            exploit_csv_path: Path to vulnerability database CSV
            output_csv_path: Optional path to save CSV results
            output_json_path: Optional path to save JSON results
        """
        # Load Nmap scan output
        nmap_df = pd.read_csv(xml_csv_path).fillna("")
        
        # Load known exploits database
        exploit_df = pd.read_csv(exploit_csv_path).fillna("")

        # Normalize fields
        exploit_df['description'] = exploit_df['description'].astype(str).str.lower()
        exploit_df['cve_id'] = exploit_df['cve_id'].astype(str).str.upper()

        matches = []

        # Iterate over each service discovered by Nmap
        for _, row in nmap_df.iterrows():
            # Combine service identifiers into a search string
            search_terms = " ".join(str(row.get(k, "")).lower() for k in ['service_name', 'product', 'version', 'cpes'])

            # Match against each known exploit description
            for _, exp in exploit_df.iterrows():
                if any(term in search_terms for term in exp['description'].split()):
                    matches.append({
                        "ip_address": row.get("ip_address", ""),
                        "service_name": row.get("service_name", ""),
                        "product": row.get("product", ""),
                        "version": row.get("version", ""),
                        "cpe": row.get("cpes", ""),
                        "matched_info": search_terms,
                        "exploit_description": exp['description'],
                        "cve_id": exp['cve_id']
                    })
                    break  # First match wins

        # Format and optionally write to CSV/JSON
        matches_df = pd.DataFrame(matches)
        if output_csv_path:
            matches_df.to_csv(output_csv_path, index=False)
        if output_json_path:
            matches_dict = matches_df.to_dict('records')
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'analysis_type': 'nmap_vulnerability_matching',
                    'total_matches': len(matches_dict),
                    'matches': matches_dict
                }, f, indent=2)

        return matches_df

    def match_traffic(self, traffic_analysis: Dict[str, Any], exploit_csv_path: str) -> List[Dict[str, Any]]:
        """
        Match network traffic analysis results against vulnerability database.
        For compatibility with existing vulnerability-analyzer API.
        """
        # Extract PCAP data from analysis results
        if 'extracted_data' in traffic_analysis:
            # Create temporary CSV from DataFrame
            temp_csv = "temp_pcap_data.csv"
            traffic_analysis['extracted_data'].to_csv(temp_csv, index=False)
            
            # Use standard PCAP matching
            matches_df = self.match_pcap_to_exploits(temp_csv, exploit_csv_path)
            
            # Clean up temp file
            import os
            if os.path.exists(temp_csv):
                os.remove(temp_csv)
            
            # Convert DataFrame to list of dicts for compatibility
            return matches_df.to_dict('records')
        
        return []

    def match_nmap_data(self, nmap_results: Dict[str, Any], exploit_csv_path: str) -> List[Dict[str, Any]]:
        """
        Match Nmap scan results against vulnerability database.
        For compatibility with existing vulnerability-analyzer API.
        """
        # Extract Nmap data from analysis results
        if 'extracted_data' in nmap_results:
            # Create temporary CSV from DataFrame
            temp_csv = "temp_nmap_data.csv"
            nmap_results['extracted_data'].to_csv(temp_csv, index=False)
            
            # Use standard Nmap matching
            matches_df = self.match_nmap_to_exploits(temp_csv, exploit_csv_path)
            
            # Clean up temp file
            import os
            if os.path.exists(temp_csv):
                os.remove(temp_csv)
            
            # Convert DataFrame to list of dicts for compatibility
            return matches_df.to_dict('records')
        
        return []
        
        # Match against RouterSploit data
        routersploit_data = self.database.load_routersploit()
        
        for vuln in routersploit_data:
            match = self._check_router_vulnerability_match(traffic_data, vuln)
            if match:
                matches.append(match)
        
        return matches
    
    def _match_indicator_to_database(self, indicator: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Match a vulnerability indicator against the database."""
        matches = []
        
        indicator_type = indicator.get('type', '')
        
        # Search database for similar vulnerability types
        search_terms = {
            'sql_injection': 'sql injection',
            'xss': 'cross-site scripting',
            'path_traversal': 'directory traversal',
            'cleartext_protocol': 'cleartext',
            'weak_authentication': 'authentication'
        }
        
        search_term = search_terms.get(indicator_type, indicator_type)
        
        if search_term:
            db_results = self.database.search(search_term, limit=10)
            
            for db_vuln in db_results:
                match = {
                    'match_type': 'traffic_indicator',
                    'confidence': self._calculate_match_confidence(indicator, db_vuln),
                    'indicator': indicator,
                    'vulnerability': db_vuln,
                    'source_ip': indicator.get('source_ip', 'unknown'),
                    'destination_ip': indicator.get('destination_ip', 'unknown'),
                    'severity': indicator.get('severity', 'UNKNOWN')
                }
                matches.append(match)
        
        return matches
    
    def _match_protocols(self, protocols: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Match detected protocols against vulnerable service patterns."""
        matches = []
        
        risky_protocols = protocols.get('risky_protocols', [])
        
        for protocol in risky_protocols:
            # Search for vulnerabilities related to this protocol
            db_results = self.database.search(protocol.lower(), limit=5)
            
            for db_vuln in db_results:
                match = {
                    'match_type': 'protocol_vulnerability',
                    'confidence': 'MEDIUM',
                    'protocol': protocol,
                    'vulnerability': db_vuln,
                    'severity': db_vuln.get('cvss_severity', 'UNKNOWN')
                }
                matches.append(match)
        
        return matches
    
    def _match_host_patterns(self, hosts: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Match host communication patterns against vulnerability indicators."""
        matches = []
        
        # Look for suspicious communication patterns that might indicate exploitation
        top_communications = hosts.get('top_communications', {})
        
        for (src_ip, dst_ip), count in top_communications.items():
            if count > 100:  # High volume communication
                # Search for vulnerabilities that might cause high traffic
                db_results = self.database.search('denial of service', limit=3)
                
                for db_vuln in db_results:
                    match = {
                        'match_type': 'communication_pattern',
                        'confidence': 'LOW',
                        'pattern': f'High volume communication: {src_ip} -> {dst_ip} ({count} packets)',
                        'vulnerability': db_vuln,
                        'source_ip': src_ip,
                        'destination_ip': dst_ip,
                        'packet_count': count
                    }
                    matches.append(match)
        
        return matches
    
    def _match_service_to_database(self, host_ip: str, port_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Match a service against vulnerability database."""
        matches = []
        
        service_name = port_info.get('service', '')
        product = port_info.get('product', '')
        version = port_info.get('version', '')
        
        # Search for service-specific vulnerabilities
        if service_name:
            db_results = self.database.search(service_name, limit=10)
            
            for db_vuln in db_results:
                confidence = self._calculate_service_match_confidence(port_info, db_vuln)
                
                if confidence != 'NONE':
                    match = {
                        'match_type': 'service_vulnerability',
                        'confidence': confidence,
                        'host': host_ip,
                        'port': port_info.get('port', 'unknown'),
                        'service': service_name,
                        'product': product,
                        'version': version,
                        'vulnerability': db_vuln,
                        'severity': db_vuln.get('cvss_severity', 'UNKNOWN')
                    }
                    matches.append(match)
        
        # Check for product/version specific vulnerabilities
        if product and version:
            search_query = f"{product} {version}"
            db_results = self.database.search(search_query, limit=5)
            
            for db_vuln in db_results:
                match = {
                    'match_type': 'product_vulnerability',
                    'confidence': 'HIGH',
                    'host': host_ip,
                    'port': port_info.get('port', 'unknown'),
                    'product': product,
                    'version': version,
                    'vulnerability': db_vuln,
                    'severity': db_vuln.get('cvss_severity', 'UNKNOWN')
                }
                matches.append(match)
        
        return matches
    
    def _match_os_to_database(self, host_ip: str, os_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Match OS information against vulnerability database."""
        matches = []
        
        os_name = os_info.get('name', '')
        os_vendor = os_info.get('vendor', '')
        
        if os_name:
            # Search for OS-specific vulnerabilities
            db_results = self.database.search(os_name, limit=5)
            
            for db_vuln in db_results:
                match = {
                    'match_type': 'os_vulnerability',
                    'confidence': 'MEDIUM',
                    'host': host_ip,
                    'os_name': os_name,
                    'os_vendor': os_vendor,
                    'vulnerability': db_vuln,
                    'severity': db_vuln.get('cvss_severity', 'UNKNOWN')
                }
                matches.append(match)
        
        return matches
    
    def _check_router_vulnerability_match(self, traffic_data: Dict[str, Any], 
                                         router_vuln: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Check if traffic data matches a router vulnerability pattern."""
        
        # Simple pattern matching - in practice this would be more sophisticated
        raw_data = traffic_data.get('raw_data', [])
        
        # Look for HTTP requests to common router interfaces
        router_indicators = [
            '192.168.',  # Common router IP ranges
            '10.0.0.',
            '172.16.',
            '/admin',
            '/cgi-bin',
            'router'
        ]
        
        for packet in raw_data:
            packet_str = str(packet)
            
            if any(indicator in packet_str for indicator in router_indicators):
                return {
                    'match_type': 'router_pattern',
                    'confidence': 'MEDIUM',
                    'vulnerability': router_vuln,
                    'traffic_pattern': packet_str[:100],  # Truncate for brevity
                    'severity': router_vuln.get('cvss_severity', 'UNKNOWN')
                }
        
        return None
    
    def _calculate_match_confidence(self, indicator: Dict[str, Any], 
                                   db_vuln: Dict[str, Any]) -> str:
        """Calculate confidence level for a vulnerability match."""
        
        # Simple confidence calculation based on text similarity
        indicator_desc = indicator.get('description', '').lower()
        vuln_desc = db_vuln.get('description', '').lower()
        
        # Count common words
        indicator_words = set(indicator_desc.split())
        vuln_words = set(vuln_desc.split())
        
        if not indicator_words or not vuln_words:
            return 'LOW'
        
        common_words = indicator_words.intersection(vuln_words)
        similarity = len(common_words) / max(len(indicator_words), len(vuln_words))
        
        if similarity > 0.5:
            return 'HIGH'
        elif similarity > 0.2:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _calculate_service_match_confidence(self, service: Dict[str, Any], 
                                          db_vuln: Dict[str, Any]) -> str:
        """Calculate confidence for service vulnerability matches."""
        
        service_name = service.get('service', '').lower()
        vuln_desc = db_vuln.get('description', '').lower()
        
        # Direct service name match
        if service_name in vuln_desc:
            return 'HIGH'
        
        # Product name match
        product = service.get('product', '').lower()
        if product and product in vuln_desc:
            return 'HIGH'
        
        # Partial matches
        if any(word in vuln_desc for word in service_name.split() if len(word) > 3):
            return 'MEDIUM'
        
        return 'LOW'