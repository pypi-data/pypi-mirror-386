kubernetes:
 remote_identity: SERVICE_ACCOUNT
 autoscaler: gke
 pod_config:
   metadata:
     annotations:
       devices.gke.io/container.tcpxo-daemon: |+
         - path: /dev/nvidia0
         - path: /dev/nvidia1
         - path: /dev/nvidia2
         - path: /dev/nvidia3
         - path: /dev/nvidia4
         - path: /dev/nvidia5
         - path: /dev/nvidia6
         - path: /dev/nvidia7
         - path: /dev/nvidiactl
         - path: /dev/nvidia-uvm
         - path: /dev/dmabuf_import_helper
       networking.gke.io/default-interface: 'eth0'
       networking.gke.io/interfaces: |
         [
           {"interfaceName":"eth0","network":"default"},
           {"interfaceName":"eth1","network":"vpc1"},
           {"interfaceName":"eth2","network":"vpc2"},
           {"interfaceName":"eth3","network":"vpc3"},
           {"interfaceName":"eth4","network":"vpc4"},
           {"interfaceName":"eth5","network":"vpc5"},
           {"interfaceName":"eth6","network":"vpc6"},
           {"interfaceName":"eth7","network":"vpc7"},
           {"interfaceName":"eth8","network":"vpc8"}
         ]
   spec:
     initContainers:
       - name: tcpxo-daemon
         image: "us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.9"
         imagePullPolicy: Always
         restartPolicy: Always
         command: ["/bin/sh", "-c"]
         args:
           - |
             set -ex
             chmod 755 /fts/entrypoint_rxdm_container.sh
             /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8 --uid= --alsologtostderr
         securityContext:
           capabilities:
             add:
               - NET_ADMIN
               - NET_BIND_SERVICE
         volumeMounts:
           - name: sys
             mountPath: /hostsysfs
           - name: proc-sys
             mountPath: /hostprocsysfs
          #  - name: aperture-devices
          #    mountPath: /dev/aperture_devices
           - name: nvidia
             mountPath: /usr/local/nvidia/lib64
         env:
           - name: LD_LIBRARY_PATH
             value: /usr/local/nvidia/lib64
          #  - name: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY
          #    value: /dev/aperture_devices
     containers:
       - env:
         - name: NCCL_FASTRAK_CTRL_DEV
           value: "eth0"
         - name: NCCL_FASTRAK_IFNAME
           value: "eth1,eth2,eth3,eth4,eth5,eth6,eth7,eth8,"
         - name: NCCL_FASTTRAK_NUM_FLOWS
           value: "2"
         - name: NCCL_SOCKET_IFNAME
           value: "eth0,"
         - name: NCCL_CROSS_NIC
           value: "0"
         - name: NCCL_ALGO
           value: "Ring,Tree"
         - name: NCCL_PROTO
           value: "Simple"
         - name: NCCL_MIN_NCHANNELS
           value: "4"
         - name: NCCL_TUNER_PLUGIN
           value: "libnccl-tuner.so"
         - name: NCCL_TUNER_CONFIG_PATH
           value: "/usr/local/nvidia/lib64/a3plus_tuner_config.textproto"
         - name: NCCL_SHIMNET_GUEST_CONFIG_CHECKER_CONFIG_FILE
           value: "/usr/local/nvidia/lib64/a3plus_guest_config.textproto"
         - name: NCCL_DYNAMIC_CHUNK_SIZE
           value: "524288"
         - name: NCCL_P2P_NET_CHUNKSIZE
           value: "524288"
         - name: NCCL_P2P_PCI_CHUNKSIZE
           value: "524288"
         - name: NCCL_P2P_NVL_CHUNKSIZE
           value: "1048576"
         - name: NCCL_FASTRAK_NUM_FLOWS
           value: "2"
         - name: NCCL_FASTRAK_USE_SNAP
           value: "1"
         - name: NCCL_FASTRAK_PLUGIN_ACCEPT_TIMEOUT_MS
           value: "600000"
         - name: NCCL_FASTRAK_ENABLE_CONTROL_CHANNEL
           value: "0"
         - name: NCCL_BUFFSIZE
           value: "8388608"
         - name: CUDA_VISIBLE_DEVICES
           value: "0,1,2,3,4,5,6,7"
         - name: NCCL_NET_GDR_LEVEL
           value: "PIX"
         - name: NCCL_FASTRAK_ENABLE_HOTPATH_LOGGING
           value: "0"
         - name: NCCL_FASTRAK_USE_LLCM
           value: "1"
         - name: NCCL_NVLS_ENABLE
           value: "0"
         - name: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY
           value: "/dev/aperture_devices"
         - name: NCCL_LIB_DIR
           value: "/usr/local/nvidia/lib64"
         volumeMounts:
           - name: sys
             mountPath: /hostsysfs
           # - name: shared-memory
           #   mountPath: /dev/shm
           - name: proc-sys
             mountPath: /hostprocsysfs
           - name: aperture-devices
             mountPath: /dev/aperture_devices
           - name: nvidia
             mountPath: /usr/local/nvidia/lib64
     volumes:
       - name: nvidia
         hostPath:
           path: /home/kubernetes/bin/nvidia/lib64
       # - name: shared-memory
       #   emptyDir:
       #     medium: "Memory"
       #     sizeLimit: 1Gi
       - name: sys
         hostPath:
           path: "/sys"
       - name: proc-sys
         hostPath:
           path: "/proc/sys"
       - name: aperture-devices
         hostPath:
           path: "/dev/aperture_devices"
