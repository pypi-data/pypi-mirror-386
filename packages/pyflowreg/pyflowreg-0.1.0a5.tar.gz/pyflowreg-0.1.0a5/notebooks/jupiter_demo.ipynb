{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupiter Demo - Motion Compensation with PyFlowReg\n",
    "\n",
    "This notebook demonstrates optical flow-based motion compensation on a Jupiter video showing atmospheric distortion.\n",
    "The example simulates a two-channel recording and compares results with and without motion compensation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import os\nimport sys\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom IPython.display import HTML\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Add parent directory to path for imports\nsys.path.insert(0, str(Path.cwd().parent))\n\nfrom pyflowreg.motion_correction.OF_options import OFOptions\nfrom pyflowreg.motion_correction.compensate_recording import compensate_recording, RegistrationConfig\nfrom pyflowreg.util.io.factory import get_video_file_reader, get_video_file_writer\nfrom pyflowreg.util.download import download_demo_data",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Jupiter Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create output directory for results\noutput_folder = Path(\"jupiter_demo\")\noutput_folder.mkdir(exist_ok=True)\n\n# Download jupiter.tiff to data folder (default location)\ninput_file = download_demo_data(\"jupiter.tiff\")\nprint(f\"✓ Jupiter data available at {input_file}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert TIFF to HDF5 Format (Simulating Multi-Channel)\n",
    "\n",
    "We simulate a two-channel recording by duplicating the single channel data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create video readers - simulating multichannel by reading the same file twice\n",
    "buffer_size = 50\n",
    "vid = get_video_file_reader([str(input_file), str(input_file)], buffer_size)\n",
    "\n",
    "print(f\"Video properties:\")\n",
    "print(f\"  Shape: {vid.shape} (frames, height, width, channels)\")\n",
    "print(f\"  Data type: {vid.dtype}\")\n",
    "\n",
    "# Create HDF5 writers\n",
    "hdf5_single_path = output_folder / \"jup_single.h5\"\n",
    "hdf5_multi_path = output_folder / \"jup_mult\"\n",
    "\n",
    "# Single HDF5 file with multiple datasets\n",
    "hdf5_writer_single = get_video_file_writer(\n",
    "    str(hdf5_single_path), 'HDF5', dataset_names=['ch1', 'ch2']\n",
    ")\n",
    "\n",
    "# Multiple HDF5 files (one per channel)\n",
    "hdf5_writer_mult = get_video_file_writer(\n",
    "    str(hdf5_multi_path), 'MULTIFILE_HDF5', dataset_names='/vid'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert TIFF to HDF5 formats\n",
    "print(\"Converting TIFF to HDF5 formats...\")\n",
    "batch_count = 0\n",
    "\n",
    "while vid.has_batch():\n",
    "    batch = vid.read_batch()\n",
    "    hdf5_writer_single.write_frames(batch)\n",
    "    hdf5_writer_mult.write_frames(batch)\n",
    "    batch_count += 1\n",
    "    if batch_count % 10 == 0:\n",
    "        print(f\"  Processed batch {batch_count}\")\n",
    "\n",
    "# Close writers\n",
    "hdf5_writer_single.close()\n",
    "hdf5_writer_mult.close()\n",
    "vid.close()\n",
    "\n",
    "print(f\"✓ Conversion complete. Processed {batch_count} batches.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Motion Compensation Using Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configure motion compensation\n",
    "comp_output_path = output_folder / \"hdf5_comp\"\n",
    "compensated_file = comp_output_path / \"compensated.HDF5\"\n",
    "\n",
    "# Check if already compensated\n",
    "if not compensated_file.exists():\n",
    "    print(\"Running motion compensation...\")\n",
    "    \n",
    "    # Create options for motion compensation\n",
    "    options = OFOptions(\n",
    "        input_file=str(hdf5_single_path),\n",
    "        output_path=str(comp_output_path),\n",
    "        output_format='HDF5',\n",
    "        alpha=4,  # Larger alpha to avoid registering changing morphology\n",
    "        min_level=3,  # Coarser resolution for final solution\n",
    "        bin_size=1,\n",
    "        buffer_size=500,\n",
    "        reference_frames=list(range(100, 201)),  # Frames 100-200 as reference\n",
    "        save_meta_info=True,\n",
    "        save_w=False  # Don't save displacement fields for this demo\n",
    "    )\n",
    "    \n",
    "    # Create registration config\n",
    "    config = RegistrationConfig(\n",
    "        n_jobs=-1,  # Use all cores\n",
    "        batch_size=100,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Run compensation\n",
    "    compensate_recording(options, config=config)\n",
    "    print(\"✓ Motion compensation complete!\")\n",
    "else:\n",
    "    print(f\"✓ Using existing compensated file: {compensated_file}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Original and Compensated Videos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Reset and load videos\n",
    "print(\"Loading videos...\")\n",
    "\n",
    "# Original (uncompensated) video\n",
    "vid_nocomp = get_video_file_reader(str(hdf5_single_path), buffer_size)\n",
    "print(f\"Original video: {vid_nocomp.shape}\")\n",
    "\n",
    "# Compensated video\n",
    "vid_comp = get_video_file_reader(str(compensated_file), buffer_size)\n",
    "print(f\"Compensated video: {vid_comp.shape}\")\n",
    "\n",
    "# Verify dimensions match\n",
    "assert vid_nocomp.shape == vid_comp.shape, \"Video dimensions mismatch!\"\n",
    "height, width = vid_nocomp.height, vid_nocomp.width\n",
    "n_frames = vid_nocomp.frame_count\n",
    "print(f\"✓ Videos loaded: {n_frames} frames, {height}x{width} pixels\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Time Courses and Temporal Slices"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize arrays for analysis\n",
    "temporal_slice_comp = np.zeros((height, n_frames), dtype=vid_comp.dtype)\n",
    "temporal_slice_nocomp = np.zeros((height, n_frames), dtype=vid_nocomp.dtype)\n",
    "time_course_comp = np.zeros(n_frames)\n",
    "time_course_nocomp = np.zeros(n_frames)\n",
    "\n",
    "# Impact location (x, y) - center of the impact event\n",
    "imp_xy = (105, 220)  # Adjust based on the actual impact location\n",
    "\n",
    "# Process videos in batches\n",
    "print(\"Processing video batches...\")\n",
    "idx = 0\n",
    "baseline_comp = None\n",
    "baseline_nocomp = None\n",
    "\n",
    "# For storing full videos for averaging\n",
    "all_frames_comp = []\n",
    "all_frames_nocomp = []\n",
    "\n",
    "while vid_nocomp.has_batch() and vid_comp.has_batch():\n",
    "    nocomp_buffer = vid_nocomp.read_batch()  # (T, H, W, C)\n",
    "    comp_buffer = vid_comp.read_batch()\n",
    "    batch_frames = nocomp_buffer.shape[0]\n",
    "    \n",
    "    # Store frames for averaging later\n",
    "    all_frames_comp.append(comp_buffer[:, :, :, 0])  # First channel only\n",
    "    all_frames_nocomp.append(nocomp_buffer[:, :, :, 0])\n",
    "    \n",
    "    # Calculate baseline from first 10 frames\n",
    "    if idx == 0:\n",
    "        baseline_comp = np.mean(comp_buffer[:10, imp_xy[1], imp_xy[0], 0])\n",
    "        baseline_nocomp = np.mean(nocomp_buffer[:10, imp_xy[1], imp_xy[0], 0])\n",
    "        print(f\"Baseline intensities - Compensated: {baseline_comp:.1f}, Original: {baseline_nocomp:.1f}\")\n",
    "    \n",
    "    # Extract time courses (relative intensity change)\n",
    "    for t in range(batch_frames):\n",
    "        val_comp = comp_buffer[t, imp_xy[1], imp_xy[0], 0]\n",
    "        val_nocomp = nocomp_buffer[t, imp_xy[1], imp_xy[0], 0]\n",
    "        \n",
    "        time_course_comp[idx + t] = (val_comp - baseline_comp) / baseline_comp if baseline_comp > 0 else 0\n",
    "        time_course_nocomp[idx + t] = (val_nocomp - baseline_nocomp) / baseline_nocomp if baseline_nocomp > 0 else 0\n",
    "        \n",
    "        # Extract temporal slices (vertical line through impact point)\n",
    "        temporal_slice_comp[:, idx + t] = comp_buffer[t, :, imp_xy[0], 0]\n",
    "        temporal_slice_nocomp[:, idx + t] = nocomp_buffer[t, :, imp_xy[0], 0]\n",
    "    \n",
    "    idx += batch_frames\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"  Processed {idx}/{n_frames} frames\")\n",
    "\n",
    "# Concatenate all frames\n",
    "all_frames_comp = np.concatenate(all_frames_comp, axis=0)\n",
    "all_frames_nocomp = np.concatenate(all_frames_nocomp, axis=0)\n",
    "\n",
    "print(f\"✓ Processing complete. Analyzed {idx} frames.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Average Frames Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate average frames\n",
    "avg_frame_comp = np.mean(all_frames_comp, axis=0)\n",
    "avg_frame_nocomp = np.mean(all_frames_nocomp, axis=0)\n",
    "\n",
    "# Calculate standard deviation (as proxy for motion blur)\n",
    "std_frame_comp = np.std(all_frames_comp, axis=0)\n",
    "std_frame_nocomp = np.std(all_frames_nocomp, axis=0)\n",
    "\n",
    "# Plot average frames\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Average frames\n",
    "im1 = axes[0, 0].imshow(avg_frame_nocomp, cmap='gray')\n",
    "axes[0, 0].set_title('Average Frame - No Compensation')\n",
    "axes[0, 0].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 0], fraction=0.046)\n",
    "\n",
    "im2 = axes[0, 1].imshow(avg_frame_comp, cmap='gray')\n",
    "axes[0, 1].set_title('Average Frame - With Compensation')\n",
    "axes[0, 1].axis('off')\n",
    "plt.colorbar(im2, ax=axes[0, 1], fraction=0.046)\n",
    "\n",
    "# Difference\n",
    "diff = avg_frame_comp - avg_frame_nocomp\n",
    "im3 = axes[0, 2].imshow(diff, cmap='RdBu_r', vmin=-np.abs(diff).max(), vmax=np.abs(diff).max())\n",
    "axes[0, 2].set_title('Difference (Comp - NoComp)')\n",
    "axes[0, 2].axis('off')\n",
    "plt.colorbar(im3, ax=axes[0, 2], fraction=0.046)\n",
    "\n",
    "# Standard deviation (motion blur indicator)\n",
    "im4 = axes[1, 0].imshow(std_frame_nocomp, cmap='hot')\n",
    "axes[1, 0].set_title('Std Dev - No Compensation (Motion Blur)')\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im4, ax=axes[1, 0], fraction=0.046)\n",
    "\n",
    "im5 = axes[1, 1].imshow(std_frame_comp, cmap='hot')\n",
    "axes[1, 1].set_title('Std Dev - With Compensation')\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im5, ax=axes[1, 1], fraction=0.046)\n",
    "\n",
    "# Reduction in motion blur\n",
    "blur_reduction = std_frame_nocomp - std_frame_comp\n",
    "im6 = axes[1, 2].imshow(blur_reduction, cmap='viridis')\n",
    "axes[1, 2].set_title('Motion Blur Reduction')\n",
    "axes[1, 2].axis('off')\n",
    "plt.colorbar(im6, ax=axes[1, 2], fraction=0.046)\n",
    "\n",
    "# Add impact location marker\n",
    "for ax in axes.flat:\n",
    "    ax.plot(imp_xy[0], imp_xy[1], 'r+', markersize=10, markeredgewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Motion blur reduction statistics:\")\n",
    "print(f\"  Average blur (std) without compensation: {std_frame_nocomp.mean():.2f}\")\n",
    "print(f\"  Average blur (std) with compensation: {std_frame_comp.mean():.2f}\")\n",
    "print(f\"  Reduction: {(1 - std_frame_comp.mean()/std_frame_nocomp.mean())*100:.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Temporal Slices Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot temporal slices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Define region of interest for temporal slice (around impact)\n",
    "roi_y = slice(95, 270)\n",
    "\n",
    "# No compensation\n",
    "im1 = axes[0].imshow(temporal_slice_nocomp[roi_y, :], aspect='auto', cmap='gray')\n",
    "axes[0].set_title('Temporal Slice - No Motion Compensation')\n",
    "axes[0].set_xlabel('Time (frames)')\n",
    "axes[0].set_ylabel('Y Position (pixels)')\n",
    "axes[0].axhline(y=imp_xy[1]-95, color='r', linestyle='--', alpha=0.5, label='Impact location')\n",
    "plt.colorbar(im1, ax=axes[0], fraction=0.046)\n",
    "\n",
    "# With compensation\n",
    "im2 = axes[1].imshow(temporal_slice_comp[roi_y, :], aspect='auto', cmap='gray')\n",
    "axes[1].set_title('Temporal Slice - With Motion Compensation')\n",
    "axes[1].set_xlabel('Time (frames)')\n",
    "axes[1].set_ylabel('Y Position (pixels)')\n",
    "axes[1].axhline(y=imp_xy[1]-95, color='r', linestyle='--', alpha=0.5, label='Impact location')\n",
    "plt.colorbar(im2, ax=axes[1], fraction=0.046)\n",
    "\n",
    "# Difference\n",
    "diff_slice = temporal_slice_comp[roi_y, :] - temporal_slice_nocomp[roi_y, :]\n",
    "im3 = axes[2].imshow(diff_slice, aspect='auto', cmap='RdBu_r', \n",
    "                     vmin=-np.abs(diff_slice).max(), vmax=np.abs(diff_slice).max())\n",
    "axes[2].set_title('Difference in Temporal Slices')\n",
    "axes[2].set_xlabel('Time (frames)')\n",
    "axes[2].set_ylabel('Y Position (pixels)')\n",
    "axes[2].axhline(y=imp_xy[1]-95, color='g', linestyle='--', alpha=0.5)\n",
    "plt.colorbar(im3, ax=axes[2], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Temporal slices show the evolution of intensity along a vertical line through the impact point.\")\n",
    "print(\"Notice how motion compensation reduces the vertical streaking caused by atmospheric distortion.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Time Course Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Time axis (assuming 66 fps from MATLAB comment)\n",
    "fps = 66\n",
    "time = np.arange(n_frames) / fps\n",
    "\n",
    "# Plot time courses\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Main time course\n",
    "axes[0].plot(time, time_course_nocomp, 'b-', alpha=0.7, label='No compensation', linewidth=1)\n",
    "axes[0].plot(time, time_course_comp, 'r-', alpha=0.7, label='With compensation', linewidth=1)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Relative Intensity Change')\n",
    "axes[0].set_title(f'Time Course of Impact Event at Position ({imp_xy[0]}, {imp_xy[1]})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Zoom in on a specific region (e.g., around the peak)\n",
    "peak_idx = np.argmax(np.abs(time_course_comp))\n",
    "zoom_range = slice(max(0, peak_idx-200), min(n_frames, peak_idx+200))\n",
    "\n",
    "axes[1].plot(time[zoom_range], time_course_nocomp[zoom_range], 'b-', alpha=0.7, \n",
    "             label='No compensation', linewidth=2)\n",
    "axes[1].plot(time[zoom_range], time_course_comp[zoom_range], 'r-', alpha=0.7, \n",
    "             label='With compensation', linewidth=2)\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Relative Intensity Change')\n",
    "axes[1].set_title('Zoomed View Around Peak')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate SNR improvement\n",
    "noise_comp = np.std(time_course_comp[100:200])  # Use reference frames for noise\n",
    "noise_nocomp = np.std(time_course_nocomp[100:200])\n",
    "signal_comp = np.max(np.abs(time_course_comp))\n",
    "signal_nocomp = np.max(np.abs(time_course_nocomp))\n",
    "\n",
    "snr_comp = signal_comp / noise_comp if noise_comp > 0 else 0\n",
    "snr_nocomp = signal_nocomp / noise_nocomp if noise_nocomp > 0 else 0\n",
    "\n",
    "print(f\"\\nSignal-to-Noise Ratio Analysis:\")\n",
    "print(f\"  SNR without compensation: {snr_nocomp:.2f}\")\n",
    "print(f\"  SNR with compensation: {snr_comp:.2f}\")\n",
    "print(f\"  SNR improvement: {(snr_comp/snr_nocomp - 1)*100:.1f}%\" if snr_nocomp > 0 else \"  SNR improvement: N/A\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Frame-by-Frame Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Select specific frames to compare - evenly spaced through the video\nn_compare = min(4, n_frames)  # Use up to 4 frames\nframe_indices = np.linspace(0, n_frames-1, n_compare, dtype=int)  # Evenly spaced frames\n\n# Filter out any invalid indices (just in case)\nvalid_indices = [idx for idx in frame_indices if idx < n_frames]\nn_compare = len(valid_indices)\n\nfig, axes = plt.subplots(2, n_compare, figsize=(4*n_compare, 8))\n\nfor i, frame_idx in enumerate(valid_indices):\n    # Original frame\n    axes[0, i].imshow(all_frames_nocomp[frame_idx], cmap='gray')\n    axes[0, i].set_title(f'Frame {frame_idx} - Original')\n    axes[0, i].axis('off')\n    axes[0, i].plot(imp_xy[0], imp_xy[1], 'r+', markersize=10, markeredgewidth=2)\n    \n    # Compensated frame\n    axes[1, i].imshow(all_frames_comp[frame_idx], cmap='gray')\n    axes[1, i].set_title(f'Frame {frame_idx} - Compensated')\n    axes[1, i].axis('off')\n    axes[1, i].plot(imp_xy[0], imp_xy[1], 'r+', markersize=10, markeredgewidth=2)\n\nplt.suptitle('Frame-by-Frame Comparison', fontsize=14)\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Create Side-by-Side Animation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create animation comparing first 200 frames\n",
    "n_anim_frames = min(200, n_frames)\n",
    "skip = 2  # Show every nth frame for speed\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Initialize plots\n",
    "im1 = ax1.imshow(all_frames_nocomp[0], cmap='gray', animated=True)\n",
    "ax1.set_title('Original')\n",
    "ax1.axis('off')\n",
    "ax1.plot(imp_xy[0], imp_xy[1], 'r+', markersize=10, markeredgewidth=2)\n",
    "\n",
    "im2 = ax2.imshow(all_frames_comp[0], cmap='gray', animated=True)\n",
    "ax2.set_title('Motion Compensated')\n",
    "ax2.axis('off')\n",
    "ax2.plot(imp_xy[0], imp_xy[1], 'r+', markersize=10, markeredgewidth=2)\n",
    "\n",
    "plt.suptitle('Jupiter Impact Event - Motion Compensation Comparison', fontsize=14)\n",
    "\n",
    "def animate(frame):\n",
    "    idx = frame * skip\n",
    "    if idx < n_frames:\n",
    "        im1.set_array(all_frames_nocomp[idx])\n",
    "        im2.set_array(all_frames_comp[idx])\n",
    "    return [im1, im2]\n",
    "\n",
    "# Create animation\n",
    "anim = animation.FuncAnimation(fig, animate, frames=n_anim_frames//skip, \n",
    "                              interval=50, blit=True)\n",
    "\n",
    "# Display animation\n",
    "plt.close()  # Prevent static display\n",
    "HTML(anim.to_jshtml())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load saved metadata if available\n",
    "meta_path = comp_output_path / \"statistics.npz\"\n",
    "if meta_path.exists():\n",
    "    stats = np.load(meta_path)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Mean displacement\n",
    "    axes[0, 0].plot(stats['mean_disp'])\n",
    "    axes[0, 0].set_title('Mean Displacement Magnitude')\n",
    "    axes[0, 0].set_xlabel('Frame')\n",
    "    axes[0, 0].set_ylabel('Pixels')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Max displacement\n",
    "    axes[0, 1].plot(stats['max_disp'])\n",
    "    axes[0, 1].set_title('Maximum Displacement Magnitude')\n",
    "    axes[0, 1].set_xlabel('Frame')\n",
    "    axes[0, 1].set_ylabel('Pixels')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mean divergence\n",
    "    axes[1, 0].plot(stats['mean_div'])\n",
    "    axes[1, 0].set_title('Mean Flow Divergence')\n",
    "    axes[1, 0].set_xlabel('Frame')\n",
    "    axes[1, 0].set_ylabel('Divergence')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mean translation\n",
    "    axes[1, 1].plot(stats['mean_translation'])\n",
    "    axes[1, 1].set_title('Mean Translation')\n",
    "    axes[1, 1].set_xlabel('Frame')\n",
    "    axes[1, 1].set_ylabel('Pixels')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Motion Compensation Statistics', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nMotion Statistics Summary:\")\n",
    "    print(f\"  Average displacement: {stats['mean_disp'].mean():.2f} pixels\")\n",
    "    print(f\"  Maximum displacement: {stats['max_disp'].max():.2f} pixels\")\n",
    "    print(f\"  Average divergence: {stats['mean_div'].mean():.4f}\")\n",
    "    print(f\"  Average translation: {stats['mean_translation'].mean():.2f} pixels\")\n",
    "else:\n",
    "    print(\"No statistics file found. Run with save_meta_info=True to generate statistics.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Close video readers\n",
    "vid_comp.close()\n",
    "vid_nocomp.close()\n",
    "\n",
    "print(\"✓ Analysis complete!\")\n",
    "print(f\"\\nResults saved in: {output_folder}\")\n",
    "print(f\"  - Original HDF5: {hdf5_single_path}\")\n",
    "print(f\"  - Compensated HDF5: {compensated_file}\")\n",
    "print(f\"  - Reference frame: {comp_output_path / 'reference_frame.npy'}\")\n",
    "print(f\"  - Statistics: {meta_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
