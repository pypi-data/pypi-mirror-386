{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19229090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentor.memory.api import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = Memory()\n",
    "\n",
    "to_process = {\n",
    "    \"user\": \"How many 'r's in strawberries?\",\n",
    "    \"agent\": \"there are 0 'r's in strawberries\",\n",
    "}\n",
    "mem.add(to_process)\n",
    "mem.get_full_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7219ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_process = {\n",
    "    \"user\": \"What is the capital of France?\",\n",
    "    \"agent\": \"Paris is the capital of France\",\n",
    "}\n",
    "mem.add(to_process)\n",
    "mem.get_full_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71510bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem.search(\"capital of a city\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce194eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "#\n",
    "# client = OpenAI()\n",
    "#\n",
    "# response = client.responses.create(\n",
    "#     model=\"gpt-5-mini\",\n",
    "#     input=\"how many 'r's in Strawberries\",\n",
    "#     reasoning={\"effort\": \"low\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "db = lancedb.connect(\"/tmp/db\")\n",
    "model = (\n",
    "    get_registry()\n",
    "    .get(\"sentence-transformers\")\n",
    "    .create(name=\"google/embeddinggemma-300M\", device=\"cpu\")\n",
    ")\n",
    "\n",
    "\n",
    "class Words(LanceModel):\n",
    "    text: str = model.SourceField()\n",
    "    vector: Vector(model.ndims()) = model.VectorField()\n",
    "\n",
    "\n",
    "table = db.create_table(\"words\", schema=Words)\n",
    "table.add([{\"text\": \"hello world\"}, {\"text\": \"goodbye world\"}])\n",
    "\n",
    "query = \"greetings\"\n",
    "actual = table.search(query).limit(1).to_pydantic(Words)[0]\n",
    "print(actual.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62170eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "from agentor.memory.tools import memory_search, memory_get_full_conversation, memory_add\n",
    "\n",
    "_instructions = \"\"\"\n",
    "You are a memory agent. You are responsible for finding relevent information from the memory for the user's request and updating the memory with the new information.\n",
    "\n",
    "You have the following tools:\n",
    "- memory_search tool to search the memory for the most relevant conversations.\n",
    "- memory_get_full_conversation tool to get the full conversation from the memory.\n",
    "- memory_add tool to add a conversation to the memory.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_memory_agent(model: str = \"gpt-5-mini\") -> Agent:\n",
    "    return Agent(\n",
    "        name=\"Memory agent\",\n",
    "        instructions=_instructions,\n",
    "        tools=[memory_search, memory_get_full_conversation, memory_add],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "\n",
    "from agents import Runner, RunContextWrapper\n",
    "from agentor.utils import AppContext\n",
    "from agentor.memory.api import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9f605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"Memory agent\", ...)\n",
      "- Final output (str):\n",
      "    The capital of France is Paris.\n",
      "    \n",
      "    Note: I tried to check and update your memory but couldn't access the memory service right now. Would you like me to try again?\n",
      "- 11 new item(s)\n",
      "- 4 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "agent = build_memory_agent()\n",
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentor.utils import CoreServices\n",
    "\n",
    "output = runner.run_streamed(\n",
    "    agent,\n",
    "    \"What is the capital of France?\",\n",
    "    context=RunContextWrapper(AppContext(core=CoreServices(memory=mem))),\n",
    ")\n",
    "async for chunk in output.stream_events():\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
