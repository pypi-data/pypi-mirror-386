"""
Point-in-Time Recovery (PITR) Manager

Production-grade PITR implementation for PostgreSQL and MySQL:
- WAL archiving and recovery for PostgreSQL
- Binary log streaming for MySQL
- Automated recovery procedures
- Recovery validation and verification
"""

import asyncio
import logging
import os
import shutil
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class PITRManager:
    """
    Point-in-Time Recovery Manager.

    Handles all aspects of PITR including:
    - WAL/binlog archiving configuration
    - Base backup creation for PITR
    - Recovery configuration
    - Recovery execution and validation
    """

    def __init__(self, archive_dir: Optional[str] = None):
        """
        Initialize PITR manager.

        Args:
            archive_dir: Directory for WAL/binlog archive storage
                        (defaults to temp directory if not specified)
        """
        if archive_dir is None:
            import tempfile

            archive_dir = os.path.join(tempfile.gettempdir(), "covet_wal_archive")

        self.archive_dir = Path(archive_dir)
        self.archive_dir.mkdir(parents=True, exist_ok=True)

    async def setup_postgresql_wal_archiving(
        self,
        data_directory: str,
        archive_command: Optional[str] = None,
        restart_required: bool = True,
    ) -> Dict[str, Any]:
        """
        Configure PostgreSQL for WAL archiving (required for PITR).

        Args:
            data_directory: PostgreSQL data directory
            archive_command: Custom archive command (auto-generated if None)
            restart_required: Whether PostgreSQL restart is required

        Returns:
            Configuration details and instructions
        """
        data_dir = Path(data_directory)

        # Create archive directory for this database
        db_archive_dir = self.archive_dir / "postgresql"
        db_archive_dir.mkdir(parents=True, exist_ok=True)

        # Generate archive command if not provided
        if archive_command is None:
            # Standard archive command that copies WAL files
            archive_command = f"test ! -f {db_archive_dir}/%f && cp %p {db_archive_dir}/%f"

        # PostgreSQL configuration for WAL archiving
        wal_config = f"""
# Point-in-Time Recovery Configuration
# Generated by CovetPy Backup System on {datetime.now().isoformat()}

# Enable WAL archiving
wal_level = replica
archive_mode = on
archive_command = '{archive_command}'

# WAL retention
wal_keep_size = 1GB
max_wal_senders = 3

# Optional: Enable continuous archiving
# archive_timeout = 300  # Force WAL file switch every 5 minutes
"""

        # Write configuration to postgresql.auto.conf
        auto_conf_path = data_dir / "postgresql.auto.conf"

        # Read existing content
        existing_content = ""
        if auto_conf_path.exists():
            existing_content = auto_conf_path.read_text()

        # Remove any existing PITR configuration
        lines = existing_content.split("\n")
        filtered_lines = [
            line
            for line in lines
            if not any(
                param in line
                for param in [
                    "wal_level",
                    "archive_mode",
                    "archive_command",
                    "wal_keep_size",
                    "max_wal_senders",
                    "archive_timeout",
                ]
            )
        ]

        # Append new configuration
        new_content = "\n".join(filtered_lines) + "\n" + wal_config
        auto_conf_path.write_text(new_content)

        logger.info(f"PostgreSQL WAL archiving configured in {auto_conf_path}")
        logger.info(f"WAL archive directory: {db_archive_dir}")

        return {
            "status": "configured",
            "archive_directory": str(db_archive_dir),
            "archive_command": archive_command,
            "config_file": str(auto_conf_path),
            "restart_required": restart_required,
            "instructions": (
                f"WAL archiving has been configured.\n"
                f"Archive directory: {db_archive_dir}\n"
                f"{'PostgreSQL must be restarted for changes to take effect.' if restart_required else ''}\n"
                f"Verify with: SHOW archive_mode; SHOW archive_command;"
            ),
        }

    async def create_postgresql_base_backup(
        self, config: Dict[str, Any], output_dir: str, wal_method: str = "stream"
    ) -> Dict[str, Any]:
        """
        Create PostgreSQL base backup with WAL files for PITR.

        Args:
            config: Database configuration
            output_dir: Output directory for base backup
            wal_method: WAL method (stream, fetch, none)

        Returns:
            Backup metadata including WAL information
        """
        from .backup_strategy import PostgreSQLBackupStrategy

        strategy = PostgreSQLBackupStrategy(config)

        # Verify WAL archiving is enabled
        wal_config = await self._verify_wal_archiving(strategy)
        if not wal_config.get("archive_mode_on"):
            logger.warning(
                "WAL archiving is not enabled. PITR may not work correctly. "
                "Run setup_postgresql_wal_archiving() first."
            )

        # Create base backup using pg_basebackup
        backup_result = await strategy.create_base_backup(output_dir, wal_method=wal_method)

        # Get current WAL position
        wal_info = await strategy._get_wal_position()

        backup_result.update(
            {
                "backup_type": "base_backup_for_pitr",
                "wal_method": wal_method,
                "current_wal_lsn": wal_info.get("current_lsn"),
                "archive_mode": wal_config.get("archive_mode"),
                "archive_command": wal_config.get("archive_command"),
            }
        )

        logger.info(f"PostgreSQL base backup created: {output_dir}")
        logger.info(f"Current WAL LSN: {wal_info.get('current_lsn')}")

        return backup_result

    async def _verify_wal_archiving(self, strategy) -> Dict[str, Any]:
        """Verify PostgreSQL WAL archiving configuration."""
        try:
            cmd = [
                strategy.psql_path,
                f"--host={strategy.host}",
                f"--port={strategy.port}",
                f"--username={strategy.user}",
                f"--dbname={strategy.database_name}",
                "--tuples-only",
                "--no-align",
                "--command=SELECT archive_mode, archive_command FROM pg_settings WHERE name IN ('archive_mode', 'archive_command');",
            ]

            env = os.environ.copy()
            if strategy.password:
                env["PGPASSWORD"] = strategy.password

            result = await asyncio.create_subprocess_exec(
                *cmd,
                env=env,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            stdout, stderr = await result.communicate()

            if result.returncode == 0 and stdout:
                lines = stdout.decode().strip().split("\n")
                config = {}
                for line in lines:
                    if "archive_mode" in line:
                        config["archive_mode_on"] = "on" in line
                    elif "archive_command" in line:
                        config["archive_command"] = line.split("|")[-1].strip()
                return config

        except Exception as e:
            logger.warning(f"Failed to verify WAL archiving: {e}")

        return {"archive_mode_on": False}

    async def configure_postgresql_recovery(
        self,
        data_directory: str,
        target_time: Optional[str] = None,
        target_lsn: Optional[str] = None,
        recovery_target_action: str = "promote",
        restore_command: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Configure PostgreSQL for point-in-time recovery.

        Args:
            data_directory: PostgreSQL data directory
            target_time: Target recovery time (ISO format)
            target_lsn: Target LSN for recovery
            recovery_target_action: Action after recovery (promote, pause, shutdown)
            restore_command: Command to restore WAL files from archive

        Returns:
            Recovery configuration details
        """
        data_dir = Path(data_directory)

        # Determine PostgreSQL version (12+ uses recovery.signal)
        # For now, we'll create both for compatibility

        # Create recovery.signal file (PostgreSQL 12+)
        recovery_signal = data_dir / "recovery.signal"
        recovery_signal.touch()
        logger.info(f"Created recovery.signal: {recovery_signal}")

        # Generate restore command if not provided
        if restore_command is None:
            db_archive_dir = self.archive_dir / "postgresql"
            restore_command = f"cp {db_archive_dir}/%f %p"

        # Build recovery configuration
        recovery_config = [
            "# Point-in-Time Recovery Configuration",
            f"# Generated by CovetPy Backup System on {datetime.now().isoformat()}",
            "",
            f"restore_command = '{restore_command}'",
        ]

        if target_time:
            recovery_config.append(f"recovery_target_time = '{target_time}'")

        if target_lsn:
            recovery_config.append(f"recovery_target_lsn = '{target_lsn}'")

        recovery_config.append(f"recovery_target_action = '{recovery_target_action}'")

        # Write to postgresql.auto.conf (PostgreSQL 12+)
        auto_conf = data_dir / "postgresql.auto.conf"

        # Read existing content
        existing_content = ""
        if auto_conf.exists():
            existing_content = auto_conf.read_text()

        # Remove any existing recovery configuration
        lines = existing_content.split("\n")
        filtered_lines = [
            line
            for line in lines
            if not any(
                param in line
                for param in [
                    "restore_command",
                    "recovery_target_time",
                    "recovery_target_lsn",
                    "recovery_target_action",
                ]
            )
        ]

        # Append recovery configuration
        new_content = "\n".join(filtered_lines) + "\n" + "\n".join(recovery_config) + "\n"
        auto_conf.write_text(new_content)

        logger.info(f"Recovery configuration written to {auto_conf}")

        return {
            "status": "configured",
            "data_directory": str(data_dir),
            "recovery_signal_created": True,
            "config_file": str(auto_conf),
            "target_time": target_time,
            "target_lsn": target_lsn,
            "recovery_target_action": recovery_target_action,
            "restore_command": restore_command,
            "instructions": (
                f"Recovery has been configured.\n"
                f"Target: {target_time or target_lsn or 'end of WAL'}\n"
                f"Action: {recovery_target_action}\n"
                f"\nStart PostgreSQL to begin recovery:\n"
                f"  pg_ctl start -D {data_dir}\n"
                f"\nMonitor recovery progress:\n"
                f"  tail -f {data_dir}/log/postgresql-*.log\n"
                f"\nCheck recovery status:\n"
                f"  SELECT pg_is_in_recovery();"
            ),
        }

    async def setup_mysql_binlog_streaming(
        self, config: Dict[str, Any], binlog_dir: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Configure MySQL binary log streaming for PITR.

        Args:
            config: MySQL configuration
            binlog_dir: Directory for binary logs (uses MySQL default if None)

        Returns:
            Configuration details
        """
        # Create binlog archive directory
        db_archive_dir = self.archive_dir / "mysql"
        db_archive_dir.mkdir(parents=True, exist_ok=True)

        # Get current binary log position
        from .backup_strategy import MySQLBackupStrategy

        strategy = MySQLBackupStrategy(config)

        binlog_info = await self._get_mysql_binlog_position(strategy)

        logger.info(f"MySQL binary log streaming configured")
        logger.info(f"Current binlog: {binlog_info.get('file')}")
        logger.info(f"Current position: {binlog_info.get('position')}")

        return {
            "status": "configured",
            "archive_directory": str(db_archive_dir),
            "current_binlog_file": binlog_info.get("file"),
            "current_binlog_position": binlog_info.get("position"),
            "instructions": (
                f"Binary log information captured.\n"
                f"Current binlog: {binlog_info.get('file')} @ {binlog_info.get('position')}\n"
                f"\nEnsure MySQL binary logging is enabled:\n"
                f"  [mysqld]\n"
                f"  log-bin=mysql-bin\n"
                f"  server-id=1\n"
                f"  binlog_format=ROW\n"
                f"\nArchive binary logs to: {db_archive_dir}\n"
                f"Use mysqlbinlog for point-in-time recovery."
            ),
        }

    async def _get_mysql_binlog_position(self, strategy) -> Dict[str, Any]:
        """Get MySQL binary log position."""
        try:
            cmd = [
                strategy.mysql_path,
                f"--host={strategy.host}",
                f"--port={strategy.port}",
                f"--user={strategy.user}",
                "--skip-column-names",
                "--execute=SHOW MASTER STATUS;",
            ]

            env = os.environ.copy()
            if strategy.password:
                env["MYSQL_PWD"] = strategy.password

            result = await asyncio.create_subprocess_exec(
                *cmd,
                env=env,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            stdout, stderr = await result.communicate()

            if result.returncode == 0 and stdout:
                # Parse: file\tposition\tbinlog_do_db\tbinlog_ignore_db
                parts = stdout.decode().strip().split("\t")
                if len(parts) >= 2:
                    return {
                        "file": parts[0],
                        "position": parts[1],
                    }

        except Exception as e:
            logger.warning(f"Failed to get binlog position: {e}")

        return {}

    async def create_mysql_backup_with_binlog(
        self, config: Dict[str, Any], output_path: str, master_data: int = 2
    ) -> Dict[str, Any]:
        """
        Create MySQL backup with binary log position for PITR.

        Args:
            config: MySQL configuration
            output_path: Output file path
            master_data: Include binlog position (1=active, 2=commented)

        Returns:
            Backup metadata with binlog information
        """
        from .backup_strategy import MySQLBackupStrategy

        strategy = MySQLBackupStrategy(config)

        # Get binlog position before backup
        binlog_before = await self._get_mysql_binlog_position(strategy)

        # Create backup with master_data to capture binlog position
        backup_result = await strategy.create_backup(
            output_path, single_transaction=True, master_data=master_data
        )

        # Get binlog position after backup
        binlog_after = await self._get_mysql_binlog_position(strategy)

        backup_result.update(
            {
                "backup_type": "full_with_binlog",
                "binlog_file_before": binlog_before.get("file"),
                "binlog_position_before": binlog_before.get("position"),
                "binlog_file_after": binlog_after.get("file"),
                "binlog_position_after": binlog_after.get("position"),
                "master_data": master_data,
            }
        )

        logger.info(f"MySQL backup created with binlog position")
        logger.info(f"Binlog: {binlog_after.get('file')} @ {binlog_after.get('position')}")

        return backup_result

    async def verify_pitr_capability(
        self, database_type: str, config: Dict[str, Any]
    ) -> Dict[str, bool]:
        """
        Verify that PITR is properly configured for a database.

        Args:
            database_type: Database type (postgresql, mysql)
            config: Database configuration

        Returns:
            Dictionary of capability checks
        """
        capabilities = {
            "pitr_supported": False,
            "archiving_enabled": False,
            "archive_directory_exists": False,
            "base_backup_possible": False,
        }

        if database_type.lower() == "postgresql":
            from .backup_strategy import PostgreSQLBackupStrategy

            strategy = PostgreSQLBackupStrategy(config)

            # Check WAL archiving
            wal_config = await self._verify_wal_archiving(strategy)
            capabilities["archiving_enabled"] = wal_config.get("archive_mode_on", False)

            # Check archive directory
            db_archive_dir = self.archive_dir / "postgresql"
            capabilities["archive_directory_exists"] = db_archive_dir.exists()

            # Check if we can create base backup
            try:
                await strategy.test_connection()
                capabilities["base_backup_possible"] = True
            except:
                pass

            capabilities["pitr_supported"] = all(
                [
                    capabilities["archiving_enabled"],
                    capabilities["archive_directory_exists"],
                    capabilities["base_backup_possible"],
                ]
            )

        elif database_type.lower() == "mysql":
            from .backup_strategy import MySQLBackupStrategy

            strategy = MySQLBackupStrategy(config)

            # Check binlog configuration
            binlog_info = await self._get_mysql_binlog_position(strategy)
            capabilities["archiving_enabled"] = bool(binlog_info.get("file"))

            # Check archive directory
            db_archive_dir = self.archive_dir / "mysql"
            capabilities["archive_directory_exists"] = db_archive_dir.exists()

            # Check if we can create backup
            try:
                await strategy.test_connection()
                capabilities["base_backup_possible"] = True
            except:
                pass

            capabilities["pitr_supported"] = all(
                [capabilities["archiving_enabled"], capabilities["base_backup_possible"]]
            )

        return capabilities


__all__ = ["PITRManager"]
