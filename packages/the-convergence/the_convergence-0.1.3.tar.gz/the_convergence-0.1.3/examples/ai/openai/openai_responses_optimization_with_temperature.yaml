# OpenAI Responses API Optimization Configuration
# For GPT-5, O3, and other next-generation models
# Documentation: https://platform.openai.com/docs/api-reference/responses
#
# The Responses API is OpenAI's recommended API for all new projects.
# It provides better reasoning support, tool calling, and more flexible output formats.
#
# Setup:
# 1. Get API key from: https://platform.openai.com/api-keys
# 2. Set environment variable: export OPENAI_API_KEY="sk-..."
# 3. Run: convergence optimize examples/ai/openai_responses_optimization.yaml

api:
  name: "openai_responses"
  endpoint: "https://api.openai.com/v1/responses"
  auth:
    type: "bearer"
    token_env: "OPENAI_API_KEY"
  
  request:
    method: "POST"
    headers:
      Content-Type: "application/json"
    timeout_seconds: 60
  
  response:
    success_field: "status"  # Check if status == "completed"
    result_field: "output"   # Array containing the response message
    error_field: "error"
  
  # Rate limit handling
  # OpenAI enforces: RPM (requests/min), TPM (tokens/min), RPD, TPD
  # The system uses exponential backoff retries automatically
  # Free tier: ~60 RPM, ~150K TPM | Tier 1: ~500 RPM, ~200K TPM

search_space:
  parameters:
    # Model selection
    # Note: Update these to match your available models
    model:
      type: "categorical"
      values:
        - "gpt-4.1-mini"        # Fast, cost-efficient
        - "gpt-4.1-nano"        # Even smaller/faster
        - "gpt-4o-mini"         # Balanced option
        # Common alternatives:
        # - "gpt-4o"            # Most capable
        # - "gpt-4-turbo"       # High performance
    
    # Temperature for response variability
    temperature:
      type: "continuous"
      min: 0.5
      max: 1.0
      step: 0.1
      # Lower = more focused, Higher = more creative

      
# Evaluation configuration
evaluation:
  # Test cases
  test_cases:
    path: "openai_responses_tests.json"
    # Path is relative to this YAML file (examples/ai/openai/)
    # Each test case has:
    # - input: prompt/instructions for the model
    # - expected: criteria for evaluation
    # - metadata: category, difficulty, weight
  
  # Local evaluator (in same folder as this YAML)
  custom_evaluator:
    enabled: true
    module: "openai_responses"
    function: "score_openai_response"
    # For reasoning models, you can also use:
    # function: "score_reasoning_response"
  
  # Metrics to optimize
  metrics:
    # Response quality (most important)
    response_quality:
      weight: 0.40
      type: "higher_is_better"
      function: "custom"
      # Uses the custom evaluator above
    
    # Latency (response time)
    latency_ms:
      weight: 0.25
      type: "lower_is_better"
      threshold: 5000
      # Prefer responses under 5 seconds
    
    # Cost per call
    cost_per_call:
      weight: 0.20
      type: "lower_is_better"
      budget_per_call: 0.10
      # Target: under $0.10 per call
    
    # Token efficiency (output quality per token)
    token_efficiency:
      weight: 0.15
      type: "higher_is_better"
      function: "custom"
      # Measures quality/cost ratio

# Optimization strategy
# QUALITY-FOCUSED OPTIMIZATION - 60 API calls per run (thorough exploration)
optimization:
  algorithm: "mab_evolution"
  
  # Multi-Armed Bandit (exploration phase)
  # Tests initial diverse configurations
  mab:
    strategy: "thompson_sampling"
    exploration_rate: 0.3           # 30% exploration for diversity
  
  # Evolutionary Algorithm (refinement phase)
  # Evolves best configurations through mutation and crossover
  evolution:
    population_size: 4              # 4 configs per generation
    generations: 3                  # 3 generations of evolution for quality
    mutation_rate: 0.3              # 30% chance to mutate parameters
    crossover_rate: 0.5             # 50% chance to combine good configs
    elite_size: 1                   # Keep best config always
  
  # Execution settings
  execution:
    experiments_per_generation: 3   # Test 3 configs per generation (MAB phase)
    # Total API calls per run (without early stopping):
    # - MAB: 3 configs × 4 test cases = 12 calls
    # - Gen 1: 4 configs × 4 test cases = 16 calls
    # - Gen 2: 4 configs × 4 test cases = 16 calls
    # - Gen 3: 4 configs × 4 test cases = 16 calls
    # TOTAL: 60 API calls exactly ✅ (quality-focused)
    
    parallel_workers: 2              # 2 parallel workers for speed
    max_retries: 3                   # Retry with exponential backoff
    early_stopping:
      enabled: true
      patience: 2                    # Stop if no improvement for 2 generations
      min_improvement: 0.0005        # Minimum 0.05% improvement (sensitive to small gains)

# Output configuration
output:
  save_path: "./results/openai_responses_optimization"
  save_all_experiments: true
  formats: ["json", "markdown", "csv"]
  
  visualizations:
    - "score_over_time"
    - "parameter_importance"
    - "pareto_front"
    - "cost_vs_quality"
  
  export_best_config:
    enabled: true
    format: "python"
    output_path: "./best_openai_config.py"

# Advanced: Agent Society (optional)
# Enables AI agents to help optimize
society:
  enabled: false  # Set to true to enable
  auto_generate_agents: true
  learning:
    rlp_enabled: true   # Reasoning-based Learning Process
    sao_enabled: true   # Self-Alignment Optimization
  collaboration:
    enabled: true
    strategy: "debate"

# Legacy tracking (session-based optimization history)
legacy:
  enabled: true
  
  # Session ID to group related runs
  session_id: "openai_responses_optimization"
  
  # Tracking backend (SQLite + CSV by default)
  tracking_backend: "builtin"
  
  # Storage paths
  sqlite_path: "./data/legacy.db"
  export_dir: "./legacy_exports"
  export_formats: ["csv", "json"]
  
  # Optional: MLflow integration
  mlflow_config:
    enabled: false
    tracking_uri: "http://localhost:5000"
    experiment_name: "openai-optimization"
  
  # Optional: Aim integration  
  aim_config:
    enabled: false
    repo_path: "./aim_repo"
  
  # Optional: Weave integration (separate from main weave config)
  weave_config:
    enabled: false
    project_name: "openai-legacy-tracking"

# Weave integration (observability)
weave:
  enabled: true
  project_name: "openai-responses-optimization"
  # Track all experiments in Weights & Biases Weave

# Usage:
# 1. Set your OpenAI API key:
#    export OPENAI_API_KEY="sk-..."
#
# 2. Run optimization:
#    convergence optimize examples/ai/openai_responses_optimization.yaml
#
# 3. View results in ./results/openai_responses_optimization/
#
# 4. Check legacy tracking:
#    sqlite3 ./data/legacy.db "SELECT generation, aggregate_score FROM runs WHERE session_id='openai_responses_optimization' ORDER BY generation;"
#    # Shows improvement over time
#
# QUALITY-FOCUSED OPTIMIZATION MODE:
# - 60 API calls per run (3 MAB + 4 configs × 3 generations)
# - Tests model + temperature combinations thoroughly
# - Multi-generational evolution with mutation/crossover
# - Cost: ~$0.02-0.10 per run
# - Run multiple times to see generation numbers increment!
#
# How it works:
# 1. MAB Phase: Tests 3 diverse configs to explore space (12 calls)
# 2. Evolution Gen 1: Tests 4 configs via mutations/crossovers (16 calls)
# 3. Evolution Gen 2: Refines best configs with improvements (16 calls)
# 4. Evolution Gen 3: Final refinement for quality (16 calls)
# 5. Each run adds to legacy session, building optimization history
#
# Common errors:
# - 401: Invalid API key (check OPENAI_API_KEY env var)
# - 429: Rate limit hit (reduce parallel_workers to 1)
# - 404: Model not available (check model names in values list)
#
# To scale up (more thorough optimization):
#   experiments_per_generation: 10+
#   population_size: 8+
#   generations: 5+
#   parallel_workers: 4+
# This will use more API calls but find better configurations

