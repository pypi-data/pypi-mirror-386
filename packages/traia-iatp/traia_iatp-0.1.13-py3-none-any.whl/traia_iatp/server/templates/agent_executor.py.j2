"""
{{ agent_name }} - A2A Server Agent Executor Implementation

This module implements the agent executor for {{ agent_name }}.
Supports both synchronous responses and SSE streaming.
"""

import asyncio
import json
import logging
import os
from typing import AsyncGenerator, Optional, Dict, Any
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.types import Message, TextPart
from a2a.utils import new_agent_text_message
from crewai import Task, LLM
from traia_iatp.mcp import MCPServerConfig, MCPAgentBuilder, run_with_mcp_tools, MCPServerInfo

# Import AgentOps for operation tracking
try:
    import agentops
    from agentops.sdk.decorators import operation
    AGENTOPS_AVAILABLE = True
except ImportError:
    AGENTOPS_AVAILABLE = False
    agentops = None
    # Create a no-op decorator if AgentOps is not available
    def operation(func):
        return func


DEFAULT_LLM = LLM(
    model=os.getenv("LLM_MODEL", "gpt-4.1-nano"),  # Using environment variable with fallback
    temperature=os.getenv("LLM_MODEL_TEMPERATURE", 0.1),
    api_key=os.getenv("OPENAI_API_KEY")
)

logger = logging.getLogger(__name__)

logger.info(f"Current LLM model used: {os.getenv("LLM_MODEL", "gpt-4.1-nano")}")

# Create a thread pool for CPU-bound CrewAI operations
executor = ThreadPoolExecutor(max_workers=10)

# Get MCP server API key if required
{% if requires_api_key %}
# Check for API keys required by the MCP server
MCP_API_KEY = None
{% for api_key_name in api_keys %}
if not MCP_API_KEY and os.getenv("{{ api_key_name }}"):
    MCP_API_KEY = os.getenv("{{ api_key_name }}")
    logger.info(f"Using API key from {{ api_key_name }} environment variable")
{% endfor %}

if not MCP_API_KEY:
    logger.warning("No API key found for MCP server authentication.")
    logger.warning("The MCP server requires one of these environment variables to be set:")
    {% for api_key_name in api_keys %}
    logger.warning("  - {{ api_key_name }}")
    {% endfor %}
else:
    logger.info("MCP server API key loaded successfully")
{% else %}
MCP_API_KEY = None
{% endif %}


class CustomEvent:
    """Custom event class for SSE streaming."""
    def __init__(self, event_type: str, data: Dict[str, Any]):
        self.type = event_type
        self.data = data


class {{ class_name }}AgentExecutor(AgentExecutor):
    """Agent executor for {{ agent_name }}."""
    
    def __init__(self, mcp_config: MCPServerConfig, supports_streaming: bool = False):
        self.mcp_config = mcp_config
        self.supports_streaming = supports_streaming
        self.mcp_server_info = MCPServerInfo(
            id="",  # Not needed for direct usage
            name=mcp_config.name,
            url=mcp_config.url,
            description=mcp_config.description,
            server_type=mcp_config.server_type,
            capabilities=mcp_config.capabilities,
            metadata=mcp_config.metadata,
            tags=mcp_config.metadata.get("tags", [])
        )
    
    @operation
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """Process a request using the {{ agent_name }} capabilities."""
        try:
            # Get the user's request from context
            request_text = context.get_user_input()
            if not request_text:
                # Send empty response with task ID if available
                msg = new_agent_text_message("No user message provided")
                if hasattr(context, 'task_id') and context.task_id:
                    msg.taskId = context.task_id
                await event_queue.enqueue_event(msg)
                return
            
            # Check if client requested streaming
            stream_requested = False
            if hasattr(context, 'configuration') and context.configuration:
                output_mode = context.configuration.get('output_mode', '')
                stream_requested = output_mode == 'text/event-stream'
            
            # Execute the request
            if stream_requested and self.supports_streaming:
                await self._execute_streaming(context, event_queue, request_text)
            else:
                await self._execute_standard(context, event_queue, request_text)
                
        except Exception as e:
            logger.error(f"Error processing request: {e}")
            msg = new_agent_text_message(f"Error processing request: {str(e)}")
            if hasattr(context, 'task_id') and context.task_id:
                msg.taskId = context.task_id
            await event_queue.enqueue_event(msg)
    
    @operation
    async def _execute_standard(self, context: RequestContext, event_queue: EventQueue, request_text: str) -> None:
        """Execute standard (non-streaming) request."""
        # Get additional context if provided
        task_context = {}
        if hasattr(context, 'metadata'):
            task_context = context.metadata or {}
        
        # Create an agent for this request
        agent = MCPAgentBuilder.create_agent(
            role=f"{{ agent_name }} Specialist",
            goal=f"Process the request using {self.mcp_config.name} capabilities",
            backstory=f"You are an expert at using {self.mcp_config.name}. {self.mcp_config.description}",
            llm=DEFAULT_LLM
        )
        
        # Create a task
        task = Task(
            description=request_text,
            expected_output="The processed result based on the request",
            agent=agent
        )
        
        # Create a wrapper function to handle the arguments properly
        def run_crew_task():
            # Build kwargs for run_with_mcp_tools
            kwargs = {
                "tasks": [task],
                "mcp_server": self.mcp_server_info,
                "inputs": task_context,
                "skip_health_check": True
            }
            
            # Only add api_key if MCP server requires authentication
            if self.mcp_config.metadata.get("requires_api_key", False) and MCP_API_KEY:
                kwargs["api_key"] = MCP_API_KEY
                logger.debug("Including API key for authenticated MCP connection")
            
            return run_with_mcp_tools(**kwargs)
        
        # Run CrewAI in thread pool to avoid blocking the event loop
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(executor, run_crew_task)
        
        # Send the result as agent message with task ID if available
        msg = new_agent_text_message(str(result))
        if hasattr(context, 'task_id') and context.task_id:
            msg.taskId = context.task_id
        await event_queue.enqueue_event(msg)
    
    @operation
    async def _execute_streaming(self, context: RequestContext, event_queue: EventQueue, request_text: str) -> None:
        """Execute streaming request using SSE."""
        try:
            # Send initial event to indicate streaming has started
            await event_queue.enqueue_event(
                CustomEvent("stream_start", {"message": "Starting streaming response"})
            )
            
            # Stream chunks as they become available
            chunk_count = 0
            async for chunk in self._stream_mcp_response(request_text, context):
                # Send each chunk as a separate SSE event
                await event_queue.enqueue_event(
                    CustomEvent("stream_chunk", {
                        "chunk_id": chunk_count,
                        "content": chunk
                    })
                )
                
                # Also emit as message event for standard SSE subscribers
                await event_queue.enqueue_event(
                    CustomEvent("message", {
                        "role": "agent",
                        "content": chunk,
                        "chunk_id": chunk_count
                    })
                )
                
                chunk_count += 1
                
                # Yield control to allow other tasks to run
                await asyncio.sleep(0)
            
            # Send completion event
            await event_queue.enqueue_event(
                CustomEvent("stream_complete", {
                    "total_chunks": chunk_count,
                    "message": "Streaming completed successfully"
                })
            )
            
        except Exception as e:
            logger.error(f"Error in streaming execution: {e}")
            await event_queue.enqueue_event(
                CustomEvent("stream_error", {
                    "error": str(e),
                    "message": "Streaming encountered an error"
                })
            )
    
    @operation
    async def _stream_mcp_response(self, request_text: str, context: RequestContext) -> AsyncGenerator[str, None]:
        """
        Stream responses from MCP server.
        This is a placeholder that should be implemented based on specific MCP server capabilities.
        """
        # For now, simulate streaming by breaking response into chunks
        # In real implementation, this would connect to MCP server's streaming endpoint
        
        # Get full response first (in real implementation, this would be streamed)
        task_context = {}
        if hasattr(context, 'metadata'):
            task_context = context.metadata or {}
        
        agent = MCPAgentBuilder.create_agent(
            role=f"{{ agent_name }} Streaming Specialist",
            goal=f"Process the streaming request using {self.mcp_config.name} capabilities",
            backstory=f"You are an expert at using {self.mcp_config.name} for streaming data. {self.mcp_config.description}"
        )
        
        task = Task(
            description=request_text,
            expected_output="The processed streaming result",
            agent=agent
        )
        
        # For demonstration, get the full result and stream it in chunks
        def run_streaming_task():
            # Build kwargs for run_with_mcp_tools
            kwargs = {
                "tasks": [task],
                "mcp_server": self.mcp_server_info,
                "inputs": task_context,
                "skip_health_check": True
            }
            
            # Only add api_key if MCP server requires authentication
            if self.mcp_config.metadata.get("requires_api_key", False) and MCP_API_KEY:
                kwargs["api_key"] = MCP_API_KEY
                logger.debug("Including API key for authenticated MCP streaming connection")
            
            return run_with_mcp_tools(**kwargs)
        
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(executor, run_streaming_task)
        
        # Simulate streaming by chunking the response
        result_str = str(result)
        chunk_size = 100  # Characters per chunk
        
        for i in range(0, len(result_str), chunk_size):
            chunk = result_str[i:i + chunk_size]
            yield chunk
            await asyncio.sleep(0.1)  # Simulate network delay
    
    async def cancel(self, task_id: str) -> None:
        """Cancel a running task."""
        logger.info(f"Cancelling task: {task_id}")
        # Implementation depends on MCP server capabilities
        # For now, just log the cancellation request
        pass 