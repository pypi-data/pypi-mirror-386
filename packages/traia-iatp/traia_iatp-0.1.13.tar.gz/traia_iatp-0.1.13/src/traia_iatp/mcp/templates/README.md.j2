# {{ api_name }} MCP Server

This is an MCP (Model Context Protocol) server that provides{{ auth_details }} access to the {{ api_name }} API. It enables AI agents and LLMs to interact with {{ api_name }} through standardized tools.

## Features

- üîß **MCP Protocol**: Built on the Model Context Protocol for seamless AI integration
- üåê **Full API Access**: Provides tools for interacting with {{ api_name }} endpoints
{% if requires_auth %}
- üîê **Secure Authentication**: Supports API key authentication via Bearer tokens
{% endif %}
- üê≥ **Docker Support**: Easy deployment with Docker and Docker Compose
- ‚ö° **Async Operations**: Built with FastMCP for efficient async handling

## API Documentation

- **{{ api_name }} Website**: [{{ api_url }}]({{ api_url }})
- **API Documentation**: [{{ docs_url }}]({{ docs_url }})

## Available Tools

This server provides the following tools:

- **`example_tool`**: Placeholder tool (to be implemented)
- **`get_api_info`**: Get information about the API service and authentication status

*Note: Replace `example_tool` with actual {{ api_name }} API tools based on the documentation.*

## Installation

### Using Docker (Recommended)

1. Clone this repository:
   ```bash
   git clone https://github.com/Traia-IO/{{ api_slug }}-mcp-server.git
   cd {{ api_slug }}-mcp-server
   ```

{% if requires_auth %}
2. Set your API key:
   ```bash
   export {{ api_key_env_var }}="your-api-key-here"
   ```

3. Run with Docker:
{% else %}
2. Run with Docker:
{% endif %}
   ```bash
   ./run_local_docker.sh
   ```

### Using Docker Compose

1. Create a `.env` file with your configuration:
   ```env
   {% if requires_auth %}{{ api_key_env_var }}=your-api-key-here
   {% endif %}PORT=8000
   ```

2. Start the server:
   ```bash
   docker-compose up
   ```

### Manual Installation

1. Install dependencies using `uv`:
   ```bash
   uv pip install -e .
   ```

2. Run the server:
   ```bash
   {% if requires_auth %}{{ api_key_env_var }}="your-api-key-here" {% endif %}uv run python -m server
   ```

## Usage

### Health Check

Test if the server is running:
```bash
python mcp_health_check.py
```

### Using with CrewAI

```python
{% if requires_auth %}from traia_iatp.mcp.traia_mcp_adapter import create_mcp_adapter_with_auth

# Connect with authentication
with create_mcp_adapter_with_auth(
    url="http://localhost:8000/mcp/",
    api_key="your-api-key"
) as tools:
    # Use the tools
    for tool in tools:
        print(f"Available tool: {tool.name}")
        
    # Example usage
    result = await tool.example_tool(query="test")
    print(result)
{% else %}from traia_iatp.mcp.traia_mcp_adapter import create_mcp_adapter

# Connect to the MCP server
with create_mcp_adapter(
    url="http://localhost:8000/mcp/"
) as tools:
    # Use the tools
    for tool in tools:
        print(f"Available tool: {tool.name}")
        
    # Example usage
    result = await tool.example_tool(query="test")
    print(result)
{% endif %}
```

{% if requires_auth %}
## Authentication

This server requires API key authentication. Clients must provide their API key in the `Authorization` header:

```
Authorization: Bearer YOUR_API_KEY
```

The API key is then used to authenticate requests to the {{ api_name }} API.
{% endif %}

## Development

### Testing the Server

1. Start the server locally
2. Run the health check: `python mcp_health_check.py`
3. Test individual tools using the CrewAI adapter

### Adding New Tools

To add new tools, edit `server.py` and:

1. Create API client functions for {{ api_name }} endpoints
2. Add `@mcp.tool()` decorated functions
3. Update this README with the new tools
4. Update `deployment_params.json` with the tool names in the capabilities array

## Deployment

### Deployment Configuration

The `deployment_params.json` file contains the deployment configuration for this MCP server:

```json
{
  "github_url": "https://github.com/Traia-IO/{{ api_slug }}-mcp-server",
  "mcp_server": {
    "name": "{{ api_slug }}-mcp",
    "description": "{{ api_description|capitalize }}",
    "server_type": "streamable-http",
    {% if requires_auth %}"requires_api_key": true,
    "api_key_header": "Authorization",
    {% endif %}"capabilities": [
      // List all implemented tool names here
      "example_tool",
      "get_api_info"
    ]
  },
  "deployment_method": "cloud_run",
  "gcp_project_id": "traia-mcp-servers",
  "gcp_region": "us-central1",
  "tags": ["{{ api_name_lower }}", "api"],
  "ref": "main"
}
```

**Important**: Always update the `capabilities` array when you add or remove tools!

### Google Cloud Run

This server is designed to be deployed on Google Cloud Run. The deployment will:

1. Build a container from the Dockerfile
2. Deploy to Cloud Run with the specified configuration
3. Expose the `/mcp` endpoint for client connections

## Environment Variables

- `PORT`: Server port (default: 8000)
- `STAGE`: Environment stage (default: MAINNET, options: MAINNET, TESTNET)
- `LOG_LEVEL`: Logging level (default: INFO)
{% if requires_auth %}- `{{ api_key_env_var }}`: Your {{ api_name }} API key (required){% endif %}

## Troubleshooting

1. **Server not starting**: Check Docker logs with `docker logs <container-id>`
{% if requires_auth %}2. **Authentication errors**: Ensure your API key is correctly set in the environment
3. **API errors**: Verify your API key has the necessary permissions{% else %}2. **Connection errors**: Ensure the server is running on the expected port{% endif %}
3. **Tool errors**: Check the server logs for detailed error messages

## Contributing

1. Fork the repository
2. Create a feature branch
3. Implement new tools or improvements
4. Update the README and deployment_params.json
5. Submit a pull request

## License

[MIT License](LICENSE)