"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .sidebysideimplementation import (
    SideBySideImplementation,
    SideBySideImplementationTypedDict,
)
from enum import Enum
from glean.api_client.types import BaseModel
import pydantic
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class ManualFeedbackSideBySideInfoSource(str, Enum):
    r"""The source associated with the side-by-side feedback event."""

    LIVE_EVAL = "LIVE_EVAL"
    CHAT = "CHAT"
    SEARCH = "SEARCH"


class ManualFeedbackSideBySideInfoVote(str, Enum):
    r"""The vote for this specific implementation."""

    UPVOTE = "UPVOTE"
    DOWNVOTE = "DOWNVOTE"
    NEUTRAL = "NEUTRAL"


class ManualFeedbackSideBySideInfoTypedDict(TypedDict):
    email: NotRequired[str]
    r"""The email address of the user who submitted the side-by-side feedback."""
    source: NotRequired[ManualFeedbackSideBySideInfoSource]
    r"""The source associated with the side-by-side feedback event."""
    query: NotRequired[str]
    r"""The query or prompt that was evaluated across multiple implementations."""
    implementations: NotRequired[List[SideBySideImplementationTypedDict]]
    r"""Array of implementations that were compared side-by-side."""
    evaluation_session_id: NotRequired[str]
    r"""Unique identifier for this evaluation session to group related feedback events."""
    implementation_id: NotRequired[str]
    r"""The ID of the implementation this specific feedback event is for."""
    vote: NotRequired[ManualFeedbackSideBySideInfoVote]
    r"""The vote for this specific implementation."""
    comments: NotRequired[str]
    r"""Specific feedback comments for this implementation."""


class ManualFeedbackSideBySideInfo(BaseModel):
    email: Optional[str] = None
    r"""The email address of the user who submitted the side-by-side feedback."""

    source: Optional[ManualFeedbackSideBySideInfoSource] = None
    r"""The source associated with the side-by-side feedback event."""

    query: Optional[str] = None
    r"""The query or prompt that was evaluated across multiple implementations."""

    implementations: Optional[List[SideBySideImplementation]] = None
    r"""Array of implementations that were compared side-by-side."""

    evaluation_session_id: Annotated[
        Optional[str], pydantic.Field(alias="evaluationSessionId")
    ] = None
    r"""Unique identifier for this evaluation session to group related feedback events."""

    implementation_id: Annotated[
        Optional[str], pydantic.Field(alias="implementationId")
    ] = None
    r"""The ID of the implementation this specific feedback event is for."""

    vote: Optional[ManualFeedbackSideBySideInfoVote] = None
    r"""The vote for this specific implementation."""

    comments: Optional[str] = None
    r"""Specific feedback comments for this implementation."""
