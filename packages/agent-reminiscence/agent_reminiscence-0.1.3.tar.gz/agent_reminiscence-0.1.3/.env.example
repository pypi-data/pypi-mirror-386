# Agent Mem Environment Configuration
# Copy this file to .env and update with your values

# ============================================================================
# LLM API Keys
# ============================================================================
# At least one API key is required for the agents to work
# Google Gemini is recommended for cost-effectiveness

GOOGLE_API_KEY=your_google_gemini_api_key_here

# Optional: Other LLM providers
#OPENAI_API_KEY=your_openai_api_key_here
#ANTHROPIC_API_KEY=your_anthropic_api_key_here
#GROK_API_KEY=your_grok_api_key_here

# ============================================================================
# PostgreSQL Configuration
# ============================================================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=agent_mem_user
POSTGRES_PASSWORD=agent_mem_password_change_me
POSTGRES_DB=agent_mem

# For testing
POSTGRES_TEST_DB=agent_mem_test

# ============================================================================
# Neo4j Configuration
# ============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j_password_change_me
NEO4J_DATABASE=neo4j

# ============================================================================
# Ollama Configuration
# ============================================================================
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
VECTOR_DIMENSION=768

# ============================================================================
# AI Agent Models
# ============================================================================
# Format: provider:model-name
# Supported providers: google, openai, anthropic, grok
# Google Gemini Flash is recommended for cost-effectiveness and speed

# ER Extractor Agent - Extracts entities and relationships from text
ER_EXTRACTOR_AGENT_MODEL=google:gemini-2.5-flash

# Memorizer Agent - Resolves conflicts and consolidates memory
MEMORIZER_AGENT_MODEL=google:gemini-2.5-flash

# Memory Update Agent - Updates active memory sections
MEMORY_UPDATE_AGENT_MODEL=google:gemini-2.5-flash

# Memory Retrieve Agent - Retrieves and synthesizes memories
MEMORY_RETRIEVE_AGENT_MODEL=google:gemini-2.5-flash

# Agent Settings
AGENT_TEMPERATURE=0.6
AGENT_RETRIES=3

# Alternative models (uncomment to use):
# ER_EXTRACTOR_AGENT_MODEL=openai:gpt-4o
# MEMORIZER_AGENT_MODEL=openai:gpt-4o
# ER_EXTRACTOR_AGENT_MODEL=anthropic:claude-3-5-sonnet

# ============================================================================
# Memory Configuration
# ============================================================================
# Number of updates before consolidation
AVG_SECTION_UPDATE_COUNT=5

# Importance score threshold for promotion to longterm
SHORTTERM_PROMOTION_THRESHOLD=0.7

# ============================================================================
# Docker Configuration (for docker-compose.yml)
# ============================================================================
# Path to Ollama data on host machine (for volume mount)
# Default: ./ollama_data (relative to project root)
# Custom example: Z:/Ollama (use forward slashes or escaped backslashes)
OLLAMA_HOST_VOLUME_PATH=./ollama_data

# Chunk configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# ============================================================================
# Search Configuration
# ============================================================================
SIMILARITY_THRESHOLD=0.7
BM25_WEIGHT=0.3
VECTOR_WEIGHT=0.7

# ============================================================================
# Development Settings
# ============================================================================
LOG_LEVEL=INFO
DEBUG=false
