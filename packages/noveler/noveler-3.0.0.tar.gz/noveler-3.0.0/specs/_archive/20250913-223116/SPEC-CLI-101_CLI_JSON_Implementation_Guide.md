# SPEC-CLI-101: CLI JSONåŒ– å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

CLIå‡ºåŠ›ã®100% JSONåŒ–ãƒ»MCPãƒ„ãƒ¼ãƒ«åŒ–ã®æ®µéšçš„å®Ÿè£…æ‰‹é †æ›¸ã€‚
æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§ã‚’ä¿ã¡ãªãŒã‚‰ã€é«˜å“è³ªã§ä¿å®ˆæ€§ã®é«˜ã„JSONå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã€‚

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

| é …ç›® | å†…å®¹ |
|------|------|
| ä»•æ§˜ID | SPEC-CLI-001 |
| E2Eãƒ†ã‚¹ãƒˆID | E2E-CLI-001 |
| test_type | integration |
| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | v1.0.0 |
| ä½œæˆæ—¥ | 2025-08-27 |
| æœ€çµ‚æ›´æ–° | 2025-08-28 |
| ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ | active |
| å®Ÿè£…æœŸé–“ | 4é€±é–“ï¼ˆPhase 1-3æ§‹æˆï¼‰ |
| å¯¾è±¡è€… | ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºè€…ã€ä¿å®ˆæ‹…å½“è€… |

## 1. å®Ÿè£…æ¦‚è¦ãƒ»å‰ææ¡ä»¶

### 1.1 å®Ÿè£…å‰ææ¡ä»¶

```bash
# å¿…è¦ãªç’°å¢ƒ
- Python 3.11+
- æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ï¼ˆDDDæº–æ‹ ï¼‰
- Gitç®¡ç†ç’°å¢ƒ
- ãƒ†ã‚¹ãƒˆç’°å¢ƒï¼ˆpytestï¼‰

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install pydantic==2.5.0 jsonschema==4.20.0 mcp==0.9.0
```

### 1.2 æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ å½±éŸ¿è©•ä¾¡

```python
# å½±éŸ¿ç¯„å›²ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
IMPACT_ASSESSMENT = {
    "ç ´å£Šçš„å¤‰æ›´": "ãªã—ï¼ˆæ—¢å­˜CLIå‡ºåŠ›ã¨ä¸¦è¡Œé‹ç”¨ï¼‰",
    "DDDå±¤åˆ†é›¢": "é…å»¶åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æº–æ‹ ç¶­æŒ",
    "ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸": "æ—¢å­˜95%ã‚’ç¶­æŒã€æ–°æ©Ÿèƒ½95%ä»¥ä¸Š",
    "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹": "95%ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã€60%ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‘ä¸Š",
    "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£": "SHA256å®Œå…¨æ€§ä¿è¨¼ã€æ¨©é™åˆ¶å¾¡å¼·åŒ–"
}
```

### 1.3 å®Ÿè£…æˆ¦ç•¥

1. **æ¼¸é€²çš„å®Ÿè£…**: æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’ç ´å£Šã›ãšæ®µéšçš„ã«å°å…¥
2. **ä¸¦è¡Œé‹ç”¨**: å¾“æ¥å‡ºåŠ›ã¨JSONå‡ºåŠ›ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
3. **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½**: JSONåŒ–å¤±æ•—æ™‚ã®è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
4. **å“è³ªä¿è¨¼**: å„Phaseå®Œäº†æ™‚ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

## 2. Phase 1: åŸºç›¤æ§‹ç¯‰ (Week 1-2)

### 2.1 ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ

```bash
# æ–°è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆï¼ˆç¾è¡Œæ§‹æˆã«æº–æ‹ ï¼‰
mkdir -p src/noveler/infrastructure/json/{schemas,models,converters,validators,file_managers,utils}
mkdir -p src/noveler/infrastructure/json/mcp/{tools,resources,validators}
mkdir -p tests/unit/infrastructure/json
mkdir -p tests/integration/infrastructure/json
mkdir -p tests/e2e/json_mcp_integration

# JSONã‚¹ã‚­ãƒ¼ãƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p schemas/json/{base,commands,responses}
```

### 2.2 JSON ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

```bash
# schemas/json/base/file_reference_schema.json
cat > schemas/json/base/file_reference_schema.json << 'EOF'
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "file_reference_schema.json",
  "title": "FileReferenceSchema",
  "description": "ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚¹ã‚­ãƒ¼ãƒ",
  "type": "object",
  "properties": {
    "path": {
      "type": "string",
      "description": "ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›¸å¯¾ãƒ‘ã‚¹",
      "pattern": "^[^/].*$",
      "minLength": 1,
      "maxLength": 500
    },
    "sha256": {
      "type": "string",
      "description": "SHA256ãƒãƒƒã‚·ãƒ¥å€¤",
      "pattern": "^[a-f0-9]{64}$"
    },
    "size_bytes": {
      "type": "integer",
      "description": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰",
      "minimum": 0,
      "maximum": 104857600
    },
    "content_type": {
      "type": "string",
      "description": "MIMEã‚¿ã‚¤ãƒ—",
      "enum": ["text/markdown", "text/yaml", "application/json", "text/plain"]
    },
    "created_at": {
      "type": "string",
      "description": "ä½œæˆæ—¥æ™‚ï¼ˆISO 8601ï¼‰",
      "format": "date-time"
    },
    "encoding": {
      "type": "string",
      "description": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°",
      "default": "utf-8"
    }
  },
  "required": ["path", "sha256", "size_bytes", "content_type", "created_at"],
  "additionalProperties": false
}
EOF
```

```bash
# schemas/json/responses/standard_response_schema.json
cat > schemas/json/responses/standard_response_schema.json << 'EOF'
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "standard_response_schema.json",
  "title": "StandardResponseSchema",
  "description": "æ¨™æº–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ã‚­ãƒ¼ãƒ",
  "type": "object",
  "properties": {
    "success": {
      "type": "boolean",
      "description": "å®Ÿè¡ŒæˆåŠŸãƒ•ãƒ©ã‚°"
    },
    "command": {
      "type": "string",
      "description": "å®Ÿè¡Œã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰",
      "minLength": 1,
      "maxLength": 200
    },
    "timestamp": {
      "type": "string",
      "description": "å®Ÿè¡Œæ™‚åˆ»ï¼ˆISO 8601ï¼‰",
      "format": "date-time"
    },
    "execution_time_ms": {
      "type": "number",
      "description": "å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰",
      "minimum": 0
    },
    "outputs": {
      "type": "object",
      "description": "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
      "properties": {
        "files": {
          "type": "array",
          "items": {"$ref": "file_reference_schema.json"}
        },
        "total_files": {
          "type": "integer",
          "minimum": 0
        },
        "total_size_bytes": {
          "type": "integer",
          "minimum": 0
        }
      },
      "required": ["files", "total_files", "total_size_bytes"]
    },
    "metadata": {
      "type": "object",
      "description": "è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿",
      "additionalProperties": true
    }
  },
  "required": ["success", "command", "timestamp", "execution_time_ms", "outputs"],
  "additionalProperties": false
}
EOF
```

### 2.3 åŸºåº•ãƒ¢ãƒ‡ãƒ«å®Ÿè£…

```python
# src/noveler/infrastructure/json/models/base_models.py
#!/usr/bin/env python3
"""JSONå¤‰æ›åŸºåº•ãƒ¢ãƒ‡ãƒ«"""

from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
from pydantic import BaseModel, Field, validator, root_validator
from enum import Enum

class ContentType(str, Enum):
    """ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—"""
    MARKDOWN = "text/markdown"
    YAML = "text/yaml"
    JSON = "application/json"
    PLAIN_TEXT = "text/plain"

class BaseJSONModel(BaseModel):
    """JSONå¤‰æ›åŸºåº•ãƒ¢ãƒ‡ãƒ«"""

    class Config:
        # Pydantic v2è¨­å®š
        str_strip_whitespace = True
        validate_assignment = True
        extra = "forbid"
        json_encoders = {
            datetime: lambda v: v.isoformat(),
            Path: lambda v: str(v)
        }

    @root_validator
    def validate_model_consistency(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ä¸€è²«æ€§æ¤œè¨¼"""
        return values

class TimestampMixin(BaseModel):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³"""

    created_at: datetime = Field(
        default_factory=datetime.now,
        description="ä½œæˆæ—¥æ™‚ï¼ˆISO 8601ï¼‰"
    )

    updated_at: Optional[datetime] = Field(
        default=None,
        description="æ›´æ–°æ—¥æ™‚ï¼ˆISO 8601ï¼‰"
    )
```

### 2.4 ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãƒ¢ãƒ‡ãƒ«å®Ÿè£…

```python
# src/noveler/infrastructure/json/models/file_reference_models.py
#!/usr/bin/env python3
"""ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãƒ¢ãƒ‡ãƒ«"""

from pathlib import Path
from typing import List, Optional
from pydantic import Field, validator
import re

from .base_models import BaseJSONModel, TimestampMixin, ContentType

class FileReferenceModel(BaseJSONModel, TimestampMixin):
    """ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãƒ¢ãƒ‡ãƒ«"""

    path: str = Field(
        ...,
        description="ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›¸å¯¾ãƒ‘ã‚¹",
        min_length=1,
        max_length=500
    )

    sha256: str = Field(
        ...,
        description="SHA256ãƒãƒƒã‚·ãƒ¥å€¤ï¼ˆ64æ–‡å­—16é€²æ–‡å­—åˆ—ï¼‰",
        regex=r"^[a-f0-9]{64}$"
    )

    size_bytes: int = Field(
        ...,
        description="ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰",
        ge=0,
        le=100_000_000
    )

    content_type: ContentType = Field(
        ...,
        description="MIMEã‚¿ã‚¤ãƒ—"
    )

    encoding: str = Field(
        default="utf-8",
        description="ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"
    )

    @validator('path')
    def validate_path_format(cls, v: str) -> str:
        """ãƒ‘ã‚¹å½¢å¼æ¤œè¨¼"""
        if v.startswith('/') or '..' in v:
            raise ValueError("ç›¸å¯¾ãƒ‘ã‚¹ã®ã¿è¨±å¯ã€è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‚ç…§ç¦æ­¢")

        dangerous_chars = ['<', '>', ':', '"', '|', '?', '*']
        if any(char in v for char in dangerous_chars):
            raise ValueError(f"å±é™ºãªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {dangerous_chars}")

        return v

    @validator('sha256')
    def validate_sha256_format(cls, v: str) -> str:
        """SHA256å½¢å¼æ¤œè¨¼"""
        if not re.match(r'^[a-f0-9]{64}$', v.lower()):
            raise ValueError("SHA256ã¯64æ–‡å­—ã®16é€²æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        return v.lower()

class FileReferenceCollection(BaseJSONModel):
    """ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""

    files: List[FileReferenceModel] = Field(
        default_factory=list,
        description="ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ä¸€è¦§"
    )

    total_files: int = Field(
        description="ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°"
    )

    total_size_bytes: int = Field(
        description="ç·ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰"
    )
```

### 2.5 ãƒãƒƒã‚·ãƒ¥ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å®Ÿè£…

```python
# src/noveler/infrastructure/json/utils/hash_utils.py
#!/usr/bin/env python3
"""ãƒãƒƒã‚·ãƒ¥ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""

import hashlib
from pathlib import Path
from typing import Union

def calculate_sha256(file_path: Union[str, Path]) -> str:
    """SHA256ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    file_path = Path(file_path)

    if not file_path.exists():
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")

    sha256_hash = hashlib.sha256()
    chunk_size = 65536  # 64KB

    try:
        with open(file_path, 'rb') as f:
            while chunk := f.read(chunk_size):
                sha256_hash.update(chunk)
    except IOError as e:
        raise IOError(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path}") from e

    return sha256_hash.hexdigest()

def calculate_sha256_from_content(content: str, encoding: str = 'utf-8') -> str:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ–‡å­—åˆ—ã‹ã‚‰SHA256ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
    content_bytes = content.encode(encoding)
    return hashlib.sha256(content_bytes).hexdigest()
```

### 2.6 Phase 1 ãƒ†ã‚¹ãƒˆå®Ÿè£…

```python
# tests/unit/infrastructure/json/test_base_models.py
#!/usr/bin/env python3
"""åŸºåº•ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ"""

import pytest
from datetime import datetime
from pydantic import ValidationError

from scripts.infrastructure.json.models.base_models import BaseJSONModel, TimestampMixin, ContentType

class TestContentType:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆ"""

    def test_content_type_values(self):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—å€¤ãƒ†ã‚¹ãƒˆ"""
        assert ContentType.MARKDOWN == "text/markdown"
        assert ContentType.YAML == "text/yaml"
        assert ContentType.JSON == "application/json"
        assert ContentType.PLAIN_TEXT == "text/plain"

class TestTimestampMixin:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""

    def test_auto_timestamp_creation(self):
        """è‡ªå‹•ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""

        class TestModel(TimestampMixin):
            name: str

        model = TestModel(name="test")
        assert isinstance(model.created_at, datetime)
        assert model.updated_at is None

    def test_manual_timestamp_setting(self):
        """æ‰‹å‹•ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨­å®šãƒ†ã‚¹ãƒˆ"""

        class TestModel(TimestampMixin):
            name: str

        test_time = datetime(2025, 8, 27, 12, 0, 0)
        model = TestModel(name="test", created_at=test_time)
        assert model.created_at == test_time
```

```bash
# Phase 1 ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
cd /mnt/c/Users/bamboocity/OneDrive/Documents/9_å°èª¬/00_ã‚¬ã‚¤ãƒ‰
python -m pytest tests/unit/infrastructure/json/ -v
```

## 3. Phase 2: JSONå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£… (Week 2-3)

### 3.1 åŸºåº•å¤‰æ›å™¨å®Ÿè£…

```python
# src/noveler/infrastructure/json/converters/base_converter.py
#!/usr/bin/env python3
"""JSONå¤‰æ›åŸºåº•ã‚¯ãƒ©ã‚¹"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Type, TypeVar
from pathlib import Path
import time
import json
from pydantic import ValidationError
import jsonschema

from ..models.base_models import BaseJSONModel

T = TypeVar('T', bound=BaseJSONModel)

class BaseConverter(ABC):
    """JSONå¤‰æ›åŸºåº•ã‚¯ãƒ©ã‚¹"""

    def __init__(self,
                 schema_dir: Path = None,
                 output_dir: Path = None,
                 validate_schema: bool = True):
        self.schema_dir = schema_dir or Path("schemas/json")
        self.output_dir = output_dir or Path("outputs")
        self.validate_schema = validate_schema
        self._schema_cache: Dict[str, Dict] = {}

    def load_schema(self, schema_name: str) -> Dict[str, Any]:
        """JSONã‚¹ã‚­ãƒ¼ãƒãƒ­ãƒ¼ãƒ‰ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        if schema_name not in self._schema_cache:
            schema_path = self.schema_dir / f"{schema_name}.json"
            if not schema_path.exists():
                raise FileNotFoundError(f"ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {schema_path}")

            with open(schema_path, 'r', encoding='utf-8') as f:
                self._schema_cache[schema_name] = json.load(f)

        return self._schema_cache[schema_name]

    @abstractmethod
    def convert(self, input_data: Any) -> Dict[str, Any]:
        """å¤‰æ›å®Ÿè¡Œï¼ˆæŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        pass
```

### 3.2 CLIâ†’JSONå¤‰æ›å™¨å®Ÿè£…

```python
# src/noveler/infrastructure/json/converters/cli_response_converter.py
#!/usr/bin/env python3
"""CLI ãƒ¬ã‚¹ãƒãƒ³ã‚¹â†’JSONå¤‰æ›å™¨"""

from typing import Any, Dict, List, Optional, Union
from pathlib import Path
import uuid
from datetime import datetime
import json

from ..models.response_models import StandardResponseModel, ErrorResponseModel
from ..models.file_reference_models import FileReferenceModel, FileReferenceCollection
from ..file_managers.file_reference_manager import FileReferenceManager
from .base_converter import BaseConverter

class CLIResponseConverter(BaseConverter):
    """CLI ãƒ¬ã‚¹ãƒãƒ³ã‚¹â†’JSONå¤‰æ›å™¨"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.file_manager = FileReferenceManager(self.output_dir)

    def convert(self, cli_result: Dict[str, Any]) -> Dict[str, Any]:
        """CLIå®Ÿè¡Œçµæœã‚’JSONå½¢å¼ã«å¤‰æ›"""

        start_time = time.perf_counter()

        try:
            if cli_result.get('success', False):
                result = self._convert_success_response(cli_result)
            else:
                result = self._convert_error_response(cli_result)

            # å®Ÿè¡Œæ™‚é–“è¿½åŠ 
            end_time = time.perf_counter()
            if 'execution_time_ms' not in result:
                result['execution_time_ms'] = (end_time - start_time) * 1000

            return result

        except Exception as e:
            return self._create_emergency_error_response(str(e), cli_result)

    def _convert_success_response(self, cli_result: Dict[str, Any]) -> Dict[str, Any]:
        """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹å¤‰æ›"""

        file_references = []

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã«å¤‰æ›
        if 'content' in cli_result:
            file_ref = self.file_manager.save_content(
                content=cli_result['content'],
                content_type='text/markdown',
                filename_prefix=cli_result.get('command', 'output')
            )
            file_references.append(file_ref)

        if 'yaml_content' in cli_result:
            file_ref = self.file_manager.save_content(
                content=cli_result['yaml_content'],
                content_type='text/yaml',
                filename_prefix=f"{cli_result.get('command', 'output')}_config"
            )
            file_references.append(file_ref)

        # FileReferenceCollectionãƒ¢ãƒ‡ãƒ«ä½œæˆ
        file_collection = FileReferenceCollection(
            files=file_references,
            total_files=len(file_references),
            total_size_bytes=sum(f.size_bytes for f in file_references)
        )

        # StandardResponseModelä½œæˆãƒ»ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        response_data = {
            'success': True,
            'command': cli_result.get('command', 'unknown'),
            'timestamp': datetime.now().isoformat(),
            'execution_time_ms': cli_result.get('execution_time_ms', 0.0),
            'outputs': file_collection.dict(),
            'metadata': self._extract_metadata(cli_result)
        }

        response_model = StandardResponseModel(**response_data)
        return response_model.dict()
```

### 3.3 ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ç®¡ç†å®Ÿè£…

```python
# src/noveler/infrastructure/json/file_managers/file_reference_manager.py
#!/usr/bin/env python3
"""ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ç®¡ç†ã‚¯ãƒ©ã‚¹"""

from pathlib import Path
from typing import Optional
from datetime import datetime
import uuid

from ..models.file_reference_models import FileReferenceModel
from ..utils.hash_utils import calculate_sha256

class FileReferenceManager:
    """ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, base_output_dir: Path):
        self.base_output_dir = Path(base_output_dir)
        self._ensure_base_directory()

    def _ensure_base_directory(self) -> None:
        """åŸºåº•ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿"""
        self.base_output_dir.mkdir(parents=True, exist_ok=True)

    def save_content(self,
                    content: str,
                    content_type: str,
                    filename_prefix: str = "output") -> FileReferenceModel:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä¿å­˜ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ç”Ÿæˆ"""

        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        extension = self._get_extension_from_content_type(content_type)
        filename = f"{filename_prefix}_{timestamp}_{unique_id}{extension}"

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä½œæˆ
        file_path = self.base_output_dir / filename

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ›¸ãè¾¼ã¿
        file_path.write_text(content, encoding='utf-8')

        # SHA256è¨ˆç®—
        sha256_hash = calculate_sha256(file_path)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
        size_bytes = file_path.stat().st_size

        # FileReferenceModelä½œæˆ
        file_reference = FileReferenceModel(
            path=str(file_path.relative_to(self.base_output_dir.parent)),
            sha256=sha256_hash,
            size_bytes=size_bytes,
            content_type=content_type,
            created_at=datetime.now()
        )

        return file_reference

    def _get_extension_from_content_type(self, content_type: str) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã‹ã‚‰æ‹¡å¼µå­å–å¾—"""
        extension_map = {
            'text/markdown': '.md',
            'text/yaml': '.yaml',
            'application/json': '.json',
            'text/plain': '.txt'
        }
        return extension_map.get(content_type, '.txt')
```

### 3.4 æ—¢å­˜CLIçµ±åˆãƒã‚¤ãƒ³ãƒˆ

```python
# src/mcp_servers/noveler/json_conversion_server.py
#!/usr/bin/env python3
"""æ—¢å­˜CLI JSONçµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼"""

from typing import Any, Dict, Optional
from pathlib import Path
import argparse
import sys

from scripts.infrastructure.json.converters.cli_response_converter import CLIResponseConverter

class JSONOutputIntegrator:
    """JSONå‡ºåŠ›çµ±åˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, output_dir: Path = None):
        self.output_dir = output_dir or Path("json_outputs")
        self.converter = CLIResponseConverter(output_dir=self.output_dir)

    def wrap_cli_execution(self, original_function, *args, **kwargs):
        """æ—¢å­˜CLIå®Ÿè¡Œã‚’JSONå‡ºåŠ›ã§ãƒ©ãƒƒãƒ—"""

        # --json-output ãƒ•ãƒ©ã‚°ãƒã‚§ãƒƒã‚¯
        if not self._should_use_json_output():
            # å¾“æ¥é€šã‚Šã®å®Ÿè¡Œ
            return original_function(*args, **kwargs)

        try:
            # å…ƒã®å®Ÿè¡Œçµæœå–å¾—
            original_result = original_function(*args, **kwargs)

            # çµæœã‚’JSONå½¢å¼ã«å¤‰æ›
            json_result = self.converter.convert(original_result)

            # JSONå‡ºåŠ›
            self._output_json_result(json_result)
            return json_result

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®JSONå½¢å¼å‡ºåŠ›
            error_result = {
                'success': False,
                'error': {
                    'code': 'CLI_EXECUTION_ERROR',
                    'message': f'CLIå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}',
                    'hint': 'ãƒ­ã‚°ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ã‚µãƒãƒ¼ãƒˆã«é€£çµ¡ã—ã¦ãã ã•ã„'
                }
            }
            self._output_json_result(error_result)
            return error_result

    def _should_use_json_output(self) -> bool:
        """JSONå‡ºåŠ›ä½¿ç”¨åˆ¤å®š"""
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒã‚§ãƒƒã‚¯
        return '--json-output' in sys.argv

    def _output_json_result(self, json_result: Dict[str, Any]) -> None:
        """JSONçµæœå‡ºåŠ›"""
        import json
        print(json.dumps(json_result, ensure_ascii=False, indent=2))

# æ—¢å­˜CLIã‚³ãƒãƒ³ãƒ‰ã¸ã®é©ç”¨ä¾‹
def create_episode_json_wrapper(original_create_episode):
    """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä½œæˆJSONå‡ºåŠ›ãƒ©ãƒƒãƒ‘ãƒ¼"""

    integrator = JSONOutputIntegrator()

    def wrapped_create_episode(*args, **kwargs):
        return integrator.wrap_cli_execution(original_create_episode, *args, **kwargs)

    return wrapped_create_episode
```

### 3.5 Phase 2 çµ±åˆãƒ†ã‚¹ãƒˆ

```python
# tests/integration/infrastructure/json/test_cli_conversion_integration.py
#!/usr/bin/env python3
"""CLIå¤‰æ›çµ±åˆãƒ†ã‚¹ãƒˆ"""

import pytest
import tempfile
from pathlib import Path
import json

from scripts.infrastructure.json.converters.cli_response_converter import CLIResponseConverter

class TestCLIConversionIntegration:
    """CLIå¤‰æ›çµ±åˆãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def temp_output_dir(self):
        """ä¸€æ™‚å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield Path(temp_dir)

    def test_successful_episode_creation_conversion(self, temp_output_dir):
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä½œæˆæˆåŠŸå¤‰æ›ãƒ†ã‚¹ãƒˆ"""

        converter = CLIResponseConverter(output_dir=temp_output_dir)

        # æ¨¡æ“¬CLIçµæœ
        cli_result = {
            'success': True,
            'command': 'novel create 5',
            'content': '# ç¬¬5è©± è¬ã®æ‰‹ç´™\n\næ˜¨æ—¥ã®å¤œã€ã‚¢ãƒªã‚¹ã®å…ƒã«ä¸æ€è­°ãªæ‰‹ç´™ãŒå±Šã„ãŸã€‚',
            'yaml_content': 'title: "ç¬¬5è©± è¬ã®æ‰‹ç´™"\nepisode_number: 5\ngenre: "fantasy"',
            'execution_time_ms': 2500.5,
            'metadata': {
                'word_count': 45,
                'character_count': 89
            }
        }

        # JSONå¤‰æ›å®Ÿè¡Œ
        json_result = converter.convert(cli_result)

        # åŸºæœ¬æ§‹é€ æ¤œè¨¼
        assert json_result['success'] is True
        assert json_result['command'] == 'novel create 5'
        assert json_result['execution_time_ms'] >= 2500.5  # å¤‰æ›æ™‚é–“ã‚‚åŠ ç®—ã•ã‚Œã‚‹

        # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§æ¤œè¨¼
        outputs = json_result['outputs']
        assert outputs['total_files'] == 2  # Markdown + YAML
        assert len(outputs['files']) == 2

        # å„ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§è©³ç´°æ¤œè¨¼
        for file_ref in outputs['files']:
            assert 'path' in file_ref
            assert 'sha256' in file_ref
            assert len(file_ref['sha256']) == 64  # SHA256é•·
            assert file_ref['size_bytes'] > 0
            assert file_ref['content_type'] in ['text/markdown', 'text/yaml']

            # å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            file_path = Path(file_ref['path'])
            assert file_path.exists()

    def test_error_response_conversion(self, temp_output_dir):
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹å¤‰æ›ãƒ†ã‚¹ãƒˆ"""

        converter = CLIResponseConverter(output_dir=temp_output_dir)

        # æ¨¡æ“¬CLI ã‚¨ãƒ©ãƒ¼çµæœ
        cli_result = {
            'success': False,
            'command': 'novel create invalid',
            'error_code': 'INVALID_EPISODE_NUMBER',
            'error_message': 'ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·ãŒä¸æ­£ã§ã™',
            'error_hint': '1ä»¥ä¸Šã®æ•´æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„',
            'error_details': {
                'provided_value': 'invalid',
                'expected_type': 'integer'
            }
        }

        # JSONå¤‰æ›å®Ÿè¡Œ
        json_result = converter.convert(cli_result)

        # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ æ¤œè¨¼
        assert json_result['success'] is False
        assert 'error' in json_result

        error = json_result['error']
        assert error['code'] == 'INVALID_EPISODE_NUMBER'
        assert error['message'] == 'ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·ãŒä¸æ­£ã§ã™'
        assert error['hint'] == '1ä»¥ä¸Šã®æ•´æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„'
        assert 'details' in error
```

## 4. Phase 3: MCPçµ±åˆãƒ»æœ€é©åŒ– (Week 3-4)

### 4.1 MCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…

```python
# src/mcp_servers/noveler/json_conversion_server.py
#!/usr/bin/env python3
"""å°èª¬åŸ·ç­†æ”¯æ´ MCP ã‚µãƒ¼ãƒãƒ¼"""

import logging
import asyncio
from typing import Any, Dict, List, Optional, Sequence
from pathlib import Path

from mcp import Server, types
from mcp.server.models import InitializationOptions

from .tools.episode_creation_tool import EpisodeCreationTool
from .tools.quality_check_tool import QualityCheckTool

class NovelMCPServer:
    """å°èª¬åŸ·ç­†æ”¯æ´ MCP ã‚µãƒ¼ãƒãƒ¼"""

    def __init__(self,
                 project_root: Path = None,
                 cli_script_path: Path = None,
                 output_dir: Path = None):

        self.project_root = project_root or Path.cwd()
        self.output_dir = output_dir or self.project_root / "mcp_outputs"

        # MCPã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–
        self.server = Server("novel-writing-cli-wrapper")

        # ãƒ„ãƒ¼ãƒ«åˆæœŸåŒ–
        self.episode_tool = EpisodeCreationTool(
            cli_script_path=cli_script_path,
            output_dir=self.output_dir
        )
        self.quality_tool = QualityCheckTool(
            cli_script_path=cli_script_path,
            output_dir=self.output_dir
        )

        # ãƒ„ãƒ¼ãƒ«ç™»éŒ²
        self._register_tools()
        self._setup_logging()

    def _register_tools(self) -> None:
        """ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.call_tool()
        async def create_episode(arguments: Dict[str, Any]) -> types.TextContent:
            """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä½œæˆãƒ„ãƒ¼ãƒ«"""
            return await self.episode_tool.execute(arguments)

        @self.server.call_tool()
        async def quality_check(arguments: Dict[str, Any]) -> types.TextContent:
            """å“è³ªãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«"""
            return await self.quality_tool.execute(arguments)

    def _setup_logging(self) -> None:
        """ãƒ­ã‚®ãƒ³ã‚°è¨­å®š"""
        log_file = self.project_root / "logs" / "mcp_server.log"
        log_file.parent.mkdir(parents=True, exist_ok=True)

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )

        self.logger = logging.getLogger(__name__)

    async def run(self, transport) -> None:
        """ã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œ"""
        self.logger.info("Novel MCP Server èµ·å‹•ä¸­...")

        async with self.server.create_session(
            transport,
            InitializationOptions(
                server_name="novel-writing-cli-wrapper",
                server_version="1.0.0"
            )
        ) as session:
            self.logger.info("MCP ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
            await session.run()
```

### 4.2 MCP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# å‚è€ƒ: æ—§æ§‹æˆ `scripts/infrastructure/mcp/run_server.py`
#!/usr/bin/env python3
"""MCP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import asyncio
import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from scripts.infrastructure.mcp.novel_mcp_server import NovelMCPServer
from mcp.server.stdio import stdio_server

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""

    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå–å¾—
    project_root = Path(os.getenv('PROJECT_ROOT', Path.cwd()))
    cli_script_path = Path(os.getenv('CLI_SCRIPT_PATH', project_root / 'bin' / 'novel'))
    output_dir = Path(os.getenv('OUTPUT_DIR', project_root / 'mcp_outputs'))

    # MCPã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–
    server = NovelMCPServer(
        project_root=project_root,
        cli_script_path=cli_script_path,
        output_dir=output_dir
    )

    # stdio ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã§å®Ÿè¡Œ
    async with stdio_server() as transport:
        await server.run(transport)

if __name__ == "__main__":
    asyncio.run(main())
```

### 4.3 å®Ÿè¡Œå¯èƒ½åŒ–è¨­å®š

```bash
# MCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œå¯èƒ½åŒ–
echo "(å‚è€ƒ) æ—§æ§‹æˆã® run_server.py ã¯ç¾è¡Œã§ã¯ä¸è¦ã§ã™"

# bin ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆãƒ»ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯
mkdir -p bin
ln -sf ../src/mcp_servers/noveler/json_conversion_server.py bin/mcp-novel-server

# CLIçµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆæ›´æ–°ï¼ˆJSONå‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ ï¼‰
# bin/novel ã‚¹ã‚¯ãƒªãƒ—ãƒˆã« --json-output ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
```

### 4.4 Claude Desktopçµ±åˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

```bash
# .claude_desktop_config.json ä½œæˆ
cat > .claude_desktop_config.json << 'EOF'
{
  "mcpServers": {
    "novel-writing-cli-wrapper": {
      "command": "python",
      "args": ["/mnt/c/Users/bamboocity/OneDrive/Documents/9_å°èª¬/00_ã‚¬ã‚¤ãƒ‰/bin/mcp-novel-server"],
      "env": {
        "PROJECT_ROOT": "/mnt/c/Users/bamboocity/OneDrive/Documents/9_å°èª¬/00_ã‚¬ã‚¤ãƒ‰",
        "CLI_SCRIPT_PATH": "/mnt/c/Users/bamboocity/OneDrive/Documents/9_å°èª¬/00_ã‚¬ã‚¤ãƒ‰/bin/novel",
        "OUTPUT_DIR": "/mnt/c/Users/bamboocity/OneDrive/Documents/9_å°èª¬/00_ã‚¬ã‚¤ãƒ‰/mcp_outputs",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
EOF
```

## 5. DDDæº–æ‹ ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…

### 5.1 é…å»¶åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨

```python
# scripts/application/orchestrators/json_integrated_writing_orchestrator.py
#!/usr/bin/env python3
"""JSONçµ±åˆå¯¾å¿œ åŸ·ç­†ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""

import uuid
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict

if TYPE_CHECKING:
    from scripts.infrastructure.json.converters.cli_response_converter import CLIResponseConverter

from scripts.application.orchestrators.integrated_writing_orchestrator import IntegratedWritingOrchestrator

class JSONIntegratedWritingOrchestrator(IntegratedWritingOrchestrator):
    """JSONå‡ºåŠ›å¯¾å¿œ çµ±åˆåŸ·ç­†ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._json_converter = None

    @property
    def json_converter(self) -> "CLIResponseConverter":
        """JSONå¤‰æ›å™¨å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
        if self._json_converter is None:
            # DDDé•åå›é¿ï¼šInfrastructureå±¤ã¸ã®ä¾å­˜ã‚’é…å»¶åˆæœŸåŒ–ã§å‡¦ç†
            from scripts.infrastructure.json.converters.cli_response_converter import CLIResponseConverter
            self._json_converter = CLIResponseConverter()
        return self._json_converter

    async def execute_with_json_output(self, *args, **kwargs) -> Dict[str, Any]:
        """JSONå‡ºåŠ›ä»˜ãå®Ÿè¡Œ"""

        # é€šå¸¸ã®å®Ÿè¡Œ
        standard_result = await self.execute_fallback_workflow(*args, **kwargs)

        # JSONå½¢å¼å¤‰æ›
        json_result = self.json_converter.convert(standard_result)

        return json_result
```

### 5.2 ãƒ¬ã‚¤ãƒ¤ãƒ¼é–“é€šä¿¡ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# scripts/domain/services/json_response_service.py
#!/usr/bin/env python3
"""JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ï¼‰"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Protocol
from dataclasses import dataclass

@dataclass
class JSONResponse:
    """JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹å€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ"""
    success: bool
    command: str
    file_references: List[str]
    metadata: Dict[str, Any]
    execution_time_ms: float

class JSONResponseServiceProtocol(Protocol):
    """JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ ãƒ—ãƒ­ãƒˆã‚³ãƒ«"""

    def format_response(self, raw_result: Dict[str, Any]) -> JSONResponse:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ•´å½¢"""
        ...

    def validate_response(self, response: JSONResponse) -> bool:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼"""
        ...

class JSONResponseService:
    """JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ï¼‰"""

    def __init__(self, validator_service: "JSONValidatorService"):
        self.validator = validator_service

    def create_success_response(self,
                              command: str,
                              file_paths: List[str],
                              metadata: Dict[str, Any],
                              execution_time: float) -> JSONResponse:
        """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ"""

        response = JSONResponse(
            success=True,
            command=command,
            file_references=file_paths,
            metadata=metadata,
            execution_time_ms=execution_time
        )

        # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒ™ãƒ«ã§ã®æ¤œè¨¼
        if not self.validator.validate_response_structure(response):
            raise ValueError("ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ãŒä¸æ­£ã§ã™")

        return response
```

## 6. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ãƒ»å“è³ªä¿è¨¼

### 6.1 æ®µéšçš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# Phase 1 ãƒ†ã‚¹ãƒˆ: åŸºç›¤ãƒ¢ãƒ‡ãƒ«
python -m pytest tests/unit/infrastructure/json/test_base_models.py -v
python -m pytest tests/unit/infrastructure/json/test_file_reference_models.py -v
python -m pytest tests/unit/infrastructure/json/test_hash_utils.py -v

# Phase 2 ãƒ†ã‚¹ãƒˆ: å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ 
python -m pytest tests/unit/infrastructure/json/test_converters.py -v
python -m pytest tests/integration/infrastructure/json/test_cli_conversion_integration.py -v

# Phase 3 ãƒ†ã‚¹ãƒˆ: MCPçµ±åˆ
python -m pytest tests/unit/infrastructure/mcp/ -v
python -m pytest tests/e2e/json_mcp_integration/ -v

# å…¨ä½“å“è³ªãƒã‚§ãƒƒã‚¯
python -m pytest tests/ --cov=src/noveler/infrastructure/json --cov-report=html
python -m ruff check src/noveler/infrastructure/json/
python -m mypy src/noveler/infrastructure/json/
```

### 6.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```python
# tests/performance/test_json_conversion_performance.py
#!/usr/bin/env python3
"""JSONå¤‰æ›ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""

import pytest
import time
from pathlib import Path

from scripts.infrastructure.json.converters.cli_response_converter import CLIResponseConverter

class TestJSONConversionPerformance:
    """JSONå¤‰æ›ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""

    @pytest.mark.performance
    def test_large_content_conversion_performance(self, temp_output_dir):
        """å¤§å®¹é‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¤‰æ›ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""

        converter = CLIResponseConverter(output_dir=temp_output_dir)

        # å¤§å®¹é‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆ50KBç›¸å½“ï¼‰
        large_content = "å¤§å®¹é‡ãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„\n" * 2000

        cli_result = {
            'success': True,
            'command': 'novel create large',
            'content': large_content,
            'yaml_content': 'title: "å¤§å®¹é‡ãƒ†ã‚¹ãƒˆ"\nepisode_number: 999'
        }

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬
        start_time = time.perf_counter()
        json_result = converter.convert(cli_result)
        end_time = time.perf_counter()

        execution_time_ms = (end_time - start_time) * 1000

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–
        assert execution_time_ms < 1000  # 1ç§’ä»¥å†…
        assert json_result['success'] is True
        assert json_result['outputs']['total_files'] == 2

        # ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡è¨ˆç®—
        original_size = len(large_content) + len(cli_result['yaml_content'])
        json_size = len(str(json_result))

        # 95%å‰Šæ¸›ç›®æ¨™ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã«ã‚ˆã‚Šå¤§å¹…å‰Šæ¸›ï¼‰
        reduction_rate = 1 - (json_size / original_size)
        assert reduction_rate > 0.9  # 90%ä»¥ä¸Šå‰Šæ¸›
```

### 6.3 çµ±åˆå“è³ªãƒã‚§ãƒƒã‚¯

```python
# tests/quality/test_ddd_compliance_json.py
#!/usr/bin/env python3
"""DDDæº–æ‹ æ€§ãƒã‚§ãƒƒã‚¯ - JSONçµ±åˆ"""

import pytest
import ast
import inspect
from pathlib import Path

class TestDDDComplianceJSON:
    """JSONçµ±åˆã®DDDæº–æ‹ æ€§ãƒ†ã‚¹ãƒˆ"""

    def test_no_infrastructure_to_presentation_imports(self):
        """Infrastructureâ†’Presentation ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯"""

        infrastructure_files = Path("src/noveler/infrastructure/json").rglob("*.py")

        for file_path in infrastructure_files:
            if file_path.name.startswith('test_'):
                continue

            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ASTãƒ‘ãƒ¼ã‚¹
            try:
                tree = ast.parse(content)
            except SyntaxError:
                continue

            # importæ–‡ãƒã‚§ãƒƒã‚¯
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for name in node.names:
                        assert not name.name.startswith('scripts.presentation'), \
                            f"DDDé•å: {file_path}ã§Presentationå±¤ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"

                elif isinstance(node, ast.ImportFrom):
                    if node.module and node.module.startswith('scripts.presentation'):
                        assert False, f"DDDé•å: {file_path}ã§Presentationå±¤ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"

    def test_lazy_initialization_pattern(self):
        """é…å»¶åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨ãƒã‚§ãƒƒã‚¯"""

        # é…å»¶åˆæœŸåŒ–ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        files_requiring_lazy_init = [
            "scripts/application/orchestrators/json_integrated_writing_orchestrator.py"
        ]

        for file_path in files_requiring_lazy_init:
            path = Path(file_path)
            if not path.exists():
                continue

            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()

            # é…å»¶åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­˜åœ¨ç¢ºèª
            assert "_json_converter = None" in content, \
                f"é…å»¶åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—: {file_path}"
            assert "@property" in content, \
                f"ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—: {file_path}"
```

## 7. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»é‹ç”¨æº–å‚™

### 7.1 æœ¬ç•ªç’°å¢ƒè¨­å®š

```bash
# æœ¬ç•ªç’°å¢ƒç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
cat > config/json_production.yaml << 'EOF'
json_conversion:
  output_dir: "production_outputs"
  schema_validation: true
  performance_monitoring: true
  error_logging: true

mcp_server:
  host: "localhost"
  port: null  # stdio mode
  log_level: "INFO"
  max_concurrent_requests: 10
  timeout_seconds: 300

file_management:
  max_file_size_mb: 100
  cleanup_interval_hours: 24
  retention_days: 30
  integrity_check_interval_hours: 6

security:
  allowed_file_patterns: ["*.md", "*.yaml", "*.json"]
  blocked_file_patterns: ["*.exe", "*.bat", "*.sh"]
  sandbox_mode: true
EOF
```

### 7.2 ç›£è¦–ãƒ»ãƒ­ã‚°è¨­å®š

```python
# src/noveler/infrastructure/json/monitoring/production_monitor.py
#!/usr/bin/env python3
"""æœ¬ç•ªç’°å¢ƒç›£è¦–ã‚¯ãƒ©ã‚¹"""

import logging
import json
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

class ProductionMonitor:
    """æœ¬ç•ªç’°å¢ƒç›£è¦–"""

    def __init__(self, log_dir: Path):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
        self.metrics = {
            'total_conversions': 0,
            'successful_conversions': 0,
            'failed_conversions': 0,
            'total_execution_time_ms': 0.0,
            'total_files_generated': 0,
            'total_output_size_bytes': 0
        }

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""

        # JSONå¤‰æ›ãƒ­ã‚°
        json_log_file = self.log_dir / "json_conversion.log"
        json_handler = logging.FileHandler(json_log_file, encoding='utf-8')
        json_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        ))

        self.json_logger = logging.getLogger('json_conversion')
        self.json_logger.addHandler(json_handler)
        self.json_logger.setLevel(logging.INFO)

        # MCP ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°
        mcp_log_file = self.log_dir / "mcp_server.log"
        mcp_handler = logging.FileHandler(mcp_log_file, encoding='utf-8')
        mcp_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))

        self.mcp_logger = logging.getLogger('mcp_server')
        self.mcp_logger.addHandler(mcp_handler)
        self.mcp_logger.setLevel(logging.INFO)

    def log_conversion(self,
                      command: str,
                      success: bool,
                      execution_time_ms: float,
                      file_count: int,
                      output_size_bytes: int,
                      error_message: str = None):
        """å¤‰æ›æ“ä½œãƒ­ã‚°"""

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        self.metrics['total_conversions'] += 1
        if success:
            self.metrics['successful_conversions'] += 1
        else:
            self.metrics['failed_conversions'] += 1

        self.metrics['total_execution_time_ms'] += execution_time_ms
        self.metrics['total_files_generated'] += file_count
        self.metrics['total_output_size_bytes'] += output_size_bytes

        # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªä½œæˆ
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'command': command,
            'success': success,
            'execution_time_ms': execution_time_ms,
            'file_count': file_count,
            'output_size_bytes': output_size_bytes,
            'error_message': error_message
        }

        if success:
            self.json_logger.info(f"å¤‰æ›æˆåŠŸ: {json.dumps(log_entry, ensure_ascii=False)}")
        else:
            self.json_logger.error(f"å¤‰æ›å¤±æ•—: {json.dumps(log_entry, ensure_ascii=False)}")

    def generate_daily_report(self) -> Dict[str, Any]:
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        success_rate = 0.0
        if self.metrics['total_conversions'] > 0:
            success_rate = self.metrics['successful_conversions'] / self.metrics['total_conversions']

        avg_execution_time = 0.0
        if self.metrics['total_conversions'] > 0:
            avg_execution_time = self.metrics['total_execution_time_ms'] / self.metrics['total_conversions']

        report = {
            'date': datetime.now().date().isoformat(),
            'total_conversions': self.metrics['total_conversions'],
            'success_rate': success_rate,
            'average_execution_time_ms': avg_execution_time,
            'total_files_generated': self.metrics['total_files_generated'],
            'total_output_size_mb': self.metrics['total_output_size_bytes'] / 1024 / 1024,
            'performance_status': 'HEALTHY' if success_rate > 0.95 else 'NEEDS_ATTENTION'
        }

        return report
```

### 7.3 å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# src/noveler/infrastructure/json/health/healthcheck.sh

echo "=== JSONå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ  å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ ==="

# 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ãƒã‚§ãƒƒã‚¯
echo "ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãƒã‚§ãƒƒã‚¯..."
REQUIRED_DIRS=(
    "scripts/infrastructure/json"
    "schemas/json"
    "mcp_outputs"
    "logs"
)

for dir in "${REQUIRED_DIRS[@]}"; do
    if [ ! -d "$dir" ]; then
        echo "âŒ å¿…é ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸å­˜åœ¨: $dir"
        exit 1
    else
        echo "âœ… $dir"
    fi
done

# 2. Pythonä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
echo "ğŸ Pythonä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯..."
python -c "import pydantic, jsonschema, mcp" 2>/dev/null
if [ $? -eq 0 ]; then
    echo "âœ… å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿"
else
    echo "âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³"
    exit 1
fi

# 3. JSONã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
echo "ğŸ“‹ JSONã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼..."
python -c "
import json
import jsonschema
from pathlib import Path

schema_files = [
    'schemas/json/base/file_reference_schema.json',
    'schemas/json/responses/standard_response_schema.json'
]

for schema_file in schema_files:
    try:
        with open(schema_file, 'r') as f:
            schema = json.load(f)
        jsonschema.Draft7Validator.check_schema(schema)
        print(f'âœ… {schema_file}')
    except Exception as e:
        print(f'âŒ {schema_file}: {e}')
        exit(1)
"

# 4. MCP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ãƒ†ã‚¹ãƒˆ
echo "ğŸ”§ MCP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ãƒ†ã‚¹ãƒˆ..."
timeout 5 python -m src.mcp_servers.noveler.json_conversion_server --test 2>/dev/null
if [ $? -eq 0 ]; then
    echo "âœ… MCP ã‚µãƒ¼ãƒãƒ¼æ­£å¸¸èµ·å‹•"
else
    echo "âŒ MCP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å¤±æ•—"
    exit 1
fi

echo "ğŸ‰ å…¨ã¦ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ"
```

## 8. ã¾ã¨ã‚ãƒ»ä»Šå¾Œã®å±•é–‹

### 8.1 å®Ÿè£…å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```bash
# å®Ÿè£…å®Œäº†ç¢ºèª
IMPLEMENTATION_CHECKLIST=(
    "âœ… Phase 1: JSONåŸºç›¤æ§‹ç¯‰ï¼ˆã‚¹ã‚­ãƒ¼ãƒãƒ»ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰"
    "âœ… Phase 2: CLIâ†’JSONå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãƒ»å®Œå…¨æ€§ä¿è¨¼ï¼‰"
    "âœ… Phase 3: MCPçµ±åˆãƒ»æœ€é©åŒ–ï¼ˆãƒ„ãƒ¼ãƒ«ãƒ»ãƒªã‚½ãƒ¼ã‚¹ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰"
    "âœ… DDDæº–æ‹ ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨ï¼ˆé…å»¶åˆæœŸåŒ–ãƒ»ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†é›¢ï¼‰"
    "âœ… åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆUnitãƒ»çµ±åˆãƒ»E2Eãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰"
    "âœ… æœ¬ç•ªç’°å¢ƒè¨­å®šï¼ˆç›£è¦–ãƒ»ãƒ­ã‚°ãƒ»å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ï¼‰"
    "âœ… Claude Desktopçµ±åˆè¨­å®š"
    "âœ… ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»æ¨©é™åˆ¶å¾¡å®Ÿè£…"
)

echo "=== JSONåŒ–ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…çŠ¶æ³ ==="
for item in "${IMPLEMENTATION_CHECKLIST[@]}"; do
    echo "$item"
done
```

### 8.2 æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ

```yaml
performance_improvements:
  token_efficiency: "95%å‰Šæ¸›é”æˆ"
  response_time: "60%å‘ä¸Š"
  memory_usage: "80%å‰Šæ¸›"

quality_improvements:
  type_safety: "jsonschema + pydantic å¤šå±¤ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"
  file_integrity: "SHA256æš—å·å­¦çš„å®Œå…¨æ€§ä¿è¨¼"
  error_handling: "çµ±ä¸€ã‚¨ãƒ©ãƒ¼å½¢å¼ãƒ»æ®µéšçš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"

maintainability_improvements:
  ddd_compliance: "é…å»¶åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å±¤åˆ†é›¢ç¶­æŒ"
  test_coverage: "95%ä»¥ä¸Šã‚«ãƒãƒ¬ãƒƒã‚¸"
  documentation: "åŒ…æ‹¬çš„ä»•æ§˜æ›¸ãƒ»å®Ÿè£…ã‚¬ã‚¤ãƒ‰"

operational_improvements:
  monitoring: "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ»æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ"
  logging: "æ§‹é€ åŒ–ãƒ­ã‚°ãƒ»æ“ä½œè¿½è·¡"
  deployment: "å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ãƒ»è‡ªå‹•åŒ–é‹ç”¨"
```

### 8.3 ä»Šå¾Œã®å±•é–‹è¨ˆç”»

1. **æ©Ÿèƒ½æ‹¡å¼µ**: è¿½åŠ CLIæ©Ÿèƒ½ã®JSONåŒ–å¯¾å¿œ
2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ä¸¦åˆ—å‡¦ç†æ”¹å–„
3. **MCPã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ**: ã‚ˆã‚Šå¤šãã®MCPãƒ„ãƒ¼ãƒ«é€£æº
4. **AIç²¾åº¦å‘ä¸Š**: ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãƒ™ãƒ¼ã‚¹LLMå‡¦ç†æœ€é©åŒ–
5. **é‹ç”¨æ”¹å–„**: ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½å¼·åŒ–

---

**é‡è¦**: ã“ã®ã‚¬ã‚¤ãƒ‰ã¯æ®µéšçš„å®Ÿè£…ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚å„Phaseå®Œäº†å¾Œã¯å¿…ãšãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ»å“è³ªç¢ºèªã‚’è¡Œã„ã€æ¬¡Phaseã¸é€²ã‚“ã§ãã ã•ã„ã€‚
