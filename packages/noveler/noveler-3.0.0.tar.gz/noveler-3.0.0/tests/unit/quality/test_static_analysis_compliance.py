"""
CODEMAPé€£æºé™çš„è§£æé•åæ¤œå‡ºãƒ†ã‚¹ãƒˆ

ASTãƒ™ãƒ¼ã‚¹ã®é«˜ç²¾åº¦é•åæ¤œå‡ºï¼ˆCODEMAPåŸºæº–ï¼‰ï¼š
- importæ–‡ã®è©³ç´°è§£æï¼ˆCODEMAPç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³åŸºæº–ï¼‰
- ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºï¼ˆCODEMAPåŸºæº–ï¼‰
- é–¢æ•°å‘¼ã³å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
- è‡ªå‹•ä¿®æ­£ææ¡ˆç”Ÿæˆï¼ˆCODEMAPæ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³åŸºæº–ï¼‰

Version: 2.0.0 - CODEMAPé€£æºå¯¾å¿œ
"""
from __future__ import annotations

import ast
import pytest
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass

# CODEMAPèª­ã¿å–ã‚Šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parents[3] / "src"))
from noveler.tools.codemap_reader import create_codemap_reader
from noveler.infrastructure.logging.unified_logger import get_logger


@dataclass
class ViolationReport:
    """é•åãƒ¬ãƒãƒ¼ãƒˆ"""
    file_path: str
    line_number: int
    violation_type: str
    severity: str
    current_code: str
    suggested_fix: str
    context: str = ""


class ASTBasedComplianceAnalyzer:
    """ASTãƒ™ãƒ¼ã‚¹å…±é€šåŸºç›¤ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è§£æå™¨"""

    def __init__(self):
        self.logger = get_logger(__name__)

        # ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.forbidden_imports = {
            'logging': 'import logging',
            'rich.console.Console': 'from rich.console import Console'
        }

        # ç¦æ­¢é–¢æ•°å‘¼ã³å‡ºã—
        self.forbidden_calls = {
            'logging.getLogger',
            'Console',
            'print'  # æ–‡è„ˆã«ã‚ˆã‚Šåˆ¤å®š
        }

        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.hardcoded_patterns = {
            '"40_åŸç¨¿"',
            '"30_ãƒ—ãƒ­ãƒƒãƒˆ"',
            '"20_è¨­å®š"',
            '"10_ä¼ç”»"'
        }

        # æ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.recommended_imports = {
            'noveler.infrastructure.logging.unified_logger': 'get_logger',
            'noveler.presentation.shared.shared_utilities': '_get_console',
            'noveler.infrastructure.factories.path_service_factory': 'create_path_service'
        }

    def analyze_file(self, file_path: Path) -> List[ViolationReport]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®é™çš„è§£æå®Ÿè¡Œ"""
        violations = []

        try:
            content = file_path.read_text(encoding='utf-8')
            tree = ast.parse(content)

            # å„ç¨®è§£æã®å®Ÿè¡Œ
            violations.extend(self._analyze_imports(tree, file_path, content))
            violations.extend(self._analyze_function_calls(tree, file_path, content))
            violations.extend(self._analyze_string_literals(tree, file_path, content))
            violations.extend(self._analyze_assignments(tree, file_path, content))

        except Exception as e:
            self.logger.error(f"ASTè§£æã‚¨ãƒ©ãƒ¼ {file_path}: {e}")

        return violations

    def _analyze_imports(self, tree: ast.AST, file_path: Path, content: str) -> List[ViolationReport]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®è§£æ"""
        violations = []
        lines = content.split('\n')

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    # ç¦æ­¢ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æ¤œå‡º
                    if alias.name in self.forbidden_imports:
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="forbidden_import",
                            severity="critical",
                            current_code=f"import {alias.name}",
                            suggested_fix="from noveler.infrastructure.logging.unified_logger import get_logger",
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    full_import = f"{node.module}.{node.names[0].name if node.names else ''}"

                    # ç¦æ­¢ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æ¤œå‡º
                    if full_import in self.forbidden_imports:
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="forbidden_from_import",
                            severity="critical",
                            current_code=f"from {node.module} import {', '.join(n.name for n in node.names)}",
                            suggested_fix=self._get_recommended_import_fix(node.module, node.names),
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

                    # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æ¤œå‡º
                    if node.module.startswith('.'):
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="relative_import",
                            severity="high",
                            current_code=f"from {node.module} import {', '.join(n.name for n in node.names)}",
                            suggested_fix=self._convert_relative_to_absolute_import(node.module, node.names),
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

        return violations

    def _analyze_function_calls(self, tree: ast.AST, file_path: Path, content: str) -> List[ViolationReport]:
        """é–¢æ•°å‘¼ã³å‡ºã—ã®è§£æ"""
        violations = []
        lines = content.split('\n')

        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                # é–¢æ•°åã®å–å¾—
                func_name = self._get_function_name(node.func)

                if func_name in self.forbidden_calls:
                    # Console()ç›´æ¥ä½œæˆã®æ¤œå‡º
                    if func_name == 'Console':
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="console_duplication",
                            severity="critical",
                            current_code="Console()",
                            suggested_fix="from noveler.presentation.shared.shared_utilities import _get_console; console = _get_console()",
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

                    # logging.getLoggerä½¿ç”¨ã®æ¤œå‡º
                    elif func_name == 'logging.getLogger':
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="legacy_getlogger",
                            severity="critical",
                            current_code="logging.getLogger(__name__)",
                            suggested_fix="get_logger(__name__)",
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

                    # printæ–‡ã®æ¤œå‡ºï¼ˆæ–‡è„ˆã«ã‚ˆã‚Šåˆ¤å®šï¼‰
                    elif func_name == 'print':
                        # MCPã‚µãƒ¼ãƒãƒ¼ä»¥å¤–ã§ã®printä½¿ç”¨ã¯æ¨å¥¨ã•ã‚Œãªã„
                        if 'mcp_servers' not in str(file_path):
                            violations.append(ViolationReport(
                                file_path=str(file_path),
                                line_number=node.lineno,
                                violation_type="print_usage",
                                severity="medium",
                                current_code=f"print({self._get_print_args(node)})",
                                suggested_fix="console.print(...) # å…±é€šConsoleã‚’ä½¿ç”¨",
                                context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                            ))

        return violations

    def _analyze_string_literals(self, tree: ast.AST, file_path: Path, content: str) -> List[ViolationReport]:
        """æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã®è§£æï¼ˆãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºï¼‰"""
        violations = []
        lines = content.split('\n')

        for node in ast.walk(tree):
            if isinstance(node, ast.Str):
                # Python 3.8ä»¥é™
                string_value = f'"{node.s}"'
            elif isinstance(node, ast.Constant) and isinstance(node.value, str):
                # Python 3.8ä»¥é™
                string_value = f'"{node.value}"'
            else:
                continue

            # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
            if string_value in self.hardcoded_patterns:
                violations.append(ViolationReport(
                    file_path=str(file_path),
                    line_number=node.lineno,
                    violation_type="hardcoded_path",
                    severity="critical",
                    current_code=string_value,
                    suggested_fix=self._get_path_service_fix(string_value),
                    context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                ))

        return violations

    def _analyze_assignments(self, tree: ast.AST, file_path: Path, content: str) -> List[ViolationReport]:
        """ä»£å…¥æ–‡ã®è§£æ"""
        violations = []
        lines = content.split('\n')

        for node in ast.walk(tree):
            if isinstance(node, ast.Assign):
                # console = Console() ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
                if (len(node.targets) == 1 and
                    isinstance(node.targets[0], ast.Name) and
                    node.targets[0].id == 'console' and
                    isinstance(node.value, ast.Call)):

                    func_name = self._get_function_name(node.value.func)
                    if func_name == 'Console':
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="console_assignment_duplication",
                            severity="critical",
                            current_code="console = Console()",
                            suggested_fix="console = _get_console()  # å…±é€šConsoleã‚’ä½¿ç”¨",
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

                # logger = logging.getLogger() ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
                elif (len(node.targets) == 1 and
                      isinstance(node.targets[0], ast.Name) and
                      node.targets[0].id == 'logger' and
                      isinstance(node.value, ast.Call)):

                    func_name = self._get_function_name(node.value.func)
                    if func_name == 'logging.getLogger':
                        violations.append(ViolationReport(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            violation_type="logger_assignment_legacy",
                            severity="critical",
                            current_code="logger = logging.getLogger(__name__)",
                            suggested_fix="logger = get_logger(__name__)",
                            context=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
                        ))

        return violations

    def _get_function_name(self, func_node: ast.AST) -> str:
        """é–¢æ•°åã®å–å¾—"""
        if isinstance(func_node, ast.Name):
            return func_node.id
        elif isinstance(func_node, ast.Attribute):
            if isinstance(func_node.value, ast.Name):
                return f"{func_node.value.id}.{func_node.attr}"
            else:
                return func_node.attr
        return ""

    def _get_print_args(self, call_node: ast.Call) -> str:
        """printé–¢æ•°ã®å¼•æ•°å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if call_node.args:
            return "..."
        return ""

    def _get_recommended_import_fix(self, module: str, names: List[ast.alias]) -> str:
        """æ¨å¥¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¿®æ­£ã®å–å¾—"""
        if module == "rich.console" and any(n.name == "Console" for n in names):
            return "from noveler.presentation.shared.shared_utilities import _get_console"
        elif module == "logging":
            return "from noveler.infrastructure.logging.unified_logger import get_logger"
        else:
            return f"# TODO: {module} ã®é©åˆ‡ãªä»£æ›¿ã‚’æ¤œè¨"

    def _convert_relative_to_absolute_import(self, module: str, names: List[ast.alias]) -> str:
        """ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤‰æ›"""
        if module.startswith('..'):
            return f"from noveler.{module[2:]} import {', '.join(n.name for n in names)}"
        elif module.startswith('.'):
            return f"from noveler{module[1:]} import {', '.join(n.name for n in names)}"
        return f"# TODO: {module} ã®çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤‰æ›"

    def _get_path_service_fix(self, hardcoded_path: str) -> str:
        """PathServiceä¿®æ­£ææ¡ˆã®å–å¾—"""
        path_mapping = {
            '"40_åŸç¨¿"': "path_service.get_manuscript_dir()",
            '"30_ãƒ—ãƒ­ãƒƒãƒˆ"': "path_service.get_plot_dir()",
            '"20_è¨­å®š"': "path_service.get_settings_dir()",
            '"10_ä¼ç”»"': "path_service.get_planning_dir()"
        }
        return path_mapping.get(hardcoded_path, f"# TODO: {hardcoded_path} ã® PathServiceå¯¾å¿œ")


class TestStaticAnalysisCompliance:
    """é™çš„è§£æã«ã‚ˆã‚‹å…±é€šåŸºç›¤ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def analyzer(self):
        """é™çš„è§£æå™¨ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
        return ASTBasedComplianceAnalyzer()

    @pytest.fixture
    def project_root(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹"""
        return Path(__file__).parent.parent.parent.parent

    @pytest.fixture
    def target_files(self, project_root):
        """è§£æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—"""
        target_dirs = [
            project_root / "src" / "noveler",
            project_root / "src" / "scripts"
        ]

        python_files = []
        for target_dir in target_dirs:
            if target_dir.exists():
                python_files.extend(target_dir.rglob("*.py"))

        return python_files

    @pytest.mark.spec("SPEC-STA-COM-001")
    def test_ast_based_import_violation_detection(self, analyzer, target_files):
        """ASTãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒãƒ¼ãƒˆé•åæ¤œå‡º"""
        all_violations = []

        for file_path in target_files[:10]:  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒ«è§£æ
            violations = analyzer.analyze_file(file_path)
            import_violations = [v for v in violations if 'import' in v.violation_type]
            all_violations.extend(import_violations)

        # é•åãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        print(f"\n=== AST-Based Import Violation Detection ===")
        print(f"Total import violations: {len(all_violations)}")

        critical_violations = [v for v in all_violations if v.severity == "critical"]
        high_violations = [v for v in all_violations if v.severity == "high"]

        print(f"Critical violations: {len(critical_violations)}")
        print(f"High priority violations: {len(high_violations)}")

        # ã‚µãƒ³ãƒ—ãƒ«é•åã®è©³ç´°è¡¨ç¤º
        for i, violation in enumerate(critical_violations[:3]):
            print(f"\nğŸ“ Violation {i+1}:")
            print(f"   File: {Path(violation.file_path).name}")
            print(f"   Line: {violation.line_number}")
            print(f"   Type: {violation.violation_type}")
            print(f"   Current: {violation.current_code}")
            print(f"   Fix: {violation.suggested_fix}")

    @pytest.mark.spec("SPEC-STA-COM-002")
    def test_ast_based_console_duplication_detection(self, analyzer, target_files):
        """ASTãƒ™ãƒ¼ã‚¹Consoleé‡è¤‡æ¤œå‡º"""
        console_violations = []

        for file_path in target_files[:20]:
            violations = analyzer.analyze_file(file_path)
            console_specific = [v for v in violations if 'console' in v.violation_type]
            console_violations.extend(console_specific)

        print(f"\n=== AST-Based Console Duplication Detection ===")
        print(f"Console violations: {len(console_violations)}")

        # é‡è¤‡ä½œæˆã®å®Œå…¨ç¦æ­¢ï¼ˆB30åŸºæº–ï¼‰
        critical_console_violations = [v for v in console_violations if v.severity == "critical"]

        if critical_console_violations:
            print(f"âŒ Critical console violations found: {len(critical_console_violations)}")
            for violation in critical_console_violations[:2]:
                print(f"   - {Path(violation.file_path).name}:{violation.line_number}")
                print(f"     Current: {violation.current_code}")
                print(f"     Fix: {violation.suggested_fix}")
        else:
            print(f"âœ… No critical console violations detected")

        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«é•åã¯0ä»¶ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(critical_console_violations) == 0, (
            f"Consoleé‡è¤‡ä½œæˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {len(critical_console_violations)}ä»¶"
        )

    @pytest.mark.spec("SPEC-STA-COM-003")
    def test_ast_based_hardcoding_detection(self, analyzer, target_files):
        """ASTãƒ™ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡º"""
        hardcoding_violations = []

        for file_path in target_files[:15]:
            violations = analyzer.analyze_file(file_path)
            hardcoding_specific = [v for v in violations if v.violation_type == "hardcoded_path"]
            hardcoding_violations.extend(hardcoding_specific)

        print(f"\n=== AST-Based Hardcoding Detection ===")
        print(f"Hardcoding violations: {len(hardcoding_violations)}")

        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è©³ç´°ã®è¡¨ç¤º
        for i, violation in enumerate(hardcoding_violations):
            print(f"\nğŸ“ Hardcoding {i+1}:")
            print(f"   File: {Path(violation.file_path).name}")
            print(f"   Line: {violation.line_number}")
            print(f"   Hardcoded: {violation.current_code}")
            print(f"   PathService fix: {violation.suggested_fix}")

        # ãƒ‘ã‚¹ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç¦æ­¢ï¼ˆB30åŸºæº–ï¼‰
        assert len(hardcoding_violations) == 0, (
            f"ãƒ‘ã‚¹ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {len(hardcoding_violations)}ä»¶"
        )

    @pytest.mark.spec("SPEC-STA-COM-004")
    def test_progressive_check_manager_ast_compliance(self, analyzer, project_root):
        """ProgressiveCheckManager ASTå®Œå…¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹"""
        pcm_file = project_root / "src" / "scripts" / "domain" / "services" / "progressive_check_manager.py"

        if not pcm_file.exists():
            pytest.skip("ProgressiveCheckManager file not found")

        violations = analyzer.analyze_file(pcm_file)

        print(f"\n=== ProgressiveCheckManager AST Compliance ===")
        print(f"Total violations: {len(violations)}")

        # å„ç¨®é•åã®åˆ†é¡
        violation_by_type = {}
        for violation in violations:
            violation_type = violation.violation_type
            if violation_type not in violation_by_type:
                violation_by_type[violation_type] = []
            violation_by_type[violation_type].append(violation)

        # é•åã‚¿ã‚¤ãƒ—åˆ¥ã®å ±å‘Š
        for vtype, vlist in violation_by_type.items():
            print(f"  {vtype}: {len(vlist)} violations")
            for v in vlist[:2]:  # æœ€å¤§2ä»¶è¡¨ç¤º
                print(f"    - Line {v.line_number}: {v.current_code}")

        # ProgressiveCheckManagerã¯100%ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’æœŸå¾…
        critical_violations = [v for v in violations if v.severity == "critical"]
        assert len(critical_violations) == 0, (
            f"ProgressiveCheckManager AST critical violations: {len(critical_violations)}"
        )

    @pytest.mark.spec("SPEC-STA-COM-005")
    def test_generate_auto_fix_suggestions(self, analyzer, target_files):
        """è‡ªå‹•ä¿®æ­£ææ¡ˆç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        fix_suggestions = {}

        for file_path in target_files[:5]:  # ã‚µãƒ³ãƒ—ãƒ«è§£æ
            violations = analyzer.analyze_file(file_path)

            if violations:
                file_fixes = []
                for violation in violations:
                    file_fixes.append({
                        'line': violation.line_number,
                        'type': violation.violation_type,
                        'current': violation.current_code,
                        'fix': violation.suggested_fix,
                        'severity': violation.severity
                    })
                fix_suggestions[str(file_path)] = file_fixes

        print(f"\n=== Auto-Fix Suggestions Generation ===")
        print(f"Files with fixable violations: {len(fix_suggestions)}")

        # ä¿®æ­£ææ¡ˆã®è©³ç´°è¡¨ç¤º
        for file_path, fixes in list(fix_suggestions.items())[:2]:
            print(f"\nğŸ“ {Path(file_path).name}")
            for fix in fixes[:3]:  # æœ€å¤§3ä»¶è¡¨ç¤º
                print(f"   Line {fix['line']} ({fix['severity']})")
                print(f"   Current: {fix['current']}")
                print(f"   Fix: {fix['fix']}")

        # è‡ªå‹•ä¿®æ­£å¯èƒ½ç‡ã®è¨ˆç®—
        total_fixes = sum(len(fixes) for fixes in fix_suggestions.values())
        auto_fixable = sum(
            1 for fixes in fix_suggestions.values()
            for fix in fixes
            if fix['fix'] and not fix['fix'].startswith('# TODO')
        )

        auto_fix_rate = auto_fixable / total_fixes if total_fixes > 0 else 1.0
        print(f"\nAuto-fixable rate: {auto_fix_rate:.2%}")

        # 50%ä»¥ä¸ŠãŒè‡ªå‹•ä¿®æ­£å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’æœŸå¾…
        assert auto_fix_rate >= 0.5, f"Auto-fix rate too low: {auto_fix_rate:.2%}"

    @pytest.mark.spec("SPEC-STA-COM-006")
    def test_compliance_trend_analysis(self, analyzer, target_files):
        """ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å‚¾å‘åˆ†æ"""
        analysis_results = {
            'total_files': len(target_files),
            'analyzed_files': 0,
            'compliant_files': 0,
            'violation_distribution': {},
            'severity_distribution': {'critical': 0, 'high': 0, 'medium': 0}
        }

        # ã‚µãƒ³ãƒ—ãƒ«è§£æå®Ÿè¡Œ
        for file_path in target_files[:25]:
            analysis_results['analyzed_files'] += 1
            violations = analyzer.analyze_file(file_path)

            if not violations:
                analysis_results['compliant_files'] += 1

            # é•ååˆ†å¸ƒã®é›†è¨ˆ
            for violation in violations:
                vtype = violation.violation_type
                analysis_results['violation_distribution'][vtype] = \
                    analysis_results['violation_distribution'].get(vtype, 0) + 1

                analysis_results['severity_distribution'][violation.severity] += 1

        print(f"\n=== Compliance Trend Analysis ===")
        print(f"Total files: {analysis_results['total_files']}")
        print(f"Analyzed files: {analysis_results['analyzed_files']}")
        print(f"Compliant files: {analysis_results['compliant_files']}")

        compliance_rate = analysis_results['compliant_files'] / analysis_results['analyzed_files']
        print(f"Compliance rate: {compliance_rate:.2%}")

        print(f"\nViolation distribution:")
        for vtype, count in analysis_results['violation_distribution'].items():
            print(f"  {vtype}: {count}")

        print(f"\nSeverity distribution:")
        for severity, count in analysis_results['severity_distribution'].items():
            print(f"  {severity}: {count}")

        # å…¨ä½“ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç‡70%ä»¥ä¸Šã‚’æœŸå¾…
        assert compliance_rate >= 0.70, f"Overall compliance rate too low: {compliance_rate:.2%}"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
