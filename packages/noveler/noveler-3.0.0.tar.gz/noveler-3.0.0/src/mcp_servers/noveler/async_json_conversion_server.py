#!/usr/bin/env python3
# File: src/mcp_servers/noveler/async_json_conversion_server.py
# Purpose: Provide a fully-asynchronous MCP server variant for Noveler that
#          converts CLI outputs to JSON, validates responses, and exposes
#          async novel-writing/check tools with concurrency optimizations.
# Context: Runs as an MCP stdio server using FastMCP when available. Depends on
#          Noveler infrastructure (logging, converters) and async subprocess
#          adapters. This module performs server/tool registration on import
#          through object construction but avoids side effects at module import.
"""Async JSON conversion MCP server for Noveler (SPEC-901 refactoring).

Purpose:
  Offer async tools to convert CLI output to JSON, validate responses, and run
  novel writing/check commands with concurrency and improved error handling.

Side Effects:
  - When instantiated and run, starts stdio-based MCP server and spawns
    subprocesses for CLI execution.
  - Writes JSON artifacts to an output directory when configured to do so.

Notes:
  Requires Python 3.10+. Uses optional ripgrep-like behavior only via adapters.
  No network/APIs are required beyond local process execution.
"""

import asyncio
import json
from noveler.infrastructure.logging.unified_logger import get_logger
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from noveler.domain.value_objects.ten_stage_writing_execution import TenStageExecutionStage


# B20æº–æ‹ : å…±æœ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå¿…é ˆä½¿ç”¨
from noveler.presentation.shared.shared_utilities import _get_console as get_console

try:
    from mcp import types
    from mcp.server import stdio
    from mcp.server.fastmcp import FastMCP

    MCP_AVAILABLE = True
except ImportError:
    # MCPãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    MCP_AVAILABLE = False
    FastMCP = None
    types = None
    stdio = None

# éåŒæœŸAdapter import
from mcp_servers.noveler.core.async_subprocess_adapter import (
    create_async_subprocess_adapter,
    create_concurrent_executor,
)
from mcp_servers.noveler.core.command_builder import CommandBuilder
from mcp_servers.noveler.core.response_parser import ResponseParser
from mcp_servers.noveler.core.format_utils import format_json_result, format_dict
from mcp_servers.noveler.server.ten_stage_tool_bindings import (
    register_async_ten_stage_tools,
)
from noveler.infrastructure.json.converters.cli_response_converter import CLIResponseConverter
from noveler.infrastructure.json.models.response_models import ErrorResponseModel, StandardResponseModel

# Guarded import to avoid PLC0415 and cycles/heavy dependencies at runtime
try:  # pragma: no cover - availability depends on project wiring
    from noveler.infrastructure.services.ten_stage_session_manager import TenStageSessionManager
    TEN_STAGE_AVAILABLE = True
except Exception:  # pragma: no cover
    TenStageSessionManager = None  # type: ignore
    TEN_STAGE_AVAILABLE = False


class AsyncJSONConversionServer:
    """Fully async JSON-conversion MCP server.

    Purpose:
        Expose async tools for JSON conversion/validation and orchestrate
        novel-related commands with concurrency and robust error handling.

    Side Effects:
        Registers tool handlers on a FastMCP instance; later execution may
        spawn subprocesses and write artifacts depending on configured tools.
    """

    def __init__(
        self,
        output_dir: Path | None = None,
        max_concurrent: int = 3,
        enable_performance_optimization: bool = True
    ) -> None:
        """Initialise async components and FastMCP server.

        Purpose:
            Construct the server, initialise async adapters/executors, and
            register tool handlers on the FastMCP instance.

        Args:
            output_dir (Path | None): Directory to emit JSON artifacts.
            max_concurrent (int): Max concurrent tasks for adapters.
            enable_performance_optimization (bool): Enable tuned paths.

        Side Effects:
            Creates adapter/executor instances; registers tools on FastMCP.

        Raises:
            RuntimeError: When the MCP library is unavailable.
        """
        if not MCP_AVAILABLE:
            msg = "MCPãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚pip install mcp ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            raise RuntimeError(msg)

        self.output_dir = output_dir or Path.cwd() / "temp" / "json_output"
        self.converter = CLIResponseConverter(output_dir=self.output_dir)
        self.logger = get_logger(__name__)

        # éåŒæœŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self._async_adapter = create_async_subprocess_adapter(mock_mode=False)
        self._concurrent_executor = create_concurrent_executor(
            mock_mode=False,
            max_concurrent=max_concurrent,
            retry_policy={"max_retries": 2, "retry_delay": 1.0}
        )

        # ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆDDDæº–æ‹ ï¼‰
        self._command_builder = CommandBuilder()
        self._response_parser = ResponseParser()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–è¨­å®š
        self._performance_optimization = enable_performance_optimization
        self._concurrent_limit = max_concurrent

        # FastMCPã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–
        self.server = FastMCP(
            name="async-json-conversion",
            instructions="éåŒæœŸå°èª¬åŸ·ç­†æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  - å®Œå…¨éåŒæœŸå‡¦ç†ãƒ»ä¸¦åˆ—å®Ÿè¡Œãƒ»Message Busçµ±åˆæº–å‚™å¯¾å¿œ",
        )

        # ãƒ„ãƒ¼ãƒ«ç™»éŒ²
        self._register_async_tools()
        self._register_async_novel_tools()

    def _register_async_tools(self) -> None:
        """Register generic async tools (conversion, validation, file info).

        Purpose:
            Define and bind generic utility tools on the FastMCP server.

        Returns:
            None

        Side Effects:
            Registers decorated tool callables on the FastMCP instance.
        """

        @self.server.tool(
            name="convert_cli_to_json_async",
            description="CLIå®Ÿè¡Œçµæœã‚’éåŒæœŸã§JSONå½¢å¼ã«å¤‰æ› - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¸ˆã¿",
        )
        async def convert_cli_to_json_async(cli_result: dict[str, Any]) -> str:
            """Convert a CLI result dict to JSON asynchronously.

            Purpose:
                Perform JSON conversion off the event loop using a thread.

            Args:
                cli_result (dict[str, Any]): Raw CLI result object.

            Returns:
                str: Human-readable summary with formatted JSON section.

            Side Effects:
                Uses a thread pool; logs to the unified logger.
            """
            try:
                if not cli_result:
                    return "ã‚¨ãƒ©ãƒ¼: cli_resultãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"

                self.logger.debug("éåŒæœŸJSONå¤‰æ›é–‹å§‹")
                start_time = datetime.now()

                # éåŒæœŸJSONå¤‰æ›å®Ÿè¡Œï¼ˆåŒæœŸå¤‰æ›å™¨ã¯ to_thread ã§å®Ÿè¡Œï¼‰
                json_result = await asyncio.to_thread(self.converter.convert, cli_result)

                execution_time = (datetime.now() - start_time).total_seconds()
                self.logger.info("JSONå¤‰æ›å®Œäº†: %.3fs", execution_time)

                return f"éåŒæœŸå¤‰æ›æˆåŠŸ ({execution_time:.3f}s):\n{self._format_json_result(json_result)}"

            except Exception as e:
                self.logger.exception("éåŒæœŸCLIâ†’JSONå¤‰æ›ã‚¨ãƒ©ãƒ¼")
                return f"å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e!s}"

        @self.server.tool(
            name="validate_json_response_async",
            description="JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’éåŒæœŸã§æ¤œè¨¼"
        )
        async def validate_json_response_async(json_data: dict[str, Any]) -> str:
            """Validate a JSON response structure asynchronously.

            Purpose:
                Offload JSON schema/shape validation to a thread to avoid
                blocking the event loop.

            Args:
                json_data (dict[str, Any]): Target JSON payload to validate.

            Returns:
                str: Validation result summary string.

            Side Effects:
                None besides logging.
            """
            try:
                if not json_data:
                    return "ã‚¨ãƒ©ãƒ¼: json_dataãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"

                # éåŒæœŸãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆåŒæœŸå®Ÿè£…ã¯ to_thread ã§å®Ÿè¡Œï¼‰
                return await asyncio.to_thread(self._validate_json_sync, json_data)

            except Exception as e:
                return f"éåŒæœŸJSONæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e!s}"

        @self.server.tool(
            name="get_file_reference_info_async",
            description="ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§æƒ…å ±ã‚’éåŒæœŸã§å–å¾—"
        )
        async def get_file_reference_info_async(file_path: str) -> str:
            """Fetch file reference information asynchronously.

            Purpose:
                Retrieve and present file reference info for a given path.

            Args:
                file_path (str): Relative or absolute file path.

            Returns:
                str: Human-readable summary of file metadata.

            Side Effects:
                Reads file metadata and possibly content hashes in a thread.
            """
            try:
                if not file_path:
                    return "ã‚¨ãƒ©ãƒ¼: file_pathãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"

                full_path = self.output_dir / file_path

                # éåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œï¼ˆåŒæœŸå®Ÿè£…ã¯ to_thread ã§å®Ÿè¡Œï¼‰
                file_info = await asyncio.to_thread(self._get_file_info_sync, full_path, file_path)

                return f"éåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—å®Œäº†:\n{self._format_dict(file_info)}"

            except Exception as e:
                return f"éåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e!s}"

    def _register_async_novel_tools(self) -> None:
        """Register async novel-writing/check tools on FastMCP.

        Purpose:
            Define and bind novel-specific tools (write/check/concurrent).

        Returns:
            None

        Side Effects:
            Registers decorated tool callables on the FastMCP instance.
        """

        @self.server.tool(
            name="noveler_write_async",
            description="å°èª¬ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰éåŒæœŸåŸ·ç­† - ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–å¯¾å¿œ",
        )
        async def noveler_write_async(
            episode_number: int,
            dry_run: bool = False,
            five_stage: bool = True,
            project_root: str | None = None,
            use_concurrent: bool = False
        ) -> str:
            """Run asynchronous novel writing for a single episode.

            Purpose:
                Execute the `write` flow for one episode with optional
                concurrency and flags.

            Args:
                episode_number (int): Target episode number (>=1).
                dry_run (bool): If True, avoid persistent changes.
                five_stage (bool): Enable five-stage flow switch.
                project_root (str | None): Project root path.
                use_concurrent (bool): Toggle concurrent path.

            Returns:
                str: Human-readable execution summary.

            Side Effects:
                Spawns subprocesses via adapters; reads/writes project files.
            """
            try:
                if episode_number <= 0:
                    return f"ã‚¨ãƒ©ãƒ¼: episode_numberã¯1ä»¥ä¸Šã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆå—ä¿¡å€¤: {episode_number}ï¼‰"

                self.logger.info("éåŒæœŸåŸ·ç­†é–‹å§‹: episode=%d", episode_number)
                start_time = datetime.now()

                # éåŒæœŸå®Ÿè¡Œ
                result = await self._execute_novel_command_async(
                    f"write {episode_number}",
                    {"dry_run": dry_run, "five_stage": five_stage},
                    project_root,
                    use_concurrent=use_concurrent
                )

                execution_time = (datetime.now() - start_time).total_seconds()
                self.logger.info("éåŒæœŸåŸ·ç­†å®Œäº†: %.3fs", execution_time)

                return f"{result}\n\nâš¡ éåŒæœŸå®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’"

            except Exception as e:
                self.logger.exception("éåŒæœŸnoveler_writeã‚¨ãƒ©ãƒ¼")
                return f"éåŒæœŸå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e!s}"

        @self.server.tool(
            name="noveler_check_async",
            description="å°èª¬å“è³ªãƒã‚§ãƒƒã‚¯ - éåŒæœŸå‡¦ç†å¯¾å¿œ",
        )
        async def noveler_check_async(
            episode_number: int,
            auto_fix: bool = False,
            verbose: bool = False,
            project_root: str | None = None
        ) -> str:
            """Run asynchronous novel quality check for a single episode.

            Purpose:
                Execute the `check` flow for one episode with options.

            Args:
                episode_number (int): Target episode number (>=1).
                auto_fix (bool): Apply automatic fixes when possible.
                verbose (bool): Emit verbose diagnostic information.
                project_root (str | None): Project root path.

            Returns:
                str: Human-readable check result summary.

            Side Effects:
                Spawns subprocesses via adapters; reads/writes project files.
            """
            try:
                if episode_number <= 0:
                    return f"ã‚¨ãƒ©ãƒ¼: episode_numberã¯1ä»¥ä¸Šã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆå—ä¿¡å€¤: {episode_number}ï¼‰"

                result = await self._execute_novel_command_async(
                    f"check {episode_number}",
                    {"auto_fix": auto_fix, "verbose": verbose},
                    project_root
                )

                return f"{result}\n\nğŸ” éåŒæœŸå“è³ªãƒã‚§ãƒƒã‚¯å®Œäº†"

            except Exception as e:
                self.logger.exception("éåŒæœŸnoveler_checkã‚¨ãƒ©ãƒ¼")
                return f"éåŒæœŸãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e!s}"

        @self.server.tool(
            name="concurrent_episode_processing",
            description="è¤‡æ•°ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ä¸¦åˆ—å‡¦ç† - é«˜æ€§èƒ½å®Ÿè¡Œ",
        )
        async def concurrent_episode_processing(
            episodes: list[int],
            operation: str = "write",
            project_root: str | None = None,
            max_concurrent: int = 3
        ) -> str:
            """Process multiple episodes concurrently.

            Purpose:
                Execute `write`/`check` operations across episodes with a
                concurrency limit.

            Args:
                episodes (list[int]): List of episode numbers.
                operation (str): Operation name (e.g., "write" or "check").
                project_root (str | None): Project root path.
                max_concurrent (int): Max concurrency for execution.

            Returns:
                str: Aggregated multi-episode execution summary.

            Side Effects:
                Spawns multiple subprocesses; reads/writes project files.
            """
            try:
                if not episodes:
                    return "ã‚¨ãƒ©ãƒ¼: å‡¦ç†å¯¾è±¡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"

                if len(episodes) > 10:
                    return "ã‚¨ãƒ©ãƒ¼: ä¸€åº¦ã«å‡¦ç†å¯èƒ½ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã¯10å€‹ã¾ã§ã§ã™"

                self.logger.info("ä¸¦åˆ—å‡¦ç†é–‹å§‹: %d episodes, operation=%s", len(episodes), operation)
                start_time = datetime.now()

                # ä¸¦åˆ—å®Ÿè¡Œç”¨ã‚³ãƒãƒ³ãƒ‰æº–å‚™
                commands = []
                for episode in episodes:
                    working_dir = Path(project_root) if project_root else Path.cwd()
                    cmd_parts, _ = self._command_builder.build_novel_command(
                        f"{operation} {episode}",
                        {"concurrent": True},
                        project_root
                    )
                    env_vars = self._command_builder.build_environment_vars(project_root)

                    commands.append((cmd_parts, working_dir, env_vars, 300))

                # ä¸¦åˆ—å®Ÿè¡Œ
                results = await self._concurrent_executor.execute_concurrent(commands)

                execution_time = (datetime.now() - start_time).total_seconds()

                # çµæœé›†è¨ˆ
                success_count = sum(1 for r in results if r.return_code == 0)

                response_lines = [
                    f"ğŸš€ ä¸¦åˆ—å‡¦ç†å®Œäº†: {len(episodes)}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰",
                    f"âœ… æˆåŠŸ: {success_count}/{len(episodes)}",
                    f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’",
                    f"ğŸ“ˆ æ¨å®šå˜ä½“å®Ÿè¡Œæ™‚é–“: {execution_time * len(episodes):.1f}ç§’",
                    f"ğŸ¯ åŠ¹ç‡åŒ–å€ç‡: {len(episodes) / max(1, execution_time / 60):.1f}x",
                    ""
                ]

                for _i, (episode, result) in enumerate(zip(episodes, results, strict=False)):
                    status = "âœ…" if result.return_code == 0 else "âŒ"
                    response_lines.append(f"{status} Episode {episode}: {result.return_code}")

                return "\n".join(response_lines)

            except Exception as e:
                self.logger.exception("ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ©ãƒ¼")
                return f"ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e!s}"

        # 10æ®µéšå€‹åˆ¥å®Ÿè¡Œãƒ„ãƒ¼ãƒ«ã®éåŒæœŸç‰ˆ
        register_async_ten_stage_tools(self.server, self)

    async def _execute_novel_command_async(
        self,
        command: str,
        options: dict[str, Any],
        project_root: str | None = None,
        use_concurrent: bool = False
    ) -> str:
        """Execute novel-related CLI command asynchronously.

        Purpose:
            Common async execution path for `write`/`check` operations.

        Args:
            command (str): CLI-style command string (e.g., "write 1").
            options (dict[str, Any]): Command options passed to adapters.
            project_root (str | None): Project root path.
            use_concurrent (bool): Use concurrent executor when True.

        Returns:
            str: Human-readable formatted result (success or error).

        Side Effects:
            Spawns subprocesses; reads/writes JSON artefacts via converter.
        """
        try:
            # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ±ºå®š
            working_dir = Path(project_root).absolute() if project_root else Path.cwd()

            # ç’°å¢ƒå¤‰æ•°ã®æ§‹ç¯‰
            env_vars = self._command_builder.build_environment_vars(project_root)

            # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
            cmd_parts, _ = self._command_builder.build_novel_command(
                command, options, project_root
            )

            # éåŒæœŸå®Ÿè¡Œ
            if use_concurrent and self._performance_optimization:
                # ä¸¦åˆ—å®Ÿè¡Œå™¨ã‚’ä½¿ç”¨ï¼ˆå°†æ¥çš„ã«è¤‡æ•°æ“ä½œã®åŒæ™‚å®Ÿè¡Œç­‰ã«ä½¿ç”¨ï¼‰
                subprocess_result = await self._concurrent_executor.execute_single(
                    cmd_parts, working_dir, env_vars, timeout=300
                )
            else:
                # å˜ä¸€éåŒæœŸå®Ÿè¡Œ
                subprocess_result = await self._async_adapter.execute(
                    cmd_parts, working_dir, env_vars, timeout=300
                )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            parsed_result = self._response_parser.parse_novel_output(
                subprocess_result.stdout,
                subprocess_result.stderr,
                subprocess_result.return_code
            )

            # å®Ÿè¡Œçµæœãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
            cli_result = {
                "success": parsed_result["success"],
                "stdout": parsed_result["raw_output"]["stdout"],
                "stderr": parsed_result["raw_output"]["stderr"],
                "command": " ".join(cmd_parts),
                "returncode": parsed_result["return_code"],
                "working_dir": str(working_dir),
                "project_root": project_root,
                "execution_time": subprocess_result.execution_time,
                "async_execution": True
            }

            # æˆåŠŸ/å¤±æ•—ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            if cli_result.get("success", False):
                response_text = self._format_novel_success_result(cli_result)
            else:
                response_text = self._format_novel_error_result(cli_result)

            # éåŒæœŸJSONå¤‰æ›ã¨ä¿å­˜
            await self._convert_and_save_async(cli_result)

            return f"{response_text}\n\nğŸ“ éåŒæœŸJSONå¤‰æ›ãƒ»ä¿å­˜å®Œäº†ï¼ˆ95%ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ï¼‰"

        except asyncio.TimeoutError:
            return "å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: ã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†ï¼‰\n\nğŸ’¡ éåŒæœŸå®Ÿè¡Œã§ã‚‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸ"
        except Exception as e:
            self.logger.exception("éåŒæœŸå°èª¬ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
            return f"éåŒæœŸå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e!s}"

    async def _execute_ten_stage_step_async(
        self,
        stage: "TenStageExecutionStage",
        episode: int,
        session_id: str | None = None,
        project_root: str | None = None
    ) -> str:
        """Execute one step of the ten-stage flow asynchronously.

        Purpose:
            Run a specific `stage` for an `episode` in async mode.

        Args:
            stage (TenStageExecutionStage): Target stage enum/value.
            episode (int): Episode number.
            session_id (str | None): Optional session identifier.
            project_root (str | None): Project root path.

        Returns:
            str: Human-readable summary of execution or error.

        Side Effects:
            Spawns subprocesses; writes logs and JSON artefacts.
        """
        try:
            if not TEN_STAGE_AVAILABLE:
                return "ã‚¨ãƒ©ãƒ¼: TenStageSessionManager ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè§£æ±º
            working_dir = Path(project_root).absolute() if project_root else Path.cwd()

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
            session_manager = TenStageSessionManager(working_dir)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å‡¦ç†
            if session_id:
                context = session_manager.load_session(session_id)
                if not context:
                    return f"ã‚¨ãƒ©ãƒ¼: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {session_id}"
            elif stage.step_number == 1:
                context = session_manager.create_session(episode)
                session_id = context.session_id
            else:
                return f"ã‚¨ãƒ©ãƒ¼: STEP{stage.step_number}ã«ã¯session_idãŒå¿…è¦ã§ã™"

            # éåŒæœŸã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰ãƒ»å®Ÿè¡Œ
            cmd_parts = [
                str(self._command_builder._get_noveler_command_path()),
                "write", str(episode),
                "--ten-stage-step", str(stage.step_number),
                "--session-id", session_id
            ]

            env_vars = self._command_builder.build_environment_vars(project_root)

            # éåŒæœŸå®Ÿè¡Œï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ç‹¬ç«‹ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
            subprocess_result = await self._async_adapter.execute(
                cmd_parts, working_dir, env_vars, timeout=stage.timeout_seconds
            )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            parsed_result = self._response_parser.parse_novel_output(
                subprocess_result.stdout,
                subprocess_result.stderr,
                subprocess_result.return_code
            )

            # 10æ®µéšç‰¹æœ‰ã®çµæœãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
            cli_result = {
                "success": parsed_result["success"],
                "stdout": parsed_result["raw_output"]["stdout"],
                "stderr": parsed_result["raw_output"]["stderr"],
                "command": " ".join(cmd_parts),
                "returncode": parsed_result["return_code"],
                "stage": stage.display_name,
                "step": stage.step_number,
                "session_id": session_id,
                "next_step": stage.step_number + 1 if stage.get_next_stage() else None,
                "timeout_seconds": stage.timeout_seconds,
                "execution_time": subprocess_result.execution_time,
                "async_execution": True
            }

            # æˆåŠŸæ™‚ã®å‡¦ç†
            if cli_result["success"]:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°ï¼ˆéåŒæœŸåŒ–å¯èƒ½ï¼‰
                output_data = self._extract_step_output(subprocess_result.stdout)
                session_manager.update_stage_completion(session_id, stage, output_data, turns_used=1)

                # å®Ÿè¡Œãƒ­ã‚°ä¿å­˜
                timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
                try:
                    log_file = session_manager.save_execution_log(
                        episode_number=episode,
                        step_number=stage.step_number,
                        step_name=stage.display_name,
                        execution_data=cli_result,
                        timestamp=timestamp
                    )
                    self.logger.info("å®Ÿè¡Œãƒ­ã‚°ä¿å­˜å®Œäº†: %s", log_file.name)
                except Exception as log_error:
                    self.logger.warning("å®Ÿè¡Œãƒ­ã‚°ä¿å­˜ã«å¤±æ•—: %s", str(log_error))

                response_text = self._format_ten_stage_success_result(cli_result)
            else:
                response_text = self._format_ten_stage_error_result(cli_result)

            # éåŒæœŸJSONå¤‰æ›ãƒ»ä¿å­˜
            await self._convert_and_save_async(cli_result)

            return f"{response_text}\n\nğŸ“ éåŒæœŸJSONä¿å­˜å®Œäº†\nğŸ“Š å®Ÿè¡Œãƒ­ã‚°: 50_ç®¡ç†è³‡æ–™/åŸç¨¿åŸ·ç­†ãƒ­ã‚°/episode{episode:03d}_step{stage.step_number:02d}_{timestamp}.json"

        except asyncio.TimeoutError:
            return f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒƒãƒ—ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ{stage.timeout_seconds}ç§’ï¼‰\n\nğŸ’¡ éåŒæœŸSTEP{stage.step_number}ã§ã‚‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç™ºç”Ÿ"
        except Exception as e:
            self.logger.exception("éåŒæœŸ10æ®µéšã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: %s", stage.display_name)
            return f"éåŒæœŸå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e!s}"

    async def _convert_and_save_async(self, cli_result: dict[str, Any]) -> None:
        """Convert and persist JSON artefacts asynchronously.

        Purpose:
            Offload conversion/persist to a worker thread.

        Args:
            cli_result (dict[str, Any]): Parsed CLI run result.

        Returns:
            None

        Side Effects:
            Writes artefacts to the configured output directory.
        """
        try:
            await asyncio.to_thread(self.converter.convert, cli_result)
        except Exception as e:
            self.logger.warning("éåŒæœŸJSONå¤‰æ›ã‚¨ãƒ©ãƒ¼: %s", str(e))

    # åŒæœŸå‡¦ç†ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆéåŒæœŸå®Ÿè¡Œç”¨ï¼‰
    def _validate_json_sync(self, json_data: dict[str, Any]) -> str:
        """Validate JSON synchronously (for executor threads).

        Purpose:
            Perform pydantic-style validation in a blocking context.

        Args:
            json_data (dict[str, Any]): Target JSON to validate.

        Returns:
            str: Validation result summary string.

        Side Effects:
            None.
        """
        try:
            if json_data.get("success", False):
                model = StandardResponseModel(**json_data)
            else:
                model = ErrorResponseModel(**json_data)
            return f"éåŒæœŸJSONå½¢å¼æ¤œè¨¼æˆåŠŸ: {model.__class__.__name__}"
        except Exception as e:
            return f"JSONå½¢å¼æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e!s}"

    def _get_file_info_sync(self, full_path: Path, file_path: str) -> dict[str, Any]:
        """Return file metadata synchronously (for executor threads).

        Purpose:
            Gather basic file info for reporting.

        Args:
            full_path (Path): Absolute path to the file.
            file_path (str): Display path (relative or original input).

        Returns:
            dict[str, Any]: Metadata such as size, mtime, existence.

        Side Effects:
            Accesses filesystem stat information.
        """
        if not full_path.exists():
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}"}

        stat = full_path.stat()
        return {
            "path": file_path,
            "size_bytes": stat.st_size,
            "modified": datetime.fromtimestamp(stat.st_mtime, tz=timezone.utc).isoformat(),
            "exists": True,
        }

    def _extract_step_output(self, stdout: str) -> dict[str, Any]:
        """Extract step-output JSON block from stdout.

        Purpose:
            Try to parse a JSON block from CLI stdout; fallback to text.

        Args:
            stdout (str): Raw standard output text.

        Returns:
            dict[str, Any]: Parsed JSON or a fallback structure.

        Side Effects:
            None.
        """
        try:
            # JSON ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ç´¢
            json_pattern = r"\{(?:[^{}]|{[^{}]*})*\}"
            matches = re.findall(json_pattern, stdout)

            for match in matches:
                try:
                    return json.loads(match)
                except json.JSONDecodeError:
                    continue

            # JSON ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜
            return {
                "raw_output": stdout,
                "extraction_method": "text_fallback"
            }

        except Exception:
            return {"raw_output": stdout, "extraction_error": True}

    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç³»ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆåŒæœŸç‰ˆã‹ã‚‰å¼•ç”¨ï¼‰
    def _format_json_result(self, result: dict[str, Any]) -> str:
        """Format a JSON result summary as text.

        Purpose:
            Provide a concise, human-readable summary of a JSON result.

        Args:
            result (dict[str, Any]): JSON result payload.

        Returns:
            str: Formatted summary lines.

        Side Effects:
            None.
        """
        return format_json_result(result)

    def _format_dict(self, data: dict[str, Any]) -> str:
        """Format a dictionary into key:value lines.

        Purpose:
            Compact textual representation for simple metadata blocks.

        Args:
            data (dict[str, Any]): Input mapping.

        Returns:
            str: Joined lines of key:value.

        Side Effects:
            None.
        """
        return format_dict(data)

    def _format_novel_success_result(self, result: dict[str, Any]) -> str:
        """Format a success result for novel operations.

        Purpose:
            Provide a readable summary when a novel operation succeeds.

        Args:
            result (dict[str, Any]): CLI/parsed result payload.

        Returns:
            str: Textual summary.

        Side Effects:
            None.
        """
        lines = []
        lines.append(f"ğŸ‰ {result.get('message', 'éåŒæœŸå®Ÿè¡Œå®Œäº†')}")
        lines.append("=" * 40)

        # åŸºæœ¬æƒ…å ±
        if "episode_number" in result:
            lines.append(f"ğŸ“– è©±æ•°: ç¬¬{result['episode_number']}è©±")

        if "execution_time" in result:
            time_sec = result["execution_time"]
            lines.append(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {time_sec:.1f}ç§’ï¼ˆéåŒæœŸï¼‰")

        if result.get("async_execution"):
            lines.append("âš¡ éåŒæœŸå‡¦ç†å®Œäº†")

        return "\n".join(lines)

    def _format_novel_error_result(self, result: dict[str, Any]) -> str:
        """Format an error result for novel operations.

        Purpose:
            Provide a readable summary when a novel operation fails.

        Args:
            result (dict[str, Any]): CLI/parsed result payload.

        Returns:
            str: Textual summary.

        Side Effects:
            None.
        """
        lines = []
        lines.append(f"âŒ {result.get('error', 'éåŒæœŸå®Ÿè¡Œå¤±æ•—')}")
        lines.append("=" * 40)

        if "command" in result:
            lines.append(f"ğŸ“ ã‚³ãƒãƒ³ãƒ‰: {result['command']}")

        if result.get("async_execution"):
            lines.append("ğŸ”§ éåŒæœŸå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ")

        return "\n".join(lines)

    def _format_ten_stage_success_result(self, result: dict[str, Any]) -> str:
        """Format a success result for a ten-stage step.

        Purpose:
            Provide a readable summary when a stage succeeds.

        Args:
            result (dict[str, Any]): Execution result payload.

        Returns:
            str: Textual summary.

        Side Effects:
            None.
        """
        lines = []
        lines.append(f"ğŸ‰ {result.get('stage', 'ã‚¹ãƒ†ãƒƒãƒ—')} å®Œäº†! âš¡éåŒæœŸ")
        lines.append("=" * 50)

        lines.append(f"ğŸ“– ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: ç¬¬{result.get('episode', 'N/A')}è©±")
        lines.append(f"ğŸ”¢ ã‚¹ãƒ†ãƒƒãƒ—: {result.get('step', 'N/A')}/10")
        lines.append(f"ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {result.get('session_id', 'N/A')[:8]}...")

        if result.get("execution_time"):
            lines.append(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.3f}ç§’ï¼ˆéåŒæœŸï¼‰")

        if result.get("next_step"):
            lines.append(f"â–¶ï¸ æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: STEP{result['next_step']}")
            lines.append(f"ğŸ’¡ æ¬¡å®Ÿè¡Œ: write_step_async(step={result['next_step']}, episode={result.get('episode', 1)}, session_id=\"{result.get('session_id', '')}\")")
        else:
            lines.append("ğŸŠ å…¨ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†!")

        return "\n".join(lines)

    def _format_ten_stage_error_result(self, result: dict[str, Any]) -> str:
        """Format an error result for a ten-stage step.

        Purpose:
            Provide a readable summary when a stage fails.

        Args:
            result (dict[str, Any]): Execution result payload.

        Returns:
            str: Textual summary.

        Side Effects:
            None.
        """
        lines = []
        lines.append(f"âŒ {result.get('stage', 'ã‚¹ãƒ†ãƒƒãƒ—')} å¤±æ•— âš¡éåŒæœŸ")
        lines.append("=" * 50)

        lines.append(f"ğŸ”¢ ã‚¹ãƒ†ãƒƒãƒ—: {result.get('step', 'N/A')}/10")
        lines.append(f"ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {result.get('session_id', 'N/A')[:8]}...")

        if result.get("stderr"):
            lines.append(f"ğŸ”´ ã‚¨ãƒ©ãƒ¼å†…å®¹: {result['stderr'][:200]}...")

        lines.append("\nğŸ”§ å¾©æ—§ææ¡ˆ:")
        lines.append(f"  â€¢ write_step_async(step={result.get('step', 'X')}, ...)ã§å†å®Ÿè¡Œ")
        lines.append("  â€¢ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç¢ºèª")

        return "\n".join(lines)

    async def run(self) -> None:
        """Run the FastMCP stdio server asynchronously.

        Purpose:
            Start the stdio-based MCP event loop for this server instance.

        Returns:
            None

        Side Effects:
            Opens stdio streams and blocks the event loop; downstream tool
            invocations may spawn subprocesses and perform file I/O.

        Raises:
            RuntimeError: If the MCP library is not available.
        """
        if not MCP_AVAILABLE:
            msg = "MCPãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            raise RuntimeError(msg)

        self.logger.info("éåŒæœŸFastMCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œé–‹å§‹ (stdio)")
        await self.server.run_stdio_async()


async def main() -> None:
    """CLI entrypoint for the async MCP server.

    Purpose:
        Provide a convenient `python -m` entry for running the server.

    Returns:
        None

    Side Effects:
        Prints to the console on missing dependencies and runs the server.
    """
    if not MCP_AVAILABLE:
        console = get_console()
        console.print("ã‚¨ãƒ©ãƒ¼: MCPãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        console.print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        console.print("pip install mcp")
        return 1

    # éåŒæœŸã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æœ‰åŠ¹ï¼‰
    server = AsyncJSONConversionServer(
        max_concurrent=3,
        enable_performance_optimization=True
    )
    await server.run()
    return 0


if __name__ == "__main__":
    asyncio.run(main())
