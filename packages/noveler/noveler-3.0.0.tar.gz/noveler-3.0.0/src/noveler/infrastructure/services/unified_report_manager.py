"""Infrastructure.services.unified_report_manager
Where: Infrastructure service managing unified report generation.
What: Collects data from multiple sources and produces consolidated reports.
Why: Provides stakeholders with cohesive reporting across systems.
"""

from noveler.presentation.shared.shared_utilities import console

"çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ \n\nä»•æ§˜æ›¸: SPEC-UNIFIED-REPORT-001\npre-commitã¨CI/CDãƒ¬ãƒãƒ¼ãƒˆã®çµ±åˆç®¡ç†\n\nè¨­è¨ˆåŸå‰‡:\n    - ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã®æ¨™æº–åŒ–\n- å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã®çµ±ä¸€\n- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†\n"
import hashlib
import json
import subprocess
from dataclasses import asdict, dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Any

from noveler.infrastructure.logging.unified_logger import get_logger

try:
    from noveler.infrastructure.services.unified_file_storage_service import FileContentType, UnifiedFileStorageService
except ImportError:
    # é–‹ç™ºæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    UnifiedFileStorageService = None
    FileContentType = None


class ViolationSeverity(Enum):
    """é•åé‡è¦åº¦ï¼ˆå¾ªç’°ä¾å­˜è§£æ¶ˆï¼‰"""

    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"


class ValidationLevel(Enum):
    """æ¤œè¨¼ãƒ¬ãƒ™ãƒ«ï¼ˆå¾ªç’°ä¾å­˜è§£æ¶ˆï¼‰"""

    STRICT = "STRICT"
    MODERATE = "MODERATE"
    BASIC = "BASIC"


class ImpactLevel(Enum):
    """å½±éŸ¿ãƒ¬ãƒ™ãƒ«ï¼ˆå¾ªç’°ä¾å­˜è§£æ¶ˆï¼‰"""

    MINIMAL = "minimal"
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class DDDViolation:
    """DDDé•åæƒ…å ±ï¼ˆå¾ªç’°ä¾å­˜è§£æ¶ˆï¼‰"""

    file_path: str
    line_number: int
    violation_type: str
    severity: ViolationSeverity
    description: str
    recommendation: str
    rule_id: str
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass
class ComplianceReport:
    """DDDæº–æ‹ æ€§ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå¾ªç’°ä¾å­˜è§£æ¶ˆï¼‰"""

    timestamp: datetime
    project_root: str
    validation_level: ValidationLevel
    total_files_analyzed: int
    violations: list[DDDViolation]
    compliance_percentage: float
    layer_compliance: dict[str, float]
    summary: dict[str, Any]


@dataclass
class ChangeImpactAnalysis:
    """å¤‰æ›´å½±éŸ¿åˆ†æï¼ˆå¾ªç’°ä¾å­˜è§£æ¶ˆï¼‰"""

    changed_files: list[str]
    overall_impact_level: ImpactLevel
    affected_layers: set[str]


@dataclass
class UnifiedQualityMetrics:
    """çµ±åˆå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    timestamp: datetime
    execution_context: str
    project_root: str
    ddd_compliance_percentage: float
    ddd_violations_total: int
    ddd_violations_by_severity: dict[str, int]
    changed_files_count: int
    impact_level: str
    affected_layers: list[str]
    analysis_duration_seconds: float
    cache_hit_rate: float
    files_analyzed: int
    compliance_trend: float | None
    violation_trend: int | None
    git_commit_hash: str | None
    git_branch: str
    execution_id: str


@dataclass
class QualityDashboardData:
    """å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿"""

    current_metrics: UnifiedQualityMetrics
    historical_trends: list[UnifiedQualityMetrics]
    compliance_history: list[dict[str, Any]]
    violation_trends: list[dict[str, Any]]
    performance_metrics: list[dict[str, Any]]
    quality_alerts: list[str]
    improvement_recommendations: list[str]


class UnifiedReportManager:
    """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

    è²¬å‹™:
        - pre-commitã¨CI/CDãƒ¬ãƒãƒ¼ãƒˆã®çµ±åˆ
        - å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¨™æº–åŒ–
        - ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        - å±¥æ­´ç®¡ç†ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    """

    def __init__(self, project_root: Path, reports_dir: Path | None = None) -> None:
        """åˆæœŸåŒ–

        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
            reports_dir: ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.project_root = project_root
        self.reports_dir = reports_dir or project_root / "reports"
        self.reports_dir.mkdir(exist_ok=True)
        self.logger = get_logger(__name__)
        self.metrics_history_file = self.reports_dir / "quality_metrics_history.jsonl"
        self.dashboard_data_file = self.reports_dir / "dashboard_data.json"
        self.summary_report_file = self.reports_dir / "quality_summary.json"

    def create_unified_metrics(
        self,
        compliance_report: ComplianceReport,
        change_analysis: ChangeImpactAnalysis | None = None,
        execution_context: str = "manual",
        analysis_duration: float = 0.0,
        cache_hit_rate: float = 0.0,
    ) -> UnifiedQualityMetrics:
        """çµ±åˆå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”Ÿæˆ

        Args:
            compliance_report: DDDæº–æ‹ æ€§ãƒ¬ãƒãƒ¼ãƒˆ
            change_analysis: å¤‰æ›´å½±éŸ¿åˆ†æçµæœ
            execution_context: å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            analysis_duration: åˆ†ææ‰€è¦æ™‚é–“
            cache_hit_rate: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡

        Returns:
            çµ±åˆå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        violations_by_severity = {}
        for violation in compliance_report.violations:
            severity = violation.severity.value
            violations_by_severity[severity] = violations_by_severity.get(severity, 0) + 1
        changed_files_count = len(change_analysis.changed_files) if change_analysis else 0
        impact_level = change_analysis.overall_impact_level.value if change_analysis else "minimal"
        affected_layers = list(change_analysis.affected_layers) if change_analysis else []
        git_info = self._get_git_info()
        execution_id = self._generate_execution_id()
        (compliance_trend, violation_trend) = self._calculate_trends(compliance_report)
        return UnifiedQualityMetrics(
            timestamp=datetime.now(timezone.utc),
            execution_context=execution_context,
            project_root=str(self.project_root),
            ddd_compliance_percentage=compliance_report.compliance_percentage,
            ddd_violations_total=len(compliance_report.violations),
            ddd_violations_by_severity=violations_by_severity,
            changed_files_count=changed_files_count,
            impact_level=impact_level,
            affected_layers=affected_layers,
            analysis_duration_seconds=analysis_duration,
            cache_hit_rate=cache_hit_rate,
            files_analyzed=compliance_report.total_files_analyzed,
            compliance_trend=compliance_trend,
            violation_trend=violation_trend,
            git_commit_hash=git_info.get("commit_hash"),
            git_branch=git_info.get("branch", "unknown"),
            execution_id=execution_id,
        )

    def save_metrics(self, metrics: UnifiedQualityMetrics) -> None:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜

        Args:
            metrics: çµ±åˆå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        try:
            with open(self.metrics_history_file, "a", encoding="utf-8") as f:
                metrics_dict = asdict(metrics)
                metrics_dict["timestamp"] = metrics.timestamp.isoformat()
                f.write(json.dumps(metrics_dict, ensure_ascii=False) + "\n")
            console.print(f"å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜å®Œäº†: {metrics.execution_id}")
        except (OSError, json.JSONEncodeError) as e:
            self.logger.exception("ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: %s", e)

    def generate_dashboard_data(
        self, current_metrics: UnifiedQualityMetrics, history_days: int = 30
    ) -> QualityDashboardData:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

        Args:
            current_metrics: ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            history_days: å±¥æ­´å–å¾—æœŸé–“ï¼ˆæ—¥æ•°ï¼‰

        Returns:
            å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        """
        historical_metrics = self._load_historical_metrics(history_days)
        compliance_history = self._generate_compliance_history(historical_metrics)
        violation_trends = self._generate_violation_trends(historical_metrics)
        performance_metrics = self._generate_performance_metrics(historical_metrics)
        quality_alerts = self._generate_quality_alerts(current_metrics, historical_metrics)
        improvement_recommendations = self._generate_improvement_recommendations(current_metrics, historical_metrics)
        return QualityDashboardData(
            current_metrics=current_metrics,
            historical_trends=historical_metrics[-10:],
            compliance_history=compliance_history,
            violation_trends=violation_trends,
            performance_metrics=performance_metrics,
            quality_alerts=quality_alerts,
            improvement_recommendations=improvement_recommendations,
        )

    def export_dashboard_data(self, dashboard_data: QualityDashboardData) -> None:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            dashboard_data: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        """
        try:
            dashboard_dict = asdict(dashboard_data)
            dashboard_dict["current_metrics"]["timestamp"] = dashboard_data.current_metrics.timestamp.isoformat()
            for trend in dashboard_dict["historical_trends"]:
                if isinstance(trend["timestamp"], datetime):
                    trend["timestamp"] = trend["timestamp"].isoformat()
            with open(self.dashboard_data_file, "w", encoding="utf-8") as f:
                json.dump(dashboard_dict, f, ensure_ascii=False, indent=2)
            console.print(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {self.dashboard_data_file}")
        except (OSError, json.JSONEncodeError) as e:
            self.logger.exception("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: %s", e)

    def generate_summary_report(self, metrics: UnifiedQualityMetrics) -> dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

        Args:
            metrics: çµ±åˆå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹

        Returns:
            ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
        """
        return {
            "execution_info": {
                "timestamp": metrics.timestamp.isoformat(),
                "context": metrics.execution_context,
                "execution_id": metrics.execution_id,
                "git_branch": metrics.git_branch,
                "git_commit": metrics.git_commit_hash[:8] if metrics.git_commit_hash else None,
            },
            "quality_overview": {
                "compliance_percentage": round(metrics.ddd_compliance_percentage, 1),
                "total_violations": metrics.ddd_violations_total,
                "quality_grade": self._calculate_quality_grade(metrics),
                "improvement_status": self._determine_improvement_status(metrics),
            },
            "performance_stats": {
                "analysis_duration": round(metrics.analysis_duration_seconds, 2),
                "files_analyzed": metrics.files_analyzed,
                "cache_hit_rate": round(metrics.cache_hit_rate * 100, 1),
                "efficiency_score": self._calculate_efficiency_score(metrics),
            },
            "change_impact": {
                "changed_files": metrics.changed_files_count,
                "impact_level": metrics.impact_level,
                "affected_layers": metrics.affected_layers,
            },
            "trends": {"compliance_trend": metrics.compliance_trend, "violation_trend": metrics.violation_trend},
        }

    def export_summary_report(self, summary: dict[str, Any]) -> None:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            summary: ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
        """
        try:
            # UnifiedFileStorageServiceã‚’ä½¿ç”¨ã—ã¦ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
            storage_service = UnifiedFileStorageService()
            storage_service.save(
                file_path=self.summary_report_file,
                content=summary,
                content_type=FileContentType.API_RESPONSE,
                metadata={
                    "report_type": "unified_quality_summary",
                    "execution_id": summary["execution_info"]["execution_id"],
                    "compliance_percentage": summary["quality_overview"]["compliance_percentage"],
                },
            )
            console.print(f"ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {self.summary_report_file}")
        except (OSError, json.JSONEncodeError) as e:
            self.logger.exception("ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: %s", e)

    def _get_git_info(self) -> dict[str, str]:
        """Gitæƒ…å ±å–å¾—"""
        git_info = {}
        try:
            result = subprocess.run(
                ["git", "rev-parse", "HEAD"], check=False, capture_output=True, text=True, cwd=self.project_root
            )
            if result.returncode == 0:
                git_info["commit_hash"] = result.stdout.strip()
            result = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                check=False,
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )
            if result.returncode == 0:
                git_info["branch"] = result.stdout.strip()
        except subprocess.SubprocessError:
            pass
        return git_info

    def _generate_execution_id(self) -> str:
        """å®Ÿè¡ŒIDç”Ÿæˆ"""
        timestamp = datetime.now(timezone.utc).isoformat()
        hash_input = f"{timestamp}{self.project_root}".encode()
        return hashlib.sha256(hash_input).hexdigest()[:16]

    def _calculate_trends(self, current_report: ComplianceReport) -> tuple[float | None, int | None]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        try:
            previous_metrics = self._load_historical_metrics(days=1)
            if not previous_metrics:
                return (None, None)
            last_metrics = previous_metrics[-1]
            compliance_trend = current_report.compliance_percentage - last_metrics.ddd_compliance_percentage
            violation_trend = len(current_report.violations) - last_metrics.ddd_violations_total
            return (compliance_trend, violation_trend)
        except (IndexError, KeyError):
            return (None, None)

    def _load_historical_metrics(self, days: int) -> list[UnifiedQualityMetrics]:
        """å±¥æ­´ãƒ¡ãƒˆãƒªã‚¯ã‚¹èª­ã¿è¾¼ã¿"""
        if not self.metrics_history_file.exists():
            return []
        cutoff_date = datetime.now(timezone.utc).timestamp() - days * 24 * 60 * 60
        metrics = []
        try:
            with open(self.metrics_history_file, encoding="utf-8") as f:
                for line in f:
                    data = json.loads(line.strip())
                    timestamp = datetime.fromisoformat(data["timestamp"])
                    if timestamp.timestamp() >= cutoff_date:
                        data["timestamp"] = timestamp
                        metrics.append(UnifiedQualityMetrics(**data))
        except (OSError, json.JSONDecodeError, ValueError) as e:
            console.print(f"å±¥æ­´ãƒ¡ãƒˆãƒªã‚¯ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return metrics

    def _generate_compliance_history(self, metrics: list[UnifiedQualityMetrics]) -> list[dict[str, Any]]:
        """æº–æ‹ ç‡å±¥æ­´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        return [
            {
                "timestamp": m.timestamp.isoformat(),
                "compliance_percentage": m.ddd_compliance_percentage,
                "context": m.execution_context,
            }
            for m in metrics
        ]

    def _generate_violation_trends(self, metrics: list[UnifiedQualityMetrics]) -> list[dict[str, Any]]:
        """é•åãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        return [
            {
                "timestamp": m.timestamp.isoformat(),
                "total_violations": m.ddd_violations_total,
                "severity_breakdown": m.ddd_violations_by_severity,
            }
            for m in metrics
        ]

    def _generate_performance_metrics(self, metrics: list[UnifiedQualityMetrics]) -> list[dict[str, Any]]:
        """æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        return [
            {
                "timestamp": m.timestamp.isoformat(),
                "analysis_duration": m.analysis_duration_seconds,
                "cache_hit_rate": m.cache_hit_rate,
                "files_analyzed": m.files_analyzed,
            }
            for m in metrics
        ]

    def _generate_quality_alerts(
        self, current: UnifiedQualityMetrics, historical: list[UnifiedQualityMetrics]
    ) -> list[str]:
        """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alerts = []
        if current.ddd_compliance_percentage < 70.0:
            alerts.append("ğŸš¨ DDDæº–æ‹ ç‡ãŒ70%ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™")
        if current.ddd_violations_total > 100:
            alerts.append("âš ï¸ é•åæ•°ãŒ100ä»¶ã‚’è¶…éã—ã¦ã„ã¾ã™")
        critical_violations = current.ddd_violations_by_severity.get("CRITICAL", 0)
        if critical_violations > 0:
            alerts.append(f"ğŸ”´ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«é•åãŒ{critical_violations}ä»¶æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™")
        if current.compliance_trend and current.compliance_trend < -5.0:
            alerts.append("ğŸ“‰ æº–æ‹ ç‡ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¦ã„ã¾ã™")
        return alerts

    def _generate_improvement_recommendations(
        self, current: UnifiedQualityMetrics, historical: list[UnifiedQualityMetrics]
    ) -> list[str]:
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        if current.cache_hit_rate < 0.3:
            recommendations.append("ğŸ’¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡å‘ä¸Šã«ã‚ˆã‚Šåˆ†æé«˜é€ŸåŒ–ãŒå¯èƒ½ã§ã™")
        if current.ddd_violations_by_severity.get("HIGH", 0) > 10:
            recommendations.append("ğŸ¯ é«˜é‡è¦åº¦é•åã®å„ªå…ˆçš„ãªä¿®æ­£ã‚’æ¨å¥¨ã—ã¾ã™")
        if len(current.affected_layers) > 3:
            recommendations.append("ğŸ—ï¸ è¤‡æ•°å±¤ã«ã¾ãŸãŒã‚‹å¤‰æ›´ã¯æ®µéšçš„ãªä¿®æ­£ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        return recommendations

    def _calculate_quality_grade(self, metrics: UnifiedQualityMetrics) -> str:
        """å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰ç®—å‡º"""
        compliance = metrics.ddd_compliance_percentage
        if compliance >= 95:
            return "A+"
        if compliance >= 90:
            return "A"
        if compliance >= 80:
            return "B"
        if compliance >= 70:
            return "C"
        return "D"

    def _determine_improvement_status(self, metrics: UnifiedQualityMetrics) -> str:
        """æ”¹å–„çŠ¶æ³åˆ¤å®š"""
        if metrics.compliance_trend is None:
            return "åˆå›åˆ†æ"
        if metrics.compliance_trend > 2.0:
            return "å¤§å¹…æ”¹å–„"
        if metrics.compliance_trend > 0:
            return "æ”¹å–„ä¸­"
        if metrics.compliance_trend == 0:
            return "å¤‰åŒ–ãªã—"
        if metrics.compliance_trend > -2.0:
            return "è»½å¾®ãªä½ä¸‹"
        return "è¦æ³¨æ„"

    def _calculate_efficiency_score(self, metrics: UnifiedQualityMetrics) -> int:
        """åŠ¹ç‡ã‚¹ã‚³ã‚¢ç®—å‡º"""
        time_score = max(0, 100 - metrics.analysis_duration_seconds * 10)
        cache_score = metrics.cache_hit_rate * 100
        file_efficiency = min(100, metrics.files_analyzed / 10)
        return int((time_score + cache_score + file_efficiency) / 3)
