#!/usr/bin/env python3

"""Domain.ai_integration.value_objects.genre_benchmark_result
Where: Domain value object summarising genre benchmark comparisons.
What: Holds per-genre scoring details and benchmark interpretations.
Why: Supports reporting on how closely works align with target genres.
"""

from __future__ import annotations

"""ã‚¸ãƒ£ãƒ³ãƒ«æ¯”è¼ƒçµæœå€¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

æ›¸ç±åŒ–ä½œå“ã¨ã®æ¯”è¼ƒåˆ†æçµæœã‚’è¡¨ç¾
"""


from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from noveler.domain.ai_integration.value_objects.genre_configuration import GenreConfiguration


class ComparisonStatus(Enum):
    """æ¯”è¼ƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""

    EXCELLENT = "âœ…"  # å„ªç§€
    GOOD = "ğŸŸ¢"  # è‰¯å¥½
    WARNING = "âš ï¸"  # è­¦å‘Š
    CRITICAL = "âŒ"  # è‡´å‘½çš„


@dataclass(frozen=True)
class StructuralComparison:
    """æ§‹é€ çš„æ¯”è¼ƒ"""

    aspect: str  # æ¯”è¼ƒè¦ç´ 
    user_value: str  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œå“ã®å€¤
    benchmark_value: str  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å€¤
    conformity_rate: float  # é©åˆç‡(0.0-1.0)
    status: ComparisonStatus

    def __post_init__(self) -> None:
        """æ¯”è¼ƒã®å¦¥å½“æ€§æ¤œè¨¼"""
        if not self.aspect:
            msg = "æ¯”è¼ƒè¦ç´ ã¯å¿…é ˆã§ã™"
            raise ValueError(msg)

        if not 0.0 <= self.conformity_rate <= 1.0:
            msg = f"é©åˆç‡ã¯0.0ä»¥ä¸Š1.0ä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {self.conformity_rate}"
            raise ValueError(msg)

    def is_problematic(self) -> bool:
        """å•é¡ŒãŒã‚ã‚‹ã‹"""
        return self.status in [ComparisonStatus.WARNING, ComparisonStatus.CRITICAL]

    def get_severity_score(self) -> int:
        """é‡è¦åº¦ã‚¹ã‚³ã‚¢(é«˜ã„ã»ã©é‡è¦)"""
        severity_map = {
            ComparisonStatus.CRITICAL: 4,
            ComparisonStatus.WARNING: 3,
            ComparisonStatus.GOOD: 2,
            ComparisonStatus.EXCELLENT: 1,
        }
        return severity_map[self.status]


@dataclass(frozen=True)
class ImprovementSuggestion:
    """æ”¹å–„ææ¡ˆ"""

    priority: str  # å„ªå…ˆåº¦
    description: str  # èª¬æ˜
    reference_work: str | None  # å‚è€ƒä½œå“
    expected_impact: str  # æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

    def __post_init__(self) -> None:
        """ææ¡ˆã®å¦¥å½“æ€§æ¤œè¨¼"""
        if not self.description:
            msg = "èª¬æ˜ã¯å¿…é ˆã§ã™"
            raise ValueError(msg)

        valid_priorities = ["é«˜", "ä¸­", "ä½"]
        if self.priority not in valid_priorities:
            msg = f"å„ªå…ˆåº¦ã¯{valid_priorities}ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {self.priority}"
            raise ValueError(msg)

    def is_high_priority(self) -> bool:
        """é«˜å„ªå…ˆåº¦ã‹"""
        return self.priority == "é«˜"


@dataclass(frozen=True)
class PublicationReadiness:
    """æ›¸ç±åŒ–æº–å‚™åº¦"""

    readiness_score: float  # æº–å‚™åº¦ã‚¹ã‚³ã‚¢(0.0-1.0)
    success_probability: float  # æˆåŠŸç¢ºç‡(0.0-1.0)
    critical_gaps: list[str]  # è‡´å‘½çš„ãªã‚®ãƒ£ãƒƒãƒ—
    competitive_advantages: list[str]  # ç«¶åˆå„ªä½æ€§

    def __post_init__(self) -> None:
        """æº–å‚™åº¦ã®å¦¥å½“æ€§æ¤œè¨¼"""
        if not 0.0 <= self.readiness_score <= 1.0:
            msg = f"æº–å‚™åº¦ã‚¹ã‚³ã‚¢ã¯0.0ä»¥ä¸Š1.0ä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {self.readiness_score}"
            raise ValueError(msg)

        if not 0.0 <= self.success_probability <= 1.0:
            msg = f"æˆåŠŸç¢ºç‡ã¯0.0ä»¥ä¸Š1.0ä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {self.success_probability}"
            raise ValueError(msg)

        # ãƒªã‚¹ãƒˆã‚’ã‚¿ãƒ—ãƒ«ã«å¤‰æ›ã—ã¦ä¸å¤‰æ€§ã‚’ä¿è¨¼
        object.__setattr__(self, "critical_gaps", tuple(self.critical_gaps))
        object.__setattr__(self, "competitive_advantages", tuple(self.competitive_advantages))

    def get_readiness_grade(self) -> str:
        """æº–å‚™åº¦ã‚°ãƒ¬ãƒ¼ãƒ‰"""
        if self.readiness_score >= 0.8:
            return "A"
        if self.readiness_score >= 0.6:
            return "B"
        if self.readiness_score >= 0.4:
            return "C"
        return "D"

    def is_publication_ready(self) -> bool:
        """æ›¸ç±åŒ–æº–å‚™å®Œäº†ã‹"""
        return self.readiness_score >= 0.7 and len(self.critical_gaps) == 0

    def get_next_milestone(self) -> str | None:
        """æ¬¡ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³"""
        if self.critical_gaps:
            return f"è‡´å‘½çš„ã‚®ãƒ£ãƒƒãƒ—ã®è§£æ¶ˆ: {self.critical_gaps[0]}"
        if self.readiness_score < 0.8:
            return "æº–å‚™åº¦80%é”æˆã«å‘ã‘ãŸæ”¹å–„"
        return None


@dataclass(frozen=True)
class GenreBenchmarkResult:
    """ã‚¸ãƒ£ãƒ³ãƒ«æ¯”è¼ƒçµæœ

    æ›¸ç±åŒ–ä½œå“ã¨ã®æ¯”è¼ƒåˆ†æçµæœã®å…¨ä½“
    """

    genre_config: GenreConfiguration
    comparison_target_count: int  # æ¯”è¼ƒå¯¾è±¡ä½œå“æ•°
    structural_comparisons: list[StructuralComparison]
    improvement_suggestions: list[ImprovementSuggestion]
    publication_readiness: PublicationReadiness
    reference_works: list[str]  # å‚è€ƒä½œå“ãƒªã‚¹ãƒˆ

    def __post_init__(self) -> None:
        """çµæœã®å¦¥å½“æ€§æ¤œè¨¼"""
        if self.comparison_target_count < 1:
            msg = f"æ¯”è¼ƒå¯¾è±¡ä½œå“æ•°ã¯1ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {self.comparison_target_count}"
            raise ValueError(msg)

        if not self.structural_comparisons:
            msg = "æ§‹é€ çš„æ¯”è¼ƒã¯1ã¤ä»¥ä¸Šå¿…è¦ã§ã™"
            raise ValueError(msg)

        # ãƒªã‚¹ãƒˆã‚’ã‚¿ãƒ—ãƒ«ã«å¤‰æ›ã—ã¦ä¸å¤‰æ€§ã‚’ä¿è¨¼
        object.__setattr__(self, "structural_comparisons", tuple(self.structural_comparisons))
        object.__setattr__(self, "improvement_suggestions", tuple(self.improvement_suggestions))
        object.__setattr__(self, "reference_works", tuple(self.reference_works))

    def get_critical_issues(self) -> list[StructuralComparison]:
        """è‡´å‘½çš„ãªå•é¡Œã‚’å–å¾—"""
        return [comp for comp in self.structural_comparisons if comp.status == ComparisonStatus.CRITICAL]

    def get_warning_issues(self) -> list[StructuralComparison]:
        """è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®å•é¡Œã‚’å–å¾—"""
        return [comp for comp in self.structural_comparisons if comp.status == ComparisonStatus.WARNING]

    def get_high_priority_suggestions(self) -> list[ImprovementSuggestion]:
        """é«˜å„ªå…ˆåº¦ã®æ”¹å–„ææ¡ˆã‚’å–å¾—"""
        return [suggestion for suggestion in self.improvement_suggestions if suggestion.is_high_priority()]

    def get_overall_conformity(self) -> float:
        """å…¨ä½“é©åˆç‡"""
        if not self.structural_comparisons:
            return 0.0

        total_conformity = sum(comp.conformity_rate for comp in self.structural_comparisons)
        return total_conformity / len(self.structural_comparisons)

    def get_market_position(self) -> str:
        """å¸‚å ´ãƒã‚¸ã‚·ãƒ§ãƒ³"""
        conformity = self.get_overall_conformity()
        critical_count = len(self.get_critical_issues())

        if conformity >= 0.8 and critical_count == 0:
            return "å¸‚å ´é©åˆåº¦ãŒé«˜ãã€æ›¸ç±åŒ–ã®å¯èƒ½æ€§ãŒé«˜ã„"
        if conformity >= 0.6 and critical_count <= 1:
            return "å¸‚å ´é©åˆåº¦ã¯è‰¯å¥½ã ãŒã€æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹"
        if conformity >= 0.4:
            return "å¸‚å ´é©åˆåº¦ã¯æ¨™æº–çš„ã€é‡è¦ãªæ”¹å–„ãŒå¿…è¦"
        return "å¸‚å ´é©åˆåº¦ãŒä½ãã€å¤§å¹…ãªè¦‹ç›´ã—ãŒå¿…è¦"

    def get_summary_report(self) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ"""
        lines = [
            f"ğŸ¯ ã‚¸ãƒ£ãƒ³ãƒ«: {self.genre_config.get_genre_combination()}",
            f"ğŸ“Š æ¯”è¼ƒå¯¾è±¡: {self.comparison_target_count}ä½œå“",
            f"ğŸ“ˆ å…¨ä½“é©åˆç‡: {self.get_overall_conformity():.1%}",
            f"ğŸ“ æ›¸ç±åŒ–æº–å‚™åº¦: {self.publication_readiness.get_readiness_grade()}ç´š",
            f"ğŸ’¡ å¸‚å ´ãƒã‚¸ã‚·ãƒ§ãƒ³: {self.get_market_position()}",
        ]

        critical_issues = self.get_critical_issues()
        if critical_issues:
            lines.append(f"âš ï¸ è‡´å‘½çš„å•é¡Œ: {len(critical_issues)}ä»¶")

        high_priority = self.get_high_priority_suggestions()
        if high_priority:
            lines.append(f"ğŸš¨ é«˜å„ªå…ˆåº¦æ”¹å–„: {len(high_priority)}é …ç›®")

        return "\n".join(lines)
