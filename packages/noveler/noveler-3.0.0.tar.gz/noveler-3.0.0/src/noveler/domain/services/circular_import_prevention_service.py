#!/usr/bin/env python3

"""Domain.services.circular_import_prevention_service
Where: Domain service module providing reusable business logic.
What: Houses service routines and helpers implemented in this module.
Why: Makes this service behaviour accessible to application workflows.
"""

from __future__ import annotations

"""å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆäºˆé˜²ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹

ä»•æ§˜æ›¸: SPEC-CIRCULAR-IMPORT-DETECTION-001
"""


from dataclasses import dataclass
from pathlib import Path
from typing import Protocol

from noveler.domain.entities.circular_import_detector import CircularDetectionResult, CircularImportDetector
from noveler.domain.value_objects.import_statement import ImportStatement

# B20æº–æ‹ : loggerä¾å­˜å‰Šé™¤ï¼ˆç´”ç²‹é–¢æ•°åŒ–ï¼‰


@dataclass
class ASTAnalysisResult:
    """ASTè§£æçµæœ"""
    imports: list[ImportStatement]
    functions: list[str]
    classes: list[str]


class ASTAnalysisPort(Protocol):
    """ASTè§£æã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ãƒ—ãƒ­ãƒˆã‚³ãƒ«"""

    def analyze_file(self, file_path: Path) -> ASTAnalysisResult:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ"""
        ...

    def analyze_project(self, include_patterns: list[str] | None = None) -> dict[Path, ASTAnalysisResult]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®åˆ†æ"""
        ...


@dataclass
class PreventionAnalysisRequest:
    """äºˆé˜²åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""

    target_files: list[Path] | None = None  # ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿åˆ†æ
    include_external: bool = False  # å¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾å­˜ã‚‚å«ã‚ã‚‹
    risk_threshold: float = 50.0  # ãƒªã‚¹ã‚¯ã—ãã„å€¤
    generate_fixes: bool = True  # ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã‹


@dataclass
class PreventionAnalysisResult:
    """äºˆé˜²åˆ†æçµæœ"""

    detection_result: CircularDetectionResult
    prevention_recommendations: list[str]
    implementation_safety_score: float  # 0-100
    critical_issues: list[str]
    automated_fixes: list[dict[str, str]]  # ãƒ•ã‚¡ã‚¤ãƒ« â†’ ä¿®æ­£å†…å®¹

    def is_safe_to_implement(self) -> bool:
        """å®Ÿè£…å®‰å…¨æ€§ã®åˆ¤å®š"""
        return (
            self.implementation_safety_score >= 70.0
            and len(self.critical_issues) == 0
            and len(self.detection_result.get_critical_paths()) == 0
        )


class CircularImportPreventionService:
    """å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆäºˆé˜²ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self, project_root: Path, ast_analyzer: ASTAnalysisPort) -> None:
        """åˆæœŸåŒ–"""
        self.project_root = project_root
        self.ast_analyzer = ast_analyzer
        self.detector = CircularImportDetector(project_root)

    def analyze_current_state(self, request: PreventionAnalysisRequest) -> PreventionAnalysisResult:
        """ç¾åœ¨ã®çŠ¶æ…‹åˆ†æ - B20æº–æ‹ ç´”ç²‹é–¢æ•°åŒ–"""

        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®æŠ½å‡º
        import_statements = self._extract_import_statements(request)

        # å¾ªç’°æ¤œå‡º
        detection_result = self.detector.detect_circular_imports(import_statements, cache_key="current_state_analysis")

        # äºˆé˜²æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        recommendations = self._generate_prevention_recommendations(detection_result)

        # å®‰å…¨æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        safety_score = self._calculate_implementation_safety_score(detection_result)

        # é‡è¦å•é¡Œã®ç‰¹å®š
        critical_issues = self._identify_critical_issues(detection_result)

        # è‡ªå‹•ä¿®æ­£ã®ç”Ÿæˆ
        automated_fixes = self._generate_automated_fixes(detection_result) if request.generate_fixes else []

        return PreventionAnalysisResult(
            detection_result=detection_result,
            prevention_recommendations=recommendations,
            implementation_safety_score=safety_score,
            critical_issues=critical_issues,
            automated_fixes=automated_fixes,
        )

        # B20æº–æ‹ : ãƒ­ã‚°å‡ºåŠ›ã¯ä¸Šä½å±¤ã®è²¬å‹™

    def validate_new_implementation(
        self, implementation_plan: dict[str, str], target_layer: str = "domain"
    ) -> tuple[bool, list[str], float]:
        """æ–°è¦å®Ÿè£…ã®äº‹å‰æ¤œè¨¼"""
        # B20æº–æ‹ : å‰¯ä½œç”¨ã‚’Imperative Shellã«å§”è­²

        validation_results = []
        overall_risk_score = 0.0

        # æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’å–å¾—
        existing_imports = self._get_existing_imports()

        # å„å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦æ¤œè¨¼
        for file_path_str, implementation_content in implementation_plan.items():
            file_path = Path(file_path_str)  # TODO: IPathServiceã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£

            # å®Ÿè£…å†…å®¹ã‹ã‚‰äºˆæƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æŠ½å‡º
            predicted_imports = self._predict_imports_from_content(implementation_content, file_path)

            # å„äºˆæƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ãƒªã‚¹ã‚¯è©•ä¾¡
            for predicted_import in predicted_imports:
                risk_score, warnings = self.detector.predict_new_import_risk(predicted_import, existing_imports)

                overall_risk_score = max(overall_risk_score, risk_score)

                if risk_score > 70.0:
                    validation_results.extend(warnings)
                    validation_results.append(
                        f"âš ï¸ é«˜ãƒªã‚¹ã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {predicted_import.module_name} (ãƒªã‚¹ã‚¯: {risk_score:.1f})"
                    )

        # DDDå±¤é…ç½®ã®æ¤œè¨¼
        layer_validation = self._validate_layer_placement(implementation_plan, target_layer)
        validation_results.extend(layer_validation)

        is_safe = overall_risk_score < 50.0 and len(validation_results) == 0

        return is_safe, validation_results, overall_risk_score

    def suggest_safe_implementation_pattern(
        self, feature_name: str, required_dependencies: list[str], target_layer: str
    ) -> dict[str, str]:
        """å®‰å…¨ãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ææ¡ˆ"""
        # B20æº–æ‹ : ãƒ‘ã‚¿ãƒ¼ãƒ³ææ¡ˆã¯ç´”ç²‹é–¢æ•°ã¨ã—ã¦å®Ÿè£…

        patterns = {}

        # DDDå±¤åˆ¥ã®å®‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        if target_layer == "domain":
            patterns.update(self._suggest_domain_patterns(feature_name, required_dependencies))
        elif target_layer == "application":
            patterns.update(self._suggest_application_patterns(feature_name, required_dependencies))
        elif target_layer == "infrastructure":
            patterns.update(self._suggest_infrastructure_patterns(feature_name, required_dependencies))

        # å…±é€šã®å®‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns.update(self._suggest_common_safe_patterns(feature_name))

        return patterns

    def generate_prevention_checklist(self, implementation_context: dict[str, str]) -> list[dict[str, str]]:
        """äºˆé˜²ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ç”Ÿæˆ"""
        checklist = [
            {
                "category": "ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¨­è¨ˆ",
                "item": "scriptsãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®ä½¿ç”¨ç¢ºèª",
                "description": "å…¨ã¦ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§scripts.ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨",
            },
            {
                "category": "ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¨­è¨ˆ",
                "item": "ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå›é¿ç¢ºèª",
                "description": "from noveler.domain.services import ã‚’ä½¿ã‚ãšã€çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨",
            },
            {
                "category": "DDDæº–æ‹ ",
                "item": "å±¤é–“ä¾å­˜é–¢ä¿‚ç¢ºèª",
                "description": "ä¸Šä½å±¤ã‹ã‚‰ä¸‹ä½å±¤ã®ã¿ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç¢ºèª",
            },
            {
                "category": "DDDæº–æ‹ ",
                "item": "Protocol-based DIæ¤œè¨",
                "description": "ç›´æ¥ã‚¯ãƒ©ã‚¹ä¾å­˜ã§ã¯ãªãã€ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµŒç”±ã§ã®ä¾å­˜æ³¨å…¥ã‚’æ¤œè¨",
            },
            {
                "category": "å¾ªç’°äºˆé˜²",
                "item": "åŒæ–¹å‘ä¾å­˜ãƒã‚§ãƒƒã‚¯",
                "description": "Aã¨BãŒç›¸äº’ã«ä¾å­˜ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯",
            },
            {
                "category": "å¾ªç’°äºˆé˜²",
                "item": "å…±é€šåŸºåº•ã®æŠ½å‡ºæ¤œè¨",
                "description": "å¾ªç’°ãƒªã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã¯å…±é€šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æŠ½å‡ºã‚’æ¤œè¨",
            },
        ]

        # å®Ÿè£…ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
        for file_path in implementation_context:
            if "service" in file_path.lower():
                checklist.append(
                    {
                        "category": "ã‚µãƒ¼ãƒ“ã‚¹è¨­è¨ˆ",
                        "item": f"{file_path}ã®è²¬å‹™å˜ä¸€åŒ–",
                        "description": "ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ãŒå˜ä¸€è²¬å‹™ã‚’æŒã¤ã“ã¨ã‚’ç¢ºèª",
                    }
                )

        return checklist

    def _extract_import_statements(self, request: PreventionAnalysisRequest) -> list[ImportStatement]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®æŠ½å‡º"""
        import_statements = []

        if request.target_files:
            # æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿åˆ†æ
            for file_path in request.target_files:
                if file_path.exists() and file_path.suffix == ".py":
                    analysis_result = self.ast_analyzer.analyze_file(file_path)
                    import_statements.extend(analysis_result.imports)
        else:
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’åˆ†æ
            analysis_results = self.ast_analyzer.analyze_project()
            for file_result in analysis_results.values():
                import_statements.extend(file_result.imports)

        # å¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if not request.include_external:
            import_statements = [
                stmt for stmt in import_statements if stmt.import_scope in ["LOCAL", "RELATIVE"]
            ]

        return import_statements

    def _generate_prevention_recommendations(self, detection_result: CircularDetectionResult) -> list[str]:
        """äºˆé˜²æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        if not detection_result.circular_paths:
            recommendations.append("âœ… ç¾åœ¨å¾ªç’°ä¾å­˜ã¯æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“")
            recommendations.append("ğŸ’¡ ã“ã®ã¾ã¾é©åˆ‡ãªè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¶­æŒã—ã¦ãã ã•ã„")
        else:
            recommendations.append(f"âš ï¸ {len(detection_result.circular_paths)}ä»¶ã®å¾ªç’°ä¾å­˜ã‚’æ¤œå‡º")

            # é«˜ãƒªã‚¹ã‚¯å¾ªç’°ã¸ã®å¯¾å¿œ
            critical_paths = detection_result.get_critical_paths()
            if critical_paths:
                recommendations.append(f"ğŸš¨ {len(critical_paths)}ä»¶ã®é«˜ãƒªã‚¹ã‚¯å¾ªç’°ã‚’å„ªå…ˆä¿®æ­£ã—ã¦ãã ã•ã„")
                for path in critical_paths:
                    recommendations.append(f"   â€¢ {' â†’ '.join(path.modules)}")

        # ä¸€èˆ¬çš„ãªäºˆé˜²ç­–
        recommendations.extend(
            [
                "ğŸ—ï¸ Protocol-basedä¾å­˜æ³¨å…¥ã®æ´»ç”¨ã‚’æ¨å¥¨",
                "ğŸ“ DDDå±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å³å®ˆ",
                "ğŸ” å®Ÿè£…å‰ã®CODEMAPç¢ºèªã®å¾¹åº•",
                "âš¡ CI/CDã§ã®å¾ªç’°æ¤œå‡ºè‡ªå‹•åŒ–",
            ]
        )

        return recommendations

    def _calculate_implementation_safety_score(self, detection_result: CircularDetectionResult) -> float:
        """å®Ÿè£…å®‰å…¨æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        base_score = 100.0

        # å¾ªç’°ãƒ‘ã‚¹æ•°ã«å¿œã˜ãŸæ¸›ç‚¹
        cycles_penalty = len(detection_result.circular_paths) * 15.0
        base_score -= cycles_penalty

        # é«˜ãƒªã‚¹ã‚¯å¾ªç’°ã®è¿½åŠ æ¸›ç‚¹
        critical_cycles_penalty = len(detection_result.get_critical_paths()) * 25.0
        base_score -= critical_cycles_penalty

        # å…¨ä½“çš„ãªãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸæ¸›ç‚¹
        overall_risk_penalty = detection_result.get_total_risk_score()
        base_score -= overall_risk_penalty

        return max(0.0, base_score)

    def _identify_critical_issues(self, detection_result: CircularDetectionResult) -> list[str]:
        """é‡è¦å•é¡Œã®ç‰¹å®š"""
        critical_issues = []

        # é«˜ãƒªã‚¹ã‚¯å¾ªç’°
        critical_paths = detection_result.get_critical_paths()
        for path in critical_paths:
            critical_issues.append(f"é«˜ãƒªã‚¹ã‚¯å¾ªç’°({path.risk_level}/5): {' â†’ '.join(path.modules)}")

        # å±¤é•åã‚’å«ã‚€å¾ªç’°
        for path in detection_result.circular_paths:
            has_layer_violation = any(self._is_layer_violation_import(stmt) for stmt in path.import_chain)

            if has_layer_violation:
                critical_issues.append(f"DDDå±¤é•åå¾ªç’°: {' â†’ '.join(path.modules)}")

        return critical_issues

    def _generate_automated_fixes(self, detection_result: CircularDetectionResult) -> list[dict[str, str]]:
        """è‡ªå‹•ä¿®æ­£ã®ç”Ÿæˆ"""
        fixes = []

        for path in detection_result.circular_paths:
            for suggestion in path.fix_suggestions:
                if "ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ" in suggestion:
                    fixes.append({"type": "relative_to_absolute", "description": suggestion, "modules": path.modules})
                elif "scriptsãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹" in suggestion:
                    fixes.append({"type": "add_scripts_prefix", "description": suggestion, "modules": path.modules})

        return fixes

    def _get_existing_imports(self) -> list[ImportStatement]:
        """æ—¢å­˜ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®å–å¾—"""
        analysis_results = self.ast_analyzer.analyze_project()
        all_imports = []
        for result in analysis_results.values():
            all_imports.extend(result.imports)
        return all_imports

    def _predict_imports_from_content(self, content: str, file_path: Path) -> list[ImportStatement]:
        """å®Ÿè£…å†…å®¹ã‹ã‚‰äºˆæƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’æŠ½å‡º"""
        # ç°¡æ˜“çš„ãªå®Ÿè£…ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªè§£æãŒå¿…è¦ï¼‰
        predicted_imports = []

        # ä¸€èˆ¬çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯

        for line_no, line in enumerate(content.splitlines(), 1):
            line = line.strip()
            if line.startswith(("from ", "import ")):
                # åŸºæœ¬çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®è§£æ
                if "from " in line and " import " in line:
                    parts = line.split()
                    if len(parts) >= 4 and parts[0] == "from" and parts[2] == "import":
                        module_name = parts[1]
                        imported_names = [parts[3]]  # ç°¡æ˜“ç‰ˆ

                        predicted_imports.append(
                            ImportStatement(
                                module_name=module_name,
                                imported_names=imported_names,
                                import_type="FROM",
                                import_scope=self._determine_scope(module_name),
                                source_file=file_path,
                                line_number=line_no,
                                statement_text=line,
                            )
                        )

        return predicted_imports

    def _determine_scope(self, module_name: str) -> str:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‹ã‚‰ã‚¹ã‚³ãƒ¼ãƒ—ã‚’åˆ¤å®š"""
        if module_name.startswith("noveler."):
            return "LOCAL"
        if module_name.startswith("."):
            return "RELATIVE"
        return "THIRD_PARTY"

    def _validate_layer_placement(self, implementation_plan: dict[str, str], target_layer: str) -> list[str]:
        """å±¤é…ç½®ã®æ¤œè¨¼"""
        violations = []

        layer_hierarchy = {"domain": 0, "application": 1, "infrastructure": 2, "presentation": 3}
        layer_hierarchy.get(target_layer, 999)

        for file_path_str in implementation_plan:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰é…ç½®å±¤ã‚’æ¨æ¸¬
            if f"/{target_layer}/" not in file_path_str:
                violations.append(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®å±¤ä¸ä¸€è‡´: {file_path_str} (æœŸå¾…: {target_layer}å±¤)")

        return violations

    def _suggest_domain_patterns(self, feature_name: str, dependencies: list[str]) -> dict[str, str]:
        """Domainå±¤å®‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return {
            "interface_segregation": "å¿…è¦æœ€å°é™ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ã¿ä¾å­˜",
            "value_object_immutability": "Value Objectã®ä¸å¤‰æ€§ç¢ºä¿",
            "aggregate_consistency": "é›†ç´„å†…éƒ¨ã§ã®ä¸€è²«æ€§ä¿è¨¼",
        }

    def _suggest_application_patterns(self, feature_name: str, dependencies: list[str]) -> dict[str, str]:
        """Applicationå±¤å®‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return {
            "use_case_orchestration": "UseCase ã«ã‚ˆã‚‹å‡¦ç†ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡",
            "repository_abstraction": "Repositoryã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çµŒç”±ã®ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹",
            "domain_service_delegation": "Domain Service ã¸ã®å‡¦ç†å§”è­²",
        }

    def _suggest_infrastructure_patterns(self, feature_name: str, dependencies: list[str]) -> dict[str, str]:
        """Infrastructureå±¤å®‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return {
            "adapter_pattern": "å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼å®Ÿè£…",
            "repository_implementation": "Repository ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…",
            "dependency_injection": "DIã‚³ãƒ³ãƒ†ãƒŠã«ã‚ˆã‚‹ä¾å­˜æ³¨å…¥",
        }

    def _suggest_common_safe_patterns(self, feature_name: str) -> dict[str, str]:
        """å…±é€šå®‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return {
            "protocol_based_di": "Protocol-basedã®ä¾å­˜æ³¨å…¥æ´»ç”¨",
            "factory_pattern": "Factoryãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ",
            "observer_pattern": "ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã«ã‚ˆã‚‹ç–çµåˆ",
        }

    def _is_layer_violation_import(self, import_stmt: ImportStatement) -> bool:
        """å±¤é•åã‚¤ãƒ³ãƒãƒ¼ãƒˆã®åˆ¤å®š"""
        # import_statement.py ã® is_ddd_layer_violation ã‚’åˆ©ç”¨
        return import_stmt.is_ddd_layer_violation("")
