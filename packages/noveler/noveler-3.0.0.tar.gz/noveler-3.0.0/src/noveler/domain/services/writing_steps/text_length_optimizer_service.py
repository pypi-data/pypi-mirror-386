"""STEP 13: æ–‡å­—æ•°æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹

A38åŸ·ç­†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¬ã‚¤ãƒ‰ã®STEP13ã€Œæ–‡å­—æ•°æœ€é©åŒ–ã€ã‚’å®Ÿè£…ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€‚
ç›®æ¨™æ–‡å­—æ•°ã«å¯¾ã™ã‚‹æœ€é©åŒ–ã‚’è¡Œã„ã€èª­ã¿å¿œãˆã¨ç°¡æ½”ã•ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¡ãªãŒã‚‰
é©åˆ‡ãªæ–‡ç« é•·ã«èª¿æ•´ã—ã¾ã™ã€‚
"""

from abc import abstractmethod
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any

from noveler.application.services.stepwise_execution_service import BaseWritingStep
from noveler.domain.models.project_model import ProjectModel
from noveler.domain.services.configuration_manager_service import ConfigurationManagerService


class OptimizationType(Enum):
    """æœ€é©åŒ–ã‚¿ã‚¤ãƒ—"""
    EXPANSION = "expansion"  # æ‹¡å¼µï¼ˆæ–‡å­—æ•°ã‚’å¢—ã‚„ã™ï¼‰
    COMPRESSION = "compression"  # åœ§ç¸®ï¼ˆæ–‡å­—æ•°ã‚’æ¸›ã‚‰ã™ï¼‰
    RESTRUCTURING = "restructuring"  # å†æ§‹æˆï¼ˆæ§‹é€ ã®æœ€é©åŒ–ï¼‰
    BALANCING = "balancing"  # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´


class ContentPriority(Enum):
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å„ªå…ˆåº¦"""
    ESSENTIAL = "essential"  # å¿…é ˆå†…å®¹
    IMPORTANT = "important"  # é‡è¦å†…å®¹
    SUPPORTING = "supporting"  # æ”¯æ´å†…å®¹
    DECORATIVE = "decorative"  # è£…é£¾å†…å®¹
    EXPENDABLE = "expendable"  # å‰Šé™¤å¯èƒ½å†…å®¹


class LengthAdjustmentStrategy(Enum):
    """æ–‡å­—æ•°èª¿æ•´æˆ¦ç•¥"""
    DETAIL_ENHANCEMENT = "detail_enhancement"  # è©³ç´°å¼·åŒ–
    SCENE_EXPANSION = "scene_expansion"  # ã‚·ãƒ¼ãƒ³æ‹¡å¼µ
    DIALOGUE_ENRICHMENT = "dialogue_enrichment"  # å¯¾è©±å¼·åŒ–
    DESCRIPTION_ADDITION = "description_addition"  # æå†™è¿½åŠ 
    REDUNDANCY_REMOVAL = "redundancy_removal"  # å†—é•·æ€§é™¤å»
    CONTENT_CONDENSATION = "content_condensation"  # å†…å®¹å‡ç¸®
    STRUCTURE_OPTIMIZATION = "structure_optimization"  # æ§‹é€ æœ€é©åŒ–


@dataclass
class TextSegment:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆ"""
    segment_id: str
    content: str
    segment_type: str  # paragraph, dialogue, description, etc.
    character_count: int
    word_count: int
    priority: ContentPriority
    function: str  # plot_advancement, character_development, etc.
    emotional_impact: float  # æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ (0-1)
    narrative_importance: float  # ãƒŠãƒ©ãƒ†ã‚£ãƒ–é‡è¦åº¦ (0-1)
    redundancy_score: float  # å†—é•·æ€§ã‚¹ã‚³ã‚¢ (0-1)
    expansion_potential: float  # æ‹¡å¼µå¯èƒ½æ€§ (0-1)
    compression_potential: float  # åœ§ç¸®å¯èƒ½æ€§ (0-1)
    related_segments: list[str]  # é–¢é€£ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ


@dataclass
class OptimizationAction:
    """æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
    action_id: str
    action_type: OptimizationType
    strategy: LengthAdjustmentStrategy
    target_segment_id: str
    description: str
    original_content: str
    optimized_content: str
    character_change: int  # æ–‡å­—æ•°å¤‰åŒ–
    impact_assessment: str
    risk_level: float  # ãƒªã‚¹ã‚¯ ãƒ¬ãƒ™ãƒ« (0-1)
    confidence: float  # ä¿¡é ¼åº¦ (0-1)
    execution_order: int  # å®Ÿè¡Œé †åº


@dataclass
class LengthAnalysis:
    """æ–‡å­—æ•°åˆ†æ"""
    current_length: int
    target_length: int
    variance_from_target: int
    variance_percentage: float
    length_distribution: dict[str, int]  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥æ–‡å­—æ•°
    density_analysis: dict[str, float]  # å¯†åº¦åˆ†æ
    pacing_analysis: dict[str, Any]  # ãƒšãƒ¼ã‚¹åˆ†æ
    balance_assessment: dict[str, float]  # ãƒãƒ©ãƒ³ã‚¹è©•ä¾¡


@dataclass
class OptimizationPlan:
    """æœ€é©åŒ–è¨ˆç”»"""
    plan_id: str
    optimization_type: OptimizationType
    target_adjustment: int  # ç›®æ¨™èª¿æ•´æ–‡å­—æ•°
    planned_actions: list[OptimizationAction]
    execution_phases: list[str]  # å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º
    risk_mitigation: list[str]  # ãƒªã‚¹ã‚¯è»½æ¸›ç­–
    quality_checkpoints: list[str]  # å“è³ªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
    fallback_strategies: list[str]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""
    result_id: str
    executed_actions: list[OptimizationAction]
    original_length: int
    optimized_length: int
    length_change: int
    quality_metrics: dict[str, float]
    readability_impact: float  # èª­ã¿ã‚„ã™ã•ã¸ã®å½±éŸ¿
    narrative_integrity: float  # ãƒŠãƒ©ãƒ†ã‚£ãƒ–å®Œå…¨æ€§
    optimization_effectiveness: float  # æœ€é©åŒ–åŠ¹æœ


@dataclass
class TextLengthOptimizationReport:
    """æ–‡å­—æ•°æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ"""
    report_id: str
    episode_number: int
    optimization_timestamp: datetime
    length_analysis: LengthAnalysis
    text_segments: list[TextSegment]
    optimization_plan: OptimizationPlan
    optimization_result: OptimizationResult
    final_text: str
    optimization_score: float  # æœ€é©åŒ–ã‚¹ã‚³ã‚¢ (0-1)
    target_achievement: float  # ç›®æ¨™é”æˆåº¦ (0-1)
    quality_preservation: float  # å“è³ªä¿æŒåº¦ (0-1)
    optimization_summary: str
    recommendations: list[str]
    optimization_metadata: dict[str, Any]


@dataclass
class TextLengthOptimizerConfig:
    """æ–‡å­—æ•°æœ€é©åŒ–è¨­å®š"""
    target_length: int = 4000  # ç›®æ¨™æ–‡å­—æ•°
    length_tolerance: float = 0.1  # è¨±å®¹èª¤å·®ï¼ˆå‰²åˆï¼‰
    min_length_threshold: int = 3000  # æœ€å°æ–‡å­—æ•°é–¾å€¤
    max_length_threshold: int = 5000  # æœ€å¤§æ–‡å­—æ•°é–¾å€¤
    optimization_aggressiveness: float = 0.5  # æœ€é©åŒ–ç©æ¥µæ€§ (0-1)
    quality_weight: float = 0.7  # å“è³ªé‡ã¿
    length_weight: float = 0.3  # æ–‡å­—æ•°é‡ã¿
    enable_expansion: bool = True
    enable_compression: bool = True
    enable_restructuring: bool = True
    preserve_dialogue: bool = True  # å¯¾è©±ä¿æŒ
    preserve_key_scenes: bool = True  # é‡è¦ã‚·ãƒ¼ãƒ³ä¿æŒ
    max_iterations: int = 3  # æœ€å¤§åå¾©å›æ•°


class TextLengthOptimizerService(BaseWritingStep):
    """STEP 13: æ–‡å­—æ•°æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹

    ç›®æ¨™æ–‡å­—æ•°ã«å¯¾ã™ã‚‹æœ€é©åŒ–ã‚’è¡Œã„ã€èª­ã¿å¿œãˆã¨ç°¡æ½”ã•ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¡ãªãŒã‚‰
    é©åˆ‡ãªæ–‡ç« é•·ã«èª¿æ•´ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€‚
    A38ã‚¬ã‚¤ãƒ‰ã®STEP13ã€Œæ–‡å­—æ•°æœ€é©åŒ–ã€ã‚’å®Ÿè£…ã€‚
    """

    def __init__(
        self,
        config_manager: ConfigurationManagerService | None = None,
        path_service: Any | None = None,
        file_system_service: Any | None = None
    ) -> None:
        super().__init__()
        self._config_manager = config_manager
        self._path_service = path_service
        self._file_system = file_system_service
        self._optimizer_config = TextLengthOptimizerConfig()

        # æœ€é©åŒ–æˆ¦ç•¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self._optimization_strategies = self._initialize_optimization_strategies()
        self._segment_analyzers = self._initialize_segment_analyzers()

    @abstractmethod
    def get_step_name(self) -> str:
        """ã‚¹ãƒ†ãƒƒãƒ—åã‚’å–å¾—"""
        return "æ–‡å­—æ•°æœ€é©åŒ–"

    @abstractmethod
    def get_step_description(self) -> str:
        """ã‚¹ãƒ†ãƒƒãƒ—ã®èª¬æ˜ã‚’å–å¾—"""
        return "ç›®æ¨™æ–‡å­—æ•°ã«å¯¾ã™ã‚‹æœ€é©åŒ–ã‚’è¡Œã„ã€èª­ã¿å¿œãˆã¨ç°¡æ½”ã•ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¡ãªãŒã‚‰é©åˆ‡ãªæ–‡ç« é•·ã«èª¿æ•´ã—ã¾ã™"

    @abstractmethod
    def execute_step(self, context: dict[str, Any]) -> dict[str, Any]:
        """STEP 13: æ–‡å­—æ•°æœ€é©åŒ–ã®å®Ÿè¡Œ

        Args:
            context: å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            æ–‡å­—æ•°æœ€é©åŒ–çµæœã‚’å«ã‚€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            episode_number = context.get("episode_number")
            project = context.get("project")

            if not episode_number or not project:
                msg = "episode_numberã¾ãŸã¯projectãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
                raise ValueError(msg)

            # åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—
            manuscript_text = self._get_manuscript_text(context)
            if not manuscript_text:
                msg = "æœ€é©åŒ–å¯¾è±¡ã®åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                raise ValueError(msg)

            # æ–‡å­—æ•°æœ€é©åŒ–ã®å®Ÿè¡Œ
            optimization_report = self._execute_text_length_optimization(
                episode_number=episode_number,
                project=project,
                manuscript_text=manuscript_text,
                context=context
            )

            # çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
            context["text_length_optimization"] = optimization_report
            context["optimized_text"] = optimization_report.final_text
            context["text_length_optimization_completed"] = True

            return context

        except Exception as e:
            context["text_length_optimization_error"] = str(e)
            raise

    def _get_manuscript_text(self, context: dict[str, Any]) -> str:
        """åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—"""
        # æ§˜ã€…ãªã‚½ãƒ¼ã‚¹ã‹ã‚‰åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã‚’è©¦è¡Œ
        manuscript_text = context.get("manuscript_text")
        if manuscript_text:
            return manuscript_text

        # ç”Ÿæˆã•ã‚ŒãŸåŸç¨¿ã‹ã‚‰å–å¾—
        manuscript_data = context.get("manuscript_generator", {})
        if manuscript_data and isinstance(manuscript_data, dict):
            return manuscript_data.get("generated_text", "")

        # åˆç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
        draft_data = context.get("manuscript_draft", {})
        if draft_data and isinstance(draft_data, dict):
            return draft_data.get("content", "")

        return ""

    def _execute_text_length_optimization(
        self,
        episode_number: int,
        project: ProjectModel,
        manuscript_text: str,
        context: dict[str, Any]
    ) -> TextLengthOptimizationReport:
        """æ–‡å­—æ•°æœ€é©åŒ–ã®å®Ÿè¡Œ"""

        # ç›®æ¨™æ–‡å­—æ•°ã®æ±ºå®š
        target_length = self._determine_target_length(context)
        self._optimizer_config.target_length = target_length

        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
        length_analysis = self._analyze_text_length(manuscript_text, target_length)

        # ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        text_segments = self._segment_text(manuscript_text)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ
        analyzed_segments = self._analyze_segments(text_segments, context)

        # æœ€é©åŒ–è¨ˆç”»ã®ä½œæˆ
        optimization_plan = self._create_optimization_plan(
            length_analysis, analyzed_segments, context
        )

        # æœ€é©åŒ–ã®å®Ÿè¡Œ
        optimization_result = self._execute_optimization(
            manuscript_text, optimization_plan, analyzed_segments
        )

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        return self._generate_optimization_report(
            episode_number=episode_number,
            length_analysis=length_analysis,
            text_segments=analyzed_segments,
            optimization_plan=optimization_plan,
            optimization_result=optimization_result
        )

    def _determine_target_length(self, context: dict[str, Any]) -> int:
        """ç›®æ¨™æ–‡å­—æ•°ã®æ±ºå®š"""
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›®æ¨™æ–‡å­—æ•°ã‚’å–å¾—
        context_target = context.get("target_word_count")
        if context_target:
            return int(context_target)

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‹ã‚‰å–å¾—
        project_settings = context.get("project", {})
        if hasattr(project_settings, "default_episode_length"):
            return project_settings.default_episode_length

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
        return self._optimizer_config.target_length

    def _analyze_text_length(self, text: str, target_length: int) -> LengthAnalysis:
        """ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—æ•°åˆ†æ"""
        current_length = len(text)
        variance = current_length - target_length
        variance_percentage = (variance / target_length) * 100 if target_length > 0 else 0

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥æ–‡å­—æ•°åˆ†å¸ƒã®åˆ†æ
        length_distribution = self._analyze_length_distribution(text)

        # å¯†åº¦åˆ†æ
        density_analysis = self._analyze_text_density(text)

        # ãƒšãƒ¼ã‚¹åˆ†æ
        pacing_analysis = self._analyze_text_pacing(text)

        # ãƒãƒ©ãƒ³ã‚¹è©•ä¾¡
        balance_assessment = self._assess_text_balance(text)

        return LengthAnalysis(
            current_length=current_length,
            target_length=target_length,
            variance_from_target=variance,
            variance_percentage=variance_percentage,
            length_distribution=length_distribution,
            density_analysis=density_analysis,
            pacing_analysis=pacing_analysis,
            balance_assessment=balance_assessment
        )

    def _segment_text(self, text: str) -> list[TextSegment]:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        segments = []

        # æ®µè½å˜ä½ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²
        paragraphs = text.split("\n\n")

        for i, paragraph in enumerate(paragraphs):
            if paragraph.strip():  # ç©ºã§ãªã„æ®µè½ã®ã¿
                segment = TextSegment(
                    segment_id=f"segment_{i}",
                    content=paragraph.strip(),
                    segment_type=self._identify_segment_type(paragraph),
                    character_count=len(paragraph.strip()),
                    word_count=len(paragraph.strip().split()),
                    priority=ContentPriority.SUPPORTING,  # åˆæœŸå€¤
                    function="unknown",  # åˆæœŸå€¤
                    emotional_impact=0.5,  # åˆæœŸå€¤
                    narrative_importance=0.5,  # åˆæœŸå€¤
                    redundancy_score=0.0,  # åˆæœŸå€¤
                    expansion_potential=0.5,  # åˆæœŸå€¤
                    compression_potential=0.5,  # åˆæœŸå€¤
                    related_segments=[]  # åˆæœŸå€¤
                )
                segments.append(segment)

        return segments

    def _analyze_segments(
        self,
        segments: list[TextSegment],
        context: dict[str, Any]
    ) -> list[TextSegment]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è©³ç´°åˆ†æ"""
        analyzed_segments = []

        for segment in segments:
            # å„ªå…ˆåº¦ã®åˆ†æ
            priority = self._analyze_segment_priority(segment, context)

            # æ©Ÿèƒ½ã®åˆ†æ
            function = self._analyze_segment_function(segment, context)

            # æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®åˆ†æ
            emotional_impact = self._analyze_emotional_impact(segment)

            # ãƒŠãƒ©ãƒ†ã‚£ãƒ–é‡è¦åº¦ã®åˆ†æ
            narrative_importance = self._analyze_narrative_importance(segment, context)

            # å†—é•·æ€§ã®åˆ†æ
            redundancy_score = self._analyze_redundancy(segment, segments)

            # æ‹¡å¼µå¯èƒ½æ€§ã®åˆ†æ
            expansion_potential = self._analyze_expansion_potential(segment)

            # åœ§ç¸®å¯èƒ½æ€§ã®åˆ†æ
            compression_potential = self._analyze_compression_potential(segment)

            # é–¢é€£ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç‰¹å®š
            related_segments = self._find_related_segments(segment, segments)

            # åˆ†æçµæœã§æ›´æ–°
            segment.priority = priority
            segment.function = function
            segment.emotional_impact = emotional_impact
            segment.narrative_importance = narrative_importance
            segment.redundancy_score = redundancy_score
            segment.expansion_potential = expansion_potential
            segment.compression_potential = compression_potential
            segment.related_segments = related_segments

            analyzed_segments.append(segment)

        return analyzed_segments

    def _create_optimization_plan(
        self,
        length_analysis: LengthAnalysis,
        segments: list[TextSegment],
        context: dict[str, Any]
    ) -> OptimizationPlan:
        """æœ€é©åŒ–è¨ˆç”»ã®ä½œæˆ"""

        variance = length_analysis.variance_from_target
        optimization_type = self._determine_optimization_type(variance)

        # æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¨ˆç”»
        planned_actions = self._plan_optimization_actions(
            optimization_type, variance, segments, context
        )

        # å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚ºã®è¨­è¨ˆ
        execution_phases = self._design_execution_phases(planned_actions)

        # ãƒªã‚¹ã‚¯è»½æ¸›ç­–ã®è¨­è¨ˆ
        risk_mitigation = self._design_risk_mitigation(planned_actions)

        # å“è³ªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š
        quality_checkpoints = self._set_quality_checkpoints(planned_actions)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã®æº–å‚™
        fallback_strategies = self._prepare_fallback_strategies(optimization_type, variance)

        return OptimizationPlan(
            plan_id=f"opt_plan_{datetime.now(tz=datetime.timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            optimization_type=optimization_type,
            target_adjustment=-variance,  # ç›®æ¨™èª¿æ•´é‡
            planned_actions=planned_actions,
            execution_phases=execution_phases,
            risk_mitigation=risk_mitigation,
            quality_checkpoints=quality_checkpoints,
            fallback_strategies=fallback_strategies
        )

    def _execute_optimization(
        self,
        original_text: str,
        optimization_plan: OptimizationPlan,
        segments: list[TextSegment]
    ) -> OptimizationResult:
        """æœ€é©åŒ–ã®å®Ÿè¡Œ"""

        current_text = original_text
        executed_actions = []

        # è¨ˆç”»ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é †æ¬¡å®Ÿè¡Œ
        for action in optimization_plan.planned_actions:
            try:
                # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
                optimized_segment = self._execute_action(action, current_text, segments)

                # ãƒ†ã‚­ã‚¹ãƒˆã®æ›´æ–°
                current_text = self._apply_segment_change(
                    current_text, action.target_segment_id, optimized_segment, segments
                )

                # å®Ÿè¡Œæ¸ˆã¿ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½åŠ 
                action.optimized_content = optimized_segment
                executed_actions.append(action)

                # å“è³ªãƒã‚§ãƒƒã‚¯
                if not self._quality_check_passed(current_text, action):
                    # å“è³ªãƒã‚§ãƒƒã‚¯å¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    current_text = self._apply_fallback(current_text, action, segments)

            except Exception as e:
                # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¤±æ•—æ™‚ã®å‡¦ç†
                self._handle_action_failure(action, str(e))
                continue

        # çµæœã®è¨ˆç®—
        original_length = len(original_text)
        optimized_length = len(current_text)
        length_change = optimized_length - original_length

        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
        quality_metrics = self._calculate_quality_metrics(
            original_text, current_text, executed_actions
        )

        return OptimizationResult(
            result_id=f"opt_result_{datetime.now(tz=datetime.timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            executed_actions=executed_actions,
            original_length=original_length,
            optimized_length=optimized_length,
            length_change=length_change,
            quality_metrics=quality_metrics,
            readability_impact=quality_metrics.get("readability_impact", 0.0),
            narrative_integrity=quality_metrics.get("narrative_integrity", 1.0),
            optimization_effectiveness=self._calculate_optimization_effectiveness(
                length_change, optimization_plan.target_adjustment
            )
        )

    def _generate_optimization_report(
        self,
        episode_number: int,
        length_analysis: LengthAnalysis,
        text_segments: list[TextSegment],
        optimization_plan: OptimizationPlan,
        optimization_result: OptimizationResult
    ) -> TextLengthOptimizationReport:
        """æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""

        # æœ€é©åŒ–ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        optimization_score = self._calculate_optimization_score(
            optimization_result, optimization_plan
        )

        # ç›®æ¨™é”æˆåº¦ã®è¨ˆç®—
        target_achievement = self._calculate_target_achievement(
            optimization_result, length_analysis
        )

        # å“è³ªä¿æŒåº¦ã®è¨ˆç®—
        quality_preservation = optimization_result.narrative_integrity

        # æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
        final_text = self._build_final_text(text_segments, optimization_result)

        # ã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ
        optimization_summary = self._generate_optimization_summary(
            length_analysis, optimization_result, optimization_score
        )

        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        recommendations = self._generate_recommendations(
            optimization_result, target_achievement, quality_preservation
        )

        return TextLengthOptimizationReport(
            report_id=f"text_opt_{episode_number}_{datetime.now(tz=datetime.timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            episode_number=episode_number,
            optimization_timestamp=datetime.now(tz=datetime.timezone.utc),
            length_analysis=length_analysis,
            text_segments=text_segments,
            optimization_plan=optimization_plan,
            optimization_result=optimization_result,
            final_text=final_text,
            optimization_score=optimization_score,
            target_achievement=target_achievement,
            quality_preservation=quality_preservation,
            optimization_summary=optimization_summary,
            recommendations=recommendations,
            optimization_metadata={
                "config": self._optimizer_config.__dict__,
                "execution_time": datetime.now(tz=datetime.timezone.utc),
                "total_segments": len(text_segments),
                "executed_actions": len(optimization_result.executed_actions)
            }
        )

    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…

    def _initialize_optimization_strategies(self) -> dict[str, Any]:
        """æœ€é©åŒ–æˆ¦ç•¥ã®åˆæœŸåŒ–"""
        return {
            OptimizationType.EXPANSION: {
                LengthAdjustmentStrategy.DETAIL_ENHANCEMENT: {
                    "description": "æå†™ã®è©³ç´°åŒ–ã«ã‚ˆã‚‹æ‹¡å¼µ",
                    "applicability": 0.8,
                    "risk_level": 0.2
                },
                LengthAdjustmentStrategy.SCENE_EXPANSION: {
                    "description": "ã‚·ãƒ¼ãƒ³ã®æ‹¡å¼µ",
                    "applicability": 0.7,
                    "risk_level": 0.3
                },
                LengthAdjustmentStrategy.DIALOGUE_ENRICHMENT: {
                    "description": "å¯¾è©±ã®å……å®ŸåŒ–",
                    "applicability": 0.9,
                    "risk_level": 0.1
                }
            },
            OptimizationType.COMPRESSION: {
                LengthAdjustmentStrategy.REDUNDANCY_REMOVAL: {
                    "description": "å†—é•·éƒ¨åˆ†ã®å‰Šé™¤",
                    "applicability": 0.9,
                    "risk_level": 0.2
                },
                LengthAdjustmentStrategy.CONTENT_CONDENSATION: {
                    "description": "å†…å®¹ã®å‡ç¸®",
                    "applicability": 0.8,
                    "risk_level": 0.3
                }
            }
        }

    def _initialize_segment_analyzers(self) -> dict[str, Any]:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æå™¨ã®åˆæœŸåŒ–"""
        return {
            "dialogue_detector": {
                "patterns": ["ã€Œ", "ã€", "ã€", "ã€"],
                "weight": 1.0
            },
            "description_detector": {
                "patterns": ["æ§˜å­", "é¢¨æ™¯", "è¡¨æƒ…", "é›°å›²æ°—"],
                "weight": 0.8
            },
            "action_detector": {
                "patterns": ["ã—ãŸ", "ã™ã‚‹", "æ­©ã", "èµ°ã‚‹"],
                "weight": 0.9
            }
        }

    def _identify_segment_type(self, paragraph: str) -> str:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®è­˜åˆ¥"""
        # å¯¾è©±ã®æ¤œå‡º
        if "ã€Œ" in paragraph and "ã€" in paragraph:
            return "dialogue"

        # æå†™ã®æ¤œå‡º
        if any(word in paragraph for word in ["æ§˜å­", "é¢¨æ™¯", "è¡¨æƒ…", "é›°å›²æ°—", "æ™¯è‰²"]):
            return "description"

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ¤œå‡º
        if any(word in paragraph for word in ["ã—ãŸ", "ã™ã‚‹", "æ­©", "èµ°", "ç§»å‹•"]):
            return "action"

        return "narrative"

    def _determine_optimization_type(self, variance: int) -> OptimizationType:
        """æœ€é©åŒ–ã‚¿ã‚¤ãƒ—ã®æ±ºå®š"""
        tolerance = self._optimizer_config.target_length * self._optimizer_config.length_tolerance

        if variance > tolerance:
            return OptimizationType.COMPRESSION
        if variance < -tolerance:
            return OptimizationType.EXPANSION
        return OptimizationType.BALANCING

    def _plan_optimization_actions(
        self,
        optimization_type: OptimizationType,
        variance: int,
        segments: list[TextSegment],
        context: dict[str, Any]
    ) -> list[OptimizationAction]:
        """æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¨ˆç”»"""
        actions = []

        if optimization_type == OptimizationType.EXPANSION:
            actions = self._plan_expansion_actions(variance, segments)
        elif optimization_type == OptimizationType.COMPRESSION:
            actions = self._plan_compression_actions(variance, segments)
        elif optimization_type == OptimizationType.BALANCING:
            actions = self._plan_balancing_actions(segments)

        return actions

    def _plan_expansion_actions(
        self,
        needed_expansion: int,
        segments: list[TextSegment]
    ) -> list[OptimizationAction]:
        """æ‹¡å¼µã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¨ˆç”»"""
        actions = []
        remaining_expansion = abs(needed_expansion)

        # æ‹¡å¼µå¯èƒ½æ€§ã®é«˜ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å„ªå…ˆ
        expandable_segments = sorted(
            segments,
            key=lambda s: s.expansion_potential,
            reverse=True
        )

        order = 0
        for segment in expandable_segments:
            if remaining_expansion <= 0:
                break

            if segment.expansion_potential > 0.5:  # æ‹¡å¼µå¯èƒ½æ€§ãŒé«˜ã„
                # æ‹¡å¼µé‡ã‚’è¨ˆç®—
                expansion_amount = min(
                    remaining_expansion,
                    int(segment.character_count * 0.3)  # æœ€å¤§30%æ‹¡å¼µ
                )

                action = OptimizationAction(
                    action_id=f"expand_{segment.segment_id}",
                    action_type=OptimizationType.EXPANSION,
                    strategy=LengthAdjustmentStrategy.DETAIL_ENHANCEMENT,
                    target_segment_id=segment.segment_id,
                    description=f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€Œ{segment.segment_id}ã€ã®è©³ç´°åŒ–æ‹¡å¼µ",
                    original_content=segment.content,
                    optimized_content="",  # å®Ÿè¡Œæ™‚ã«è¨­å®š
                    character_change=expansion_amount,
                    impact_assessment="å“è³ªã‚’ä¿ã¡ãªãŒã‚‰æ–‡å­—æ•°ã‚’å¢—åŠ ",
                    risk_level=0.2,
                    confidence=0.8,
                    execution_order=order
                )
                actions.append(action)
                remaining_expansion -= expansion_amount
                order += 1

        return actions

    def _plan_compression_actions(
        self,
        needed_compression: int,
        segments: list[TextSegment]
    ) -> list[OptimizationAction]:
        """åœ§ç¸®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¨ˆç”»"""
        actions = []
        remaining_compression = abs(needed_compression)

        # å†—é•·æ€§ã®é«˜ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å„ªå…ˆ
        compressible_segments = sorted(
            segments,
            key=lambda s: s.redundancy_score + s.compression_potential,
            reverse=True
        )

        order = 0
        for segment in compressible_segments:
            if remaining_compression <= 0:
                break

            if segment.compression_potential > 0.3:  # åœ§ç¸®å¯èƒ½
                # åœ§ç¸®é‡ã‚’è¨ˆç®—
                compression_amount = min(
                    remaining_compression,
                    int(segment.character_count * 0.2)  # æœ€å¤§20%åœ§ç¸®
                )

                action = OptimizationAction(
                    action_id=f"compress_{segment.segment_id}",
                    action_type=OptimizationType.COMPRESSION,
                    strategy=LengthAdjustmentStrategy.REDUNDANCY_REMOVAL,
                    target_segment_id=segment.segment_id,
                    description=f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€Œ{segment.segment_id}ã€ã®å†—é•·æ€§é™¤å»",
                    original_content=segment.content,
                    optimized_content="",  # å®Ÿè¡Œæ™‚ã«è¨­å®š
                    character_change=-compression_amount,
                    impact_assessment="å†—é•·æ€§ã‚’é™¤å»ã—ã¦ç°¡æ½”åŒ–",
                    risk_level=0.3,
                    confidence=0.7,
                    execution_order=order
                )
                actions.append(action)
                remaining_compression -= compression_amount
                order += 1

        return actions

    def _plan_balancing_actions(
        self,
        segments: list[TextSegment]
    ) -> list[OptimizationAction]:
        """ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¨ˆç”»"""
        # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã®ãŸã‚ã®å¾®ç´°ãªæœ€é©åŒ–
        actions = []

        # æ§‹é€ æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        for i, segment in enumerate(segments):
            if segment.priority == ContentPriority.SUPPORTING and segment.redundancy_score > 0.5:
                action = OptimizationAction(
                    action_id=f"balance_{segment.segment_id}",
                    action_type=OptimizationType.RESTRUCTURING,
                    strategy=LengthAdjustmentStrategy.STRUCTURE_OPTIMIZATION,
                    target_segment_id=segment.segment_id,
                    description=f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€Œ{segment.segment_id}ã€ã®æ§‹é€ æœ€é©åŒ–",
                    original_content=segment.content,
                    optimized_content="",
                    character_change=0,
                    impact_assessment="æ§‹é€ ã‚’æœ€é©åŒ–ã—ã¦å“è³ªå‘ä¸Š",
                    risk_level=0.1,
                    confidence=0.9,
                    execution_order=i
                )
                actions.append(action)

        return actions

    # åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚¹ã‚¿ãƒ–å®Ÿè£…

    def _analyze_length_distribution(self, text: str) -> dict[str, int]:
        """æ–‡å­—æ•°åˆ†å¸ƒã®åˆ†æ"""
        return {"paragraph": 80, "dialogue": 20}

    def _analyze_text_density(self, text: str) -> dict[str, float]:
        """ãƒ†ã‚­ã‚¹ãƒˆå¯†åº¦ã®åˆ†æ"""
        return {"information_density": 0.8, "emotional_density": 0.6}

    def _analyze_text_pacing(self, text: str) -> dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒšãƒ¼ã‚¹ã®åˆ†æ"""
        return {"pacing_score": 0.7, "rhythm_consistency": 0.8}

    def _assess_text_balance(self, text: str) -> dict[str, float]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ©ãƒ³ã‚¹ã®è©•ä¾¡"""
        return {"narrative_balance": 0.8, "descriptive_balance": 0.7}

    def _analyze_segment_priority(self, segment: TextSegment, context: dict[str, Any]) -> ContentPriority:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå„ªå…ˆåº¦ã®åˆ†æ"""
        if segment.segment_type == "dialogue":
            return ContentPriority.IMPORTANT
        if segment.narrative_importance > 0.8:
            return ContentPriority.ESSENTIAL
        return ContentPriority.SUPPORTING

    def _analyze_segment_function(self, segment: TextSegment, context: dict[str, Any]) -> str:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ©Ÿèƒ½ã®åˆ†æ"""
        if segment.segment_type == "dialogue":
            return "character_development"
        if segment.segment_type == "description":
            return "atmosphere_building"
        return "plot_advancement"

    def _analyze_emotional_impact(self, segment: TextSegment) -> float:
        """æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®åˆ†æ"""
        emotional_words = ["æ‚²ã—ã„", "å¬‰ã—ã„", "é©šã", "æ€’ã‚Š", "æ„›"]
        count = sum(1 for word in emotional_words if word in segment.content)
        return min(count / 5.0, 1.0)

    def _analyze_narrative_importance(self, segment: TextSegment, context: dict[str, Any]) -> float:
        """ãƒŠãƒ©ãƒ†ã‚£ãƒ–é‡è¦åº¦ã®åˆ†æ"""
        return 0.7 if segment.segment_type in ["dialogue", "action"] else 0.5

    def _analyze_redundancy(self, segment: TextSegment, all_segments: list[TextSegment]) -> float:
        """å†—é•·æ€§ã®åˆ†æ"""
        # åŒæ§˜ã®å†…å®¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        similar_count = 0
        for other_segment in all_segments:
            if other_segment.segment_id != segment.segment_id:
                # å†…å®¹ã®é¡ä¼¼æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                common_words = set(segment.content.split()) & set(other_segment.content.split())
                if len(common_words) > 3:
                    similar_count += 1

        return min(similar_count / len(all_segments), 1.0)

    def _analyze_expansion_potential(self, segment: TextSegment) -> float:
        """æ‹¡å¼µå¯èƒ½æ€§ã®åˆ†æ"""
        if segment.segment_type == "description":
            return 0.8
        if segment.segment_type == "dialogue":
            return 0.6
        return 0.5

    def _analyze_compression_potential(self, segment: TextSegment) -> float:
        """åœ§ç¸®å¯èƒ½æ€§ã®åˆ†æ"""
        if len(segment.content) > 200:  # é•·ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯åœ§ç¸®å¯èƒ½æ€§ãŒé«˜ã„
            return 0.7
        if segment.redundancy_score > 0.5:
            return 0.8
        return 0.3

    def _find_related_segments(self, segment: TextSegment, all_segments: list[TextSegment]) -> list[str]:
        """é–¢é€£ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç™ºè¦‹"""
        related = []
        for other_segment in all_segments:
            if other_segment.segment_id != segment.segment_id:
                # å†…å®¹ã®é–¢é€£æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                if segment.segment_type == other_segment.segment_type:
                    related.append(other_segment.segment_id)
        return related[:3]  # æœ€å¤§3å€‹ã¾ã§

    # å®Ÿè¡Œé–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚¹ã‚¿ãƒ–å®Ÿè£…

    def _design_execution_phases(self, actions: list[OptimizationAction]) -> list[str]:
        """å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚ºã®è¨­è¨ˆ"""
        if not actions:
            return ["no_action_required"]

        phases = []
        if any(action.action_type == OptimizationType.COMPRESSION for action in actions):
            phases.append("compression_phase")
        if any(action.action_type == OptimizationType.EXPANSION for action in actions):
            phases.append("expansion_phase")
        if any(action.action_type == OptimizationType.RESTRUCTURING for action in actions):
            phases.append("restructuring_phase")

        return phases if phases else ["optimization_phase"]

    def _design_risk_mitigation(self, actions: list[OptimizationAction]) -> list[str]:
        """ãƒªã‚¹ã‚¯è»½æ¸›ç­–ã®è¨­è¨ˆ"""
        return [
            "å“è³ªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§ã®æ¤œè¨¼",
            "æ®µéšçš„ãªæœ€é©åŒ–å®Ÿè¡Œ",
            "é‡è¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ä¿è­·"
        ]

    def _set_quality_checkpoints(self, actions: list[OptimizationAction]) -> list[str]:
        """å“è³ªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š"""
        return [
            "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œå‰ã®å“è³ªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç¢ºç«‹",
            "å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¾Œã®å“è³ªç¢ºèª",
            "æœ€çµ‚çµæœã®ç·åˆå“è³ªè©•ä¾¡"
        ]

    def _prepare_fallback_strategies(self, optimization_type: OptimizationType, variance: int) -> list[str]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã®æº–å‚™"""
        strategies = ["å…ƒã®çŠ¶æ…‹ã¸ã®å¾©å…ƒ"]

        if optimization_type == OptimizationType.COMPRESSION:
            strategies.append("è»½å¾®ãªåœ§ç¸®ã¸ã®èª¿æ•´")
        elif optimization_type == OptimizationType.EXPANSION:
            strategies.append("å¿…è¦æœ€å°é™ã®æ‹¡å¼µã¸ã®èª¿æ•´")

        return strategies

    def _execute_action(
        self,
        action: OptimizationAction,
        current_text: str,
        segments: list[TextSegment]
    ) -> str:
        """å€‹åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ"""

        # å¯¾è±¡ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        target_segment = next(
            (s for s in segments if s.segment_id == action.target_segment_id),
            None
        )

        if not target_segment:
            return action.original_content

        # æˆ¦ç•¥ã«å¿œã˜ãŸæœ€é©åŒ–ã‚’å®Ÿè¡Œ
        if action.strategy == LengthAdjustmentStrategy.DETAIL_ENHANCEMENT:
            return self._enhance_details(target_segment.content)
        if action.strategy == LengthAdjustmentStrategy.REDUNDANCY_REMOVAL:
            return self._remove_redundancy(target_segment.content)
        if action.strategy == LengthAdjustmentStrategy.STRUCTURE_OPTIMIZATION:
            return self._optimize_structure(target_segment.content)
        return target_segment.content

    def _enhance_details(self, content: str) -> str:
        """è©³ç´°ã®å¼·åŒ–"""
        # ç°¡æ˜“å®Ÿè£…ï¼šå½¢å®¹è©ã‚„å‰¯è©ã‚’è¿½åŠ 
        enhanced = content
        if "æ­©ã„ãŸ" in content:
            enhanced = content.replace("æ­©ã„ãŸ", "ã‚†ã£ãã‚Šã¨æ­©ã„ãŸ")
        if "è¦‹ãŸ" in content:
            enhanced = enhanced.replace("è¦‹ãŸ", "ã˜ã£ã¨è¦‹ã¤ã‚ãŸ")
        return enhanced

    def _remove_redundancy(self, content: str) -> str:
        """å†—é•·æ€§ã®é™¤å»"""
        # ç°¡æ˜“å®Ÿè£…ï¼šé‡è¤‡è¡¨ç¾ã®å‰Šé™¤
        compressed = content
        # é‡è¤‡ã™ã‚‹å‰¯è©ã®å‰Šé™¤
        compressed = compressed.replace("ã¨ã¦ã‚‚éå¸¸ã«", "éå¸¸ã«")
        return compressed.replace("æœ¬å½“ã«ã¨ã¦ã‚‚", "ã¨ã¦ã‚‚")

    def _optimize_structure(self, content: str) -> str:
        """æ§‹é€ ã®æœ€é©åŒ–"""
        # ç°¡æ˜“å®Ÿè£…ï¼šæ–‡æ§‹é€ ã®æ•´ç†
        return content.strip()

    def _apply_segment_change(
        self,
        current_text: str,
        segment_id: str,
        new_content: str,
        segments: list[TextSegment]
    ) -> str:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå¤‰æ›´ã®é©ç”¨"""

        target_segment = next(
            (s for s in segments if s.segment_id == segment_id),
            None
        )

        if target_segment:
            # å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ç½®ãæ›ãˆ
            updated_text = current_text.replace(target_segment.content, new_content)
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚‚æ›´æ–°
            target_segment.content = new_content
            target_segment.character_count = len(new_content)
            return updated_text

        return current_text

    def _quality_check_passed(self, current_text: str, action: OptimizationAction) -> bool:
        """å“è³ªãƒã‚§ãƒƒã‚¯"""
        # ç°¡æ˜“å“è³ªãƒã‚§ãƒƒã‚¯
        return len(current_text.strip()) > 0 and action.risk_level < 0.8

    def _apply_fallback(
        self,
        current_text: str,
        failed_action: OptimizationAction,
        segments: list[TextSegment]
    ) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®é©ç”¨"""
        # å…ƒã®å†…å®¹ã«æˆ»ã™
        return self._apply_segment_change(
            current_text,
            failed_action.target_segment_id,
            failed_action.original_content,
            segments
        )

    def _handle_action_failure(self, action: OptimizationAction, error: str) -> None:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¤±æ•—ã®å‡¦ç†"""
        # ãƒ­ã‚°è¨˜éŒ²ãªã©ï¼ˆå®Ÿè£…ã¯çœç•¥ï¼‰

    def _calculate_quality_metrics(
        self,
        original_text: str,
        optimized_text: str,
        actions: list[OptimizationAction]
    ) -> dict[str, float]:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        return {
            "readability_impact": 0.9,
            "narrative_integrity": 0.95,
            "coherence_score": 0.9,
            "style_consistency": 0.85
        }

    def _calculate_optimization_effectiveness(self, actual_change: int, target_change: int) -> float:
        """æœ€é©åŒ–åŠ¹æœã®è¨ˆç®—"""
        if target_change == 0:
            return 1.0

        effectiveness = 1.0 - abs(actual_change - target_change) / abs(target_change)
        return max(0.0, effectiveness)

    def _calculate_optimization_score(
        self,
        result: OptimizationResult,
        plan: OptimizationPlan
    ) -> float:
        """æœ€é©åŒ–ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""

        # åŠ¹æœã‚¹ã‚³ã‚¢ (0-0.4)
        effectiveness_score = result.optimization_effectiveness * 0.4

        # å“è³ªã‚¹ã‚³ã‚¢ (0-0.4)
        quality_score = result.narrative_integrity * 0.4

        # å®Ÿè¡ŒæˆåŠŸåº¦ (0-0.2)
        execution_score = len(result.executed_actions) / len(plan.planned_actions) * 0.2 if plan.planned_actions else 0.2

        return effectiveness_score + quality_score + execution_score

    def _calculate_target_achievement(
        self,
        result: OptimizationResult,
        analysis: LengthAnalysis
    ) -> float:
        """ç›®æ¨™é”æˆåº¦ã®è¨ˆç®—"""
        final_variance = abs(result.optimized_length - analysis.target_length)
        tolerance = analysis.target_length * self._optimizer_config.length_tolerance

        if final_variance <= tolerance:
            return 1.0
        # è¨±å®¹ç¯„å›²ã‚’è¶…ãˆãŸåˆ†ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        penalty = (final_variance - tolerance) / analysis.target_length
        return max(0.0, 1.0 - penalty)

    def _build_final_text(
        self,
        segments: list[TextSegment],
        result: OptimizationResult
    ) -> str:
        """æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰"""
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆã—ã¦æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
        return "\n\n".join(segment.content for segment in segments)

    def _generate_optimization_summary(
        self,
        analysis: LengthAnalysis,
        result: OptimizationResult,
        score: float
    ) -> str:
        """æœ€é©åŒ–ã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ"""

        change_direction = "å¢—åŠ " if result.length_change > 0 else "æ¸›å°‘" if result.length_change < 0 else "å¤‰åŒ–ãªã—"

        summary_parts = [
            f"æ–‡å­—æ•°ã‚’{abs(result.length_change)}æ–‡å­—{change_direction}ã€‚",
            f"ç›®æ¨™{analysis.target_length}æ–‡å­—ã«å¯¾ã—ã¦{result.optimized_length}æ–‡å­—ã€‚"
        ]

        if score >= 0.8:
            summary_parts.append("é«˜å“è³ªãªæœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        elif score >= 0.6:
            summary_parts.append("è‰¯å¥½ãªæœ€é©åŒ–çµæœã§ã™ã€‚")
        else:
            summary_parts.append("æœ€é©åŒ–ã«èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")

        return " ".join(summary_parts)

    def _generate_recommendations(
        self,
        result: OptimizationResult,
        target_achievement: float,
        quality_preservation: float
    ) -> list[str]:
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        if target_achievement < 0.8:
            recommendations.append("ğŸ“ ç›®æ¨™æ–‡å­—æ•°ã«ã‚ˆã‚Šè¿‘ã¥ã‘ã‚‹è¿½åŠ èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

        if quality_preservation < 0.8:
            recommendations.append("ğŸ“ å“è³ªå‘ä¸Šã®ãŸã‚ã®è¦‹ç›´ã—ã‚’æ¨å¥¨ã—ã¾ã™")

        if result.optimization_effectiveness < 0.7:
            recommendations.append("ğŸ”„ æœ€é©åŒ–æ‰‹æ³•ã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

        if not recommendations:
            recommendations.append("âœ… æœ€é©åŒ–ã¯è‰¯å¥½ã«å®Œäº†ã—ã¾ã—ãŸ")

        return recommendations
