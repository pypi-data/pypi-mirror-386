"""Infrastructure.tools.api_discovery_scanner
Where: Infrastructure tool for scanning API definitions.
What: Parses project files to discover API endpoints and generate metadata.
Why: Supports tooling that relies on up-to-date API discovery information.
"""

from __future__ import annotations

from noveler.presentation.shared.shared_utilities import console

"\næ—¢å­˜APIç™ºè¦‹ãƒ„ãƒ¼ãƒ«: å®Ÿè£…å‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯è‡ªå‹•åŒ–\n\nã“ã®ãƒ„ãƒ¼ãƒ«ã¯NIHç—‡å€™ç¾¤ï¼ˆNot Invented Hereï¼‰ã‚’é˜²ããŸã‚ã€\næ–°è¦å®Ÿè£…å‰ã«æ—¢å­˜ã®é¡ä¼¼APIã‚’ç™ºè¦‹ãƒ»æç¤ºã—ã¾ã™ã€‚\n"
import ast
import re
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Any, ClassVar

import yaml


class FunctionType(Enum):
    """é–¢æ•°ã®åˆ†é¡ã‚¿ã‚¤ãƒ—"""

    CRUD_OPERATION = "crud"
    DATA_VALIDATION = "validation"
    DATA_TRANSFORMATION = "transformation"
    FILE_OPERATION = "file_io"
    SERVICE_COORDINATION = "service"
    UTILITY_FUNCTION = "utility"
    FACTORY_CREATION = "factory"


@dataclass(frozen=True)
class ExistingAPI:
    """æ—¢å­˜APIã®æƒ…å ±"""

    file_path: Path
    function_name: str
    class_name: str | None
    function_type: FunctionType
    parameters: list[str]
    return_type: str | None
    docstring: str | None
    line_number: int
    complexity_score: int


@dataclass(frozen=True)
class SimilarityMatch:
    """é¡ä¼¼åº¦ãƒãƒƒãƒãƒ³ã‚°çµæœ"""

    existing_api: ExistingAPI
    similarity_score: float
    similarity_reasons: list[str]


class APIDiscoveryScanner:
    """
    æ—¢å­˜APIç™ºè¦‹ãƒ»é‡è¤‡ãƒã‚§ãƒƒã‚¯è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«

    æ©Ÿèƒ½:
    - æ–°è¦å®Ÿè£…äºˆå®šæ©Ÿèƒ½ã®ä»•æ§˜ã‹ã‚‰æ—¢å­˜APIæ¤œç´¢
    - æ©Ÿèƒ½åãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»æˆ»ã‚Šå€¤ã®é¡ä¼¼åº¦åˆ¤å®š
    - NIHç—‡å€™ç¾¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•æ¤œå‡º
    - æ¨å¥¨ã•ã‚Œã‚‹æ—¢å­˜APIã®ææ¡ˆ
    """

    FUNCTION_PATTERNS: ClassVar[dict[FunctionType, list[str]]] = {
        FunctionType.CRUD_OPERATION: [
            "(create|save|insert|add)_",
            "(get|find|fetch|load|retrieve)_",
            "(update|modify|change)_",
            "(delete|remove|destroy)_",
        ],
        FunctionType.DATA_VALIDATION: ["(validate|check|verify)_", "is_valid", "(ensure|assert)_"],
        FunctionType.DATA_TRANSFORMATION: ["(convert|transform|parse|format)_", "to_", "from_", "_(to|from)_"],
        FunctionType.FILE_OPERATION: ["(read|write|load|save)_file", "(export|import)_", "file_(read|write|load|save)"],
        FunctionType.SERVICE_COORDINATION: ["(execute|process|handle)_", "(coordinate|orchestrate)_", "_service$"],
        FunctionType.FACTORY_CREATION: ["create_", "build_", "make_", "_factory"],
        FunctionType.UTILITY_FUNCTION: ["(calculate|compute)_", "(format|normalize)_", "(extract|collect)_"],
    }
    KEYWORD_WEIGHTS: ClassVar[dict[str, float]] = {
        "episode": 0.9,
        "plot": 0.9,
        "quality": 0.8,
        "check": 0.8,
        "validate": 0.8,
        "repository": 0.7,
        "service": 0.7,
        "manager": 0.6,
        "utility": 0.5,
        "helper": 0.5,
    }

    def __init__(self, project_root: Path, logger_service=None, console_service=None) -> None:
        """
        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.project_root = project_root
        self.scripts_root = project_root / "scripts"
        self.existing_apis: list[ExistingAPI] = []
        if logger_service is None:
            from noveler.infrastructure.di.container import resolve_service

            try:
                self.logger_service = resolve_service("ILogger")
            except ValueError:
                from noveler.infrastructure.adapters.domain_logger_adapter import DomainLoggerAdapter

                self.logger_service = DomainLoggerAdapter()
        else:
            self.logger_service = logger_service
        if console_service is None:
            from noveler.infrastructure.di.container import resolve_service

            try:
                self.console_service = resolve_service("IConsoleService")
            except ValueError:
                from noveler.infrastructure.adapters.console_service_adapter import ConsoleServiceAdapter

                self.console_service = ConsoleServiceAdapter()
        else:
            self.console_service = console_service

    def scan_existing_apis(self) -> list[ExistingAPI]:
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®æ—¢å­˜APIã‚’ã‚¹ã‚­ãƒ£ãƒ³

        Returns:
            ç™ºè¦‹ã•ã‚ŒãŸæ—¢å­˜APIã®ãƒªã‚¹ãƒˆ
        """
        self.existing_apis.clear()
        python_files = list(self.scripts_root.rglob("*.py"))
        for python_file in python_files:
            try:
                self._scan_file(python_file)
            except Exception as e:
                self.console_service.print(f"âš ï¸ {python_file}: ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼ - {e}")
        return self.existing_apis

    def find_similar_apis(
        self,
        function_name: str,
        parameters: list[str] | None = None,
        description: str | None = None,
        threshold: float = 0.5,
    ) -> list[SimilarityMatch]:
        """
        æŒ‡å®šã•ã‚ŒãŸæ©Ÿèƒ½ä»•æ§˜ã«é¡ä¼¼ã™ã‚‹æ—¢å­˜APIã‚’æ¤œç´¢

        Args:
            function_name: å®Ÿè£…äºˆå®šã®é–¢æ•°å
            parameters: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
            description: æ©Ÿèƒ½ã®èª¬æ˜
            threshold: é¡ä¼¼åº¦ã®é–¾å€¤ï¼ˆ0.0-1.0ï¼‰

        Returns:
            é¡ä¼¼åº¦ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸãƒãƒƒãƒãƒ³ã‚°çµæœ
        """
        matches = []
        for api in self.existing_apis:
            (similarity_score, reasons) = self._calculate_similarity(function_name, parameters or [], description, api)
            if similarity_score >= threshold:
                matches.append(
                    SimilarityMatch(existing_api=api, similarity_score=similarity_score, similarity_reasons=reasons)
                )
        matches.sort(key=lambda m: m.similarity_score, reverse=True)
        return matches

    def detect_nih_patterns(self, new_function_spec: dict[str, Any]) -> list[str]:
        """
        NIHç—‡å€™ç¾¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º

        Args:
            new_function_spec: æ–°è¦é–¢æ•°ã®ä»•æ§˜

        Returns:
            æ¤œå‡ºã•ã‚ŒãŸNIHãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
        """
        nih_warnings = []
        function_name = new_function_spec.get("name", "")
        common_patterns = ["Manager", "Service", "Repository", "Utility", "Helper"]
        for pattern in common_patterns:
            if pattern.lower() in function_name.lower():
                similar_count = len(
                    [
                        api
                        for api in self.existing_apis
                        if pattern.lower() in api.function_name.lower()
                        or (api.class_name and pattern.lower() in api.class_name.lower())
                    ]
                )
                if similar_count > 0:
                    nih_warnings.append(
                        f"âš ï¸ {pattern}ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ—¢ã«{similar_count}ç®‡æ‰€ã§å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚çµ±åˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
                    )
        matches = self.find_similar_apis(
            function_name, new_function_spec.get("parameters", []), new_function_spec.get("description"), threshold=0.7
        )
        if matches:
            nih_warnings.append(
                f"ğŸ”„ é«˜ã„é¡ä¼¼åº¦({matches[0].similarity_score:.1%})ã®æ—¢å­˜å®Ÿè£…ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {matches[0].existing_api.file_path}:{matches[0].existing_api.line_number}"
            )
        return nih_warnings

    def _scan_file(self, file_path: Path) -> None:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®APIã‚¹ã‚­ãƒ£ãƒ³"""
        content = file_path.read_text(encoding="utf-8")
        try:
            tree = ast.parse(content)
        except SyntaxError:
            return
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                self._extract_function_api(file_path, node)
            elif isinstance(node, ast.ClassDef):
                self._extract_class_methods(file_path, node)

    def _extract_function_api(self, file_path: Path, node: ast.FunctionDef, class_name: str | None = None) -> None:
        """é–¢æ•°å®šç¾©ã‹ã‚‰APIæƒ…å ±ã‚’æŠ½å‡º"""
        if node.name.startswith("_"):
            return
        parameters = [arg.arg for arg in node.args.args if arg.arg != "self"]
        return_type = None
        if node.returns:
            return_type = ast.unparse(node.returns)
        docstring = ast.get_docstring(node)
        function_type = self._classify_function_type(node.name, docstring)
        complexity_score = self._calculate_complexity(node)
        api = ExistingAPI(
            file_path=file_path,
            function_name=node.name,
            class_name=class_name,
            function_type=function_type,
            parameters=parameters,
            return_type=return_type,
            docstring=docstring,
            line_number=node.lineno,
            complexity_score=complexity_score,
        )
        self.existing_apis.append(api)

    def _extract_class_methods(self, file_path: Path, node: ast.ClassDef) -> None:
        """ã‚¯ãƒ©ã‚¹å†…ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŠ½å‡º"""
        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                self._extract_function_api(file_path, item, node.name)

    def _classify_function_type(self, function_name: str, docstring: str | None) -> FunctionType:
        """é–¢æ•°åã¨docstringã‹ã‚‰æ©Ÿèƒ½ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡"""
        function_text = f"{function_name} {docstring or ''}".lower()
        for func_type, patterns in self.FUNCTION_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, function_text):
                    return func_type
        return FunctionType.UTILITY_FUNCTION

    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """é–¢æ•°ã®è¤‡é›‘åº¦ã‚’è¨ˆç®—ï¼ˆ1-10ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰"""
        complexity = 1
        for child in ast.walk(node):
            if isinstance(child, ast.If | ast.While | ast.For):
                complexity += 1
            elif isinstance(child, ast.Try | ast.AsyncFunctionDef):
                complexity += 2
        return min(complexity, 10)

    def _calculate_similarity(
        self, target_name: str, target_params: list[str], target_description: str | None, api: ExistingAPI
    ) -> tuple[float, list[str]]:
        """é¡ä¼¼åº¦è¨ˆç®—"""
        similarity_score = 0.0
        reasons = []
        name_similarity = self._string_similarity(target_name, api.function_name)
        similarity_score += name_similarity * 0.4
        if name_similarity > 0.5:
            reasons.append(f"é–¢æ•°åãŒé¡ä¼¼ ({name_similarity:.1%})")
        param_similarity = self._list_similarity(target_params, api.parameters)
        similarity_score += param_similarity * 0.3
        if param_similarity > 0.3:
            reasons.append(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé¡ä¼¼ ({param_similarity:.1%})")
        if target_description and api.docstring:
            desc_similarity = self._string_similarity(target_description, api.docstring)
            similarity_score += desc_similarity * 0.2
            if desc_similarity > 0.3:
                reasons.append(f"æ©Ÿèƒ½èª¬æ˜ãŒé¡ä¼¼ ({desc_similarity:.1%})")
        keyword_score = self._keyword_matching(target_name, api.function_name)
        similarity_score += keyword_score * 0.1
        if keyword_score > 0.0:
            reasons.append("é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´")
        return (similarity_score, reasons)

    def _string_similarity(self, str1: str, str2: str) -> float:
        """æ–‡å­—åˆ—ã®é¡ä¼¼åº¦è¨ˆç®—ï¼ˆLevenshteinè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰"""
        (str1, str2) = (str1.lower(), str2.lower())
        if str1 == str2:
            return 1.0
        if str1 in str2 or str2 in str1:
            return 0.7
        common_chars = set(str1) & set(str2)
        total_chars = set(str1) | set(str2)
        if not total_chars:
            return 0.0
        return len(common_chars) / len(total_chars)

    def _list_similarity(self, list1: list[str], list2: list[str]) -> float:
        """ãƒªã‚¹ãƒˆã®é¡ä¼¼åº¦è¨ˆç®—"""
        if not list1 and (not list2):
            return 1.0
        if not list1 or not list2:
            return 0.0
        (set1, set2) = (set(list1), set(list2))
        intersection = set1 & set2
        union = set1 | set2
        return len(intersection) / len(union) if union else 0.0

    def _keyword_matching(self, str1: str, str2: str) -> float:
        """é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒãƒãƒ³ã‚°"""
        score = 0.0
        (str1, str2) = (str1.lower(), str2.lower())
        for keyword, weight in self.KEYWORD_WEIGHTS.items():
            if keyword in str1 and keyword in str2:
                score += weight
        return min(score / len(self.KEYWORD_WEIGHTS), 1.0)

    def export_scan_results(self, output_path: Path, include_similarity: bool = True) -> None:
        """ã‚¹ã‚­ãƒ£ãƒ³çµæœã‚’YAMLã§å‡ºåŠ›"""
        results_data: dict[str, Any] = {
            "metadata": {
                "project_root": str(self.project_root),
                "total_apis": len(self.existing_apis),
                "function_type_distribution": self._get_type_distribution(),
            },
            "existing_apis": [
                {
                    "file_path": str(api.file_path.relative_to(self.project_root)),
                    "function_name": api.function_name,
                    "class_name": api.class_name,
                    "function_type": api.function_type.value,
                    "parameters": api.parameters,
                    "return_type": api.return_type,
                    "docstring": api.docstring,
                    "line_number": api.line_number,
                    "complexity_score": api.complexity_score,
                }
                for api in self.existing_apis
            ],
        }
        with output_path.Path("w").open(encoding="utf-8") as f:
            yaml.dump(results_data, f, allow_unicode=True, sort_keys=False)

    def _get_type_distribution(self) -> dict[str, int]:
        """æ©Ÿèƒ½ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒã‚’å–å¾—"""
        distribution = {}
        for api in self.existing_apis:
            type_name = api.function_type.value
            distribution[type_name] = distribution.get(type_name, 0) + 1
        return distribution

    def interactive_search(self) -> None:
        """å¯¾è©±å¼APIæ¤œç´¢"""
        self.console_service.print("ğŸ” æ—¢å­˜APIæ¤œç´¢ãƒ„ãƒ¼ãƒ«")
        self.console_service.print("å®Ÿè£…äºˆå®šã®æ©Ÿèƒ½ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„:")
        function_name = input("é–¢æ•°å: ").strip()
        if not function_name:
            self.console_service.print("âŒ é–¢æ•°åã¯å¿…é ˆã§ã™")
            return
        description = input("æ©Ÿèƒ½èª¬æ˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: ").strip() or None
        self.console_service.print("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ï¼ˆä¾‹: episode_id, quality_levelï¼‰:")
        param_input = input("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ").strip()
        parameters = [p.strip() for p in param_input.split(",") if p.strip()] if param_input else []
        matches = self.find_similar_apis(function_name, parameters, description)
        if not matches:
            self.console_service.print("âœ… é¡ä¼¼ã™ã‚‹æ—¢å­˜APIã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        self.console_service.print(f"\nğŸ¯ {len(matches)}ä»¶ã®é¡ä¼¼APIã‚’ç™ºè¦‹:")
        for i, match in enumerate(matches[:5], 1):
            api = match.existing_api
            self.console_service.print(f"\n{i}. {api.function_name} (é¡ä¼¼åº¦: {match.similarity_score:.1%})")
            self.console_service.print(f"   ğŸ“ {api.file_path.relative_to(self.project_root)}:{api.line_number}")
            if api.class_name:
                self.console_service.print(f"   ğŸ·ï¸  ã‚¯ãƒ©ã‚¹: {api.class_name}")
            self.console_service.print(f"   ğŸ“‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {', '.join(api.parameters) or '(ãªã—)'}")
            if api.docstring:
                self.console_service.print(f"   ğŸ“ èª¬æ˜: {api.docstring[:100]}...")
            self.console_service.print(f"   ğŸ”— é¡ä¼¼ç†ç”±: {', '.join(match.similarity_reasons)}")
        nih_warnings = self.detect_nih_patterns(
            {"name": function_name, "parameters": parameters, "description": description}
        )
        if nih_warnings:
            self.console_service.print("\nâš ï¸ NIHç—‡å€™ç¾¤ã®å¯èƒ½æ€§:")
            for warning in nih_warnings:
                self.console_service.print(f"   {warning}")


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ—¢å­˜APIç™ºè¦‹ãƒ»é‡è¤‡ãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--project-root", type=Path, default=Path(), help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output", type=Path, help="çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆYAMLå½¢å¼ï¼‰")
    parser.add_argument("--interactive", action="store_true", help="å¯¾è©±å¼æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--function", type=str, help="æ¤œç´¢å¯¾è±¡ã®é–¢æ•°å")
    parser.add_argument("--description", type=str, help="æ©Ÿèƒ½ã®èª¬æ˜")
    args = parser.parse_args()
    from noveler.infrastructure.di.container import resolve_service

    try:
        resolve_service("IConsoleService")
    except ValueError:
        from noveler.infrastructure.adapters.console_service_adapter import ConsoleServiceAdapter

        ConsoleServiceAdapter()
    scanner = APIDiscoveryScanner(args.project_root)
    console.print("ğŸ” æ—¢å­˜APIã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
    apis = scanner.scan_existing_apis()
    console.print(f"ğŸ“Š {len(apis)}å€‹ã®APIã‚’ç™ºè¦‹")
    if args.output:
        scanner.export_scan_results(args.output)
        console.print(f"ğŸ“„ çµæœã‚’å‡ºåŠ›: {args.output}")
    if args.interactive:
        scanner.interactive_search()
    elif args.function:
        matches = scanner.find_similar_apis(args.function, description=args.description)
        if matches:
            console.print(f"\nğŸ¯ '{args.function}'ã«é¡ä¼¼ã™ã‚‹API:")
            for match in matches[:3]:
                api = match.existing_api
                console.print(f"  - {api.function_name} ({match.similarity_score:.1%})")
                console.print(f"    {api.file_path.relative_to(args.project_root)}:{api.line_number}")
        else:
            console.print(f"âœ… '{args.function}'ã«é¡ä¼¼ã™ã‚‹APIã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()
