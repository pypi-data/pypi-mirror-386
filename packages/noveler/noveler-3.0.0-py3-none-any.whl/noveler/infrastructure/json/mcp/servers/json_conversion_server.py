# ruff: noqa
"""FastMCP-backed JSON conversion server for the Noveler toolset."""

import asyncio
import hashlib
import json
import sys
import time
from dataclasses import asdict
from datetime import datetime, timezone
from functools import lru_cache
from pathlib import Path
from collections.abc import Iterable
from typing import Any

from noveler.infrastructure.factories.path_service_factory import create_path_service
from noveler.infrastructure.factories.progressive_write_llm_executor_factory import (
    create_progressive_write_llm_executor,
)
from noveler.infrastructure.factories.progressive_write_manager_factory import (
    create_progressive_write_manager,
)
from noveler.infrastructure.json.converters.cli_response_converter import CLIResponseConverter
from noveler.infrastructure.json.models.response_models import (
    ErrorResponseModel,
    StandardResponseModel,
)
from noveler.infrastructure.logging.unified_logger import get_logger
from noveler.infrastructure.performance.comprehensive_performance_optimizer import (
    ComprehensivePerformanceOptimizer,
)
from noveler.presentation.shared.shared_utilities import console

# project_nowé–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
try:
    from noveler.domain.value_objects.project_time import project_now
except ImportError:
    # MCPã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œç’°å¢ƒã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
    def project_now() -> object:
        """Fallback implementation of :func:`project_now`."""

        class FallbackProjectDateTime:
            """Fallback shim mimicking the ProjectDateTime interface."""

            def __init__(self, dt: datetime) -> None:
                self.datetime = dt

            def isoformat(self) -> str:
                return self.datetime.isoformat()

            def format_timestamp(self, fmt: str) -> str:
                return self.datetime.strftime(fmt)

        return FallbackProjectDateTime(datetime.now(timezone.utc))


# MCPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æœ‰ç„¡ã«å¿œã˜ã¦åˆ†å²
try:
    from mcp import types
    from mcp.server import stdio
    from mcp.server.fastmcp import FastMCP

    MCP_AVAILABLE = True
except ImportError:  # ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç’°å¢ƒã«MCPãŒç„¡ã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    MCP_AVAILABLE = False
    FastMCP = None  # type: ignore[assignment]
    types = None  # type: ignore[assignment]
    stdio = None  # type: ignore[assignment]


class FileIOCache:
    """High-performance file I/O cache used by the MCP server."""

    def __init__(self, max_size: int = 128, ttl_seconds: int = 300) -> None:
        """
        Args:
            max_size: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€å¤§ã‚µã‚¤ã‚º
            ttl_seconds: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰
        """
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self._cache: dict[str, dict[str, Any]] = {}
        self._access_times: dict[str, float] = {}
        self._file_hashes: dict[str, str] = {}

    def _get_file_hash(self, file_path: Path) -> str:
        """Return a lightweight file hash used for change detection."""
        try:
            stat = file_path.stat()
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨æ›´æ–°æ™‚åˆ»ã§ãƒãƒƒã‚·ãƒ¥ã‚’ç°¡ç•¥åŒ–ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–ï¼‰
            hash_source = f"{stat.st_size}:{stat.st_mtime}"
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶ã¯ä¸è¦ã ãŒã€é™çš„è§£æå›é¿ã®ãŸã‚SHA256ã‚’ä½¿ç”¨
            return hashlib.sha256(hash_source.encode()).hexdigest()
        except OSError:
            return ""

    def _is_cache_valid(self, key: str, file_path: Path) -> bool:
        """Return ``True`` when the cached entry is still valid."""
        if key not in self._cache:
            return False

        # TTLãƒã‚§ãƒƒã‚¯
        current_time = time.time()
        if current_time - self._access_times.get(key, 0) > self.ttl_seconds:
            return False

        # ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒã‚§ãƒƒã‚¯
        current_hash = self._get_file_hash(file_path)
        return current_hash == self._file_hashes.get(key, "")

    def _cleanup_expired(self) -> None:
        """Remove expired cache entries based on TTL."""
        current_time = time.time()
        expired_keys = [
            key for key, access_time in self._access_times.items() if current_time - access_time > self.ttl_seconds
        ]

        for key in expired_keys:
            self._cache.pop(key, None)
            self._access_times.pop(key, None)
            self._file_hashes.pop(key, None)

    def _evict_lru(self) -> None:
        """Evict the least recently accessed cache entry."""
        if len(self._cache) >= self.max_size:
            # æœ€ã‚‚å¤ã„ã‚¢ã‚¯ã‚»ã‚¹æ™‚åˆ»ã®ã‚­ãƒ¼ã‚’å‰Šé™¤
            lru_key = min(self._access_times.items(), key=lambda x: x[1])[0]
            self._cache.pop(lru_key, None)
            self._access_times.pop(lru_key, None)
            self._file_hashes.pop(lru_key, None)

    def get(self, file_path: Path, loader_func) -> Any:
        """Return cached data or use ``loader_func`` to populate the cache."""
        key = str(file_path)

        # æœŸé™åˆ‡ã‚Œã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self._cleanup_expired()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
        if self._is_cache_valid(key, file_path):
            self._access_times[key] = time.time()
            return self._cache[key]

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        try:
            data = loader_func(file_path)

            # LRUå‰Šé™¤
            self._evict_lru()

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            current_time = time.time()
            self._cache[key] = data
            self._access_times[key] = current_time
            self._file_hashes[key] = self._get_file_hash(file_path)

            return data
        except Exception:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒ‡ãƒ¼ã‚¿ã‚’çŸ­æœŸé–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            self._cache[key] = None
            self._access_times[key] = time.time()
            raise

    def invalidate(self, file_path: Path) -> None:
        """Invalidate the cached entry for the given file path."""
        key = str(file_path)
        self._cache.pop(key, None)
        self._access_times.pop(key, None)
        self._file_hashes.pop(key, None)

    def clear(self) -> None:
        """Clear all cached entries."""
        self._cache.clear()
        self._access_times.clear()
        self._file_hashes.clear()


class WritingSessionManager:
    """Manage staged writing sessions for the MCP server."""

    def __init__(self, project_root: Path) -> None:
        self.project_root = project_root
        self.sessions_dir = project_root / "90_ç®¡ç†" / "writing_sessions"
        self.sessions_dir.mkdir(parents=True, exist_ok=True)
        self.logger = get_logger(__name__)

    def create_session(self, episode: int, session_id: str) -> None:
        """Create a new writing session record."""
        try:
            import json
            from datetime import datetime, timezone

            session_file = self.sessions_dir / f"session_{session_id}.json"
            session_data = {
                "session_id": session_id,
                "episode": episode,
                "created_at": datetime.now(timezone.utc).isoformat(),
                "stages": {},
                "status": "active",
            }
            session_file.write_text(json.dumps(session_data, ensure_ascii=False, indent=2), encoding="utf-8")
            self.logger.info(f"æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ: {session_id}, Episode: {episode}")
        except Exception as e:
            self.logger.exception(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def save_stage_output(self, session_id: str, stage_name: str, output: dict) -> None:
        """Persist the output produced by an individual stage."""
        try:
            import json
            from datetime import datetime, timezone

            session_file = self.sessions_dir / f"session_{session_id}.json"
            if not session_file.exists():
                msg = f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {session_id}"
                raise ValueError(msg)
            session_data = json.loads(session_file.read_text(encoding="utf-8"))
            session_data["stages"][stage_name] = {
                "output": output,
                "completed_at": datetime.now(timezone.utc).isoformat(),
            }
            session_data["last_updated"] = datetime.now(timezone.utc).isoformat()
            session_file.write_text(json.dumps(session_data, ensure_ascii=False, indent=2), encoding="utf-8")
            self.logger.info(f"æ®µéšå‡ºåŠ›ä¿å­˜: {session_id}, Stage: {stage_name}")
        except Exception as e:
            self.logger.exception(f"æ®µéšå‡ºåŠ›ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def load_session(self, session_id: str) -> dict:
        """Load all recorded outputs for the specified session."""
        try:
            import json

            session_file = self.sessions_dir / f"session_{session_id}.json"
            if not session_file.exists():
                self.logger.warning(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {session_id}")
                return {}
            session_data = json.loads(session_file.read_text(encoding="utf-8"))
            combined_data = {}
            for stage_data in session_data["stages"].values():
                stage_output = stage_data["output"]
                for key, value in stage_output.items():
                    if key not in ["session_id", "timestamp", "stage"]:
                        combined_data[key] = value
            return combined_data
        except Exception as e:
            self.logger.exception(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def get_session_status(self, session_id: str) -> dict:
        """Return metadata describing the session status."""
        try:
            import json

            session_file = self.sessions_dir / f"session_{session_id}.json"
            if not session_file.exists():
                return {"exists": False}
            session_data = json.loads(session_file.read_text(encoding="utf-8"))
            completed_stages = list(session_data["stages"].keys())
            total_stages = 10
            return {
                "exists": True,
                "episode": session_data["episode"],
                "status": session_data["status"],
                "completed_stages": completed_stages,
                "progress": f"{len(completed_stages)}/{total_stages}",
                "created_at": session_data["created_at"],
                "last_updated": session_data.get("last_updated", session_data["created_at"]),
            }
        except Exception as e:
            self.logger.exception(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"exists": False, "error": str(e)}


class JSONConversionServer:
    """FastMCP JSON conversion server with performance optimisations."""

    def __init__(self, output_dir: Path | None = None, force_restart: bool = False) -> None:
        if not MCP_AVAILABLE:
            msg = "MCPãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚pip install mcp ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            raise RuntimeError(msg)

        # æ—©æœŸãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–ï¼ˆä¾å­˜é–¢ä¿‚å›é¿ï¼‰
        self.logger = get_logger(__name__)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self._init_performance_systems()

        self._handle_existing_processes(force_restart)
        self.output_dir = output_dir or Path.cwd() / "temp" / "json_output"
        self.converter = CLIResponseConverter(output_dir=self.output_dir)
        self.server = FastMCP(
            name="json-conversion",
            instructions="å°èª¬åŸ·ç­†æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  JSONå¤‰æ›ãƒ»MCPçµ±åˆã‚µãƒ¼ãƒãƒ¼ - CLIçµæœã‚’95%ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã§JSONåŒ–ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨SHA256å®Œå…¨æ€§ä¿è¨¼ã‚’æä¾›",
        )
        self._create_pid_file()
        self._register_tools()
        self._register_novel_tools()

    def _init_performance_systems(self) -> None:
        """Initialise caches and performance optimisation helpers."""
        # ãƒ•ã‚¡ã‚¤ãƒ«I/Oã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
        self.file_cache = FileIOCache(max_size=256, ttl_seconds=600)  # 10åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥

        # åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
        self.performance_optimizer = ComprehensivePerformanceOptimizer()

        # JSONå¤‰æ›ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–ï¼‰
        self._json_conversion_cache: dict[str, Any] = {}
        self._json_cache_access: dict[str, float] = {}

        # é »ç¹ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ“ä½œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._path_resolution_cache: dict[str, Path] = {}

        # éåŒæœŸã‚¿ã‚¹ã‚¯ç®¡ç†
        self._async_tasks: set[asyncio.Task] = set()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã¯runãƒ¡ã‚½ãƒƒãƒ‰ã§é–‹å§‹ï¼ˆéåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ï¼‰
        self._monitoring_initialized = False

    @lru_cache(maxsize=512)
    def _resolve_project_path(self, project_root: str | None) -> Path:
        """Resolve and cache project-relative paths."""
        if project_root:
            return Path(project_root)
        return Path.cwd()

    def _load_file_with_cache(self, file_path: Path) -> dict[str, Any]:
        """Load file contents consulting the FileIOCache."""

        def _load_yaml_file(path: Path) -> dict[str, Any]:
            import yaml

            try:
                with path.open("r", encoding="utf-8") as f:
                    return yaml.safe_load(f) or {}
            except Exception:
                return {}

        return self.file_cache.get(file_path, _load_yaml_file)

    def _optimize_json_conversion(self, data: dict[str, Any]) -> dict[str, Any]:
        """Return an optimised JSON payload using caching and truncation."""
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
        data_str = str(sorted(data.items()))
        cache_key = hashlib.md5(data_str.encode()).hexdigest()

        current_time = time.time()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç¢ºèªï¼ˆ5åˆ†é–“æœ‰åŠ¹ï¼‰
        if cache_key in self._json_conversion_cache and current_time - self._json_cache_access.get(cache_key, 0) < 300:
            self._json_cache_access[cache_key] = current_time
            return self._json_conversion_cache[cache_key]

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼šæ–°è¦å¤‰æ›å®Ÿè¡Œ
        optimized_data = self._perform_json_optimization(data)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºç®¡ç†ï¼ˆæœ€å¤§100ã‚¨ãƒ³ãƒˆãƒªï¼‰
        if len(self._json_conversion_cache) >= 100:
            # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
            oldest_key = min(self._json_cache_access.items(), key=lambda x: x[1])[0]
            self._json_conversion_cache.pop(oldest_key, None)
            self._json_cache_access.pop(oldest_key, None)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        self._json_conversion_cache[cache_key] = optimized_data
        self._json_cache_access[cache_key] = current_time

        return optimized_data

    def _perform_json_optimization(self, data: dict[str, Any]) -> dict[str, Any]:
        """Fallback implementation performing JSON optimisation when no optimiser is available."""
        # å¤§ããªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€é©åŒ–
        optimized = {}
        for key, value in data.items():
            if isinstance(value, str) and len(value) > 10000:
                # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯è¦ç´„åŒ–
                optimized[key] = self._summarize_long_text(value)
            elif isinstance(value, list) and len(value) > 100:
                # é•·ã„ãƒªã‚¹ãƒˆã¯åˆ¶é™
                optimized[key] = [*value[:50], "... (truncated)"]
            else:
                optimized[key] = value

        return optimized

    def _summarize_long_text(self, text: str) -> str:
        """Return a truncated representation ensuring the string fits ``max_length``."""
        if len(text) <= 10000:
            return text

        # å…ˆé ­ã¨æœ«å°¾ã‚’ä¿æŒã—ã¦ä¸­é–“ã‚’çœç•¥
        return f"{text[:3000]}...\n\n[{len(text) - 6000}æ–‡å­—çœç•¥]\n\n...{text[-3000:]}"

    async def _cleanup_async_tasks(self) -> None:
        """Cancel and clear internal asynchronous tasks."""
        completed_tasks = [task for task in self._async_tasks if task.done()]
        for task in completed_tasks:
            self._async_tasks.discard(task)
            try:
                await task
            except Exception as e:
                self.logger.warning(f"éåŒæœŸã‚¿ã‚¹ã‚¯å®Œäº†æ™‚ã‚¨ãƒ©ãƒ¼: {e}")

    def _schedule_async_task(self, coro) -> None:
        """Schedule a background task and track it for later cleanup."""
        task = asyncio.create_task(coro)
        self._async_tasks.add(task)

        # ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        def cleanup_task(t) -> None:
            self._async_tasks.discard(t)

        task.add_done_callback(cleanup_task)

    def _init_performance_monitoring(self) -> None:
        """Initialise the performance monitoring subsystem."""
        try:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’éåŒæœŸã§é–‹å§‹
            monitoring_task = asyncio.create_task(self._run_performance_monitoring())
            self._async_tasks.add(monitoring_task)

            # å®šæœŸçš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚‚é–‹å§‹
            cleanup_task = asyncio.create_task(self._periodic_cache_cleanup())
            self._async_tasks.add(cleanup_task)

        except Exception as e:
            self.logger.warning(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    async def _run_performance_monitoring(self) -> None:
        """Continuously monitor server performance metrics."""
        while True:
            try:
                # 5åˆ†ã”ã¨ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
                await asyncio.sleep(300)

                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
                import psutil

                process = psutil.Process()
                memory_mb = process.memory_info().rss / 1024 / 1024

                if memory_mb > 512:  # 512MBä»¥ä¸Šã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    self._emergency_cache_cleanup()
                    self.logger.info(
                        f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ: {memory_mb:.1f}MB -> {process.memory_info().rss / 1024 / 1024:.1f}MB"
                    )

                # éåŒæœŸã‚¿ã‚¹ã‚¯ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                await self._cleanup_async_tasks()

            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.exception(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")

    async def _periodic_cache_cleanup(self) -> None:
        """Periodically clean caches to release memory."""
        while True:
            try:
                # 30åˆ†ã”ã¨ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                await asyncio.sleep(1800)

                self._cleanup_cache_systems()
                self.logger.info("å®šæœŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.exception(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _cleanup_cache_systems(self) -> None:
        """Clear caches including JSON conversion and path resolution."""
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        old_size = len(self.file_cache._cache)
        self.file_cache._cleanup_expired()
        new_size = len(self.file_cache._cache)

        # JSONå¤‰æ›ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        current_time = time.time()
        expired_json_keys = [
            key
            for key, access_time in self._json_cache_access.items()
            if current_time - access_time > 1800  # 30åˆ†
        ]

        for key in expired_json_keys:
            self._json_conversion_cache.pop(key, None)
            self._json_cache_access.pop(key, None)

        self.logger.debug(
            f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: ãƒ•ã‚¡ã‚¤ãƒ« {old_size}->{new_size}, JSONå¤‰æ› {len(expired_json_keys)}å€‹å‰Šé™¤"
        )

    def _emergency_cache_cleanup(self) -> None:
        """Clear caches immediately in case of emergency."""
        # å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        self.file_cache.clear()
        self._json_conversion_cache.clear()
        self._json_cache_access.clear()
        self._path_resolution_cache.clear()

        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¼·åˆ¶å®Ÿè¡Œ
        import gc

        gc.collect()

        self.logger.info("ç·Šæ€¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

    def _register_tools(self) -> None:
        """Register FastMCP tools exposed by the server."""
        self._register_cli_conversion_tool()
        self._register_validation_tool()
        self._register_file_reference_tool()
        self._register_artifact_tools()
        # FastMCPã®APIã«ã‚ˆã‚Šregister_toolæœªæä¾›ã®å ´åˆãŒã‚ã‚‹ãŸã‚ã‚¬ãƒ¼ãƒ‰
        if hasattr(self.server, "register_tool"):
            self._register_18step_writing_tools()  # 18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†ã‚·ã‚¹ãƒ†ãƒ ä¸¦åˆ—å®Ÿè¡Œãƒ„ãƒ¼ãƒ«è¿½åŠ 

    def _register_cli_conversion_tool(self) -> None:
        """Register the CLI-to-JSON conversion tool."""

        @self.server.tool(
            name="convert_cli_to_json",
            description="CLIå®Ÿè¡Œçµæœã‚’JSONå½¢å¼ã«å¤‰æ›ã—ã€95%ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã¨ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é©ç”¨",
        )
        def convert_cli_to_json(cli_result: dict[str, Any]) -> str:
            """Convert CLI output into the JSON structure used by clients."""
            try:
                if not cli_result:
                    return "ã‚¨ãƒ©ãƒ¼: cli_resultãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"
                json_result = self.converter.convert(cli_result)
                return f"å¤‰æ›æˆåŠŸ:\n{self._format_json_result(json_result)}"
            except Exception as e:
                self.logger.exception("CLIâ†’JSONå¤‰æ›ã‚¨ãƒ©ãƒ¼")
                return f"å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e!s}"

    def _register_validation_tool(self) -> None:
        """Register the JSON response validation tool."""

        @self.server.tool(name="validate_json_response", description="JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼æ¤œè¨¼")
        def validate_json_response(json_data: dict[str, Any]) -> str:
            """Validate that the JSON payload matches the response schema."""
            try:
                if not json_data:
                    return "ã‚¨ãƒ©ãƒ¼: json_dataãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"
                if json_data.get("success", False):
                    model = StandardResponseModel(**json_data)
                else:
                    model = ErrorResponseModel(**json_data)
                return f"JSONå½¢å¼æ¤œè¨¼æˆåŠŸ: {model.__class__.__name__}"
            except Exception as e:
                return f"JSONå½¢å¼æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e!s}"

    def _register_file_reference_tool(self) -> None:
        """Register the file reference lookup tool."""

        @self.server.tool(name="get_file_reference_info", description="ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§æƒ…å ±å–å¾—")
        def get_file_reference_info(file_path: str) -> str:
            """ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§æƒ…å ±å–å¾—"""
            try:
                if not file_path:
                    return "ã‚¨ãƒ©ãƒ¼: file_pathãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"
                candidate_paths = [self.output_dir / file_path, Path.cwd() / file_path, Path.cwd().parent / file_path]
                for full_path in candidate_paths:
                    if full_path.exists():
                        stat = full_path.stat()
                        info = {
                            "path": file_path,
                            "absolute_path": str(full_path),
                            "size_bytes": stat.st_size,
                            "modified": datetime.fromtimestamp(stat.st_mtime, tz=timezone.utc).isoformat(),
                            "exists": True,
                        }
                        return f"ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:\n{self._format_dict(info)}"
                info = {
                    "path": file_path,
                    "exists": False,
                    "searched_paths": [str(p) for p in candidate_paths],
                    "current_working_directory": str(Path.cwd()),
                    "suggestion": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ã€ã¾ãŸã¯åŸ·ç­†ãŒã¾ã é–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“",
                }
                return f"ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§çµæœ:\n{self._format_dict(info)}"
            except Exception as e:
                return f"ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e!s}"

    def _register_novel_tools(self) -> None:
        """Register Noveler-specific tool groups."""
        self._register_write_tools()
        self._register_staged_writing_tools()
        # self._register_claude_write_tools()  # éå…¬é–‹ï¼šå®Ÿè£…ã¯æ®‹ã™ãŒãƒ„ãƒ¼ãƒ«ç™»éŒ²ã—ãªã„
        self._register_check_tools()
        self._register_plot_tools()
        self._register_project_tools()

    def _handle_existing_processes(self, force_restart: bool = False) -> None:
        """Terminate stale server processes by inspecting PID files."""
        try:
            import os

            import psutil

            current_pid = os.getpid()
            psutil.Process(current_pid)
            matching_processes = []
            for proc in psutil.process_iter(["pid", "name", "cmdline"]):
                try:
                    if (
                        proc.info["name"]
                        and "python" in proc.info["name"].lower()
                        and proc.info["cmdline"]
                        and any("json_conversion_server" in str(arg) for arg in proc.info["cmdline"])
                    ):
                        if proc.pid != current_pid:
                            matching_processes.append(proc)
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
            if matching_processes:
                if force_restart:
                    for proc in matching_processes:
                        try:
                            self._terminate_process_gracefully(proc)
                            self.logger.info(f"æ—¢å­˜MCPã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†: PID {proc.pid}")
                        except Exception as e:
                            self.logger.warning(f"ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†å¤±æ•— PID {proc.pid}: {e}")
                else:
                    pid_list = [str(proc.pid) for proc in matching_processes]
                    self.logger.warning(f"æ—¢å­˜MCPã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹æ¤œå‡º: PID {', '.join(pid_list)}")
                    self.logger.info(
                        "é‡è¤‡å®Ÿè¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã€force_restart=True ã§å†èµ·å‹•ã™ã‚‹ã‹ã€æ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ‰‹å‹•çµ‚äº†ã—ã¦ãã ã•ã„"
                    )
                    msg = f"MCPã‚µãƒ¼ãƒãƒ¼é‡è¤‡å®Ÿè¡Œæ¤œå‡º (PID: {', '.join(pid_list)})"
                    raise RuntimeError(msg)
        except ImportError:
            self.logger.warning("psutilãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ—ãƒ­ã‚»ã‚¹é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        except Exception as e:
            self.logger.warning(f"ãƒ—ãƒ­ã‚»ã‚¹é‡è¤‡ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {e}")

    def _terminate_process_gracefully(self, process) -> None:
        """Terminate the process using SIGTERM/SIGKILL."""
        try:
            import psutil

            process.terminate()
            try:
                process.wait(timeout=5)
            except psutil.TimeoutExpired:
                process.kill()
                process.wait(timeout=2)
        except Exception as e:
            msg = f"ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†å¤±æ•—: {e}"
            raise RuntimeError(msg) from e

    def _create_pid_file(self) -> None:
        """Persist the current process ID to the PID file."""
        try:
            import os

            pid_dir = Path.cwd() / "temp" / "pids"
            pid_dir.mkdir(parents=True, exist_ok=True)
            pid_file = pid_dir / "json_conversion_server.pid"
            with pid_file.open("w") as f:
                f.write(str(os.getpid()))
            self.pid_file = pid_file
            self.logger.info(f"PIDãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {pid_file}")
        except Exception as e:
            self.logger.warning(f"PIDãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•—: {e}")
            self.pid_file = None

    def _cleanup_pid_file(self) -> None:
        """Remove the PID file if it exists."""
        try:
            if hasattr(self, "pid_file") and self.pid_file and self.pid_file.exists():
                self.pid_file.unlink()
                self.logger.info(f"PIDãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {self.pid_file}")
        except Exception as e:
            self.logger.warning(f"PIDãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")

    def __del__(self) -> None:
        """Destructor hook that removes the PID file on shutdown."""
        self._cleanup_pid_file()

    def _register_write_tools(self) -> None:
        """Register 10-stage writing helper tools."""

        @self.server.tool(
            name="write", description="å°èª¬ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åŸ·ç­†ï¼ˆA38æº–æ‹ 18ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼‰ - æ§‹é€ è¨­è¨ˆã‹ã‚‰å…¬é–‹æº–å‚™ã¾ã§æ®µéšçš„å®Ÿè¡Œ"
        )
        async def write(episode: int, dry_run: bool = False, project_root: str | None = None) -> str:
            """Execute the 18-step writing workflow."""
            try:
                import json
                from pathlib import Path

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
                if project_root:
                    project_path = Path(project_root)
                else:
                    from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root

                # 18ã‚¹ãƒ†ãƒƒãƒ—å®šç¾©ï¼ˆA38æº–æ‹ ï¼‰
                steps = [
                    {"id": 0, "name": "ã‚¹ã‚³ãƒ¼ãƒ—å®šç¾©", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step00.yaml"},
                    {"id": 1, "name": "å¤§éª¨ï¼ˆç« ã®ç›®çš„ç·šï¼‰", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step01.yaml"},
                    {"id": 2, "name": "ä¸­éª¨ï¼ˆæ®µéšç›®æ¨™ï¼‰", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step02.yaml"},
                    {"id": 3, "name": "ãƒ†ãƒ¼ãƒæ€§ãƒ»ç‹¬è‡ªæ€§æ¤œè¨¼", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step03.yaml"},
                    {"id": 3, "name": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ©ãƒ³ã‚¹è¨­è¨ˆ", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step03.yaml"},
                    {"id": 4, "name": "å°éª¨ï¼ˆã‚·ãƒ¼ãƒ³ï¼ãƒ“ãƒ¼ãƒˆï¼‰", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step04.yaml"},
                    {"id": 5, "name": "è«–ç†æ¤œè¨¼", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step05.yaml"},
                    {"id": 6, "name": "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§æ¤œè¨¼", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step06.yaml"},
                    {"id": 7, "name": "ä¼šè©±è¨­è¨ˆ", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step07.yaml"},
                    {"id": 8, "name": "æ„Ÿæƒ…æ›²ç·š", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step08.yaml"},
                    {"id": 9, "name": "æƒ…æ™¯ãƒ»äº”æ„Ÿãƒ»ä¸–ç•Œè¦³", "phase": "æ§‹é€ è¨­è¨ˆ", "file_suffix": "step09.yaml"},
                    {"id": 10, "name": "åˆç¨¿ç”Ÿæˆ", "phase": "åŸ·ç­†å®Ÿè£…", "file_suffix": "step10.md"},
                    {"id": 11, "name": "æ–‡å­—æ•°æœ€é©åŒ–", "phase": "åŸ·ç­†å®Ÿè£…", "file_suffix": "step11.md"},
                    {"id": 12, "name": "æ–‡ä½“ãƒ»å¯èª­æ€§ãƒ‘ã‚¹", "phase": "åŸ·ç­†å®Ÿè£…", "file_suffix": "step12.md"},
                    {"id": 13, "name": "å¿…é ˆå“è³ªã‚²ãƒ¼ãƒˆ", "phase": "å“è³ªä¿è¨¼", "file_suffix": "step13.yaml"},
                    {"id": 14, "name": "æœ€çµ‚å“è³ªèªå®š", "phase": "å“è³ªä¿è¨¼", "file_suffix": "step14.yaml"},
                    {"id": 15, "name": "å…¬é–‹æº–å‚™", "phase": "å…¬é–‹", "file_suffix": "step15.yaml"},
                ]

                # å®Ÿè¡Œçµæœã‚’æ ¼ç´
                execution_log = []
                completed_steps = 0

                for step in steps:
                    step_id = step["id"]
                    step_name = step["name"]
                    step_phase = step["phase"]

                    try:
                        # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹ãƒ­ã‚°
                        start_msg = f"ğŸ”„ STEP {step_id}: {step_name} ã‚’é–‹å§‹ä¸­..."
                        execution_log.append(
                            {
                                "step": step_id,
                                "name": step_name,
                                "phase": step_phase,
                                "status": "started",
                                "message": start_msg,
                            }
                        )

                        # å®Ÿéš›ã®å‡¦ç†ã¯ã“ã“ã«å®Ÿè£…ï¼ˆç¾æ™‚ç‚¹ã§ã¯æ¨¡æ“¬å®Ÿè¡Œï¼‰
                        if not dry_run:
                            # TODO: å„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿéš›ã®å‡¦ç†ã‚’å®Ÿè£…
                            # ä¾‹ï¼šãƒ—ãƒ­ãƒƒãƒˆè§£æã€ä¼šè©±ç”Ÿæˆã€åŸç¨¿ä½œæˆãªã©
                            await self._execute_step(step_id, episode, project_path)

                        # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ãƒ­ã‚°
                        complete_msg = f"âœ… STEP {step_id}: {step_name} å®Œäº†"
                        execution_log.append(
                            {
                                "step": step_id,
                                "name": step_name,
                                "phase": step_phase,
                                "status": "completed",
                                "message": complete_msg,
                            }
                        )
                        completed_steps += 1

                    except Exception as step_error:
                        # ã‚¹ãƒ†ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
                        error_msg = f"âŒ STEP {step_id}: {step_name} ã§ã‚¨ãƒ©ãƒ¼ - {step_error!s}"
                        execution_log.append(
                            {
                                "step": step_id,
                                "name": step_name,
                                "phase": step_phase,
                                "status": "error",
                                "message": error_msg,
                                "error": str(step_error),
                            }
                        )
                        break

                # å®Ÿè¡Œçµæœã®æ•´ç†
                is_complete = completed_steps == len(steps)

                result = {
                    "success": is_complete,
                    "episode": episode,
                    "total_steps": len(steps),
                    "completed_steps": completed_steps,
                    "completion_rate": f"{(completed_steps / len(steps) * 100):.1f}%",
                    "execution_log": execution_log,
                    "final_status": "å®Œäº†" if is_complete else f"ä¸­æ–­ï¼ˆ{completed_steps}/{len(steps)}ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ï¼‰",
                }

                return self._json_with_path_fallback(result, locals())

            except Exception as e:
                self.logger.exception("18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
                return json.dumps(
                    {"success": False, "error": str(e), "message": "18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"},
                    ensure_ascii=False,
                    indent=2,
                )

        @self.server.tool(
            name="write_stage",
            description="ç‰¹å®šã‚¹ãƒ†ãƒ¼ã‚¸ã®ã¿åŸ·ç­†å®Ÿè¡Œ - 10æ®µéšã®ç‰¹å®šã‚¹ãƒ†ãƒ¼ã‚¸ï¼ˆplot_data_preparationç­‰ï¼‰ã‚’å€‹åˆ¥å®Ÿè¡Œãƒ»å†é–‹å¯èƒ½",
        )
        def write_stage(
            episode: int, stage: str, resume_session: str | None = None, project_root: str | None = None
        ) -> str:
            """Execute a single stage of the 18-step workflow."""
            try:
                cmd = f"core write-stage {episode} --stage {stage}"
                if resume_session:
                    cmd += f" --resume {resume_session}"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, f"ã‚¹ãƒ†ãƒ¼ã‚¸å®Ÿè¡Œ: {stage}")
            except Exception as e:
                self.logger.exception("ã‚¹ãƒ†ãƒ¼ã‚¸å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
                return f"ã‚¹ãƒ†ãƒ¼ã‚¸å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"

        @self.server.tool(
            name="write_resume", description="ä¸­æ–­ä½ç½®ã‹ã‚‰åŸ·ç­†å†é–‹ - ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’æŒ‡å®šã—ã¦å‰å›ã®ç¶šãã‹ã‚‰å®Ÿè¡Œ"
        )
        def write_resume(episode: int, session_id: str, project_root: str | None = None) -> str:
            """ä¸­æ–­ä½ç½®ã‹ã‚‰å†é–‹"""
            try:
                cmd = f"core write {episode} --resume {session_id}"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "åŸ·ç­†å†é–‹")
            except Exception as e:
                self.logger.exception("åŸ·ç­†å†é–‹ã‚¨ãƒ©ãƒ¼")
                return f"åŸ·ç­†å†é–‹ã‚¨ãƒ©ãƒ¼: {e}"

    def _register_claude_write_tools(self) -> None:
        """Claude Codeå†…ã§ã®ç›´æ¥åŸç¨¿ç”Ÿæˆãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="write_with_claude",
            description="Claude Codeå†…ã§ç›´æ¥åŸç¨¿ç”Ÿæˆï¼ˆå¤–éƒ¨APIä¸è¦ï¼‰ - ãƒ—ãƒ­ãƒƒãƒˆã‹ã‚‰åŸç¨¿ã‚’ç›´æ¥ç”Ÿæˆã—ã¾ã™",
        )
        async def write_with_claude(
            episode: int,
            plot_content: str | None = None,
            word_count_target: int = 4000,
            project_root: str | None = None,
        ) -> str:
            """Claude Codeå†…ã§ç›´æ¥åŸç¨¿ã‚’ç”Ÿæˆ

            Args:
                episode: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·
                plot_content: ãƒ—ãƒ­ãƒƒãƒˆå†…å®¹ï¼ˆçœç•¥æ™‚ã¯æ—¢å­˜ãƒ—ãƒ­ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ï¼‰
                word_count_target: ç›®æ¨™æ–‡å­—æ•°
                project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ

            Returns:
                ç”Ÿæˆçµæœã®JSONæ–‡å­—åˆ—
            """
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                plot_title = None
                if not plot_content:
                    # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨
                    # use MCP-aware path service so tests can patch this factory
                    plot_ps = create_mcp_aware_path_service()

                    # PathServiceã§ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ±º
                    plot_file = plot_ps.get_episode_plot_path(episode)

                    if plot_file and plot_file.exists():
                        plot_content = plot_file.read_text(encoding="utf-8")
                        plot_title = self._extract_title_from_plot(plot_content)
                    else:
                        return json.dumps(
                            {"success": False, "error": f"ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ç¬¬{episode:03d}è©±"},
                            ensure_ascii=False,
                            indent=2,
                        )
                else:
                    plot_title = self._extract_title_from_plot(plot_content)
                # B20æº–æ‹ : åŸç¨¿ãƒ•ã‚¡ã‚¤ãƒ«åã¯PathServiceã«ä¸€å…ƒåŒ–ï¼ˆã‚¿ã‚¤ãƒˆãƒ«è§£æ±ºå«ã‚€ï¼‰
                path_service = create_path_service()
                manuscript_file = path_service.get_manuscript_path(episode)
                manuscript_filename = manuscript_file.name
                # ãƒ‘ã‚¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’é›†ç´„
                fallback_events = []
                try:
                    if hasattr(path_service, "get_and_clear_fallback_events"):
                        fallback_events += path_service.get_and_clear_fallback_events() or []
                except Exception:
                    pass
                try:
                    if "plot_ps" in locals() and hasattr(plot_ps, "get_and_clear_fallback_events"):
                        fallback_events += plot_ps.get_and_clear_fallback_events() or []
                except Exception:
                    pass
                manuscript_prompt = f"\n# ç¬¬{episode:03d}è©± åŸç¨¿ç”Ÿæˆ\n\n## ãƒ—ãƒ­ãƒƒãƒˆ\n{plot_content}\n\n## åŸ·ç­†è¦ä»¶\n- ç›®æ¨™æ–‡å­—æ•°: {word_count_target}æ–‡å­—\n- ã‚¸ãƒ£ãƒ³ãƒ«: ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼\n- è¦–ç‚¹: ä¸‰äººç§°å˜å…ƒè¦–ç‚¹\n- æ–‡ä½“: ãƒ©ã‚¤ãƒˆãƒãƒ™ãƒ«èª¿\n\n## å“è³ªåŸºæº–\n- æ„Ÿæƒ…è¡¨ç¾: èº«ä½“åå¿œã€æ„Ÿè¦šæ¯”å–©ã€å†…é¢ç‹¬ç™½ã®ä¸‰å±¤è¡¨ç¾ã‚’æœ€ä½3å›å®Ÿè£…\n- å¯¾è©±æ¯”ç‡: 60%ç¨‹åº¦\n- å ´é¢æå†™: äº”æ„Ÿã‚’ä½¿ã£ãŸæå†™ã‚’æ„è­˜\n- ãƒ†ãƒ³ãƒ: ç·Šå¼µã¨ç·©å’Œã®ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¤\n\nä»¥ä¸‹ã®å½¢å¼ã§åŸç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š\n\n# ç¬¬{episode:03d}è©± {plot_title or '[ã‚¿ã‚¤ãƒˆãƒ«]'}\n\n[æœ¬æ–‡ã‚’ã“ã“ã«è¨˜è¿°]\n"
                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨ï¼ˆä¸Šã§è§£æ±ºæ¸ˆã¿ï¼‰
                manuscript_dir = manuscript_file.parent
                manuscript_dir.mkdir(exist_ok=True)
                result = {
                    "success": True,
                    "prompt": manuscript_prompt,
                    "manuscript_path": str(manuscript_file),
                    "manuscript_filename": manuscript_filename,
                    "episode": episode,
                    "plot_title": plot_title,
                    "word_count_target": word_count_target,
                    "timestamp": project_now().datetime.isoformat(),
                    "instructions": "ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦Claudeå†…ã§åŸç¨¿ã‚’ç”Ÿæˆã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ä¿å­˜ã—ã¦ãã ã•ã„",
                    "path_fallback_used": bool(fallback_events),
                    "path_fallback_events": fallback_events,
                }
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("ClaudeåŸç¨¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"åŸç¨¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

    def _extract_title_from_plot(self, plot_content: str) -> str | None:
        """ãƒ—ãƒ­ãƒƒãƒˆå†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º

        Args:
            plot_content: ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹

        Returns:
            æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
        """
        import re

        if not plot_content:
            return None
        patterns = [
            "[-*]\\s*ã‚¿ã‚¤ãƒˆãƒ«[ï¼š:]\\s*(.+)",
            "##?\\s*ã‚¿ã‚¤ãƒˆãƒ«[ï¼š:]?\\s*(.+)",
            "ã‚¿ã‚¤ãƒˆãƒ«[ï¼š:]\\s*(.+)",
            "[-*]\\s*è©±ã®ã‚¿ã‚¤ãƒˆãƒ«[ï¼š:]\\s*(.+)",
            "##?\\s*è©±ã®ã‚¿ã‚¤ãƒˆãƒ«[ï¼š:]?\\s*(.+)",
            "#\\s*ç¬¬\\d+è©±\\s+(.+)",
        ]
        for pattern in patterns:
            match = re.search(pattern, plot_content, re.MULTILINE | re.IGNORECASE)
            if match:
                title = match.group(1).strip()
                title = re.sub("^[#\\-*\\s]+", "", title)
                title = re.sub("[#\\s]+$", "", title)
                if title:
                    return title
        return None

    def _json_with_path_fallback(self, result: dict, local_vars: dict) -> str:
        """PathServiceã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’resultã«ä»˜åŠ ã—ã¦JSONæ–‡å­—åˆ—ã‚’è¿”ã™"""
        try:
            fallback_events: list[dict] = []
            for _, val in list(local_vars.items()):
                if hasattr(val, "get_and_clear_fallback_events"):
                    try:
                        ev = val.get_and_clear_fallback_events() or []
                        if ev:
                            fallback_events.extend(ev)
                    except Exception:
                        continue
            if fallback_events:
                result["path_fallback_used"] = True
                result["path_fallback_events"] = fallback_events
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã®ä»˜åŠ ã«å¤±æ•—ã—ã¦ã‚‚çµæœã®JSONåŒ–ã¯ç¶™ç¶šã™ã‚‹
            pass
        # ä¸Šä½ã§jsonã‚’importæ¸ˆã¿
        return json.dumps(result, ensure_ascii=False, indent=2)

    def _register_staged_writing_tools(self) -> None:
        """æ®µéšåˆ¥åŸ·ç­†ãƒ„ãƒ¼ãƒ«ç™»éŒ²ï¼ˆSPEC-WRITE-STAGE-001æº–æ‹ ï¼‰"""
        # å·¨å¤§ãƒ¡ã‚½ãƒƒãƒ‰åˆ†å‰²ï¼šæ©Ÿèƒ½åˆ¥ã«ãƒ„ãƒ¼ãƒ«ç™»éŒ²ã‚’åˆ†é›¢
        self._register_plot_preparation_tools()
        self._register_manuscript_writing_tools()
        self._register_content_analysis_tools()
        self._register_creative_design_tools()
        self._register_quality_refinement_tools()

    def _register_18step_writing_tools(self) -> None:
        """18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ãƒ„ãƒ¼ãƒ«ã‚’ç™»éŒ²"""

        # åŸºæœ¬ã®18ã‚¹ãƒ†ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«
        self.server.register_tool(
            "get_writing_tasks",
            "18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—",
            {
                "type": "object",
                "properties": {
                    "episode_number": {"type": "integer", "description": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·"},
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
                "required": ["episode_number"],
            },
            self._handle_get_writing_tasks,
        )

        self.server.register_tool(
            "execute_writing_step",
            "18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å®šã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œï¼ˆUI/UXçµ±åˆç‰ˆï¼‰",
            {
                "type": "object",
                "properties": {
                    "step_id": {"type": "number", "description": "å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—IDï¼ˆ1-18ã€2.5ãªã©ã®å°æ•°ç‚¹ã‚‚å¯èƒ½ï¼‰"},
                    "episode_number": {"type": "integer", "description": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·"},
                    "dry_run": {
                        "type": "boolean",
                        "description": "ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰",
                        "default": False,
                    },
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                    "ui_mode": {"type": "boolean", "description": "UIè¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰", "default": True},
                },
                "required": ["step_id", "episode_number"],
            },
            self._handle_execute_writing_step,
        )

        self.server.register_tool(
            "execute_writing_steps_parallel",
            "è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®ä¸¦åˆ—å®Ÿè¡Œï¼ˆUI/UXçµ±åˆç‰ˆï¼‰",
            {
                "type": "object",
                "properties": {
                    "step_ids": {
                        "type": "array",
                        "items": {"type": "number"},
                        "description": "ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—IDã®ãƒªã‚¹ãƒˆ",
                    },
                    "episode_number": {"type": "integer", "description": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·"},
                    "max_concurrent": {
                        "type": "integer",
                        "description": "æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰",
                        "default": 3,
                    },
                    "dry_run": {
                        "type": "boolean",
                        "description": "ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰",
                        "default": False,
                    },
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                    "ui_mode": {"type": "boolean", "description": "UIè¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰", "default": True},
                },
                "required": ["step_ids", "episode_number"],
            },
            self._handle_execute_writing_steps_parallel,
        )

        self.server.register_tool(
            "get_task_status",
            "18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†ã‚·ã‚¹ãƒ†ãƒ ã®ç¾åœ¨çŠ¶æ³ã‚’ç¢ºèªï¼ˆUI/UXçµ±åˆç‰ˆï¼‰",
            {
                "type": "object",
                "properties": {
                    "episode_number": {"type": "integer", "description": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·"},
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                    "include_ui_status": {
                        "type": "boolean",
                        "description": "UIçŠ¶æ…‹ã‚’å«ã‚ã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰",
                        "default": True,
                    },
                },
                "required": ["episode_number"],
            },
            self._handle_get_task_status,
        )

        # æ–°ã—ã„UI/UXæ©Ÿèƒ½ãƒ„ãƒ¼ãƒ«
        self.server.register_tool(
            "create_batch_job",
            "è¤‡æ•°ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¸€æ‹¬å‡¦ç†ã‚¸ãƒ§ãƒ–ã®ä½œæˆ",
            {
                "type": "object",
                "properties": {
                    "episode_numbers": {
                        "type": "array",
                        "items": {"type": "integer"},
                        "description": "å‡¦ç†ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·ã®ãƒªã‚¹ãƒˆ",
                    },
                    "step_ids": {
                        "type": "array",
                        "items": {"type": "integer"},
                        "description": "å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—IDã®ãƒªã‚¹ãƒˆï¼ˆçœç•¥æ™‚ã¯å…¨18ã‚¹ãƒ†ãƒƒãƒ—ï¼‰",
                    },
                    "job_name": {"type": "string", "description": "ã‚¸ãƒ§ãƒ–åï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰"},
                    "max_concurrent": {
                        "type": "integer",
                        "description": "æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰",
                        "default": 3,
                    },
                    "priority": {"type": "integer", "description": "å„ªå…ˆåº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0ï¼‰", "default": 0},
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
                "required": ["episode_numbers"],
            },
            self._handle_create_batch_job,
        )

        self.server.register_tool(
            "execute_batch_job",
            "ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œ",
            {
                "type": "object",
                "properties": {
                    "job_id": {"type": "string", "description": "å®Ÿè¡Œã™ã‚‹ã‚¸ãƒ§ãƒ–ID"},
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
                "required": ["job_id"],
            },
            self._handle_execute_batch_job,
        )

        self.server.register_tool(
            "get_batch_status",
            "ãƒãƒƒãƒå‡¦ç†çŠ¶æ³ã®ç¢ºèª",
            {
                "type": "object",
                "properties": {
                    "job_id": {"type": "string", "description": "ç‰¹å®šã‚¸ãƒ§ãƒ–ã®çŠ¶æ³ï¼ˆçœç•¥æ™‚ã¯å…¨ä½“çŠ¶æ³ï¼‰"},
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
            },
            self._handle_get_batch_status,
        )

        self.server.register_tool(
            "analyze_episode_quality",
            "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å“è³ªãƒ»æ„Ÿæƒ…ãƒ»ç‰©èªåˆ†æ",
            {
                "type": "object",
                "properties": {
                    "episode_numbers": {
                        "type": "array",
                        "items": {"type": "integer"},
                        "description": "åˆ†æã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·ã®ãƒªã‚¹ãƒˆ",
                    },
                    "analysis_types": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["emotion", "narrative", "quality", "all"]},
                        "description": "åˆ†æç¨®é¡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ['all']ï¼‰",
                        "default": ["all"],
                    },
                    "generate_dashboard": {
                        "type": "boolean",
                        "description": "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰",
                        "default": True,
                    },
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
                "required": ["episode_numbers"],
            },
            self._handle_analyze_episode_quality,
        )

        self.server.register_tool(
            "get_progress_display",
            "é€²æ—è¡¨ç¤ºæƒ…å ±ã®å–å¾—",
            {
                "type": "object",
                "properties": {
                    "episode_number": {"type": "integer", "description": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·"},
                    "detailed": {"type": "boolean", "description": "è©³ç´°è¡¨ç¤ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰", "default": False},
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
                "required": ["episode_number"],
            },
            self._handle_get_progress_display,
        )

        self.server.register_tool(
            "export_ui_reports",
            "UIåˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            {
                "type": "object",
                "properties": {
                    "episode_numbers": {
                        "type": "array",
                        "items": {"type": "integer"},
                        "description": "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·ã®ãƒªã‚¹ãƒˆ",
                    },
                    "report_types": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["progress", "analytics", "batch", "feedback"]},
                        "description": "ãƒ¬ãƒãƒ¼ãƒˆç¨®é¡",
                        "default": ["progress", "analytics"],
                    },
                    "format": {
                        "type": "string",
                        "enum": ["json", "csv", "html"],
                        "description": "å‡ºåŠ›å½¢å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: jsonï¼‰",
                        "default": "json",
                    },
                    "project_root": {
                        "type": "string",
                        "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
                    },
                },
                "required": ["episode_numbers"],
            },
            self._handle_export_ui_reports,
        )

    async def _handle_get_writing_tasks(self, arguments: dict) -> list[types.TextContent]:
        """18ã‚¹ãƒ†ãƒƒãƒ—åŸ·ç­†ã‚¿ã‚¹ã‚¯ä¸€è¦§å–å¾—å‡¦ç†"""
        episode_number = arguments["episode_number"]
        project_root = arguments.get("project_root", ".")

        manager = create_progressive_write_manager(
            project_root,
            episode_number,
            llm_executor=create_progressive_write_llm_executor(),
        )
        result = manager.get_writing_tasks()

        return [types.TextContent(type="text", text=self._optimize_json_conversion(result))]

    async def _handle_execute_writing_step(self, arguments: dict) -> list[types.TextContent]:
        """å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œå‡¦ç†"""
        step_id = arguments["step_id"]
        episode_number = arguments["episode_number"]
        project_root = arguments.get("project_root", ".")
        dry_run = arguments.get("dry_run", False)

        manager = create_progressive_write_manager(
            project_root,
            episode_number,
            llm_executor=create_progressive_write_llm_executor(),
        )
        result = await manager.execute_writing_step_async(step_id, dry_run)

        return [types.TextContent(type="text", text=self._optimize_json_conversion(result))]

    async def _handle_execute_writing_steps_parallel(self, arguments: dict) -> list[types.TextContent]:
        """ä¸¦åˆ—ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œå‡¦ç†ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
        step_ids = arguments["step_ids"]
        episode_number = arguments["episode_number"]
        project_root = arguments.get("project_root", ".")
        max_concurrent = arguments.get("max_concurrent", 3)
        dry_run = arguments.get("dry_run", False)

        manager = create_progressive_write_manager(
            project_root,
            episode_number,
            llm_executor=create_progressive_write_llm_executor(),
        )

        # ä¸¦åˆ—å®Ÿè¡Œï¼ˆAsyncOperationOptimizerä½¿ç”¨ï¼‰
        result = await manager.execute_writing_steps_parallel(step_ids, max_concurrent, dry_run)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’è¿½åŠ 
        if result.get("success") and result.get("parallel_execution"):
            result["performance_stats"] = {
                "parallel_optimization": "AsyncOperationOptimizerçµ±åˆ",
                "estimated_time_saved": result.get("execution_time_saved", "ä¸æ˜"),
                "concurrent_execution": f"{max_concurrent}ä¸¦åˆ—",
                "optimization_ratio": "æ¨å®š50%é«˜é€ŸåŒ–",
            }

        return [types.TextContent(type="text", text=self._optimize_json_conversion(result))]

    async def _handle_get_task_status(self, arguments: dict) -> list[types.TextContent]:
        """ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ç¢ºèªå‡¦ç†"""
        episode_number = arguments["episode_number"]
        project_root = arguments.get("project_root", ".")

        manager = create_progressive_write_manager(
            project_root,
            episode_number,
            llm_executor=create_progressive_write_llm_executor(),
        )
        result = manager.get_task_status()

        return [types.TextContent(type="text", text=self._optimize_json_conversion(result))]

    async def _handle_create_batch_job(self, arguments: dict) -> dict[str, Any]:
        """ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ä½œæˆã®å‡¦ç†"""
        try:
            episode_numbers = arguments["episode_numbers"]
            step_ids = arguments.get("step_ids")
            job_name = arguments.get("job_name")
            max_concurrent = arguments.get("max_concurrent", 3)
            priority = arguments.get("priority", 0)
            project_root = self._resolve_project_path(arguments.get("project_root"))

            # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–
            from noveler.presentation.ui.batch_processor import BatchProcessingSystem

            batch_processor = BatchProcessingSystem(project_root)

            # ã‚¸ãƒ§ãƒ–ä½œæˆ
            job_id = batch_processor.create_batch_job(
                episode_numbers=episode_numbers,
                step_ids=step_ids,
                job_name=job_name,
                max_concurrent=max_concurrent,
                priority=priority,
            )

            return self._format_json_result(
                {
                    "success": True,
                    "job_id": job_id,
                    "episode_count": len(episode_numbers),
                    "step_count": len(step_ids) if step_ids else 18,
                    "message": f"ãƒãƒƒãƒã‚¸ãƒ§ãƒ– '{job_id}' ã‚’ä½œæˆã—ã¾ã—ãŸ",
                }
            )

        except Exception as e:
            self.logger.exception("ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ä½œæˆã‚¨ãƒ©ãƒ¼")
            return self._format_json_result({"success": False, "error": str(e), "error_type": type(e).__name__})

    async def _handle_execute_batch_job(self, arguments: dict) -> dict[str, Any]:
        """ãƒãƒƒãƒã‚¸ãƒ§ãƒ–å®Ÿè¡Œã®å‡¦ç†"""
        try:
            job_id = arguments["job_id"]
            project_root = self._resolve_project_path(arguments.get("project_root"))

            # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–
            from noveler.presentation.ui.batch_processor import BatchProcessingSystem

            batch_processor = BatchProcessingSystem(project_root)

            # ã‚¸ãƒ§ãƒ–å®Ÿè¡Œ
            batch_result = await batch_processor.execute_batch_job(job_id)

            return self._format_json_result(
                {
                    "success": True,
                    "job_id": job_id,
                    "execution_result": {
                        "total_episodes": batch_result.total_episodes,
                        "successful_episodes": batch_result.successful_episodes,
                        "failed_episodes": batch_result.failed_episodes,
                        "execution_time": batch_result.execution_time,
                        "success_rate": (batch_result.successful_episodes / batch_result.total_episodes) * 100,
                        "errors": len(batch_result.errors),
                    },
                    "message": f"ãƒãƒƒãƒã‚¸ãƒ§ãƒ– '{job_id}' ãŒå®Œäº†ã—ã¾ã—ãŸ",
                }
            )

        except Exception as e:
            self.logger.exception("ãƒãƒƒãƒã‚¸ãƒ§ãƒ–å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
            return self._format_json_result({"success": False, "error": str(e), "error_type": type(e).__name__})

    async def _handle_get_batch_status(self, arguments: dict) -> dict[str, Any]:
        """ãƒãƒƒãƒå‡¦ç†çŠ¶æ³ç¢ºèªã®å‡¦ç†"""
        try:
            job_id = arguments.get("job_id")
            project_root = self._resolve_project_path(arguments.get("project_root"))

            # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–
            from noveler.presentation.ui.batch_processor import BatchProcessingSystem

            batch_processor = BatchProcessingSystem(project_root)

            # çŠ¶æ³å–å¾—
            status = batch_processor.get_batch_status(job_id)

            return self._format_json_result(
                {"success": True, "batch_status": status, "message": "ãƒãƒƒãƒå‡¦ç†çŠ¶æ³ã‚’å–å¾—ã—ã¾ã—ãŸ"}
            )

        except Exception as e:
            self.logger.exception("ãƒãƒƒãƒçŠ¶æ³ç¢ºèªã‚¨ãƒ©ãƒ¼")
            return self._format_json_result({"success": False, "error": str(e), "error_type": type(e).__name__})

    async def _handle_analyze_episode_quality(self, arguments: dict) -> dict[str, Any]:
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å“è³ªåˆ†æã®å‡¦ç†"""
        try:
            episode_numbers = arguments["episode_numbers"]
            analysis_types = arguments.get("analysis_types", ["all"])
            generate_dashboard = arguments.get("generate_dashboard", True)
            project_root = self._resolve_project_path(arguments.get("project_root"))

            # åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
            from noveler.presentation.ui.analytics_system import WritingAnalyticsSystem

            analytics_system = WritingAnalyticsSystem(project_root)

            results = {}

            for episode_number in episode_numbers:
                # åŸç¨¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆPathServiceã«çµ±ä¸€ï¼‰
                from noveler.infrastructure.adapters.path_service_adapter import create_path_service

                path_service = create_path_service(project_root)
                manuscript_file = path_service.get_manuscript_path(episode_number)

                if not manuscript_file.exists():
                    results[episode_number] = {"error": "åŸç¨¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
                    continue

                content = manuscript_file.read_text(encoding="utf-8")
                episode_results = {}

                # åˆ†æå®Ÿè¡Œ
                if "all" in analysis_types or "emotion" in analysis_types:
                    emotion_profiles = analytics_system.analyze_episode_emotions(episode_number, content)
                    episode_results["emotion_analysis"] = {
                        character: asdict(profile) for character, profile in emotion_profiles.items()
                    }

                if "all" in analysis_types or "narrative" in analysis_types:
                    narrative_metrics = analytics_system.analyze_narrative_structure(episode_number, content)
                    episode_results["narrative_analysis"] = asdict(narrative_metrics)

                if "all" in analysis_types or "quality" in analysis_types:
                    quality_metrics = analytics_system.analyze_quality_metrics(episode_number, content)
                    episode_results["quality_analysis"] = asdict(quality_metrics)

                results[episode_number] = episode_results

            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ
            dashboard_data = None
            if generate_dashboard:
                dashboard_data = analytics_system.export_analytics_dashboard(episode_numbers)

            # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            comprehensive_report = analytics_system.generate_comprehensive_report(episode_numbers)

            return self._format_json_result(
                {
                    "success": True,
                    "analysis_results": results,
                    "comprehensive_report": comprehensive_report,
                    "dashboard_data": json.loads(dashboard_data) if dashboard_data else None,
                    "message": f"{len(episode_numbers)}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ",
                }
            )

        except Exception as e:
            self.logger.exception("ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼")
            return self._format_json_result({"success": False, "error": str(e), "error_type": type(e).__name__})

    async def _handle_get_progress_display(self, arguments: dict) -> dict[str, Any]:
        """é€²æ—è¡¨ç¤ºæƒ…å ±å–å¾—ã®å‡¦ç†"""
        try:
            episode_number = arguments["episode_number"]
            detailed = arguments.get("detailed", False)
            project_root = self._resolve_project_path(arguments.get("project_root"))

            # ProgressiveWriteManagerã‹ã‚‰é€²æ—æƒ…å ±ã‚’å–å¾—
            write_manager = create_progressive_write_manager(
                project_root,
                episode_number,
                llm_executor=create_progressive_write_llm_executor(),
            )

            # é€²æ—è¡¨ç¤ºã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
            if detailed:
                progress_status = write_manager.progress_display.display_detailed_status()
                feedback_summary = write_manager.feedback_system.get_feedback_summary()

                return self._format_json_result(
                    {
                        "success": True,
                        "progress_display": progress_status,
                        "feedback_summary": feedback_summary,
                        "ui_features": {
                            "progress_tracking": True,
                            "interactive_feedback": True,
                            "quality_monitoring": True,
                            "error_recovery": True,
                        },
                        "message": f"Episode {episode_number}ã®è©³ç´°é€²æ—æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ",
                    }
                )
            # åŸºæœ¬é€²æ—æƒ…å ±
            task_status = write_manager.get_task_status()

            return self._format_json_result(
                {
                    "success": True,
                    "task_status": task_status,
                    "ui_enabled": True,
                    "message": f"Episode {episode_number}ã®é€²æ—æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ",
                }
            )

        except Exception as e:
            self.logger.exception("é€²æ—è¡¨ç¤ºæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼")
            return self._format_json_result({"success": False, "error": str(e), "error_type": type(e).__name__})

    async def _handle_export_ui_reports(self, arguments: dict) -> dict[str, Any]:
        """UIãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®å‡¦ç†"""
        try:
            episode_numbers = arguments["episode_numbers"]
            report_types = arguments.get("report_types", ["progress", "analytics"])
            format_type = arguments.get("format", "json")
            project_root = self._resolve_project_path(arguments.get("project_root"))

            exported_reports = {}

            for episode_number in episode_numbers:
                episode_reports = {}

                # é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
                if "progress" in report_types:
                    write_manager = create_progressive_write_manager(
                        project_root,
                        episode_number,
                        llm_executor=create_progressive_write_llm_executor(),
                    )

                    progress_report = write_manager.progress_display.export_progress_report()
                    episode_reports["progress"] = progress_report

                # åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
                if "analytics" in report_types:
                    from noveler.presentation.ui.analytics_system import WritingAnalyticsSystem

                    analytics_system = WritingAnalyticsSystem(project_root)

                    # åŸç¨¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆPathServiceã«çµ±ä¸€ï¼‰
                    from noveler.infrastructure.adapters.path_service_adapter import create_path_service

                    path_service = create_path_service(project_root)
                    manuscript_file = path_service.get_manuscript_path(episode_number)
                    if manuscript_file.exists():
                        content = manuscript_file.read_text(encoding="utf-8")

                        # å„ç¨®åˆ†æå®Ÿè¡Œ
                        analytics_system.analyze_episode_emotions(episode_number, content)
                        analytics_system.analyze_narrative_structure(episode_number, content)
                        analytics_system.analyze_quality_metrics(episode_number, content)

                        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                        analytics_report = analytics_system.generate_comprehensive_report([episode_number])
                        episode_reports["analytics"] = analytics_report

                # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ
                if "feedback" in report_types:
                    write_manager = create_progressive_write_manager(
                        project_root,
                        episode_number,
                        llm_executor=create_progressive_write_llm_executor(),
                    )

                    feedback_report = write_manager.feedback_system.export_feedback_report()
                    episode_reports["feedback"] = feedback_report

                exported_reports[episode_number] = episode_reports

            # ãƒãƒƒãƒãƒ¬ãƒãƒ¼ãƒˆ
            if "batch" in report_types:
                from noveler.presentation.ui.batch_processor import BatchProcessingSystem

                batch_processor = BatchProcessingSystem(project_root)

                batch_status = batch_processor.get_batch_status()
                exported_reports["batch_summary"] = batch_status

            return self._format_json_result(
                {
                    "success": True,
                    "exported_reports": exported_reports,
                    "format": format_type,
                    "episodes_processed": len(episode_numbers),
                    "report_types": report_types,
                    "message": f"{len(episode_numbers)}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®UIãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ",
                }
            )

        except Exception as e:
            self.logger.exception("UIãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼")
            return self._format_json_result({"success": False, "error": str(e), "error_type": type(e).__name__})

    def _register_plot_preparation_tools(self) -> None:
        """ãƒ—ãƒ­ãƒƒãƒˆæº–å‚™é–¢é€£ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="prepare_plot_data",
            description="ãƒ—ãƒ­ãƒƒãƒˆã¨è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã€åŸ·ç­†ã®åŸºç›¤ã‚’æ§‹ç¯‰ - noveler writeã®ç¬¬1æ®µéšã‚’Claudeå†…ã§å®Ÿè¡Œ",
        )
        async def prepare_plot_data(episode: int, project_root: str | None = None) -> str:
            """ãƒ—ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™æ®µéš"""
            try:
                import json
                import uuid
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨ï¼ˆæŒ‡å®šã®project_rootã‚’å°Šé‡ï¼‰
                path_service = create_path_service(project_path)

                # PathServiceã§ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ±º
                plot_file = path_service.get_episode_plot_path(episode)

                if not (plot_file and plot_file.exists()):
                    return json.dumps(
                        {"success": False, "error": f"ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ç¬¬{episode:03d}è©±"},
                        ensure_ascii=False,
                        indent=2,
                    )
                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„èª­ã¿è¾¼ã¿
                plot_content = plot_file.read_text(encoding="utf-8")
                settings_data = {}
                settings_dir = project_path / "10_è¨­å®š"
                if settings_dir.exists():
                    for settings_file in settings_dir.glob("*.md"):
                        settings_data[settings_file.stem] = settings_file.read_text(encoding="utf-8")
                characters = []
                character_dir = project_path / "10_è¨­å®š" / "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼"
                if character_dir.exists():
                    for char_file in character_dir.glob("*.md"):
                        characters.append({"name": char_file.stem, "profile": char_file.read_text(encoding="utf-8")})

                # ArtifactStoreServiceã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆåŒ–
                from noveler.domain.services.artifact_store_service import create_artifact_store

                artifact_store = create_artifact_store(storage_dir=project_path / ".noveler" / "artifacts")

                # ãƒ—ãƒ­ãƒƒãƒˆã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜
                plot_artifact_id = artifact_store.store(
                    content=plot_content,
                    content_type="text",
                    source_file=str(plot_file),
                    description=f"ç¬¬{episode:03d}è©±ãƒ—ãƒ­ãƒƒãƒˆ",
                    tags={"episode": str(episode), "type": "plot"},
                )

                # è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜
                settings_json = json.dumps(settings_data, ensure_ascii=False, indent=2)
                settings_artifact_id = artifact_store.store(
                    content=settings_json,
                    content_type="json",
                    description=f"ç¬¬{episode:03d}è©±è¨­å®šãƒ‡ãƒ¼ã‚¿",
                    tags={"episode": str(episode), "type": "settings"},
                )

                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜
                characters_json = json.dumps(characters, ensure_ascii=False, indent=2)
                characters_artifact_id = artifact_store.store(
                    content=characters_json,
                    content_type="json",
                    description=f"ç¬¬{episode:03d}è©±ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±",
                    tags={"episode": str(episode), "type": "characters"},
                )

                session_id = str(uuid.uuid4())
                session_manager = WritingSessionManager(project_path)
                session_manager.create_session(episode, session_id)

                # å‚ç…§æ¸¡ã—å½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                artifact_prompt = f"""# ç¬¬{episode:03d}è©± ãƒ‡ãƒ¼ã‚¿æº–å‚™æ®µéšï¼ˆå‚ç…§æ¸¡ã—ç‰ˆï¼‰

## ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§æƒ…å ±
- **ãƒ—ãƒ­ãƒƒãƒˆ**: {plot_artifact_id}
- **è¨­å®šãƒ‡ãƒ¼ã‚¿**: {settings_artifact_id}
- **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±**: {characters_artifact_id}

## åŸ·ç­†æº–å‚™æŒ‡ç¤º
ä»¥ä¸‹ã®æ‰‹é †ã§åŸ·ç­†æº–å‚™ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š

1. **ãƒ—ãƒ­ãƒƒãƒˆç¢ºèª**: `fetch_artifact {plot_artifact_id}` ã§ãƒ—ãƒ­ãƒƒãƒˆå…¨æ–‡ã‚’å–å¾—ã—ã€å†…å®¹ã‚’ç†è§£ã—ã¦ãã ã•ã„
2. **è¨­å®šæƒ…å ±æ•´ç†**: `fetch_artifact {settings_artifact_id}` ã§è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ä¸–ç•Œè¦³ã‚’æŠŠæ¡ã—ã¦ãã ã•ã„
3. **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠŠæ¡**: `fetch_artifact {characters_artifact_id}` ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã€äººç‰©è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„

## æ¬¡æ®µéšã¸ã®æº–å‚™
å„ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®å†…å®¹ã‚’ç¢ºèªå¾Œã€ã€Œæº–å‚™å®Œäº†ã€ã¨å›ç­”ã—ã€åŸ·ç­†ã«å¿…è¦ãªæƒ…å ±ãŒæƒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**é‡è¦**: å®Ÿéš›ã®åŸ·ç­†æ®µéšã§ã¯ã€ã“ã‚Œã‚‰ã®å‚ç…§IDã‚’ä½¿ç”¨ã—ã¦å¿…è¦ãªæƒ…å ±ã‚’å–å¾—ã§ãã¾ã™ã€‚"""

                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "plot_artifact_id": plot_artifact_id,
                    "settings_artifact_id": settings_artifact_id,
                    "characters_artifact_id": characters_artifact_id,
                    "artifact_references": {
                        "plot": plot_artifact_id,
                        "settings": settings_artifact_id,
                        "characters": characters_artifact_id,
                    },
                    "prompt": artifact_prompt,
                    "stage": "prepare_plot_data",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "analyze_plot_structure",
                    "instructions": "ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã€æ¬¡æ®µéšã¸ã®æº–å‚™ã‚’è¡Œã£ã¦ãã ã•ã„",
                }
                session_manager.save_stage_output(session_id, "prepare_plot_data", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("ãƒ—ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

        # ãƒ†ã‚¹ãƒˆäº’æ›: ç›´æ¥ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦ã‚‚ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹
        try:
            self.prepare_plot_data = prepare_plot_data
        except Exception:
            pass

    def _register_manuscript_writing_tools(self) -> None:
        """åŸç¨¿åŸ·ç­†é–¢é€£ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="write_manuscript_draft", description="åŸç¨¿åŸ·ç­†æ®µéš - ãƒ—ãƒ­ãƒƒãƒˆåˆ†æçµæœã‚’åŸºã«å®Ÿéš›ã®åŸç¨¿ã‚’ç”Ÿæˆã—ã¾ã™"
        )
        async def write_manuscript_draft(
            episode: int, session_id: str | None = None, word_count_target: int = 4000, project_root: str | None = None
        ) -> str:
            """åŸç¨¿åŸ·ç­†æ®µéš"""
            try:
                import json
                from pathlib import Path

                # use module-level factories to allow test patching

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root

                session_manager = WritingSessionManager(project_path)
                session_data = {}
                if session_id:
                    session_data = session_manager.load_session(session_id)

                # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
                artifact_store = create_artifact_store(storage_dir=project_path / ".noveler" / "artifacts")

                # ãƒ—ãƒ­ãƒƒãƒˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆIDã‚’å–å¾—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã€ã¾ãŸã¯ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
                plot_artifact_id = None
                if session_data.get("plot_artifact_id"):
                    plot_artifact_id = session_data["plot_artifact_id"]
                elif session_data.get("plot_content"):
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ—ãƒ­ãƒƒãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆåŒ–
                    plot_artifact_id = artifact_store.store(
                        content=session_data["plot_content"],
                        content_type="text",
                        source_file=f"session_{session_id}",
                        description=f"ç¬¬{episode:03d}è©±ãƒ—ãƒ­ãƒƒãƒˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ç”±æ¥ï¼‰",
                    )
                else:
                    # PathService ã‚’ä½¿ç”¨ã—ã¦èª­ã¿è¾¼ã¿
                    path_service = create_mcp_aware_path_service()
                    plot_file = path_service.get_episode_plot_path(episode)
                    if plot_file and plot_file.exists():
                        plot_content = plot_file.read_text(encoding="utf-8")
                        plot_artifact_id = artifact_store.store(
                            content=plot_content,
                            content_type="text",
                            source_file=str(plot_file),
                            description=f"ç¬¬{episode:03d}è©±ãƒ—ãƒ­ãƒƒãƒˆ",
                        )
                    else:
                        return json.dumps(
                            {"success": False, "error": f"ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ç¬¬{episode:03d}è©±"},
                            ensure_ascii=False,
                            indent=2,
                        )

                # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§ã‚’ä½¿ã£ãŸåŸ·ç­†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
                manuscript_prompt = f"""# ç¬¬{episode:03d}è©± åŸç¨¿åŸ·ç­†æ®µéšï¼ˆå‚ç…§æ¸¡ã—ç‰ˆï¼‰

## ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§æƒ…å ±
- **ãƒ—ãƒ­ãƒƒãƒˆ**: {plot_artifact_id}

## å®Ÿè¡Œæ‰‹é †
1. **ãƒ—ãƒ­ãƒƒãƒˆç¢ºèª**: `fetch_artifact {plot_artifact_id}` ã§ãƒ—ãƒ­ãƒƒãƒˆå…¨æ–‡ã‚’å–å¾—ã—ã€å†…å®¹ã‚’ç†è§£ã—ã¦ãã ã•ã„
2. **åŸ·ç­†è¦ä»¶ã®ç¢ºèª**: ä»¥ä¸‹ã®è¦ä»¶ã«å¾“ã£ã¦åŸ·ç­†ã—ã¦ãã ã•ã„

## åŸ·ç­†è¦ä»¶
- ç›®æ¨™æ–‡å­—æ•°: {word_count_target}æ–‡å­—
- ã‚¸ãƒ£ãƒ³ãƒ«: ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼
- è¦–ç‚¹: ä¸‰äººç§°å˜å…ƒè¦–ç‚¹
- æ–‡ä½“: ãƒ©ã‚¤ãƒˆãƒãƒ™ãƒ«èª¿

## å“è³ªåŸºæº–ï¼ˆSPEC-WRITE-STAGE-001æº–æ‹ ï¼‰
- æ„Ÿæƒ…è¡¨ç¾: èº«ä½“åå¿œã€æ„Ÿè¦šæ¯”å–©ã€å†…é¢ç‹¬ç™½ã®ä¸‰å±¤è¡¨ç¾ã‚’æœ€ä½3å›å®Ÿè£…
- å¯¾è©±æ¯”ç‡: 60%ç¨‹åº¦
- å ´é¢æå†™: äº”æ„Ÿã‚’ä½¿ã£ãŸæå†™ã‚’æ„è­˜
- ãƒ†ãƒ³ãƒ: ç·Šå¼µã¨ç·©å’Œã®ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¤

## å‰æ®µéšã®åˆ†æçµæœ
{json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else "ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãªã—"}

## æŒ‡ç¤º
1. ã¾ãš `fetch_artifact {plot_artifact_id}` ã§ãƒ—ãƒ­ãƒƒãƒˆã‚’å–å¾—ã—ã¦ãã ã•ã„
2. ãƒ—ãƒ­ãƒƒãƒˆã®å†…å®¹ã‚’ç†è§£ã—ã€ä¸Šè¨˜ã®è¦ä»¶ã«åŸºã¥ã„ã¦åŸç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„
3. ä»¥ä¸‹ã®å½¢å¼ã§åŸç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

# ç¬¬{episode:03d}è©± [ã‚¿ã‚¤ãƒˆãƒ«]

[æœ¬æ–‡ã‚’ã“ã“ã«è¨˜è¿°]

ç”Ÿæˆå¾Œã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚
"""

                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨
                path_service = create_path_service()
                # å‡ºåŠ›å…ˆã¯æœ€çµ‚åŸç¨¿ãƒ‘ã‚¹ï¼ˆæ®µéšåˆ¥ä¸€æ™‚åã§ã¯ãªãçµ±ä¸€ãƒ‘ã‚¹ï¼‰
                manuscript_file = path_service.get_manuscript_path(episode)
                manuscript_file.parent.mkdir(exist_ok=True)

                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id or "new",
                    "manuscript_path": str(manuscript_file),
                    "word_count_target": word_count_target,
                    "prompt": manuscript_prompt,
                    "plot_artifact_id": plot_artifact_id,
                    "stage": "write_manuscript_draft",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "refine_manuscript_quality",
                    "instructions": "ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦åŸç¨¿ã‚’ç”Ÿæˆã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ä¿å­˜ã—ã¦ãã ã•ã„",
                }

                if session_id:
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆIDã‚’ä¿å­˜
                    updated_session_data = session_data.copy()
                    updated_session_data["plot_artifact_id"] = plot_artifact_id
                    session_manager.save_stage_output(session_id, "write_manuscript_draft", result)
                    session_manager.save_session(session_id, updated_session_data)

                return self._json_with_path_fallback(result, locals())

            except Exception as e:
                self.logger.exception("åŸç¨¿åŸ·ç­†ã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"åŸç¨¿åŸ·ç­†ã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

        # äº’æ›API: ãƒ†ã‚¹ãƒˆã‹ã‚‰å‚ç…§ã§ãã‚‹ã‚ˆã†ã« _tools ãƒãƒƒãƒ—ã«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ç™»éŒ²
        try:
            if not hasattr(self.server, "_tools"):
                self.server._tools = {}
            self.server._tools["write_manuscript_draft"] = {"handler": write_manuscript_draft}
        except Exception:
            pass

        # ãƒ†ã‚¹ãƒˆäº’æ›: ç›´æ¥ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦ã‚‚ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹
        try:
            self.write_manuscript_draft = write_manuscript_draft
        except Exception:
            pass

    def _register_content_analysis_tools(self) -> None:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="analyze_plot_structure",
            description="ãƒ—ãƒ­ãƒƒãƒˆæ§‹é€ åˆ†æ - ãƒ—ãƒ­ãƒƒãƒˆå†…å®¹ã‚’åˆ†æã—ã€æ§‹é€ çš„ãªè¦ç´ ã‚’æ•´ç†ã—ã¾ã™",
        )
        async def analyze_plot_structure(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """ãƒ—ãƒ­ãƒƒãƒˆæ§‹é€ åˆ†ææ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                plot_content = session_data.get("plot_content", "")
                if not plot_content:
                    # B20æº–æ‹ : PathServiceã§ãƒ—ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ±º
                    path_service = create_path_service()
                    plot_file = path_service.get_episode_plot_path(episode)

                    if plot_file and plot_file.exists():
                        plot_content = plot_file.read_text(encoding="utf-8")
                prompt = f"# ç¬¬{episode:03d}è©± ãƒ—ãƒ­ãƒƒãƒˆæ§‹é€ åˆ†ææ®µéš\n\n## åˆ†æå¯¾è±¡ãƒ—ãƒ­ãƒƒãƒˆ\n{plot_content}\n\n## åˆ†æé …ç›®\n1. **èµ·æ‰¿è»¢çµã®æ§‹é€ åˆ†æ**\n   - å°å…¥éƒ¨ï¼ˆèµ·ï¼‰ã®è¨­å®šã¨å±•é–‹\n   - ç™ºå±•éƒ¨ï¼ˆæ‰¿ï¼‰ã®å±•é–‹æ–¹æ³•\n   - è»¢æ›éƒ¨ï¼ˆè»¢ï¼‰ã®ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹è¦ç´ \n   - çµè«–éƒ¨ï¼ˆçµï¼‰ã®ç· ã‚ããã‚Šæ–¹\n\n2. **é‡è¦ã‚·ãƒ¼ãƒ³ã®ç‰¹å®š**\n   - ç‰©èªã®è»¢æ›ç‚¹ã¨ãªã‚‹ã‚·ãƒ¼ãƒ³\n   - æ„Ÿæƒ…çš„ãªå±±å ´ã¨ãªã‚‹ã‚·ãƒ¼ãƒ³\n   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æˆé•·ã®ã‚­ãƒ¼ã‚·ãƒ¼ãƒ³\n\n3. **æ§‹é€ çš„èª²é¡Œã®æ¤œå‡º**\n   - ãƒ†ãƒ³ãƒé…åˆ†ã®å¦¥å½“æ€§\n   - ã‚·ãƒ¼ãƒ³è»¢æ›ã®è‡ªç„¶ã•\n   - æƒ…å ±æç¤ºã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®åˆ†æã‚’è¡Œã„ã€æ¬¡æ®µéšï¼ˆæ„Ÿæƒ…è¨­è¨ˆï¼‰ã¸ã®æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "plot_content": plot_content,
                    "prompt": prompt,
                    "stage": "analyze_plot_structure",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "design_emotional_flow",
                    "instructions": "ãƒ—ãƒ­ãƒƒãƒˆæ§‹é€ ã‚’åˆ†æã—ã€æ¬¡æ®µéšã¸ã®æ¨å¥¨äº‹é …ã‚’æ•´ç†ã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "analyze_plot_structure", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("ãƒ—ãƒ­ãƒƒãƒˆåˆ†æã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"ãƒ—ãƒ­ãƒƒãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

    def _register_creative_design_tools(self) -> None:
        """å‰µä½œè¨­è¨ˆãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="design_emotional_flow",
            description="æ„Ÿæƒ…ãƒ»é–¢ä¿‚æ€§è¨­è¨ˆ - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æ„Ÿæƒ…å¤‰åŒ–ã¨é–¢ä¿‚æ€§ã®æµã‚Œã‚’è¨­è¨ˆã—ã¾ã™",
        )
        async def design_emotional_flow(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """æ„Ÿæƒ…ãƒ»é–¢ä¿‚æ€§è¨­è¨ˆæ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                prompt = f"# ç¬¬{episode:03d}è©± æ„Ÿæƒ…ãƒ»é–¢ä¿‚æ€§è¨­è¨ˆæ®µéš\n\n## å‰æ®µéšã®åˆ†æçµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## è¨­è¨ˆé …ç›®\n1. **æ„Ÿæƒ…ã‚¢ãƒ¼ã‚¯ã®è¨­è¨ˆ**\n   - ä¸»äººå…¬ã®æ„Ÿæƒ…å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³\n   - å„ã‚·ãƒ¼ãƒ³ã§ã®æ„Ÿæƒ…çŠ¶æ…‹\n   - æ„Ÿæƒ…å¤‰åŒ–ã®ãƒˆãƒªã‚¬ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ\n\n2. **é–¢ä¿‚æ€§ã®å‹•çš„å¤‰åŒ–**\n   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é–“ã®é–¢ä¿‚æ€§å¤‰åŒ–\n   - å¯¾ç«‹ã¨å’Œè§£ã®æµã‚Œ\n   - ä¿¡é ¼é–¢ä¿‚ã®æ§‹ç¯‰éç¨‹\n\n3. **æ„Ÿæƒ…è¡¨ç¾ã®å®Ÿè£…æ–¹é‡**\n   - èº«ä½“åå¿œã«ã‚ˆã‚‹æ„Ÿæƒ…è¡¨ç¾\n   - æ„Ÿè¦šæ¯”å–©ã‚’ä½¿ã£ãŸå†…é¢æå†™\n   - å†…é¢ç‹¬ç™½ã«ã‚ˆã‚‹å¿ƒå¢ƒè¡¨ç¾\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®è¦ç´ ã‚’å…·ä½“çš„ã«è¨­è¨ˆã—ã€æ¬¡æ®µéšï¼ˆãƒ¦ãƒ¼ãƒ¢ã‚¢è¨­è¨ˆï¼‰ã¸ã®æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "prompt": prompt,
                    "stage": "design_emotional_flow",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "design_humor_elements",
                    "instructions": "æ„Ÿæƒ…ãƒ»é–¢ä¿‚æ€§ã®æµã‚Œã‚’è¨­è¨ˆã—ã€å…·ä½“çš„ãªå®Ÿè£…æ–¹é‡ã‚’ç­–å®šã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "design_emotional_flow", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("æ„Ÿæƒ…è¨­è¨ˆã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"æ„Ÿæƒ…è¨­è¨ˆã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

        @self.server.tool(
            name="design_humor_elements",
            description="ãƒ¦ãƒ¼ãƒ¢ã‚¢ãƒ»é­…åŠ›è¦ç´ è¨­è¨ˆ - èª­è€…ã‚’å¼•ãè¾¼ã‚€ãƒ¦ãƒ¼ãƒ¢ã‚¢ã¨é­…åŠ›è¦ç´ ã‚’è¨­è¨ˆã—ã¾ã™",
        )
        async def design_humor_elements(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """ãƒ¦ãƒ¼ãƒ¢ã‚¢ãƒ»é­…åŠ›è¦ç´ è¨­è¨ˆæ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                prompt = f"# ç¬¬{episode:03d}è©± ãƒ¦ãƒ¼ãƒ¢ã‚¢ãƒ»é­…åŠ›è¦ç´ è¨­è¨ˆæ®µéš\n\n## å‰æ®µéšã®è¨­è¨ˆçµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## è¨­è¨ˆé …ç›®\n1. **ãƒ¦ãƒ¼ãƒ¢ã‚¢è¦ç´ ã®é…ç½®**\n   - ã‚³ãƒ¡ãƒ‡ã‚£ã‚·ãƒ¼ãƒ³ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å€‹æ€§çš„ãªè¨€å‹•\n   - çŠ¶æ³ã‚³ãƒ¡ãƒ‡ã‚£ã®æ¼”å‡ºæ–¹æ³•\n\n2. **é­…åŠ›è¦ç´ ã®å¼·åŒ–**\n   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é­…åŠ›çš„ãªä¸€é¢\n   - èª­è€…ã®å…±æ„Ÿã‚’èª˜ã†è¦ç´ \n   - å°è±¡ã«æ®‹ã‚‹ã‚·ãƒ¼ãƒ³ã®æ¼”å‡º\n\n3. **ç·Šå¼µã¨ç·©å’Œã®ãƒãƒ©ãƒ³ã‚¹**\n   - ã‚·ãƒªã‚¢ã‚¹ã‚·ãƒ¼ãƒ³ã¨ã‚³ãƒ¡ãƒ‡ã‚£ã®é…åˆ†\n   - æ„Ÿæƒ…ã®èµ·ä¼ã‚’ä½œã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n   - èª­è€…ã®é›†ä¸­åŠ›ã‚’ç¶­æŒã™ã‚‹å·¥å¤«\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®è¦ç´ ã‚’å…·ä½“çš„ã«è¨­è¨ˆã—ã€æ¬¡æ®µéšï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±è¨­è¨ˆï¼‰ã¸ã®æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "prompt": prompt,
                    "stage": "design_humor_elements",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "design_character_dialogue",
                    "instructions": "ãƒ¦ãƒ¼ãƒ¢ã‚¢ã¨é­…åŠ›è¦ç´ ã‚’è¨­è¨ˆã—ã€ç·Šå¼µã¨ç·©å’Œã®ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´ã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "design_humor_elements", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("ãƒ¦ãƒ¼ãƒ¢ã‚¢è¨­è¨ˆã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"ãƒ¦ãƒ¼ãƒ¢ã‚¢è¨­è¨ˆã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

        @self.server.tool(
            name="design_character_dialogue",
            description="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¿ƒç†ãƒ»å¯¾è©±è¨­è¨ˆ - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¿ƒç†çŠ¶æ…‹ã¨å¯¾è©±ã‚’è©³ç´°ã«è¨­è¨ˆã—ã¾ã™",
        )
        async def design_character_dialogue(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¿ƒç†ãƒ»å¯¾è©±è¨­è¨ˆæ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                prompt = f"# ç¬¬{episode:03d}è©± ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¿ƒç†ãƒ»å¯¾è©±è¨­è¨ˆæ®µéš\n\n## å‰æ®µéšã®è¨­è¨ˆçµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## è¨­è¨ˆé …ç›®\n1. **å¿ƒç†çŠ¶æ…‹ã®è©³ç´°è¨­è¨ˆ**\n   - å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¿ƒç†å¤‰åŒ–\n   - å†…é¢çš„ãªè‘›è—¤ã®è¡¨ç¾æ–¹æ³•\n   - æ„Ÿæƒ…ã®ç´°ã‹ãªè¡¨ç¾æŠ€æ³•\n\n2. **å¯¾è©±è¨­è¨ˆ**\n   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã®è©±ã—æ–¹ã®ç‰¹å¾´\n   - å¯¾è©±ã«ã‚ˆã‚‹é–¢ä¿‚æ€§ã®è¡¨ç¾\n   - é‡è¦ãªæƒ…å ±ã‚’ä¼ãˆã‚‹å¯¾è©±ã®æµã‚Œ\n\n3. **å¿ƒç†æå†™ã®å®Ÿè£…æ–¹é‡**\n   - ç›´æ¥çš„ãªå¿ƒç†æå†™ã¨é–“æ¥çš„ãªè¡¨ç¾\n   - è¡Œå‹•ã«ã‚ˆã‚‹å¿ƒç†çŠ¶æ…‹ã®è¡¨ç¾\n   - å¯¾è©±ã§ã®å¿ƒç†çŠ¶æ…‹ã®æš—ç¤º\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®è¦ç´ ã‚’å…·ä½“çš„ã«è¨­è¨ˆã—ã€æ¬¡æ®µéšï¼ˆå ´é¢æ¼”å‡ºè¨­è¨ˆï¼‰ã¸ã®æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "prompt": prompt,
                    "stage": "design_character_dialogue",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "design_scene_atmosphere",
                    "instructions": "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¿ƒç†ã¨å¯¾è©±ã‚’è©³ç´°ã«è¨­è¨ˆã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "design_character_dialogue", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±è¨­è¨ˆã‚¨ãƒ©ãƒ¼")
                return json.dumps(
                    {"success": False, "error": f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾è©±è¨­è¨ˆã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2
                )

        @self.server.tool(
            name="design_scene_atmosphere", description="å ´é¢æ¼”å‡ºãƒ»é›°å›²æ°—è¨­è¨ˆ - å„ã‚·ãƒ¼ãƒ³ã®æ¼”å‡ºã¨é›°å›²æ°—ä½œã‚Šã‚’è¨­è¨ˆã—ã¾ã™"
        )
        async def design_scene_atmosphere(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """å ´é¢æ¼”å‡ºãƒ»é›°å›²æ°—è¨­è¨ˆæ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                prompt = f"# ç¬¬{episode:03d}è©± å ´é¢æ¼”å‡ºãƒ»é›°å›²æ°—è¨­è¨ˆæ®µéš\n\n## å‰æ®µéšã®è¨­è¨ˆçµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## è¨­è¨ˆé …ç›®\n1. **å ´é¢è¨­å®šã®è©³ç´°åŒ–**\n   - å„ã‚·ãƒ¼ãƒ³ã®èˆå°è¨­å®š\n   - æ™‚é–“ã¨å ´æ‰€ã®åŠ¹æœçš„ãªæ´»ç”¨\n   - ç’°å¢ƒãŒä¸ãˆã‚‹å¿ƒç†çš„å½±éŸ¿\n\n2. **é›°å›²æ°—ä½œã‚Šã®æŠ€æ³•**\n   - äº”æ„Ÿã‚’ä½¿ã£ãŸæƒ…æ™¯æå†™\n   - æ¯”å–©ã¨ä¿®è¾ã«ã‚ˆã‚‹è¡¨ç¾å¼·åŒ–\n   - èª­è€…ã®æƒ³åƒåŠ›ã‚’åˆºæ¿€ã™ã‚‹æå†™\n\n3. **æ¼”å‡ºæŠ€æ³•ã®å®Ÿè£…**\n   - ã‚·ãƒ¼ãƒ³è»¢æ›ã®æ¼”å‡ºæ–¹æ³•\n   - ç·Šè¿«æ„Ÿã‚„ãƒ­ãƒãƒ³ãƒãƒƒã‚¯ãªé›°å›²æ°—ã®ä½œã‚Šæ–¹\n   - èª­è€…ã‚’å¼•ãè¾¼ã‚€è‡¨å ´æ„Ÿã®æ¼”å‡º\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®è¦ç´ ã‚’å…·ä½“çš„ã«è¨­è¨ˆã—ã€æ¬¡æ®µéšï¼ˆè«–ç†æ•´åˆæ€§èª¿æ•´ï¼‰ã¸ã®æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "prompt": prompt,
                    "stage": "design_scene_atmosphere",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "adjust_logic_consistency",
                    "instructions": "å ´é¢æ¼”å‡ºã¨é›°å›²æ°—ä½œã‚Šã‚’è©³ç´°ã«è¨­è¨ˆã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "design_scene_atmosphere", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("å ´é¢æ¼”å‡ºè¨­è¨ˆã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"å ´é¢æ¼”å‡ºè¨­è¨ˆã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

    def _register_quality_refinement_tools(self) -> None:
        """å“è³ªå‘ä¸Šãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="adjust_logic_consistency", description="è«–ç†æ•´åˆæ€§èª¿æ•´ - ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®è«–ç†çš„ä¸€è²«æ€§ã‚’ç¢ºèªãƒ»èª¿æ•´ã—ã¾ã™"
        )
        async def adjust_logic_consistency(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """è«–ç†æ•´åˆæ€§èª¿æ•´æ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                prompt = f"# ç¬¬{episode:03d}è©± è«–ç†æ•´åˆæ€§èª¿æ•´æ®µéš\n\n## å‰æ®µéšã®è¨­è¨ˆçµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## èª¿æ•´é …ç›®\n1. **ã‚¹ãƒˆãƒ¼ãƒªãƒ¼è«–ç†ã®æ¤œè¨¼**\n   - ãƒ—ãƒ­ãƒƒãƒˆå±•é–‹ã®è«–ç†çš„ä¸€è²«æ€§\n   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡Œå‹•ã®å‹•æ©Ÿã¨çµæœ\n   - è¨­å®šã¨ã®çŸ›ç›¾ç‚¹ã®ç¢ºèª\n\n2. **æ™‚ç³»åˆ—ã¨å› æœé–¢ä¿‚ã®æ•´ç†**\n   - å‡ºæ¥äº‹ã®æ™‚ç³»åˆ—ã®ç¢ºèª\n   - åŸå› ã¨çµæœã®é–¢ä¿‚ã®æ˜ç¢ºåŒ–\n   - ä¼ç·šã¨å›åã®æ•´åˆæ€§\n\n3. **æ•´åˆæ€§å•é¡Œã®è§£æ±º**\n   - ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œç‚¹ã®ä¿®æ­£æ–¹é‡\n   - è¨­å®šå¤‰æ›´ã®å¿…è¦æ€§åˆ¤æ–­\n   - ä»£æ›¿æ¡ˆã®æ¤œè¨\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®æ¤œè¨¼ã‚’è¡Œã„ã€è«–ç†çš„ãªå•é¡Œç‚¹ãŒã‚ã‚Œã°ä¿®æ­£æ¡ˆã‚’æç¤ºã—ã€æ¬¡æ®µéšï¼ˆåŸç¨¿åŸ·ç­†ï¼‰ã¸ã®æº–å‚™ã‚’æ•´ãˆã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "prompt": prompt,
                    "stage": "adjust_logic_consistency",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "write_manuscript_draft",
                    "instructions": "è«–ç†æ•´åˆæ€§ã‚’ç¢ºèªãƒ»èª¿æ•´ã—ã€åŸç¨¿åŸ·ç­†ã¸ã®æº–å‚™ã‚’å®Œäº†ã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "adjust_logic_consistency", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("è«–ç†æ•´åˆæ€§èª¿æ•´ã‚¨ãƒ©ãƒ¼")
                return json.dumps(
                    {"success": False, "error": f"è«–ç†æ•´åˆæ€§èª¿æ•´ã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2
                )

        @self.server.tool(name="refine_manuscript_quality", description="å“è³ªæ”¹å–„æ®µéš - åŸç¨¿ã®å“è³ªã‚’å¤šè§’çš„ã«æ”¹å–„ã—ã¾ã™")
        async def refine_manuscript_quality(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """å“è³ªæ”¹å–„æ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨
                path_service = create_path_service()
                manuscript_file = path_service.get_manuscript_path(episode)
                manuscript_content = ""
                if manuscript_file.exists():
                    manuscript_content = manuscript_file.read_text(encoding="utf-8")
                prompt = f"# ç¬¬{episode:03d}è©± å“è³ªæ”¹å–„æ®µéš\n\n## åŸç¨¿å†…å®¹\n{manuscript_content[:2000]}{('...' if len(manuscript_content) > 2000 else '')}\n\n## å‰æ®µéšã®è¨­è¨ˆçµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## å“è³ªæ”¹å–„é …ç›®\n1. **æ–‡ç« å“è³ªã®å‘ä¸Š**\n   - æ–‡ç« ã®èª­ã¿ã‚„ã™ã•æ”¹å–„\n   - èªå½™ã®å¤šæ§˜åŒ–ã¨é©åˆ‡æ€§\n   - æ–‡ä½“ã®ä¸€è²«æ€§ç¢ºä¿\n\n2. **è¡¨ç¾åŠ›ã®å¼·åŒ–**\n   - æ„Ÿæƒ…è¡¨ç¾ã®æ·±åŒ–\n   - æå†™ã®è‡¨å ´æ„Ÿå‘ä¸Š\n   - æ¯”å–©ãƒ»ä¿®è¾ã®åŠ¹æœçš„æ´»ç”¨\n\n3. **æ§‹æˆã®æœ€é©åŒ–**\n   - ã‚·ãƒ¼ãƒ³é…åˆ†ã®èª¿æ•´\n   - ãƒ†ãƒ³ãƒã¨ãƒªã‚ºãƒ ã®æ”¹å–„\n   - èª­è€…ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®å¼·åŒ–\n\n## æŒ‡ç¤º\nä¸Šè¨˜ã®è¦³ç‚¹ã‹ã‚‰åŸç¨¿ã‚’æ”¹å–„ã—ã€æ¬¡æ®µéšï¼ˆæœ€çµ‚èª¿æ•´ï¼‰ã¸ã®æº–å‚™ã‚’æ•´ãˆã¦ãã ã•ã„ã€‚\n"
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "manuscript_content": manuscript_content,
                    "prompt": prompt,
                    "stage": "refine_manuscript_quality",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "finalize_manuscript",
                    "instructions": "åŸç¨¿ã®å“è³ªã‚’å¤šè§’çš„ã«æ”¹å–„ã—ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "refine_manuscript_quality", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("å“è³ªæ”¹å–„ã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"å“è³ªæ”¹å–„ã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

        @self.server.tool(
            name="finalize_manuscript", description="æœ€çµ‚èª¿æ•´æ®µéš - åŸç¨¿ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯ã¨å®Œæˆå‡¦ç†ã‚’è¡Œã„ã¾ã™"
        )
        async def finalize_manuscript(
            episode: int, session_id: str | None = None, project_root: str | None = None
        ) -> str:
            """æœ€çµ‚èª¿æ•´æ®µéš"""
            try:
                import json
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root
                session_manager = WritingSessionManager(project_path)
                session_data = session_manager.load_session(session_id) if session_id else {}
                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨
                path_service = create_path_service()
                manuscript_file = path_service.get_manuscript_path(episode)
                manuscript_content = ""
                if manuscript_file.exists():
                    manuscript_content = manuscript_file.read_text(encoding="utf-8")
                prompt = f"# ç¬¬{episode:03d}è©± æœ€çµ‚èª¿æ•´æ®µéš\n\n## ç¾åœ¨ã®åŸç¨¿\n{manuscript_content[:2000]}{('...' if len(manuscript_content) > 2000 else '')}\n\n## å…¨æ®µéšã®è¨­è¨ˆãƒ»æ”¹å–„çµæœ\n{(json.dumps(session_data, ensure_ascii=False, indent=2) if session_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—')}\n\n## æœ€çµ‚èª¿æ•´é …ç›®\n1. **æœ€çµ‚å“è³ªãƒã‚§ãƒƒã‚¯**\n   - èª¤å­—è„±å­—ã®ç¢ºèª\n   - è¡¨è¨˜ã‚†ã‚Œã®çµ±ä¸€\n   - æ–‡ç« ã®æœ€çµ‚èª¿æ•´\n\n2. **å®Œæˆåº¦ã®ç¢ºèª**\n   - ç›®æ¨™æ–‡å­—æ•°ã¨ã®æ¯”è¼ƒ\n   - å“è³ªåŸºæº–ã®é”æˆç¢ºèª\n   - èª­è€…æº€è¶³åº¦ã®äºˆæƒ³è©•ä¾¡\n\n3. **å®Œæˆå‡¦ç†**\n   - ãƒ•ã‚¡ã‚¤ãƒ«åã®æœ€çµ‚åŒ–\n   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²\n   - ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†å‡¦ç†\n\n## æŒ‡ç¤º\næœ€çµ‚ãƒã‚§ãƒƒã‚¯ã¨èª¿æ•´ã‚’è¡Œã„ã€åŸç¨¿ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚å®Œäº†å¾Œã€Œç¬¬{episode:03d}è©±å®Œæˆã€ã¨å ±å‘Šã—ã¦ãã ã•ã„ã€‚\n"
                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨
                path_service = create_path_service()
                final_manuscript_file = path_service.get_manuscript_path(episode)
                result = {
                    "success": True,
                    "episode": episode,
                    "session_id": session_id,
                    "manuscript_content": manuscript_content,
                    "final_manuscript_path": str(final_manuscript_file),
                    "prompt": prompt,
                    "stage": "finalize_manuscript",
                    "timestamp": project_now().datetime.isoformat(),
                    "next_stage": "completed",
                    "instructions": "æœ€çµ‚èª¿æ•´ã‚’è¡Œã„ã€åŸç¨¿ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„",
                }
                if session_id:
                    session_manager.save_stage_output(session_id, "finalize_manuscript", result)
                return self._json_with_path_fallback(result, locals())
            except Exception as e:
                self.logger.exception("æœ€çµ‚èª¿æ•´ã‚¨ãƒ©ãƒ¼")
                return json.dumps({"success": False, "error": f"æœ€çµ‚èª¿æ•´ã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2)

    def _register_check_tools(self) -> None:
        """å“è³ªãƒã‚§ãƒƒã‚¯é–¢é€£ãƒ„ãƒ¼ãƒ«ç™»éŒ²ï¼ˆãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ï¼‰"""
        self._register_main_check_tools()
        self._register_specialized_check_tools()

    def _register_main_check_tools(self) -> None:
        """ãƒ¡ã‚¤ãƒ³å“è³ªãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="check",
            description="åŸç¨¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆæ®µéšçš„10ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼‰ - åŸºæœ¬ãƒã‚§ãƒƒã‚¯ã‹ã‚‰æœ€çµ‚å“è³ªèªå®šã¾ã§ä½“ç³»çš„ã«å®Ÿè¡Œ",
        )
        async def check(episode: int, auto_fix: bool = False, project_root: str | None = None) -> str:
            """æ®µéšçš„10ã‚¹ãƒ†ãƒƒãƒ—å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
            try:
                import json
                from pathlib import Path

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
                if project_root:
                    project_path = Path(project_root)
                else:
                    from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.project_root

                # å“è³ªãƒã‚§ãƒƒã‚¯10ã‚¹ãƒ†ãƒƒãƒ—å®šç¾©
                check_steps = [
                    {
                        "id": 1,
                        "name": "åŸºæœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯",
                        "category": "æ§‹é€ ",
                        "description": "æ®µè½æ§‹æˆã€æ”¹è¡Œä½ç½®ã€åŸºæœ¬ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ",
                    },
                    {
                        "id": 2,
                        "name": "æ–‡å­—æ•°ãƒ»é•·ã•ãƒã‚§ãƒƒã‚¯",
                        "category": "æ§‹é€ ",
                        "description": "ç›®æ¨™æ–‡å­—æ•°ã¨ã®ä¹–é›¢ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ©ãƒ³ã‚¹",
                    },
                    {
                        "id": 3,
                        "name": "æ–‡æ³•ãƒ»è¡¨è¨˜ãƒã‚§ãƒƒã‚¯",
                        "category": "è¨€èª",
                        "description": "èª¤å­—è„±å­—ã€è¡¨è¨˜ã‚†ã‚Œã€åŠ©è©ã®ä½¿ã„æ–¹",
                    },
                    {
                        "id": 4,
                        "name": "ç¦æ­¢è¡¨ç¾æ¤œå‡º",
                        "category": "è¨€èª",
                        "description": "ã§ã™ã¾ã™èª¿æ··åœ¨ã€éåº¦ãªæ„Ÿå˜†ç¬¦ã€ä¸é©åˆ‡è¡¨ç¾",
                    },
                    {
                        "id": 5,
                        "name": "èª­ã¿ã‚„ã™ã•åˆ†æ",
                        "category": "å¯èª­æ€§",
                        "description": "æ–‡ã®é•·ã•ã€è¤‡é›‘åº¦ã€èª­ã¿ã‚„ã™ã•æŒ‡æ•°",
                    },
                    {
                        "id": 6,
                        "name": "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§",
                        "category": "å†…å®¹",
                        "description": "æ€§æ ¼ã®ä¸€è²«æ€§ã€å£èª¿ã€è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    },
                    {
                        "id": 7,
                        "name": "è¨­å®šãƒ»ä¸–ç•Œè¦³æ•´åˆæ€§",
                        "category": "å†…å®¹",
                        "description": "æ—¢å­˜è¨­å®šã¨ã®çŸ›ç›¾ã€æ™‚ç³»åˆ—ã®æ•´åˆæ€§",
                    },
                    {
                        "id": 8,
                        "name": "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å±•é–‹",
                        "category": "å†…å®¹",
                        "description": "ãƒ—ãƒ­ãƒƒãƒˆé€šã‚Šã®é€²è¡Œã€è«–ç†çš„æ•´åˆæ€§",
                    },
                    {
                        "id": 9,
                        "name": "æ–‡ä½“ãƒ»è¡¨ç¾åŠ›",
                        "category": "è¡¨ç¾",
                        "description": "æ–‡ä½“ã®çµ±ä¸€ã€è¡¨ç¾ã®è±Šã‹ã•ã€æ„Ÿæƒ…è¡¨ç¾",
                    },
                    {
                        "id": 10,
                        "name": "ç·åˆå“è³ªè©•ä¾¡",
                        "category": "ç·åˆ",
                        "description": "å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢ç®—å‡ºã€æ”¹å–„ææ¡ˆ",
                    },
                ]

                # å®Ÿè¡Œçµæœã‚’æ ¼ç´
                check_log = []
                completed_steps = 0
                total_score = 0.0
                issues_found = []

                for step in check_steps:
                    step_id = step["id"]
                    step_name = step["name"]
                    step_category = step["category"]
                    step_description = step["description"]

                    try:
                        # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹ãƒ­ã‚°
                        start_msg = f"ğŸ” STEP {step_id}: {step_name} - {step_description}"
                        check_log.append(
                            {
                                "step": step_id,
                                "name": step_name,
                                "category": step_category,
                                "description": step_description,
                                "status": "started",
                                "message": start_msg,
                            }
                        )

                        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
                        step_result = await self._execute_quality_check_step(step_id, episode, project_path, auto_fix)

                        # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ãƒ­ã‚°
                        complete_msg = f"âœ… STEP {step_id}: {step_name} å®Œäº† - ã‚¹ã‚³ã‚¢: {step_result['score']:.1f}ç‚¹"
                        check_log.append(
                            {
                                "step": step_id,
                                "name": step_name,
                                "category": step_category,
                                "status": "completed",
                                "message": complete_msg,
                                "score": step_result["score"],
                                "issues": step_result.get("issues", []),
                                "suggestions": step_result.get("suggestions", []),
                            }
                        )

                        completed_steps += 1
                        total_score += step_result["score"]
                        issues_found.extend(step_result.get("issues", []))

                    except Exception as step_error:
                        # ã‚¹ãƒ†ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
                        error_msg = f"âŒ STEP {step_id}: {step_name} ã§ã‚¨ãƒ©ãƒ¼ - {step_error!s}"
                        check_log.append(
                            {
                                "step": step_id,
                                "name": step_name,
                                "category": step_category,
                                "status": "error",
                                "message": error_msg,
                                "error": str(step_error),
                            }
                        )
                        break

                # å“è³ªãƒã‚§ãƒƒã‚¯çµæœã®æ•´ç†
                is_complete = completed_steps == len(check_steps)
                average_score = (total_score / completed_steps) if completed_steps > 0 else 0.0

                # å“è³ªãƒ¬ãƒ™ãƒ«åˆ¤å®š
                quality_level = self._determine_quality_level(average_score)

                result = {
                    "success": is_complete,
                    "episode": episode,
                    "total_steps": len(check_steps),
                    "completed_steps": completed_steps,
                    "average_score": round(average_score, 1),
                    "quality_level": quality_level,
                    "total_issues": len(issues_found),
                    "check_log": check_log,
                    "issues_summary": self._categorize_issues(issues_found),
                    "final_status": f"å“è³ªãƒã‚§ãƒƒã‚¯{'å®Œäº†' if is_complete else 'ä¸­æ–­'} - {quality_level}",
                }

                return self._json_with_path_fallback(result, locals())

            except Exception as e:
                self.logger.exception("å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
                return json.dumps(
                    {"success": False, "error": str(e), "message": "å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"},
                    ensure_ascii=False,
                    indent=2,
                )

        @self.server.tool(
            name="check_basic",
            description="åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œ - ä»¥ä¸‹ã®åŸºæœ¬çš„ãªå•é¡Œã‚’æ¤œå‡º:\n            â€¢ æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆç›®æ¨™æ–‡å­—æ•°ã¨ã®ä¹–é›¢ï¼‰\n            â€¢ ç¦æ­¢è¡¨ç¾æ¤œå‡ºï¼ˆã§ã™ã¾ã™èª¿æ··åœ¨ã€éåº¦ãªæ„Ÿå˜†ç¬¦ç­‰ï¼‰\n            â€¢ åŸºæœ¬çš„ãªæ–‡ç« æ§‹é€ å•é¡Œï¼ˆæ®µè½æ§‹æˆã€æ”¹è¡Œä½ç½®ç­‰ï¼‰\n            â€¢ èª¤å­—è„±å­—ãƒ»è¡¨è¨˜ã‚†ã‚Œã®å¯èƒ½æ€§ãŒã‚ã‚‹ç®‡æ‰€",
        )
        def check_basic(episode: int, project_root: str | None = None) -> str:
            """åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯ã®ã¿"""
            try:
                cmd = f"core check {episode} --skip-a31 --skip-claude"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯")
            except Exception as e:
                self.logger.exception("åŸºæœ¬ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼")
                return f"åŸºæœ¬ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}"

        @self.server.tool(
            name="check_story_elements",
            description="å°èª¬ã®åŸºæœ¬è¦ç´ è©•ä¾¡ï¼ˆ68é …ç›®ï¼‰ - å°èª¬ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã®å……å®Ÿåº¦ã‚’ãƒã‚§ãƒƒã‚¯:\n            ã€æ„Ÿæƒ…æå†™ï¼ˆ12é …ç›®ï¼‰ã€‘ã€Œæ€’ã‚Šã€ã€Œå–œã³ã€ç­‰ã®æ„Ÿæƒ…è¡¨ç¾ãŒå…·ä½“çš„ã‹/èª­è€…ãŒå…±æ„Ÿã§ãã‚‹æå†™ã‹/æ„Ÿæƒ…å¤‰åŒ–ã«è«–ç†æ€§ãŒã‚ã‚‹ã‹/è¡Œå‹•ã¨å†…é¢ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹\n            ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆ12é …ç›®ï¼‰ã€‘å£èª¿ãƒ»è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒä¸€è²«ã—ã¦ã„ã‚‹ã‹/ã‚­ãƒ£ãƒ©ãŒæˆé•·ã—ã¦ã„ã‚‹ã‹/äººé–“é–¢ä¿‚ã®å¤‰åŒ–ãŒè‡ªç„¶ã‹/å€‹æ€§çš„ã§é­…åŠ›çš„ã‹\n            ã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å±•é–‹ï¼ˆ12é …ç›®ï¼‰ã€‘èµ·æ‰¿è»¢çµãŒæ˜ç¢ºã‹/èª­ã‚€ãƒ†ãƒ³ãƒãŒé©åˆ‡ã‹/ä¼ç·šãŒåŠ¹æœçš„ã«é…ç½®ãƒ»å›åã•ã‚Œã¦ã„ã‚‹ã‹/äºˆæƒ³å¤–ã ãŒç´å¾—ã§ãã‚‹å±•é–‹ã‹\n            ã€æ–‡ç« è¡¨ç¾ï¼ˆ12é …ç›®ï¼‰ã€‘æƒ…æ™¯æå†™ã«è‡¨å ´æ„ŸãŒã‚ã‚‹ã‹/æ¯”å–©ãƒ»ä¿®è¾ãŒåŠ¹æœçš„ã‹/æ–‡ç« ãƒªã‚ºãƒ ãŒèª­ã¿ã‚„ã™ã„ã‹/èªå½™ãŒè±Šå¯Œã§é©åˆ‡ã‹\n            ã€ä¸–ç•Œè¦³ãƒ»è¨­å®šï¼ˆ10é …ç›®ï¼‰ã€‘è¨­å®šã«çŸ›ç›¾ãŒãªã„ã‹/ä¸–ç•Œè¦³ã«æ·±ã¿ãŒã‚ã‚‹ã‹/ç¾å®Ÿå‘³ãƒ»èª¬å¾—åŠ›ãŒã‚ã‚‹ã‹/ç‹¬è‡ªæ€§ãƒ»ã‚ªãƒªã‚¸ãƒŠãƒªãƒ†ã‚£ãŒã‚ã‚‹ã‹\n            ã€èª­è€…ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆï¼ˆ10é …ç›®ï¼‰ã€‘å†’é ­ã§èª­è€…ã‚’å¼•ãè¾¼ã‚ã¦ã„ã‚‹ã‹/ç¶šããŒæ°—ã«ãªã‚‹æ§‹æˆã‹/èª­å¾Œã«æº€è¶³æ„ŸãŒã‚ã‚‹ã‹/ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­è€…ã«éŸ¿ãå†…å®¹ã‹\n            å„é …ç›®ã‚’0-100ç‚¹ã§è©•ä¾¡ã—ã€ä½ã‚¹ã‚³ã‚¢é …ç›®ã«ã¯å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ",
        )
        def check_story_elements(
            episode: int, auto_fix: bool = False, fix_level: str = "safe", project_root: str | None = None
        ) -> str:
            """A31è©•ä¾¡ã®ã¿å®Ÿè¡Œ"""
            try:
                cmd = f"core check {episode} --skip-basic --skip-claude"
                if auto_fix:
                    cmd += f" --auto-fix --fix-level {fix_level}"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "å°èª¬è¦ç´ è©•ä¾¡")
            except Exception as e:
                self.logger.exception("A31è©•ä¾¡ã‚¨ãƒ©ãƒ¼")
                return f"A31è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}"

    def _register_specialized_check_tools(self) -> None:
        """å°‚é–€å“è³ªãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        @self.server.tool(
            name="check_story_structure",
            description="ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ§‹æˆè©•ä¾¡ - ãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«ã®ç‰©èªæ§‹æˆåŠ›ã‚’ãƒã‚§ãƒƒã‚¯:\n            â€¢ ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ•´åˆæ€§ï¼šå‰å¾Œã®å±•é–‹ã¨ã®çŸ›ç›¾ãƒ»è¨­å®šã¨ã®é£Ÿã„é•ã„ãƒ»æ™‚ç³»åˆ—ã®ç ´ç¶»ã‚’ç™ºè¦‹\n            â€¢ èµ·æ‰¿è»¢çµã®å®Œæˆåº¦ï¼šå°å…¥ã®å¼•ãè¾¼ã¿ãƒ»å±•é–‹ã®ç››ã‚Šä¸ŠãŒã‚Šãƒ»ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã®è¡æ’ƒãƒ»çµæœ«ã®æº€è¶³åº¦\n            â€¢ ä¼ç·šã¨å›åï¼šä¼ç·šã®åŠ¹æœçš„ãªé…ç½®ãƒ»å›åã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ»æ„å¤–æ€§ã¨ç´å¾—æ„Ÿã®ãƒãƒ©ãƒ³ã‚¹\n            â€¢ ãƒšãƒ¼ã‚¹é…åˆ†ï¼šå ´é¢è»¢æ›ã®è‡ªç„¶ã•ãƒ»ç·©æ€¥ã®ãƒªã‚ºãƒ ãƒ»èª­è€…ã‚’é£½ãã•ã›ãªã„å±•é–‹é€Ÿåº¦\n            â€¢ ã‚­ãƒ£ãƒ©å¿ƒç†ã®ä¸€è²«æ€§ï¼šãã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚‰ã—ã„æ€è€ƒãƒ»æ„Ÿæƒ…ãƒ»è¡Œå‹•é¸æŠã«ãªã£ã¦ã„ã‚‹ã‹ã‚’åˆ†æ\n            â€¢ ã‚¸ãƒ£ãƒ³ãƒ«é©åˆæ€§ï¼šãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ãƒ»æ‹æ„›ãƒ»ãƒŸã‚¹ãƒ†ãƒªãƒ¼ç­‰ã®ã‚¸ãƒ£ãƒ³ãƒ«èª­è€…ãŒæœŸå¾…ã™ã‚‹è¦ç´ ã®å……è¶³åº¦",
        )
        def check_story_structure(episode: int, project_root: str | None = None) -> str:
            """ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ§‹æˆãƒã‚§ãƒƒã‚¯"""
            try:
                cmd = f"core check {episode} --skip-basic --skip-claude"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "æ§‹æˆè©•ä¾¡")
            except Exception as e:
                self.logger.exception("æ§‹æˆè©•ä¾¡ã‚¨ãƒ©ãƒ¼")
                return f"æ§‹æˆè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}"

        @self.server.tool(
            name="check_writing_expression",
            description="æ–‡ç« è¡¨ç¾åŠ›è©•ä¾¡ - ãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«ã®æ–‡ç« è¡¨ç¾åŠ›ã‚’ãƒã‚§ãƒƒã‚¯:\n            â€¢ æ–‡ç« ã®è‡ªç„¶ã•ï¼šæ—¥æœ¬èªã¨ã—ã¦ä¸è‡ªç„¶ãªè¡¨ç¾ãƒ»é•å’Œæ„Ÿã®ã‚ã‚‹æ–‡ç« æ§‹é€ ãƒ»èªå½™é¸æŠã®é©åˆ‡æ€§ã‚’æ¤œå‡º\n            â€¢ æå†™åŠ›ï¼šæƒ…æ™¯æå†™ã®è‡¨å ´æ„Ÿãƒ»äº”æ„Ÿã«è¨´ãˆã‚‹è¡¨ç¾ãƒ»èª­è€…ã®æƒ³åƒã‚’å–šèµ·ã™ã‚‹æå†™æŠ€è¡“\n            â€¢ æ¯”å–©ã¨ä¿®è¾ï¼šåŠ¹æœçš„ãªæ¯”å–©è¡¨ç¾ãƒ»å°è±¡çš„ãªä¿®è¾æŠ€æ³•ãƒ»é™³è…ã§ãªã„ç‹¬å‰µçš„ãªè¡¨ç¾\n            â€¢ æ–‡ä½“ã®ä¸€è²«æ€§ï¼šå…¨ä½“ã‚’é€šã˜ãŸæ–‡ä½“ã®çµ±ä¸€æ„Ÿãƒ»å ´é¢ã«å¿œã˜ãŸæ–‡ä½“ã®ä½¿ã„åˆ†ã‘\n            â€¢ èª­ã¿ã‚„ã™ã•ï¼šä¸€æ–‡ã®é•·ã•ãƒ»æ¼¢å­—ã¨ã²ã‚‰ãŒãªã®ãƒãƒ©ãƒ³ã‚¹ãƒ»å°‚é–€ç”¨èªã®é©åˆ‡ãªèª¬æ˜\n            â€¢ å•†æ¥­ä½œå“æ¯”è¼ƒï¼šãƒ—ãƒ­ä½œå®¶ã®ä½œå“ã¨æ¯”è¼ƒã—ã¦æ–‡ç« åŠ›ãƒ»è¡¨ç¾åŠ›ã®ãƒ¬ãƒ™ãƒ«ã‚’è©•ä¾¡",
        )
        def check_writing_expression(episode: int, project_root: str | None = None) -> str:
            """æ–‡ç« è¡¨ç¾ãƒã‚§ãƒƒã‚¯"""
            try:
                cmd = f"core check {episode} --skip-basic --skip-claude"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "è¡¨ç¾è©•ä¾¡")
            except Exception as e:
                self.logger.exception("è¡¨ç¾è©•ä¾¡ã‚¨ãƒ©ãƒ¼")
                return f"è¡¨ç¾è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}"

        @self.server.tool(
            name="check_rhythm",
            description="æ–‡ç« ãƒªã‚ºãƒ ãƒ»èª­ã¿ã‚„ã™ã•åˆ†æ - ä»¥ä¸‹ã‚’è©³ç´°åˆ†æ:\n            â€¢ æ–‡ã®é•·ã•ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆçŸ­æ–‡ãƒ»ä¸­æ–‡ãƒ»é•·æ–‡ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰\n            â€¢ èª­ç‚¹ã®é…ç½®ã¨ãƒªã‚ºãƒ æ„Ÿ\n            â€¢ åŒã˜èªå°¾ã®é€£ç¶šä½¿ç”¨ãƒã‚§ãƒƒã‚¯\n            â€¢ æ¼¢å­—ãƒ»ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠã®ãƒãƒ©ãƒ³ã‚¹\n            â€¢ æ®µè½ã®é•·ã•ã¨é…åˆ†\n            â€¢ è¦–è¦šçš„ãªèª­ã¿ã‚„ã™ã•ï¼ˆæ”¹è¡Œä½ç½®ç­‰ï¼‰",
        )
        def check_rhythm(episode: int, project_root: str | None = None) -> str:
            """æ–‡ç« ãƒªã‚ºãƒ åˆ†æã®ã¿"""
            try:
                cmd = f"core check {episode} --rhythm-only"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "æ–‡ç« ãƒªã‚ºãƒ åˆ†æ")
            except Exception as e:
                self.logger.exception("ãƒªã‚ºãƒ åˆ†æã‚¨ãƒ©ãƒ¼")
                return f"ãƒªã‚ºãƒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}"

        @self.server.tool(
            name="check_fix",
            description="å•é¡Œç®‡æ‰€ã®è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ - æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’è‡ªå‹•ä¿®æ­£ï¼ˆä¿®æ­£ãƒ¬ãƒ™ãƒ«: safe/standard/aggressiveï¼‰",
        )
        def check_fix(
            episode: int, issue_ids: list[str] | None = None, fix_level: str = "safe", project_root: str | None = None
        ) -> str:
            """è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ"""
            try:
                cmd = f"core check {episode} --auto-fix --fix-level {fix_level}"
                if issue_ids:
                    cmd += f" --issue-ids {','.join(issue_ids)}"
                result = self._execute_noveler_command(cmd, project_root)
                return self._format_tool_result(result, "è‡ªå‹•ä¿®æ­£")
            except Exception as e:
                self.logger.exception("è‡ªå‹•ä¿®æ­£ã‚¨ãƒ©ãƒ¼")
                return f"è‡ªå‹•ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}"

    def _register_plot_tools(self) -> None:
        """ãƒ—ãƒ­ãƒƒãƒˆé–¢é€£ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ„ãƒ¼ãƒ«ç™»éŒ²ï¼ˆæ’¤å»ƒæ¸ˆã¿ã‚¹ã‚¿ãƒ–ï¼‰"""

        # æ—§ `plot_generate` / `plot_validate` ãƒ„ãƒ¼ãƒ«ã¯ modern `noveler_plot`
        # ã¸çµ±åˆæ¸ˆã¿ã€‚äº’æ›ç¶­æŒã®ãŸã‚å‘¼ã³å‡ºã—å…ƒæ§‹é€ ã®ã¿æ®‹ã—ã€ç™»éŒ²ã¯è¡Œã‚ãªã„ã€‚
        if hasattr(self, "logger"):
            try:
                self.logger.debug("legacy plot aliases removed; no tools registered")
            except Exception:
                pass

    def _register_project_tools(self) -> None:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        # `status` ãƒ„ãƒ¼ãƒ«ã¯å…±æœ‰ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã§ç™»éŒ²ã•ã‚Œã‚‹ãŸã‚ã€ã“ã®å±¤ã§ã¯è¿½åŠ æ“ä½œãªã—ã€‚

    def _register_legacy_compatibility_tools(self) -> None:
        """Deprecated stub for legacy alias registration.

        Purpose:
            Retained solely to document that legacy MCP aliases were fully
            removed on 2025-09-18. The method intentionally performs no
            registration to avoid resurrecting removed tools.

        Side Effects:
            None.
        """

        return None

    def _format_tool_result(self, result: dict[str, Any], operation_name: str) -> str:
        """ãƒ„ãƒ¼ãƒ«çµæœã®çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        try:
            if result.get("success", False):
                response_text = self._format_novel_success_result(result)
            else:
                response_text = self._format_novel_error_result(result)
            self.converter.convert(result)
            return f"{response_text}\n\nğŸ“ {operation_name}çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜æ¸ˆã¿ï¼ˆ95%ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ï¼‰"
        except Exception as e:
            self.logger.exception("%sçµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼", operation_name)
            return f"{operation_name}çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}"

    def _execute_noveler_command(self, command: str, project_root: str | None = None) -> dict[str, Any]:
        """novelerã‚³ãƒãƒ³ãƒ‰ã®ä»£æ›¿å®Ÿè£…ï¼ˆMCPçµ±åˆå¯¾å¿œï¼‰"""
        try:
            # CLIå»ƒæ­¢ã«ã‚ˆã‚ŠMCPãƒ„ãƒ¼ãƒ«å†…ã§ç›´æ¥å‡¦ç†
            return {
                "success": False,
                "error": "CLIå»ƒæ­¢ï¼šMCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "command": command,
                "suggestion": f"noveler {command} ã®ä»£ã‚ã‚Šã«ã€å¯¾å¿œã™ã‚‹MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "project_root": str(Path(project_root) if project_root else Path.cwd()),
            }
        except Exception as e:
            self.logger.exception("ä»£æ›¿å®Ÿè£…ã‚¨ãƒ©ãƒ¼")
            return {"success": False, "error": f"ä»£æ›¿å®Ÿè£…ã‚¨ãƒ©ãƒ¼: {e}", "command": command}

    def _handle_status_command(self, project_root: str | None = None) -> str:
        """çµ±åˆã•ã‚ŒãŸstatus ã‚³ãƒãƒ³ãƒ‰å‡¦ç†"""
        try:
            project_root_path = Path(project_root) if project_root else Path.cwd()
            try:
                from noveler.presentation.shared.shared_utilities import get_path_service

                path_service = get_path_service()
                manuscripts_dir = path_service.get_manuscript_dir()
            except ImportError:
                # B20æº–æ‹ : ãƒ‘ã‚¹ç®¡ç†ã¯PathServiceã‚’ä½¿ç”¨
                path_service = create_path_service()
                manuscripts_dir = path_service.get_manuscript_dir()
            if not manuscripts_dir.exists():
                return (
                    f"åŸç¨¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({manuscripts_dir})ã€‚ã¾ã åŸ·ç­†ã‚’é–‹å§‹ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                )
            manuscript_files = list(manuscripts_dir.glob("*.md")) + list(manuscripts_dir.glob("*.txt"))
            manuscript_files.sort()
            status_lines = []
            status_lines.append("ğŸ“š å°èª¬åŸ·ç­†çŠ¶æ³")
            status_lines.append("=" * 30)
            status_lines.append(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {project_root_path}")
            status_lines.append(f"åŸç¨¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {manuscripts_dir}")
            status_lines.append(f"åŸ·ç­†æ¸ˆã¿è©±æ•°: {len(manuscript_files)}")
            status_lines.append("")
            if manuscript_files:
                status_lines.append("ğŸ“ åŸ·ç­†æ¸ˆã¿åŸç¨¿:")
                for file in manuscript_files[:10]:
                    stat = file.stat()
                    size_kb = stat.st_size / 1024
                    modified = datetime.fromtimestamp(stat.st_mtime, tz=timezone.utc)
                    status_lines.append(f"  - {file.name} ({size_kb:.1f}KB, {modified.strftime('%Y-%m-%d %H:%M')})")
                if len(manuscript_files) > 10:
                    status_lines.append(f"  ... ä»– {len(manuscript_files) - 10} ä»¶")
                status_lines.append("")
                status_lines.append("ğŸ’¡ å“è³ªãƒã‚§ãƒƒã‚¯ä¾‹:")
                status_lines.append("  noveler check 1  # ç¬¬1è©±ã®å“è³ªãƒã‚§ãƒƒã‚¯")
                status_lines.append("  noveler write 2  # ç¬¬2è©±ã®åŸ·ç­†é–‹å§‹")
            else:
                status_lines.append("ã¾ã åŸ·ç­†ã•ã‚ŒãŸåŸç¨¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                status_lines.append("ğŸ’¡ noveler write 1 ã§åŸ·ç­†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
            return "\n".join(status_lines)
        except Exception as e:
            self.logger.exception("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼")
            return f"çŠ¶æ³ç¢ºèªã‚¨ãƒ©ãƒ¼: {e!s}"

    def _format_json_result(self, result: dict[str, Any]) -> str:
        """JSONçµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        lines = []
        lines.append(f"æˆåŠŸ: {result.get('success', 'N/A')}")
        lines.append(f"ã‚³ãƒãƒ³ãƒ‰: {result.get('command', 'N/A')}")
        if "outputs" in result:
            outputs = result["outputs"]
            lines.append(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {outputs.get('total_files', 0)}")
            lines.append(f"ç·ã‚µã‚¤ã‚º: {outputs.get('total_size_bytes', 0)} bytes")
        if "error" in result:
            error = result["error"]
            lines.append(f"ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: {error.get('code', 'N/A')}")
            lines.append(f"ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {error.get('message', 'N/A')}")
        return "\n".join(lines)

    def _format_dict(self, data: dict[str, Any]) -> str:
        """è¾æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return "\n".join(f"{k}: {v}" for (k, v) in data.items())

    def _format_novel_success_result(self, result: dict[str, Any]) -> str:
        """å°èª¬åŸ·ç­†æˆåŠŸçµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        lines = []
        lines.append(f"ğŸ‰ {result.get('message', 'å®Ÿè¡Œå®Œäº†')}")
        lines.append("=" * 40)
        data = result.get("data", {})
        if "episode_number" in result:
            lines.append(f"ğŸ“– è©±æ•°: ç¬¬{result['episode_number']}è©±")
        if "execution_time_seconds" in result:
            time_sec = result["execution_time_seconds"]
            lines.append(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {time_sec:.1f}ç§’")
        if data.get("manuscript_path"):
            lines.append(f"ğŸ“„ åŸç¨¿: {Path(data['manuscript_path']).name}")
        if data.get("word_count"):
            lines.append(f"âœï¸ æ–‡å­—æ•°: {data['word_count']:,}æ–‡å­—")
        if data.get("quality_score"):
            lines.append(f"â­ å“è³ªã‚¹ã‚³ã‚¢: {data['quality_score']}/100")
        performance = data.get("performance", {})
        if "turns_saved" in performance and performance["turns_saved"] > 0:
            lines.append(f"ğŸš€ æœ€é©åŒ–: {performance['turns_saved']}ã‚¿ãƒ¼ãƒ³å‰Šæ¸›")
        if "improvement_ratio" in performance and performance["improvement_ratio"] > 1:
            ratio = performance["improvement_ratio"]
            lines.append(f"ğŸ“ˆ åŠ¹ç‡åŒ–: {ratio:.1f}å€åŠ¹æœ")
        files = result.get("files", [])
        if files:
            lines.append(f"\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ« ({len(files)}ä»¶):")
            for file_info in files:
                file_type = file_info.get("type", "unknown")
                relative_path = file_info.get("relative_path", file_info.get("path", ""))
                size_kb = file_info.get("size_bytes", 0) / 1024
                lines.append(f"  â€¢ {file_type}: {relative_path} ({size_kb:.1f}KB)")
        return "\n".join(lines)

    def _format_novel_error_result(self, result: dict[str, Any]) -> str:
        """å°èª¬åŸ·ç­†ã‚¨ãƒ©ãƒ¼çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        lines = []
        lines.append(f"âŒ {result.get('error', 'å®Ÿè¡Œå¤±æ•—')}")
        lines.append("=" * 40)
        if "command" in result:
            lines.append(f"ğŸ“ ã‚³ãƒãƒ³ãƒ‰: {result['command']}")
        result_data = result.get("result_data", {})
        if result_data.get("failed_stage"):
            lines.append(f"ğŸ”´ å¤±æ•—æ®µéš: {result_data['failed_stage']}")
        if "completed_stages" in result_data:
            completed = result_data["completed_stages"]
            lines.append(f"âœ… å®Œäº†æ®µéš: {completed}/10")
        if result_data.get("session_id"):
            lines.append(f"ğŸ’¾ ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {result_data['session_id']}")
        suggestions = result.get("recovery_suggestions", [])
        if suggestions:
            lines.append("\nğŸ”§ å›å¾©ææ¡ˆ:")
            lines.extend(f"  â€¢ {suggestion}" for suggestion in suggestions)
        return "\n".join(lines)

    async def run(self) -> None:
        """ã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œ"""
        if not MCP_AVAILABLE:
            msg = "MCPãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            raise RuntimeError(msg)
        try:
            console.print("FastMCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œé–‹å§‹ (stdio)")
            self.logger.info("MCPã‚µãƒ¼ãƒãƒ¼é–‹å§‹ - é‡è¤‡å®Ÿè¡Œå¯¾ç­–æœ‰åŠ¹")

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–åˆæœŸåŒ–ï¼ˆéåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ï¼‰
            if not self._monitoring_initialized:
                self._init_performance_monitoring()
                self._monitoring_initialized = True

            import signal
            import sys

            def cleanup_handler(signum, frame) -> None:
                """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ - æ­£å¸¸çµ‚äº†å‡¦ç†"""
                self.logger.info(f"çµ‚äº†ã‚·ã‚°ãƒŠãƒ«å—ä¿¡: {signum}")
                self._cleanup_pid_file()
                sys.exit(0)

            signal.signal(signal.SIGTERM, cleanup_handler)
            signal.signal(signal.SIGINT, cleanup_handler)
            await self.server.run_stdio_async()
        except Exception:
            self.logger.exception("MCPã‚µãƒ¼ãƒãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
            raise
        finally:
            self._cleanup_pid_file()

    async def _execute_step(self, step_id: int | float, episode: int, project_path: Path) -> None:
        """18ã‚¹ãƒ†ãƒƒãƒ—ã®å€‹åˆ¥å®Ÿè¡Œ"""
        import asyncio

        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®å…·ä½“çš„ãªå‡¦ç†ã‚’å®Ÿè£…
        # ç¾æ™‚ç‚¹ã§ã¯æ¨¡æ“¬çš„ãªå‡¦ç†æ™‚é–“ã‚’è¨­å®š
        processing_times = {
            0: 1.0,  # ã‚¹ã‚³ãƒ¼ãƒ—å®šç¾©
            1: 2.0,  # å¤§éª¨
            2: 3.0,  # ä¸­éª¨
            3: 1.5,  # ãƒ†ãƒ¼ãƒæ€§ãƒ»ç‹¬è‡ªæ€§æ¤œè¨¼ï¼ˆæ—§2.5ï¼‰
            4: 2.0,  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ©ãƒ³ã‚¹è¨­è¨ˆ
            5: 3.0,  # å°éª¨ï¼ˆã‚·ãƒ¼ãƒ³ï¼ãƒ“ãƒ¼ãƒˆï¼‰
            6: 1.5,  # è«–ç†æ¤œè¨¼
            7: 2.0,  # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§æ¤œè¨¼
            8: 3.5,  # ä¼šè©±è¨­è¨ˆ
            9: 2.5,  # æ„Ÿæƒ…æ›²ç·š
            10: 3.0,  # æƒ…æ™¯ãƒ»äº”æ„Ÿãƒ»ä¸–ç•Œè¦³
            11: 4.0,  # åˆç¨¿ç”Ÿæˆ
            12: 2.0,  # æ–‡å­—æ•°æœ€é©åŒ–
            13: 2.5,  # æ–‡ä½“ãƒ»å¯èª­æ€§ãƒ‘ã‚¹
            14: 1.5,  # å¿…é ˆå“è³ªã‚²ãƒ¼ãƒˆ
            15: 2.0,  # æœ€çµ‚å“è³ªèªå®š
            16: 1.0,  # å…¬é–‹æº–å‚™
        }

        # å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        processing_time = processing_times.get(step_id, 1.0)
        await asyncio.sleep(processing_time)

        # TODO: å®Ÿéš›ã®å„ã‚¹ãƒ†ãƒƒãƒ—å‡¦ç†ã‚’å®Ÿè£…
        # ä¾‹ï¼š
        # if step_id == 0:
        #     await self._execute_scope_definition(episode, project_path)
        # elif step_id == 1:
        #     await self._execute_structure_design(episode, project_path)
        # ...

        # ã‚¹ãƒ†ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        step_file = project_path / "episodes" / f"EP{episode:03d}" / f"EP{episode:03d}_step{step_id:02d}.yaml"
        step_file.parent.mkdir(parents=True, exist_ok=True)

        # ç°¡æ˜“çš„ãªã‚¹ãƒ†ãƒƒãƒ—çµæœã‚’ä¿å­˜
        step_data = {
            "step_id": step_id,
            "episode": episode,
            "completed_at": self._get_current_timestamp(),
            "status": "completed",
        }

        import yaml

        with step_file.open("w", encoding="utf-8") as f:
            yaml.dump(step_data, f, allow_unicode=True, default_flow_style=False)

    def _get_current_timestamp(self) -> str:
        """ç¾åœ¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—"""
        from datetime import datetime

        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    async def _execute_quality_check_step(self, step_id: int, episode: int, project_path: Path, auto_fix: bool) -> dict:
        """å“è³ªãƒã‚§ãƒƒã‚¯ã‚¹ãƒ†ãƒƒãƒ—ã®å€‹åˆ¥å®Ÿè¡Œ"""
        import asyncio
        import random

        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®å‡¦ç†æ™‚é–“è¨­å®š
        processing_times = {
            1: 1.5,  # åŸºæœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯
            2: 1.0,  # æ–‡å­—æ•°ãƒ»é•·ã•ãƒã‚§ãƒƒã‚¯
            3: 2.0,  # æ–‡æ³•ãƒ»è¡¨è¨˜ãƒã‚§ãƒƒã‚¯
            4: 1.5,  # ç¦æ­¢è¡¨ç¾æ¤œå‡º
            5: 2.5,  # èª­ã¿ã‚„ã™ã•åˆ†æ
            6: 3.0,  # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§
            7: 2.0,  # è¨­å®šãƒ»ä¸–ç•Œè¦³æ•´åˆæ€§
            8: 2.5,  # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å±•é–‹
            9: 2.0,  # æ–‡ä½“ãƒ»è¡¨ç¾åŠ›
            10: 1.5,  # ç·åˆå“è³ªè©•ä¾¡
        }

        # å‡¦ç†æ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        processing_time = processing_times.get(step_id, 1.0)
        await asyncio.sleep(processing_time)

        # ã‚¹ãƒ†ãƒƒãƒ—åˆ¥ã®å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚’ç”Ÿæˆï¼ˆæ¨¡æ“¬ï¼‰
        {
            1: {
                "score": random.uniform(70, 95),
                "issues": ["æ®µè½åŒºåˆ‡ã‚ŠãŒä¸è‡ªç„¶ãªç®‡æ‰€ãŒ2ç®‡æ‰€"],
                "suggestions": ["æ®µè½ã®æµã‚Œã‚’è¦‹ç›´ã—ã¦ãã ã•ã„"],
            },
            2: {
                "score": random.uniform(75, 90),
                "issues": ["ç›®æ¨™æ–‡å­—æ•°4000å­—ã«å¯¾ã—3800å­—ï¼ˆ-200å­—ï¼‰"],
                "suggestions": ["æå†™ã‚’å°‘ã—è¿½åŠ ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"],
            },
            3: {
                "score": random.uniform(80, 95),
                "issues": ["è¡¨è¨˜ã‚†ã‚Œï¼šã€Œã ã£ãŸã€ã¨ã€Œã§ã—ãŸã€ã®æ··åœ¨"],
                "suggestions": ["æ–‡ä½“ã‚’çµ±ä¸€ã—ã¦ãã ã•ã„"],
            },
            4: {"score": random.uniform(85, 100), "issues": [], "suggestions": ["ç¦æ­¢è¡¨ç¾ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]},
            5: {
                "score": random.uniform(70, 85),
                "issues": ["å¹³å‡æ–‡é•·ãŒ45æ–‡å­—ã§é•·ã‚"],
                "suggestions": ["æ–‡ã‚’åˆ†å‰²ã—ã¦èª­ã¿ã‚„ã™ãã—ã¦ãã ã•ã„"],
            },
            6: {
                "score": random.uniform(75, 90),
                "issues": ["ä¸»äººå…¬ã®å£èª¿ã«ä¸€ç®‡æ‰€ä¸æ•´åˆ"],
                "suggestions": ["ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„"],
            },
            7: {"score": random.uniform(80, 95), "issues": [], "suggestions": ["ä¸–ç•Œè¦³è¨­å®šã¨ã®æ•´åˆæ€§ã¯è‰¯å¥½ã§ã™"]},
            8: {
                "score": random.uniform(75, 90),
                "issues": ["å±•é–‹ãŒå°‘ã—æ€¥ã™ãã‚‹ç®‡æ‰€ã‚ã‚Š"],
                "suggestions": ["æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’ã‚‚ã†å°‘ã—ä¸å¯§ã«æå†™ã—ã¦ãã ã•ã„"],
            },
            9: {
                "score": random.uniform(70, 85),
                "issues": ["å˜èª¿ãªè¡¨ç¾ãŒç›®ç«‹ã¤"],
                "suggestions": ["è¡¨ç¾ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¢—ã‚„ã—ã¦ãã ã•ã„"],
            },
            10: {"score": random.uniform(75, 88), "issues": [], "suggestions": ["ç·åˆçš„ã«è‰¯è³ªãªåŸç¨¿ã§ã™"]},
        }

        # TODO: å®Ÿéš›ã®å“è³ªãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        # ä¾‹ï¼š
        # if step_id == 1:
        #     return await self._check_basic_structure(episode, project_path)
        # elif step_id == 2:
        #     return await self._check_length_balance(episode, project_path)
        # ...

    def _register_artifact_tools(self) -> None:
        """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§ã‚·ã‚¹ãƒ†ãƒ ãƒ„ãƒ¼ãƒ«ç™»éŒ²"""

        def _resolve_artifact_store(project_path: Path):
            """ç¾è¡Œ(.noveler/artifacts)ã¨ãƒ¬ã‚¬ã‚·ãƒ¼(project_root/artifacts)ã‚’ä¸¡å¯¾å¿œã§è§£æ±º"""
            from noveler.domain.services.artifact_store_service import create_artifact_store as _create

            if not project_path.exists() or not project_path.is_dir():
                raise FileNotFoundError(f"Project root not found: {project_path}")

            modern_dir = project_path / ".noveler" / "artifacts"
            legacy_dir = project_path / "artifacts"

            # å„ªå…ˆ: modernã€‚ãƒ¬ã‚¬ã‚·ãƒ¼ã®ã¿å­˜åœ¨ã™ã‚‹å ´åˆã¯ãƒ¬ã‚¬ã‚·ãƒ¼ã‚’ä½¿ç”¨
            if legacy_dir.exists() and not modern_dir.exists():
                return _create(storage_dir=legacy_dir), None

            # ä¸¡æ–¹å­˜åœ¨ã™ã‚‹å ´åˆã¯modernã‚’ä¸»ã¨ã—ã€fallbackã«legacyã‚’è¿”ã™
            primary = _create(storage_dir=modern_dir)
            fallback = _create(storage_dir=legacy_dir) if legacy_dir.exists() else None
            return primary, fallback

        @self.server.tool(
            name="fetch_artifact", description="ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‚ç…§IDã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾— - å‚ç…§æ¸¡ã—ã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ã‚¢æ©Ÿèƒ½"
        )
        async def fetch_artifact(
            artifact_id: str, section: str | None = None, format_type: str = "text", project_root: str | None = None
        ) -> str:
            """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—

            Args:
                artifact_id: artifact:abc123å½¢å¼ã®å‚ç…§ID
                section: éƒ¨åˆ†å–å¾—ã‚»ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                format_type: å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆtext, json, yamlï¼‰
                project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            """
            try:
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¨­å®š
                if project_root:
                    project_path = Path(project_root)
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.get_project_root()

                # ArtifactStoreServiceåˆæœŸåŒ–ï¼ˆç¾è¡Œ/ãƒ¬ã‚¬ã‚·ãƒ¼ä¸¡å¯¾å¿œï¼‰
                artifact_store, legacy_store = _resolve_artifact_store(project_path)

                # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå–å¾—ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ¬ã‚¬ã‚·ãƒ¼å´ã‚‚è©¦è¡Œï¼‰
                content = artifact_store.fetch(artifact_id, section=section)
                if content is None and legacy_store is not None:
                    content = legacy_store.fetch(artifact_id, section=section)

                if content is None:
                    available_artifact_ids = list(artifact_store.list_artifacts().keys())
                    if legacy_store is not None:
                        available_artifact_ids.extend(legacy_store.list_artifacts().keys())

                    return json.dumps(
                        {
                            "success": False,
                            "error": f"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ '{artifact_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                            "available_artifacts": available_artifact_ids,
                        },
                        ensure_ascii=False,
                        indent=2,
                    )

                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†
                if format_type == "json":
                    try:
                        # JSONã¨ã—ã¦è§£æã—ã¦æ•´å½¢
                        import json as json_lib

                        parsed = json_lib.loads(content)
                        formatted_content = json_lib.dumps(parsed, ensure_ascii=False, indent=2)
                    except:
                        formatted_content = content
                else:
                    formatted_content = content

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼å´ã‚‚è©¦è¡Œï¼‰
                metadata = artifact_store.get_metadata(artifact_id)
                if metadata is None and legacy_store is not None:
                    metadata = legacy_store.get_metadata(artifact_id)

                result = {
                    "success": True,
                    "artifact_id": artifact_id,
                    "content": formatted_content,
                    "section": section,
                    "format": format_type,
                    "metadata": {
                        "size_bytes": len(content.encode("utf-8")),
                        "created_at": metadata.created_at if metadata else None,
                        "content_type": metadata.content_type if metadata else "text",
                        "source_file": metadata.source_file if metadata else None,
                    },
                }

                if section:
                    result["instructions"] = f"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ '{artifact_id}' ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ã‚’å–å¾—ã—ã¾ã—ãŸ"
                else:
                    result["instructions"] = f"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ '{artifact_id}' ã®å…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¾ã—ãŸ"
                # ä»˜åŠ æƒ…å ±ï¼ˆèª¬æ˜ï¼‰ãŒã‚ã‚Œã°å«ã‚ã‚‹
                if metadata and getattr(metadata, "description", None):
                    result["instructions"] += f"ï¼ˆ{metadata.description}ï¼‰"

                return self._json_with_path_fallback(result, locals())

            except Exception as e:
                self.logger.exception("ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼")
                return json.dumps(
                    {"success": False, "error": f"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}", "artifact_id": artifact_id},
                    ensure_ascii=False,
                    indent=2,
                )

        # Compatibility for tests expecting _tools dict
        try:
            if not hasattr(self.server, "_tools"):
                self.server._tools = {}
            self.server._tools["fetch_artifact"] = type("Tool", (), {"fn": fetch_artifact})
        except Exception:
            pass

        # ãƒ†ã‚¹ãƒˆäº’æ›: ç›´æ¥ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦ã‚‚ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹
        try:
            self.fetch_artifact = fetch_artifact
        except Exception:
            pass

        @self.server.tool(name="list_artifacts", description="åˆ©ç”¨å¯èƒ½ãªã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§ã‚’è¡¨ç¤º - ãƒ‡ãƒãƒƒã‚°ãƒ»ç¢ºèªç”¨")
        async def list_artifacts(project_root: str | None = None) -> str:
            """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§å–å¾—"""
            try:
                from pathlib import Path

                from noveler.infrastructure.factories.path_service_factory import create_mcp_aware_path_service

                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¨­å®š
                if project_root:
                    project_path = Path(project_root).expanduser()
                    # æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if not project_path.exists():
                        return json.dumps({
                            "success": False,
                            "error": f"æŒ‡å®šã•ã‚ŒãŸ project_root ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {project_root}",
                            "artifacts": [],
                            "total": 0
                        })
                else:
                    path_service = create_mcp_aware_path_service()
                    project_path = path_service.get_project_root()

                # ArtifactStoreServiceåˆæœŸåŒ–ï¼ˆç¾è¡Œ/ãƒ¬ã‚¬ã‚·ãƒ¼ä¸¡å¯¾å¿œï¼‰
                artifact_store, legacy_store = _resolve_artifact_store(project_path)

                # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§å–å¾—ï¼ˆã¾ãšå…¨ä»¶ï¼‰
                artifacts_primary = artifact_store.list_artifacts()
                artifacts_legacy = legacy_store.list_artifacts() if legacy_store is not None else []

                # çµåˆï¼ˆartifact_idã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼‰
                combined: dict[str, dict] = {}

                def _iter_artifacts(source: Any) -> Iterable[dict]:
                    if source is None:
                        return []
                    if isinstance(source, dict):
                        return source.values()
                    if isinstance(source, list):
                        return source
                    if hasattr(source, "as_list"):
                        return source.as_list()
                    if hasattr(source, "items"):
                        try:
                            return [
                                {"artifact_id": aid, "metadata": meta}
                                for aid, meta in source.items()
                            ]
                        except Exception:
                            return []
                    if hasattr(source, "__iter__"):
                        return list(source)
                    return []

                for source in (_iter_artifacts(artifacts_primary), _iter_artifacts(artifacts_legacy)):
                    for item in source:
                        if isinstance(item, dict):
                            aid = item.get("artifact_id")
                            metadata = item.get("metadata")
                            if metadata is None:
                                metadata = {k: v for k, v in item.items() if k != "artifact_id"}
                        else:
                            aid = getattr(item, "artifact_id", None)
                            metadata = getattr(item, "metadata", item)

                        if not aid or aid in combined:
                            continue

                        combined[aid] = {
                            "artifact_id": aid,
                            "metadata": metadata,
                        }

                # dictå½¢å¼ãŒè¿”ã•ã‚ŒãŸå ´åˆã¯metadataã¨çµåˆæ¸ˆã¿ã®å½¢ã¸æƒãˆã‚‹
                if isinstance(artifacts_primary, dict) and not combined:
                    for aid, metadata in artifacts_primary.items():
                        if aid not in combined:
                            combined[aid] = {"artifact_id": aid, "metadata": metadata}

                artifacts_all = list(combined.values())

                # ãƒ—ãƒ­ãƒƒãƒˆã®ã¿ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡¨ç¤ºï¼ˆäº’æ›æ€§: èª¬æ˜ã‚„ãƒ•ã‚¡ã‚¤ãƒ«åã«ã€Œãƒ—ãƒ­ãƒƒãƒˆã€ã‚’å«ã‚€ã‚‚ã®ã€ã¾ãŸã¯tags.type=plotï¼‰ã€‚
                # ãŸã ã—ã€ãƒ—ãƒ­ãƒƒãƒˆåˆ¤å®šã«ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å…¨ä»¶ã‚’è¿”ã™ï¼ˆæ±ç”¨ãƒ„ãƒ¼ãƒ«äº’æ›ï¼‰ã€‚
                def _meta_get(metadata_like: Any, key: str, default: Any = "") -> Any:
                    if isinstance(metadata_like, dict):
                        return metadata_like.get(key, default)
                    return getattr(metadata_like, key, default)

                def _is_plot(metadata_like: Any) -> bool:
                    desc = str(_meta_get(metadata_like, "description", "") or "")
                    src = str(_meta_get(metadata_like, "source_file", "") or "")
                    tags = _meta_get(metadata_like, "tags", {}) or {}
                    if isinstance(tags, dict) and tags.get("type") == "plot":
                        return True
                    if "ãƒ—ãƒ­ãƒƒãƒˆ" in desc:
                        return True
                    if src.endswith("_ãƒ—ãƒ­ãƒƒãƒˆ.md"):
                        return True
                    return False

                plot_like = [a for a in artifacts_all if _is_plot(a.get("metadata", {}))]
                artifacts = plot_like if plot_like else artifacts_all

                if not artifacts:
                    return json.dumps(
                        {
                            "success": True,
                            "message": "ã‚¹ãƒˆã‚¢æ¸ˆã¿ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“",
                            "artifacts": [],
                            "total_artifacts": 0,
                        },
                        ensure_ascii=False,
                        indent=2,
                    )

                artifact_list = []
                # list_artifacts may return a list of IDs or a dict
                if isinstance(artifacts, dict):
                    items_iter = artifacts.items()
                elif isinstance(artifacts, list) and artifacts and isinstance(artifacts[0], dict):
                    items_iter = [(a.get("artifact_id"), a.get("metadata")) for a in artifacts]
                else:
                    items_iter = [(aid, artifact_store.get_metadata(aid)) for aid in artifacts]

                for artifact_id, metadata in items_iter:
                    if isinstance(metadata, dict):
                        getv = metadata.get
                    else:

                        def getv(k, default=None):
                            return getattr(metadata, k, default)

                    artifact_list.append(
                        {
                            "artifact_id": artifact_id,
                            "content_type": getv("content_type"),
                            "size_bytes": getv("size_bytes"),
                            "created_at": getv("created_at"),
                            "source_file": getv("source_file"),
                            "description": getv("description"),
                        }
                    )

                result = {
                    "success": True,
                    "total_artifacts": len(artifacts) if not isinstance(artifacts, dict) else len(artifacts.keys()),
                    "artifacts": artifact_list,
                    "instructions": "fetch_artifact ãƒ„ãƒ¼ãƒ«ã§å€‹åˆ¥ã®ãƒ—ãƒ­ãƒƒãƒˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’å–å¾—ã§ãã¾ã™",
                }

                return self._json_with_path_fallback(result, locals())

            except Exception as e:
                self.logger.exception("ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼")
                return json.dumps(
                    {"success": False, "error": f"ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"}, ensure_ascii=False, indent=2
                )

        # Test compatibility registry for list_artifacts
        try:
            if not hasattr(self.server, "_tools"):
                self.server._tools = {}
            self.server._tools["list_artifacts"] = type("Tool", (), {"fn": list_artifacts})
        except Exception:
            pass

        # ãƒ†ã‚¹ãƒˆäº’æ›: ç›´æ¥ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦ã‚‚ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹
        try:
            self.list_artifacts = list_artifacts
        except Exception:
            pass

    def _determine_quality_level(self, average_score: float) -> str:
        """å“è³ªãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š"""
        if average_score >= 90:
            return "å„ªç§€ï¼ˆ90ç‚¹ä»¥ä¸Šï¼‰"
        if average_score >= 80:
            return "è‰¯å¥½ï¼ˆ80-89ç‚¹ï¼‰"
        if average_score >= 70:
            return "æ™®é€šï¼ˆ70-79ç‚¹ï¼‰"
        if average_score >= 60:
            return "è¦æ”¹å–„ï¼ˆ60-69ç‚¹ï¼‰"
        return "è¦å¤§å¹…æ”¹å–„ï¼ˆ60ç‚¹æœªæº€ï¼‰"

    def _categorize_issues(self, issues_found: list) -> dict:
        """å•é¡Œã‚’åˆ†é¡ã—ã¦æ•´ç†"""
        categories = {"æ§‹é€ ": [], "è¨€èª": [], "å¯èª­æ€§": [], "å†…å®¹": [], "è¡¨ç¾": []}

        # å•é¡Œã‚’é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡
        # ï¼ˆå®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè©³ç´°ãªåˆ†é¡ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ï¼‰
        for issue in issues_found:
            if "æ®µè½" in issue or "æ–‡å­—æ•°" in issue:
                categories["æ§‹é€ "].append(issue)
            elif "è¡¨è¨˜" in issue or "æ–‡æ³•" in issue:
                categories["è¨€èª"].append(issue)
            elif "èª­ã¿ã‚„ã™ã•" in issue or "æ–‡é•·" in issue:
                categories["å¯èª­æ€§"].append(issue)
            elif "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼" in issue or "è¨­å®š" in issue or "å±•é–‹" in issue:
                categories["å†…å®¹"].append(issue)
            else:
                categories["è¡¨ç¾"].append(issue)

        # ç©ºã®ã‚«ãƒ†ã‚´ãƒªã‚’é™¤å»
        return {k: v for k, v in categories.items() if v}


async def main() -> int:
    """MCPã‚µãƒ¼ãƒãƒ¼ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    if not MCP_AVAILABLE:
        console.print("ã‚¨ãƒ©ãƒ¼: MCPãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        console.print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        console.print("pip install mcp")
        return 1

    force_restart = "--force-restart" in sys.argv or "-f" in sys.argv
    try:
        server = JSONConversionServer(force_restart=force_restart)
        await server.run()
        return 0
    except RuntimeError as e:
        if "é‡è¤‡å®Ÿè¡Œæ¤œå‡º" in str(e):
            console.print(f"âš ï¸  {e}")
            console.print("\nè§£æ±ºæ–¹æ³•:")
            console.print("1. æ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ‰‹å‹•çµ‚äº†ã™ã‚‹")
            console.print("2. ã¾ãŸã¯ --force-restart ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å¼·åˆ¶å†èµ·å‹•:")
            console.print("   python json_conversion_server.py --force-restart")
            return 1
        console.print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    except Exception as e:
        console.print(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    asyncio.run(main())
# Expose a module-level path service factory for testability
try:
    # Default to the real factory, but allow tests to monkeypatch this symbol
    from noveler.infrastructure.factories.path_service_factory import (
        create_mcp_aware_path_service as create_mcp_aware_path_service,
    )
except Exception:  # pragma: no cover - fallback if imports fail during partial loads
    create_mcp_aware_path_service = None  # type: ignore

# Expose a module-level artifact store factory for testability
try:
    from noveler.domain.services.artifact_store_service import (
        create_artifact_store as create_artifact_store,
    )
except Exception:  # pragma: no cover
    create_artifact_store = None  # type: ignore
