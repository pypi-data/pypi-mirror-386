"""Infrastructure.simple_quality_record_creator
Where: Infrastructure module generating basic quality records.
What: Writes simplified quality record files for lightweight workflows and tests.
Why: Provides a fallback record creator when full pipelines are unnecessary.
"""

from noveler.presentation.shared.shared_utilities import console

"ç°¡æ˜“å“è³ªè¨˜éŒ²ä½œæˆã‚·ã‚¹ãƒ†ãƒ \n\nTDDã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å“è³ªè¨˜éŒ²ä½œæˆå•é¡Œã®è§£æ±ºç­–ã‚’æä¾›ã™ã‚‹\ncomplete-episodeã®è¤‡é›‘æ€§ã‚’å›é¿ã—ã€ç›´æ¥çš„ã«å“è³ªè¨˜éŒ²ã‚’ä½œæˆã™ã‚‹\n"
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import yaml
from noveler.infrastructure.adapters.path_service_adapter import create_path_service


class SimpleQualityRecordCreator:
    """ç°¡æ˜“å“è³ªè¨˜éŒ²ä½œæˆå™¨

    novel writeã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ç›´æ¥å‘¼ã³å‡ºã•ã‚Œã‚‹è»½é‡ãªå“è³ªè¨˜éŒ²ä½œæˆæ©Ÿèƒ½
    """

    def __init__(self, project_path, logger_service=None, console_service=None) -> None:
        """åˆæœŸåŒ–

        Args:
            project_path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
        """
        self.project_path = project_path
        path_service = create_path_service(project_path)
        self.quality_dir = path_service.get_management_dir()
        self.record_dir = self.quality_dir / "åŸ·ç­†è¨˜éŒ²"
        self.record_dir.mkdir(parents=True, exist_ok=True)
        self.logger_service = logger_service
        self.console_service = console_service

    def create_episode_quality_record(self, episode_number: int, title: str, content: str) -> None:
        """å€‹åˆ¥ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å“è³ªè¨˜éŒ²ã‚’ä½œæˆ

        Args:
            episode_number: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·
            title: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«
            content: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æœ¬æ–‡
        """
        quality_data: dict[str, Any] = self._analyze_basic_quality(content)
        record_data: dict[str, Any] = {
            "åŸºæœ¬æƒ…å ±": {
                "è©±æ•°": f"ç¬¬{episode_number:03d}è©±",
                "ã‚¿ã‚¤ãƒˆãƒ«": title,
                "åŸ·ç­†æ—¥": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                "æœ€çµ‚æ›´æ–°æ—¥": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                "æ–‡å­—æ•°": len(content),
            },
            "å“è³ªãƒã‚§ãƒƒã‚¯çµæœ": {
                "æœ€çµ‚ã‚¹ã‚³ã‚¢": quality_data["total_score"],
                "ãƒã‚§ãƒƒã‚¯å®Ÿæ–½æ—¥": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                "è©³ç´°ã‚¹ã‚³ã‚¢": quality_data["detailed_scores"],
                "ä¸»ãªæŒ‡æ‘˜äº‹é …": quality_data["issues"],
            },
            "åŸ·ç­†å†…å®¹ã®ç‰¹å¾´": {
                "æ§‹æˆè¦ç´ ": quality_data["structure_elements"],
                "æ–‡ä½“ã®ç‰¹å¾´": quality_data["writing_style"],
            },
            "ç‰¹è¨˜äº‹é …": quality_data["notes"],
        }
        record_file = self.record_dir / f"ç¬¬{episode_number:03d}è©±_å“è³ªè¨˜éŒ².yaml"
        with record_file.Path("w").open(encoding="utf-8") as f:
            yaml.dump(record_data, f, allow_unicode=True, default_flow_style=False)

    def create_ai_learning_record(self, project_name: str, episode_number: int, quality_data: dict) -> None:
        """AIå­¦ç¿’ç”¨ã®çµ±åˆå“è³ªè¨˜éŒ²ã‚’ä½œæˆãƒ»æ›´æ–°

        Args:
            project_name: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
            episode_number: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·
            quality_data: å“è³ªåˆ†æãƒ‡ãƒ¼ã‚¿
        """
        ai_record_file = self.quality_dir / "å“è³ªè¨˜éŒ²_AIå­¦ç¿’ç”¨.yaml"
        if ai_record_file.exists():
            with ai_record_file.Path(encoding="utf-8").open() as f:
                ai_record = yaml.safe_load(f) or {}
        else:
            ai_record = {
                "metadata": {
                    "project_name": project_name,
                    "version": "1.0",
                    "last_updated": datetime.now(timezone.utc).isoformat(),
                    "entry_count": 0,
                },
                "quality_checks": [],
                "learning_data": {
                    "improvement_trends": {},
                    "common_issues": [],
                    "personal_growth": {"strengths": [], "areas_for_improvement": [], "learning_goals": []},
                },
            }
        episode_entry = {
            "episode_number": episode_number,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "category_scores": quality_data["detailed_scores"],
            "total_score": quality_data["total_score"],
            "issues_count": len(quality_data["issues"]),
            "improvement_from_previous": 0.0,
        }
        ai_record["quality_checks"].append(episode_entry)
        ai_record["metadata"]["entry_count"] = len(ai_record["quality_checks"])
        ai_record["metadata"]["last_updated"] = datetime.now(timezone.utc).isoformat()
        with ai_record_file.Path("w").open(encoding="utf-8") as f:
            yaml.dump(ai_record, f, allow_unicode=True, default_flow_style=False)

    def create_learning_session_record(
        self, project_name: str, episode_number: int, writing_time_minutes: int | None = None
    ) -> None:
        """å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²ã‚’ä½œæˆ

        Args:
            project_name: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
            episode_number: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·
            writing_time_minutes: åŸ·ç­†æ™‚é–“(åˆ†)
        """
        session_file = self.quality_dir / "å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ².yaml"
        if session_file.exists():
            with session_file.Path(encoding="utf-8").open() as f:
                sessions = yaml.safe_load(f) or []
        else:
            sessions = []
        session_entry = {
            "project_name": project_name,
            "episode_number": episode_number,
            "start_time": datetime.now(timezone.utc).isoformat(),
            "end_time": datetime.now(timezone.utc).isoformat(),
            "total_writing_time": writing_time_minutes or 60,
            "is_completed": True,
            "writing_environment": "standard",
            "target_audience": "ä¸€èˆ¬",
            "writing_goal": "å“è³ªå‘ä¸Š",
        }
        sessions.append(session_entry)
        with session_file.Path("w").open(encoding="utf-8") as f:
            yaml.dump(sessions, f, allow_unicode=True, default_flow_style=False)

    def _analyze_basic_quality(self, content) -> dict[str, Any]:
        """åŸºæœ¬çš„ãªå“è³ªåˆ†æã‚’å®Ÿè¡Œ

        Args:
            content: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æœ¬æ–‡

        Returns:
            å“è³ªåˆ†æçµæœ
        """
        char_count = len(content)
        len(content.split("\n"))
        paragraph_count = len([p for p in content.split("\n\n") if p.strip()])
        detailed_scores = {
            "æ–‡ç« æ§‹æˆ": min(95, 70 + paragraph_count * 2),
            "èª­ã¿ã‚„ã™ã•": min(95, 75 + char_count // 100),
            "å†…å®¹ã®å……å®Ÿåº¦": min(95, 60 + char_count // 50),
            "æŠ€è¡“çš„å“è³ª": 85,
        }
        total_score = sum(detailed_scores.values()) / len(detailed_scores)
        issues = []
        if char_count < 1000:
            issues.append("æ–‡å­—æ•°ãŒå°‘ãªã„(1000æ–‡å­—æœªæº€)")
        if paragraph_count < 3:
            issues.append("æ®µè½æ•°ãŒå°‘ãªã„")
        if "ã€‚ã€‚ã€‚" in content:
            issues.append("ä¸‰ç‚¹ãƒªãƒ¼ãƒ€ãƒ¼ã®å½¢å¼(...â†’â€¦â€¦)")
        structure_elements = []
        if "##" in content:
            structure_elements.append("è¦‹å‡ºã—æ§‹é€ ã‚’ä½¿ç”¨")
        if "ã€Œ" in content and "ã€" in content:
            structure_elements.append("å¯¾è©±æå†™ã‚ã‚Š")
        if "~" in content:
            structure_elements.append("æå†™çš„è¡¨ç¾ã‚ã‚Š")
        return {
            "total_score": round(total_score, 1),
            "detailed_scores": detailed_scores,
            "issues": issues,
            "structure_elements": structure_elements,
            "writing_style": ["æ¨™æº–çš„ãªå°èª¬æ–‡ä½“"],
            "notes": [f"æ–‡å­—æ•°: {char_count}æ–‡å­—", f"æ®µè½æ•°: {paragraph_count}æ®µè½", "åŸºæœ¬çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿæ–½"],
        }


def create_quality_records_for_episode(project_path, episode_number: int, title: str, content: str) -> None:
    """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å…¨å“è³ªè¨˜éŒ²ã‚’ä½œæˆã™ã‚‹ä¾¿åˆ©é–¢æ•°

    Args:
        project_path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹
        episode_number: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·
        title: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«
        content: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æœ¬æ–‡
    """
    creator = SimpleQualityRecordCreator(project_path)
    creator.create_episode_quality_record(episode_number, title, content)
    quality_data: dict[str, Any] = creator._analyze_basic_quality(content)
    project_name = project_path.name
    creator.create_ai_learning_record(project_name, episode_number, quality_data)
    creator.create_learning_session_record(project_name, episode_number)


if __name__ == "__main__":
    import tempfile

    from noveler.infrastructure.di.container import resolve_service

    try:
        console_service = resolve_service("IConsoleService")
    except ValueError:
        from noveler.infrastructure.adapters.console_service_adapter import ConsoleServiceAdapter

        console_service = ConsoleServiceAdapter()
    with tempfile.TemporaryDirectory() as temp_dir:
        test_project = Path(temp_dir) / "ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"
        test_project.mkdir()
        sample_content = "# ç¬¬001è©± ãƒ†ã‚¹ãƒˆ\n\n## ã‚ã‚‰ã™ã˜\nã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§ã™ã€‚\n\n## æœ¬æ–‡\n\nã€Œã“ã‚“ã«ã¡ã¯ã€ã¨å½¼ã¯è¨€ã£ãŸã€‚\né¢¨ãŒå¹ã„ã¦ã„ã‚‹ã€‚\nãã—ã¦ç‰©èªã¯ç¶šãã€‚\n\nå½¼å¥³ã¯æŒ¯ã‚Šè¿”ã£ãŸã€‚\nã€Œã•ã‚ˆã†ãªã‚‰ã€\nãã†è¨€ã£ã¦å»ã£ã¦ã„ãã€‚\n\n## çµæœ«\n\nç‰©èªã¯çµ‚ã‚ã‚Šã‚’è¿ãˆãŸã€‚\n"
        create_quality_records_for_episode(test_project, 1, "ãƒ†ã‚¹ãƒˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰", sample_content)
        console.print("âœ… å“è³ªè¨˜éŒ²ä½œæˆãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        quality_dir = test_project / "50_ç®¡ç†è³‡æ–™"
        for file_path in quality_dir.rglob("*.yaml"):
            console.print(f"ğŸ“„ ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
