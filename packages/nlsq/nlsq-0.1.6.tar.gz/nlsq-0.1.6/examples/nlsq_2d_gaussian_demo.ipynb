{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLSQ 2D Gaussian Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/NLSQ_2D_Gaussian_Demo.ipynb)\n",
    "\n",
    "**Requirements:** Python 3.12 or higher\n",
    "\n",
    "This notebook demonstrates 2D Gaussian fitting with improved GPU error handling and advanced NLSQ features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing\n",
    "\n",
    "Make sure your runtime type is set to GPU if available (though this will work with CPU as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:55.570790Z",
     "iopub.status.busy": "2025-10-08T19:56:55.570340Z",
     "iopub.status.idle": "2025-10-08T19:56:56.181893Z",
     "shell.execute_reply": "2025-10-08T19:56:56.180231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install NLSQ if not already installed\n",
    "!pip install nlsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment\n",
    "\n",
    "Set up JAX to handle GPU memory properly and avoid cuSolver errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:56.188244Z",
     "iopub.status.busy": "2025-10-08T19:56:56.187634Z",
     "iopub.status.idle": "2025-10-08T19:56:56.196721Z",
     "shell.execute_reply": "2025-10-08T19:56:56.195880Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Check Python version\n",
    "print(f\"✅ Python {sys.version_info.major}.{sys.version_info.minor} meets requirements\")\n",
    "\n",
    "# Configure JAX for better GPU memory handling\n",
    "os.environ[\"JAX_PREALLOCATE_GPU_MEMORY\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"JAX_GPU_MEMORY_FRACTION\"] = \"0.8\"\n",
    "\n",
    "# Optional: Force CPU if GPU issues persist\n",
    "# os.environ['JAX_PLATFORMS'] = 'cpu'\n",
    "\n",
    "print(\"Environment configured for optimal performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NLSQ before importing JAX since we need NLSQ to set JAX to use 64-bit precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:56.200767Z",
     "iopub.status.busy": "2025-10-08T19:56:56.200223Z",
     "iopub.status.idle": "2025-10-08T19:56:57.136076Z",
     "shell.execute_reply": "2025-10-08T19:56:57.135716Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from nlsq import CurveFit, __version__\n",
    "\n",
    "print(f\"NLSQ version: {__version__}\")\n",
    "\n",
    "# Check which device we're using\n",
    "try:\n",
    "    devices = jax.devices()\n",
    "    print(f\"Available JAX devices: {devices}\")\n",
    "    print(f\"Using device: {devices[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Device detection: {e}\")\n",
    "    print(\"Will use CPU fallback if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:57.137577Z",
     "iopub.status.busy": "2025-10-08T19:56:57.137382Z",
     "iopub.status.idle": "2025-10-08T19:56:57.139842Z",
     "shell.execute_reply": "2025-10-08T19:56:57.139538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import advanced NLSQ features\n",
    "from nlsq import (\n",
    "    AlgorithmSelector,\n",
    "    LargeDatasetConfig,\n",
    "    MemoryConfig,\n",
    "    auto_select_algorithm,\n",
    "    configure_for_large_datasets,\n",
    "    estimate_memory_requirements,\n",
    "    get_memory_config,\n",
    "    memory_context,\n",
    "    set_memory_limits,\n",
    ")\n",
    "\n",
    "print(\"Advanced NLSQ features imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the 2D Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Management and Algorithm Selection\n",
    "\n",
    "For 2D fitting problems, memory usage can become significant. Let's demonstrate NLSQ's advanced memory management and automatic algorithm selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:57.141041Z",
     "iopub.status.busy": "2025-10-08T19:56:57.140932Z",
     "iopub.status.idle": "2025-10-08T19:56:57.144883Z",
     "shell.execute_reply": "2025-10-08T19:56:57.144602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Memory management for 2D data\n",
    "print(\"=== Memory Management for 2D Gaussian Fitting ===\")\n",
    "\n",
    "# Calculate data size for different image dimensions\n",
    "sizes = [100, 200, 500, 1000]\n",
    "n_params = 7  # 2D Gaussian has 7 parameters\n",
    "\n",
    "print(\"Memory estimates for different 2D image sizes:\")\n",
    "for size in sizes:\n",
    "    n_points = size * size  # 2D data\n",
    "    stats = estimate_memory_requirements(n_points, n_params)\n",
    "    print(f\"  {size}x{size} image ({n_points:,} points):\")\n",
    "    print(f\"    Memory needed: {stats.total_memory_estimate_gb:.3f} GB\")\n",
    "    print(f\"    Recommended chunk size: {stats.recommended_chunk_size:,}\")\n",
    "    print()\n",
    "\n",
    "# We'll set the current dataset size that will be used later\n",
    "current_size = 200  # This will match the 'length' variable defined later\n",
    "current_points = current_size * current_size\n",
    "current_stats = estimate_memory_requirements(current_points, n_params)\n",
    "\n",
    "print(f\"For our planned {current_size}x{current_size} dataset:\")\n",
    "print(f\"  Memory estimate: {current_stats.total_memory_estimate_gb:.3f} GB\")\n",
    "\n",
    "# Configure memory automatically\n",
    "recommended_limit = max(2.0, current_stats.total_memory_estimate_gb * 2.0)\n",
    "set_memory_limits(memory_limit_gb=recommended_limit)\n",
    "print(f\"  Set memory limit: {get_memory_config().memory_limit_gb} GB\")\n",
    "\n",
    "print(f\"\\nMemory configuration completed for {current_size}x{current_size} dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:57.145863Z",
     "iopub.status.busy": "2025-10-08T19:56:57.145757Z",
     "iopub.status.idle": "2025-10-08T19:56:57.148457Z",
     "shell.execute_reply": "2025-10-08T19:56:57.148171Z"
    }
   },
   "outputs": [],
   "source": [
    "def rotate_coordinates2D(coords, theta):\n",
    "    \"\"\"Rotate 2D coordinates by angle theta.\"\"\"\n",
    "    R = jnp.array([[jnp.cos(theta), -jnp.sin(theta)], [jnp.sin(theta), jnp.cos(theta)]])\n",
    "\n",
    "    shape = coords[0].shape\n",
    "    coords = jnp.stack([coord.flatten() for coord in coords])\n",
    "    rcoords = R @ coords\n",
    "    return [jnp.reshape(coord, shape) for coord in rcoords]\n",
    "\n",
    "\n",
    "def gaussian2d(coords, n0, x0, y0, sigma_x, sigma_y, theta, offset):\n",
    "    \"\"\"2D Gaussian function with rotation.\"\"\"\n",
    "    coords = [coords[0] - x0, coords[1] - y0]  # translate first\n",
    "    X, Y = rotate_coordinates2D(coords, theta)\n",
    "    density = n0 * jnp.exp(-0.5 * (X**2 / sigma_x**2 + Y**2 / sigma_y**2))\n",
    "    return density + offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Fitting with Optimized Settings\n",
    "\n",
    "Now let's perform the curve fitting using the recommended algorithm settings and demonstrate robustness features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:57.149771Z",
     "iopub.status.busy": "2025-10-08T19:56:57.149597Z",
     "iopub.status.idle": "2025-10-08T19:56:57.151970Z",
     "shell.execute_reply": "2025-10-08T19:56:57.151660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Advanced fitting with optimized settings - placeholder for now\n",
    "print(\"=== Advanced Fitting with Optimized Settings ===\")\n",
    "print(\"This section will be populated after data generation and algorithm selection.\")\n",
    "print(\"Advanced fitting demonstration will appear after the main fitting section.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:57.153100Z",
     "iopub.status.busy": "2025-10-08T19:56:57.152966Z",
     "iopub.status.idle": "2025-10-08T19:56:58.001443Z",
     "shell.execute_reply": "2025-10-08T19:56:58.000864Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_coordinates(width, height):\n",
    "    x = np.linspace(0, width - 1, width)\n",
    "    y = np.linspace(0, height - 1, height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def get_gaussian_parameters(length):\n",
    "    n0 = 1\n",
    "    x0 = length / 2\n",
    "    y0 = length / 2\n",
    "    sigx = length / 6\n",
    "    sigy = length / 8\n",
    "    theta = np.pi / 3\n",
    "    offset = 0.1 * n0\n",
    "    params = [n0, x0, y0, sigx, sigy, theta, offset]\n",
    "    return params\n",
    "\n",
    "\n",
    "# Start with a moderate size for testing\n",
    "length = 200  # Reduced from 500 to avoid memory issues\n",
    "XY_tuple = get_coordinates(length, length)\n",
    "\n",
    "params = get_gaussian_parameters(length)\n",
    "print(f\"True parameters: {params}\")\n",
    "\n",
    "# Generate noisy data\n",
    "zdata = gaussian2d(XY_tuple, *params)\n",
    "zdata += np.random.normal(0, 0.1, size=(length, length))\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(zdata, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Intensity\")\n",
    "plt.title(f\"2D Gaussian Data ({length}x{length})\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Curve Fitting\n",
    "\n",
    "We'll fit the data multiple times with different random seeds to test robustness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:58.004009Z",
     "iopub.status.busy": "2025-10-08T19:56:58.003873Z",
     "iopub.status.idle": "2025-10-08T19:56:59.543642Z",
     "shell.execute_reply": "2025-10-08T19:56:59.543156Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def get_random_float(low, high):\n",
    "    delta = high - low\n",
    "    return low + delta * np.random.random()\n",
    "\n",
    "\n",
    "# Flatten data for fitting\n",
    "flat_data = zdata.flatten()\n",
    "flat_XY_tuple = [coord.flatten() for coord in XY_tuple]\n",
    "\n",
    "# Initialize NLSQ CurveFit object\n",
    "jcf = CurveFit()\n",
    "\n",
    "# Perform multiple fits\n",
    "n_fits = 10  # Reduced from 100 for faster testing\n",
    "times = []\n",
    "all_results = []\n",
    "\n",
    "print(f\"Performing {n_fits} fits...\")\n",
    "\n",
    "for i in range(n_fits):\n",
    "    if i % 5 == 0:\n",
    "        print(f\"  Fit {i + 1}/{n_fits}\")\n",
    "\n",
    "    # Random seed near true values\n",
    "    seed = [val * get_random_float(0.9, 1.2) for val in params]\n",
    "\n",
    "    try:\n",
    "        st = time.time()\n",
    "        popt, pcov = jcf.curve_fit(gaussian2d, flat_XY_tuple, flat_data, p0=seed)\n",
    "        fit_time = time.time() - st\n",
    "\n",
    "        times.append(fit_time)\n",
    "        all_results.append(popt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Fit {i + 1} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "if times:\n",
    "    print(f\"\\nCompleted {len(times)}/{n_fits} fits successfully\")\n",
    "    print(\n",
    "        f\"Average fit time: {np.mean(times[1:]):.3f} seconds (excluding JIT compilation)\"\n",
    "    )\n",
    "    print(f\"First fit time (includes JIT): {times[0]:.3f} seconds\")\n",
    "else:\n",
    "    print(\"No successful fits. Please check your environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection and Advanced Optimization\n",
    "\n",
    "Now that we have data, let's demonstrate NLSQ's algorithm selection capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:59.545051Z",
     "iopub.status.busy": "2025-10-08T19:56:59.544941Z",
     "iopub.status.idle": "2025-10-08T19:57:01.782011Z",
     "shell.execute_reply": "2025-10-08T19:57:01.781481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Algorithm selection using the actual data we just generated\n",
    "if flat_data is not None and len(flat_data) > 0:\n",
    "    print(\"=== Automatic Algorithm Selection ===\")\n",
    "\n",
    "    # Use a subset for algorithm analysis (for speed)\n",
    "    sample_size = min(5000, len(flat_data))\n",
    "    sample_coords = [coord[:sample_size] for coord in flat_XY_tuple]\n",
    "    sample_y = flat_data[:sample_size]\n",
    "\n",
    "    try:\n",
    "        recommendations = auto_select_algorithm(gaussian2d, sample_coords, sample_y)\n",
    "        print(f\"Recommended algorithm: {recommendations['algorithm']}\")\n",
    "        print(f\"Recommended tolerance: {recommendations['ftol']}\")\n",
    "        print(\"Problem characteristics:\")\n",
    "        for key, value in recommendations.items():\n",
    "            if key not in [\"algorithm\", \"ftol\"]:\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "        # Now demonstrate advanced fitting with the recommendations\n",
    "        print(\"\\n=== Advanced Fitting with Optimized Settings ===\")\n",
    "\n",
    "        # Create CurveFit with optimized settings\n",
    "        try:\n",
    "            jcf_optimized = CurveFit(use_dynamic_sizing=True)\n",
    "            print(\n",
    "                f\"Using optimized CurveFit with {recommendations.get('algorithm', 'trf')} algorithm\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Using default CurveFit: {e}\")\n",
    "            jcf_optimized = CurveFit()\n",
    "\n",
    "        # Performance comparison with different settings\n",
    "        print(\"\\\\nComparing different optimization approaches:\")\n",
    "\n",
    "        approaches = [\n",
    "            (\"Default\", CurveFit()),\n",
    "            (\"Optimized\", jcf_optimized),\n",
    "        ]\n",
    "\n",
    "        results_comparison = []\n",
    "\n",
    "        for name, fitter in approaches:\n",
    "            try:\n",
    "                # Use memory context for this specific fit\n",
    "                seed = [val * get_random_float(0.9, 1.1) for val in params]\n",
    "\n",
    "                start_time = time.time()\n",
    "                popt, pcov = fitter.curve_fit(\n",
    "                    gaussian2d,\n",
    "                    flat_XY_tuple,\n",
    "                    flat_data,\n",
    "                    p0=seed,\n",
    "                    ftol=recommendations.get(\"ftol\", 1e-8),\n",
    "                )\n",
    "                fit_time = time.time() - start_time\n",
    "\n",
    "                # Calculate fit quality\n",
    "                fitted_data_flat = gaussian2d(\n",
    "                    [coord.reshape(XY_tuple[0].shape) for coord in flat_XY_tuple[:2]],\n",
    "                    *popt,\n",
    "                ).flatten()\n",
    "                mse = np.mean((flat_data - fitted_data_flat) ** 2)\n",
    "                max_error = np.max(\n",
    "                    np.abs((popt - params) / params)[:-1]\n",
    "                )  # Exclude offset\n",
    "\n",
    "                results_comparison.append(\n",
    "                    {\n",
    "                        \"name\": name,\n",
    "                        \"time\": fit_time,\n",
    "                        \"mse\": mse,\n",
    "                        \"max_error\": max_error,\n",
    "                        \"params\": popt,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    f\"  {name:12s}: {fit_time:.3f}s, MSE: {mse:.6f}, Max Error: {max_error:.4f}\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  {name:12s}: Failed - {e}\")\n",
    "\n",
    "        # Show best result\n",
    "        if results_comparison:\n",
    "            best_result = min(results_comparison, key=lambda x: x[\"mse\"])\n",
    "            print(\n",
    "                f\"\\\\nBest approach: {best_result['name']} (lowest MSE: {best_result['mse']:.6f})\"\n",
    "            )\n",
    "            print(f\"True parameters:  {params}\")\n",
    "            print(f\"Fitted parameters: {list(best_result['params'])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Algorithm selection failed: {e}\")\n",
    "        print(\"Continuing with default settings...\")\n",
    "else:\n",
    "    print(\"No data available for algorithm selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:57:01.783628Z",
     "iopub.status.busy": "2025-10-08T19:57:01.783497Z",
     "iopub.status.idle": "2025-10-08T19:57:05.994683Z",
     "shell.execute_reply": "2025-10-08T19:57:05.993878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate handling of larger datasets\n",
    "print(\"=== Large Dataset Handling Demo ===\")\n",
    "\n",
    "# Test with progressively larger datasets\n",
    "large_sizes = [300, 400, 500]  # Be careful not to go too large in Colab\n",
    "\n",
    "large_results = []\n",
    "\n",
    "# Use the existing CurveFit or create a new optimized one\n",
    "try:\n",
    "    # Try to use the optimized fitter if it was created\n",
    "    test_fitter = jcf_optimized if \"jcf_optimized\" in locals() else CurveFit()\n",
    "except NameError:\n",
    "    test_fitter = CurveFit()\n",
    "\n",
    "for size in large_sizes:\n",
    "    print(f\"\\nTesting {size}x{size} image ({size * size:,} points)...\")\n",
    "\n",
    "    # Generate larger dataset\n",
    "    XY_large = get_coordinates(size, size)\n",
    "    params_large = get_gaussian_parameters(size)\n",
    "\n",
    "    # Estimate memory requirements\n",
    "    n_points_large = size * size\n",
    "    stats_large = estimate_memory_requirements(n_points_large, n_params)\n",
    "\n",
    "    print(f\"  Memory estimate: {stats_large.total_memory_estimate_gb:.3f} GB\")\n",
    "    print(f\"  Recommended chunk size: {stats_large.recommended_chunk_size:,}\")\n",
    "\n",
    "    # Configure for large dataset\n",
    "    try:\n",
    "        # Auto-configure memory settings\n",
    "        memory_limit = max(4.0, stats_large.total_memory_estimate_gb * 1.5)\n",
    "\n",
    "        with memory_context(\n",
    "            MemoryConfig(\n",
    "                memory_limit_gb=memory_limit, enable_mixed_precision_fallback=True\n",
    "            )\n",
    "        ):\n",
    "            # Generate noisy data\n",
    "            zdata_large = gaussian2d(XY_large, *params_large)\n",
    "            zdata_large += np.random.normal(0, 0.05, size=(size, size))\n",
    "\n",
    "            flat_data_large = zdata_large.flatten()\n",
    "            flat_XY_large = [coord.flatten() for coord in XY_large]\n",
    "\n",
    "            # Fit with optimized settings\n",
    "            seed_large = [val * get_random_float(0.95, 1.05) for val in params_large]\n",
    "\n",
    "            start_time = time.time()\n",
    "            popt_large, pcov_large = test_fitter.curve_fit(\n",
    "                gaussian2d,\n",
    "                flat_XY_large,\n",
    "                flat_data_large,\n",
    "                p0=seed_large,\n",
    "                ftol=1e-6,  # Slightly relaxed for large data\n",
    "            )\n",
    "            fit_time = time.time() - start_time\n",
    "\n",
    "            # Calculate accuracy\n",
    "            max_error_large = np.max(\n",
    "                np.abs((popt_large - params_large) / params_large)[:-1]\n",
    "            )\n",
    "\n",
    "            result = {\n",
    "                \"size\": size,\n",
    "                \"time\": fit_time,\n",
    "                \"memory_gb\": stats_large.total_memory_estimate_gb,\n",
    "                \"max_error\": max_error_large,\n",
    "                \"success\": True,\n",
    "            }\n",
    "\n",
    "            large_results.append(result)\n",
    "            print(\n",
    "                f\"  ✓ Fit completed: {fit_time:.3f}s, Max error: {max_error_large:.4f}\"\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "        large_results.append(\n",
    "            {\n",
    "                \"size\": size,\n",
    "                \"time\": np.nan,\n",
    "                \"memory_gb\": stats_large.total_memory_estimate_gb,\n",
    "                \"max_error\": np.nan,\n",
    "                \"success\": False,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Summary of large dataset performance\n",
    "if any(r[\"success\"] for r in large_results):\n",
    "    print(\"\\n=== Large Dataset Performance Summary ===\")\n",
    "    successful_results = [r for r in large_results if r[\"success\"]]\n",
    "\n",
    "    for result in successful_results:\n",
    "        print(\n",
    "            f\"{result['size']:3d}x{result['size']:3d}: \"\n",
    "            f\"{result['time']:6.3f}s, \"\n",
    "            f\"{result['memory_gb']:5.3f}GB memory, \"\n",
    "            f\"error: {result['max_error']:.4f}\"\n",
    "        )\n",
    "\n",
    "    # Plot scaling if we have multiple successful results\n",
    "    if len(successful_results) >= 2:\n",
    "        sizes_successful = [r[\"size\"] for r in successful_results]\n",
    "        times_successful = [r[\"time\"] for r in successful_results]\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot([s**2 for s in sizes_successful], times_successful, \"bo-\")\n",
    "        plt.xlabel(\"Number of Data Points\")\n",
    "        plt.ylabel(\"Fit Time (seconds)\")\n",
    "        plt.title(\"Scaling with Data Size\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        memory_values = [r[\"memory_gb\"] for r in successful_results]\n",
    "        plt.plot(sizes_successful, memory_values, \"ro-\")\n",
    "        plt.xlabel(\"Image Size (pixels)\")\n",
    "        plt.ylabel(\"Memory Usage (GB)\")\n",
    "        plt.title(\"Memory Scaling\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\n",
    "        \"\\n✓ NLSQ successfully handled large 2D datasets with automatic memory management!\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"\\nNote: Large dataset tests failed. Try reducing dataset sizes or using CPU mode.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:57:05.996903Z",
     "iopub.status.busy": "2025-10-08T19:57:05.996779Z",
     "iopub.status.idle": "2025-10-08T19:57:06.263713Z",
     "shell.execute_reply": "2025-10-08T19:57:06.263217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare with a single SciPy fit\n",
    "if all_results:\n",
    "    print(\"Comparing NLSQ with SciPy...\")\n",
    "\n",
    "    # Use the last seed for comparison\n",
    "    seed = [val * get_random_float(0.9, 1.2) for val in params]\n",
    "\n",
    "    # Time SciPy\n",
    "    st = time.time()\n",
    "    popt_scipy, pcov_scipy = curve_fit(gaussian2d, flat_XY_tuple, flat_data, p0=seed)\n",
    "    scipy_time = time.time() - st\n",
    "\n",
    "    # Get last NLSQ result\n",
    "    popt_nlsq = all_results[-1]\n",
    "\n",
    "    print(\"\\nFit times:\")\n",
    "    print(\n",
    "        f\"  NLSQ (after JIT): {np.mean(times[1:]) if len(times) > 1 else times[0]:.3f} seconds\"\n",
    "    )\n",
    "    print(f\"  SciPy: {scipy_time:.3f} seconds\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nSpeedup: {scipy_time / np.mean(times[1:]) if len(times) > 1 else scipy_time / times[0]:.1f}x\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nParameter comparison:\")\n",
    "    print(f\"  True params:  {params}\")\n",
    "    print(f\"  NLSQ params:  {list(popt_nlsq)}\")\n",
    "    print(f\"  SciPy params: {list(popt_scipy)}\")\n",
    "\n",
    "    # Calculate errors\n",
    "    nlsq_error = np.max(\n",
    "        np.abs((np.array(popt_nlsq) - np.array(params)) / np.array(params))[:-1]\n",
    "    )\n",
    "    scipy_error = np.max(\n",
    "        np.abs((np.array(popt_scipy) - np.array(params)) / np.array(params))[:-1]\n",
    "    )\n",
    "\n",
    "    print(\"\\nMax relative errors (excluding offset):\")\n",
    "    print(f\"  NLSQ:  {nlsq_error:.4f}\")\n",
    "    print(f\"  SciPy: {scipy_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:57:06.265057Z",
     "iopub.status.busy": "2025-10-08T19:57:06.264946Z",
     "iopub.status.idle": "2025-10-08T19:57:06.533500Z",
     "shell.execute_reply": "2025-10-08T19:57:06.533153Z"
    }
   },
   "outputs": [],
   "source": [
    "if all_results and len(times) > 1:\n",
    "    # Plot fit times\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(times[1:], \"b-\", label=\"NLSQ (after JIT)\")\n",
    "    plt.axhline(y=scipy_time, color=\"r\", linestyle=\"--\", label=\"SciPy\")\n",
    "    plt.xlabel(\"Fit Number\")\n",
    "    plt.ylabel(\"Fit Time (seconds)\")\n",
    "    plt.title(\"Fitting Speed Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot fitted vs true data\n",
    "    plt.subplot(1, 2, 2)\n",
    "    fitted_data = gaussian2d(XY_tuple, *popt_nlsq).reshape(length, length)\n",
    "    residuals = zdata - fitted_data\n",
    "\n",
    "    plt.imshow(residuals, cmap=\"RdBu\", vmin=-0.3, vmax=0.3)\n",
    "    plt.colorbar(label=\"Residuals\")\n",
    "    plt.title(\"Fit Residuals\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nResiduals RMS: {np.sqrt(np.mean(residuals**2)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter GPU errors:\n",
    "\n",
    "1. **cuSolver Errors**: The notebook now includes automatic CPU fallback\n",
    "2. **Out of Memory**: Reduce the `length` parameter or restart the runtime\n",
    "3. **Force CPU**: Uncomment the `JAX_PLATFORMS='cpu'` line in the configuration cell\n",
    "4. **Colab Specific**: Use Runtime → Restart runtime if GPU issues persist\n",
    "\n",
    "The implementation now includes:\n",
    "- Automatic GPU/CPU fallback for SVD operations\n",
    "- Better memory management\n",
    "- More robust error handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
