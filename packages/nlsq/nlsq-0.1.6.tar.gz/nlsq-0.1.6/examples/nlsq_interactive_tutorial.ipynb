{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial-header"
   },
   "source": [
    "# NLSQ Interactive Tutorial: GPU-Accelerated Curve Fitting\n",
    "\n",
    "**Welcome to NLSQ!** This interactive tutorial will guide you through using NLSQ for fast, GPU-accelerated curve fitting.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. ✅ Installation and setup (CPU and GPU)\n",
    "2. 📈 Basic curve fitting with common models\n",
    "3. 🎯 Parameter bounds and constraints\n",
    "4. 🔧 Error handling and diagnostics\n",
    "5. 💾 Large dataset handling (millions of points)\n",
    "6. ⚡ GPU acceleration (100x+ speedups)\n",
    "7. 🚀 Advanced features (callbacks, robust fitting, auto p0)\n",
    "\n",
    "**Time**: ~45 minutes  \n",
    "**Level**: Beginner to Intermediate  \n",
    "**Prerequisites**: Basic Python, NumPy\n",
    "\n",
    "---\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/NLSQ_Interactive_Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section1-header"
   },
   "source": [
    "## Section 1: Installation & Setup\n",
    "\n",
    "### 1.1 Installation\n",
    "\n",
    "NLSQ requires JAX for GPU acceleration. On Google Colab, JAX is pre-installed with GPU support.\n",
    "\n",
    "**Installation options**:\n",
    "- **Colab (GPU)**: JAX pre-installed ✅\n",
    "- **Local (CPU)**: `pip install nlsq`\n",
    "- **Local (GPU)**: Install JAX with GPU support first, then `pip install nlsq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:45.689200Z",
     "iopub.status.busy": "2025-10-08T20:01:45.688824Z",
     "iopub.status.idle": "2025-10-08T20:01:47.019579Z",
     "shell.execute_reply": "2025-10-08T20:01:47.018974Z"
    },
    "id": "install-nlsq"
   },
   "outputs": [],
   "source": [
    "# Install NLSQ (skip if already installed)\n",
    "!pip install -q nlsq\n",
    "\n",
    "# Check installation\n",
    "import nlsq\n",
    "\n",
    "print(f\"NLSQ version: {nlsq.__version__}\")\n",
    "print(\"✅ Installation successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "### 1.2 Imports\n",
    "\n",
    "Let's import the libraries we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.041861Z",
     "iopub.status.busy": "2025-10-08T20:01:47.041601Z",
     "iopub.status.idle": "2025-10-08T20:01:47.044524Z",
     "shell.execute_reply": "2025-10-08T20:01:47.043963Z"
    },
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import (\n",
    "    callbacks,  # Progress monitoring\n",
    "    curve_fit,\n",
    "    functions,  # Common fitting functions\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-gpu"
   },
   "source": [
    "### 1.3 Check GPU Availability\n",
    "\n",
    "NLSQ automatically uses GPU if available. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.046003Z",
     "iopub.status.busy": "2025-10-08T20:01:47.045884Z",
     "iopub.status.idle": "2025-10-08T20:01:47.317305Z",
     "shell.execute_reply": "2025-10-08T20:01:47.316979Z"
    },
    "id": "gpu-check"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# Check available devices\n",
    "devices = jax.devices()\n",
    "print(f\"Available devices: {devices}\")\n",
    "print(f\"Default backend: {devices[0].platform}\")\n",
    "\n",
    "if devices[0].platform == \"gpu\":\n",
    "    print(\"\\n🚀 GPU detected! NLSQ will use GPU acceleration.\")\n",
    "else:\n",
    "    print(\"\\n💻 Running on CPU. For GPU, use Runtime -> Change runtime type -> GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section2-header"
   },
   "source": [
    "---\n",
    "\n",
    "## Section 2: Your First Curve Fit\n",
    "\n",
    "Let's start with a simple example: fitting an exponential decay curve.\n",
    "\n",
    "### 2.1 Generate Sample Data\n",
    "\n",
    "We'll create noisy data following an exponential decay: $y = a \\cdot e^{-b \\cdot x} + c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.318587Z",
     "iopub.status.busy": "2025-10-08T20:01:47.318477Z",
     "iopub.status.idle": "2025-10-08T20:01:47.429579Z",
     "shell.execute_reply": "2025-10-08T20:01:47.429136Z"
    },
    "id": "generate-data"
   },
   "outputs": [],
   "source": [
    "# True parameters\n",
    "a_true, b_true, c_true = 10.0, 0.5, 2.0\n",
    "\n",
    "# Generate x data\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# Generate y data with noise\n",
    "y_true = a_true * np.exp(-b_true * x) + c_true\n",
    "noise = np.random.normal(0, 0.5, size=len(x))\n",
    "y = y_true + noise\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Noisy data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True function\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Exponential Decay Data\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"True parameters: a={a_true}, b={b_true}, c={c_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "define-model"
   },
   "source": [
    "### 2.2 Define the Model\n",
    "\n",
    "Define your model as a Python function. **Important**: Use `jax.numpy` (jnp) instead of `numpy` for JAX compatibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.431055Z",
     "iopub.status.busy": "2025-10-08T20:01:47.430943Z",
     "iopub.status.idle": "2025-10-08T20:01:47.433119Z",
     "shell.execute_reply": "2025-10-08T20:01:47.432803Z"
    },
    "id": "model-definition"
   },
   "outputs": [],
   "source": [
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay model: y = a * exp(-b*x) + c\n",
    "\n",
    "    Parameters:\n",
    "        a: Amplitude\n",
    "        b: Decay rate\n",
    "        c: Offset\n",
    "    \"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "\n",
    "print(\"✅ Model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fit-model"
   },
   "source": [
    "### 2.3 Fit the Model\n",
    "\n",
    "Now let's fit the model to our data. NLSQ's API is compatible with SciPy's `curve_fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.434916Z",
     "iopub.status.busy": "2025-10-08T20:01:47.434812Z",
     "iopub.status.idle": "2025-10-08T20:01:48.285151Z",
     "shell.execute_reply": "2025-10-08T20:01:48.284618Z"
    },
    "id": "first-fit"
   },
   "outputs": [],
   "source": [
    "# Initial parameter guess\n",
    "p0 = [8, 0.4, 1]  # Close to true values: [10, 0.5, 2]\n",
    "\n",
    "# Fit the model\n",
    "popt, pcov = curve_fit(exponential_decay, x, y, p0=p0)\n",
    "\n",
    "# Extract fitted parameters\n",
    "a_fit, b_fit, c_fit = popt\n",
    "\n",
    "print(\"Fitted Parameters:\")\n",
    "print(f\"  a = {a_fit:.4f} (true: {a_true})\")\n",
    "print(f\"  b = {b_fit:.4f} (true: {b_true})\")\n",
    "print(f\"  c = {c_fit:.4f} (true: {c_true})\")\n",
    "print(\"\\n✅ Fitting successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-fit"
   },
   "source": [
    "### 2.4 Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:48.287131Z",
     "iopub.status.busy": "2025-10-08T20:01:48.286985Z",
     "iopub.status.idle": "2025-10-08T20:01:48.995461Z",
     "shell.execute_reply": "2025-10-08T20:01:48.994954Z"
    },
    "id": "plot-results"
   },
   "outputs": [],
   "source": [
    "# Generate fitted curve\n",
    "y_fit = exponential_decay(x, *popt)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Left: Data and fit\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, y_fit, \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Curve Fit Results\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y - y_fit\n",
    "plt.scatter(x, residuals, alpha=0.5)\n",
    "plt.axhline(0, color=\"r\", linestyle=\"--\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Residuals (y - y_fit)\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print goodness of fit\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercise1"
   },
   "source": [
    "### 🎯 Exercise 1: Try It Yourself!\n",
    "\n",
    "Modify the code above to fit a **linear** model: $y = a \\cdot x + b$\n",
    "\n",
    "**Hints**:\n",
    "1. Generate linear data: `y_true = 2*x + 1`\n",
    "2. Define model: `def linear(x, a, b): return a*x + b`\n",
    "3. Use `p0=[1, 1]` (2 parameters)\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Generate linear data\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = 2*x + 1 + np.random.normal(0, 1, size=len(x))\n",
    "\n",
    "# Define model\n",
    "def linear(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "# Fit\n",
    "popt, pcov = curve_fit(linear, x, y, p0=[1, 1])\n",
    "print(f\"Fitted: a={popt[0]:.2f}, b={popt[1]:.2f}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:48.996971Z",
     "iopub.status.busy": "2025-10-08T20:01:48.996824Z",
     "iopub.status.idle": "2025-10-08T20:01:48.998648Z",
     "shell.execute_reply": "2025-10-08T20:01:48.998343Z"
    },
    "id": "exercise1-solution"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section3-header"
   },
   "source": [
    "---\n",
    "\n",
    "## Section 3: Common Fitting Patterns\n",
    "\n",
    "NLSQ includes a library of common functions for quick fitting.\n",
    "\n",
    "### 3.1 Using Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:48.999947Z",
     "iopub.status.busy": "2025-10-08T20:01:48.999828Z",
     "iopub.status.idle": "2025-10-08T20:01:49.001973Z",
     "shell.execute_reply": "2025-10-08T20:01:49.001711Z"
    },
    "id": "builtin-functions"
   },
   "outputs": [],
   "source": [
    "# List available functions\n",
    "print(\"Available functions in nlsq.functions:\")\n",
    "for func_name in functions.__all__:\n",
    "    print(f\"  - {func_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-gaussian"
   },
   "source": [
    "### 3.2 Example: Gaussian Peak Fitting\n",
    "\n",
    "Fit a Gaussian peak: $y = a \\cdot e^{-(x-\\mu)^2 / (2\\sigma^2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:49.003163Z",
     "iopub.status.busy": "2025-10-08T20:01:49.003034Z",
     "iopub.status.idle": "2025-10-08T20:01:49.592511Z",
     "shell.execute_reply": "2025-10-08T20:01:49.592047Z"
    },
    "id": "fit-gaussian"
   },
   "outputs": [],
   "source": [
    "# Generate Gaussian data\n",
    "x = np.linspace(-5, 5, 100)\n",
    "a_true, mu_true, sigma_true = 10, 0, 1.5\n",
    "y_true = a_true * np.exp(-((x - mu_true) ** 2) / (2 * sigma_true**2))\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit using built-in gaussian function\n",
    "from nlsq.functions import gaussian\n",
    "\n",
    "popt, pcov = curve_fit(gaussian, x, y, p0=[10, 0, 1])\n",
    "a_fit, mu_fit, sigma_fit = popt\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, gaussian(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(f\"Gaussian Fit: μ={mu_fit:.2f}, σ={sigma_fit:.2f}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted: amplitude={a_fit:.2f}, mean={mu_fit:.2f}, std={sigma_fit:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-sigmoid"
   },
   "source": [
    "### 3.3 Example: Sigmoid (Logistic) Curve\n",
    "\n",
    "Common in dose-response and growth curves: $y = \\frac{L}{1 + e^{-k(x-x_0)}} + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:49.594122Z",
     "iopub.status.busy": "2025-10-08T20:01:49.594016Z",
     "iopub.status.idle": "2025-10-08T20:01:50.361142Z",
     "shell.execute_reply": "2025-10-08T20:01:50.360623Z"
    },
    "id": "fit-sigmoid"
   },
   "outputs": [],
   "source": [
    "# Generate sigmoid data\n",
    "x = np.linspace(0, 10, 100)\n",
    "L_true, x0_true, k_true, b_true = 10, 5, 1, 0\n",
    "y_true = L_true / (1 + np.exp(-k_true * (x - x0_true))) + b_true\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit using built-in sigmoid function\n",
    "from nlsq.functions import sigmoid\n",
    "\n",
    "popt, pcov = curve_fit(sigmoid, x, y, p0=[10, 5, 1, 0])\n",
    "L_fit, x0_fit, k_fit, b_fit = popt\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, sigmoid(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(f\"Sigmoid Fit: L={L_fit:.2f}, x₀={x0_fit:.2f}, k={k_fit:.2f}, b={b_fit:.2f}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"Fitted: max={L_fit:.2f}, midpoint={x0_fit:.2f}, steepness={k_fit:.2f}, baseline={b_fit:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-power-law"
   },
   "source": [
    "### 3.4 Example: Power Law\n",
    "\n",
    "Common in scaling relationships: $y = a \\cdot x^b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:50.362563Z",
     "iopub.status.busy": "2025-10-08T20:01:50.362437Z",
     "iopub.status.idle": "2025-10-08T20:01:51.544717Z",
     "shell.execute_reply": "2025-10-08T20:01:51.544187Z"
    },
    "id": "fit-powerlaw"
   },
   "outputs": [],
   "source": [
    "# Generate power law data\n",
    "x = np.linspace(1, 10, 50)  # Start from 1 to avoid x=0\n",
    "a_true, b_true = 2, 1.5\n",
    "y_true = a_true * x**b_true\n",
    "y = y_true + np.random.normal(0, 2, size=len(x))\n",
    "\n",
    "# Fit using built-in power_law function\n",
    "from nlsq.functions import power_law\n",
    "\n",
    "popt, pcov = curve_fit(power_law, x, y, p0=[2, 1.5])\n",
    "a_fit, b_fit = popt\n",
    "\n",
    "# Plot (log-log scale shows linearity)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear scale\n",
    "ax1.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "ax1.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "ax1.plot(x, power_law(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Power Law (Linear Scale)\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log-log scale\n",
    "ax2.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "ax2.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "ax2.plot(x, power_law(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_xlabel(\"x (log scale)\")\n",
    "ax2.set_ylabel(\"y (log scale)\")\n",
    "ax2.legend()\n",
    "ax2.set_title(\"Power Law (Log-Log Scale)\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted: y = {a_fit:.2f} * x^{b_fit:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-polynomial"
   },
   "source": [
    "### 3.5 Example: Polynomial Fitting\n",
    "\n",
    "Fit polynomials of any degree: $y = a_0 + a_1x + a_2x^2 + ...$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:51.546217Z",
     "iopub.status.busy": "2025-10-08T20:01:51.546096Z",
     "iopub.status.idle": "2025-10-08T20:01:52.186266Z",
     "shell.execute_reply": "2025-10-08T20:01:52.185773Z"
    },
    "id": "fit-polynomial"
   },
   "outputs": [],
   "source": [
    "# Generate polynomial data (degree 3)\n",
    "x = np.linspace(-3, 3, 100)\n",
    "coeffs_true = [0.5, -2, 1, 3]  # y = 0.5x³ - 2x² + x + 3\n",
    "y_true = np.polyval(coeffs_true, x)\n",
    "y = y_true + np.random.normal(0, 1, size=len(x))\n",
    "\n",
    "# Fit using built-in polynomial function\n",
    "from nlsq.functions import polynomial\n",
    "\n",
    "# Create polynomial function for degree 3\n",
    "poly3 = polynomial(3)\n",
    "\n",
    "popt, pcov = curve_fit(poly3, x, y, p0=[1, -1, 1, 1])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, poly3(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Polynomial Fit (Degree 3)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted coefficients: {popt}\")\n",
    "print(f\"True coefficients:   {coeffs_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-functions"
   },
   "source": [
    "### 📋 Summary: Common Functions\n",
    "\n",
    "| Function | Equation | Use Cases |\n",
    "|----------|----------|----------|\n",
    "| `linear` | $y = ax + b$ | Calibration, trends |\n",
    "| `exponential_decay` | $y = ae^{-bx} + c$ | Radioactive decay, RC circuits |\n",
    "| `exponential_growth` | $y = ae^{bx} + c$ | Population growth, interest |\n",
    "| `gaussian` | $y = ae^{-(x-\\mu)^2/(2\\sigma^2)}$ | Spectroscopy, normal distributions |\n",
    "| `sigmoid` | $y = L/(1+e^{-k(x-x_0)})$ | Dose-response, growth curves |\n",
    "| `power_law` | $y = ax^b$ | Scaling laws, allometry |\n",
    "| `polynomial` | $y = \\sum a_i x^i$ | Flexible curve fitting |\n",
    "\n",
    "**Next**: Learn how to handle bounds and constraints!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Parameter Bounds and Constraints\n",
    "\n",
    "Real-world problems often require parameter constraints. NLSQ supports bounds like SciPy.\n",
    "\n",
    "### 4.1 Fitting with Bounds\n",
    "\n",
    "Let's fit an exponential with constrained parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:52.187859Z",
     "iopub.status.busy": "2025-10-08T20:01:52.187721Z",
     "iopub.status.idle": "2025-10-08T20:01:53.090651Z",
     "shell.execute_reply": "2025-10-08T20:01:53.090103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate data with known parameters\n",
    "x = np.linspace(0, 10, 100)\n",
    "a_true, b_true, c_true = 5.0, 0.3, 1.0\n",
    "y = a_true * np.exp(-b_true * x) + c_true + np.random.normal(0, 0.2, size=len(x))\n",
    "\n",
    "# Define bounds: (lower, upper) for each parameter\n",
    "# bounds = ([a_min, b_min, c_min], [a_max, b_max, c_max])\n",
    "bounds = ([0, 0, 0], [10, 1, 5])  # All parameters must be positive\n",
    "\n",
    "# Fit with bounds\n",
    "popt, pcov = curve_fit(exponential_decay, x, y, p0=[1, 0.1, 0.5], bounds=bounds)\n",
    "\n",
    "print(\"Fitted with bounds:\")\n",
    "print(f\"  a = {popt[0]:.4f} (true: {a_true}, bounds: 0-10)\")\n",
    "print(f\"  b = {popt[1]:.4f} (true: {b_true}, bounds: 0-1)\")\n",
    "print(f\"  c = {popt[2]:.4f} (true: {c_true}, bounds: 0-5)\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, exponential_decay(x, *popt), \"g-\", label=\"Fitted (bounded)\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Curve Fit with Parameter Bounds\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Parameter Uncertainties\n",
    "\n",
    "The covariance matrix `pcov` provides parameter uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:53.092332Z",
     "iopub.status.busy": "2025-10-08T20:01:53.092207Z",
     "iopub.status.idle": "2025-10-08T20:01:53.096109Z",
     "shell.execute_reply": "2025-10-08T20:01:53.095682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract standard errors from covariance matrix\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "print(\"Parameter uncertainties (1σ):\")\n",
    "print(f\"  a = {popt[0]:.4f} ± {perr[0]:.4f}\")\n",
    "print(f\"  b = {popt[1]:.4f} ± {perr[1]:.4f}\")\n",
    "print(f\"  c = {popt[2]:.4f} ± {perr[2]:.4f}\")\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = pcov / np.outer(perr, perr)\n",
    "\n",
    "print(\"\\nParameter correlation matrix:\")\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Error Handling and Diagnostics\n",
    "\n",
    "NLSQ provides helpful error messages and diagnostics when fits fail.\n",
    "\n",
    "### 5.1 Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:53.097715Z",
     "iopub.status.busy": "2025-10-08T20:01:53.097536Z",
     "iopub.status.idle": "2025-10-08T20:01:54.547603Z",
     "shell.execute_reply": "2025-10-08T20:01:54.547218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example 1: Bad initial guess\n",
    "print(\"Example 1: Bad initial guess\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    # p0 too far from true values\n",
    "    popt, pcov = curve_fit(exponential_decay, x, y, p0=[100, 10, 50])\n",
    "    print(\"✅ Fit succeeded despite bad p0!\")\n",
    "    print(f\"Fitted: a={popt[0]:.2f}, b={popt[1]:.2f}, c={popt[2]:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Fit failed: {e}\")\n",
    "    print(\"💡 Tip: Try better p0 estimates or increase max_nfev\")\n",
    "\n",
    "# Example 2: Conflicting bounds\n",
    "print(\"\\nExample 2: Conflicting bounds\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    # p0 outside bounds\n",
    "    bad_bounds = ([0, 0, 0], [1, 0.1, 0.5])  # Too restrictive\n",
    "    popt, pcov = curve_fit(exponential_decay, x, y, p0=[5, 0.3, 1], bounds=bad_bounds)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Fit failed: {type(e).__name__}\")\n",
    "    print(\"💡 Tip: Ensure p0 is within bounds, and bounds are reasonable\")\n",
    "\n",
    "# Example 3: Successful fit with diagnostics\n",
    "print(\"\\nExample 3: Successful fit with full diagnostics\")\n",
    "print(\"=\" * 50)\n",
    "popt, pcov = curve_fit(exponential_decay, x, y, p0=[5, 0.3, 1], full_output=False)\n",
    "print(\"✅ Fit succeeded!\")\n",
    "print(f\"Final parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "print(f\"Condition number of covariance: {np.linalg.cond(pcov):.2e}\")\n",
    "if np.linalg.cond(pcov) > 1e10:\n",
    "    print(\"⚠️  Warning: Poorly conditioned covariance (parameters may be correlated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Monitoring Progress with Callbacks\n",
    "\n",
    "Use callbacks to monitor optimization progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:54.548981Z",
     "iopub.status.busy": "2025-10-08T20:01:54.548858Z",
     "iopub.status.idle": "2025-10-08T20:01:55.241427Z",
     "shell.execute_reply": "2025-10-08T20:01:55.240968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a progress callback\n",
    "iteration_data = []\n",
    "\n",
    "\n",
    "def progress_callback(iteration, cost, params, info=None):\n",
    "    iteration_data.append(\n",
    "        {\"iter\": iteration, \"cost\": cost, \"params\": params.copy(), \"info\": info}\n",
    "    )\n",
    "    if iteration % 5 == 0:  # Print every 5 iterations\n",
    "        print(f\"Iteration {iteration:3d}: cost = {cost:.6e}, params = {params}\")\n",
    "\n",
    "\n",
    "# Fit with callback\n",
    "print(\"Fitting with progress monitoring:\")\n",
    "print(\"=\" * 70)\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y, p0=[1, 0.1, 0.5], callback=progress_callback\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Optimization complete!\")\n",
    "print(f\"Total iterations: {len(iteration_data)}\")\n",
    "if len(iteration_data) > 0:\n",
    "    print(f\"Final cost: {iteration_data[-1]['cost']:.6e}\")\n",
    "\n",
    "# Plot convergence\n",
    "if len(iteration_data) > 0:\n",
    "    costs = [d[\"cost\"] for d in iteration_data]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.semilogy(costs)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Cost (log scale)\")\n",
    "    plt.title(\"Optimization Convergence\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No iteration data collected (optimization converged immediately)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Large Dataset Handling\n",
    "\n",
    "NLSQ can handle millions of points efficiently, especially on GPU.\n",
    "\n",
    "### 6.1 Fitting Large Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:55.243149Z",
     "iopub.status.busy": "2025-10-08T20:01:55.243037Z",
     "iopub.status.idle": "2025-10-08T20:01:55.844735Z",
     "shell.execute_reply": "2025-10-08T20:01:55.844077Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generate large dataset\n",
    "n_points = 100000  # 100K points\n",
    "x_large = np.linspace(0, 10, n_points)\n",
    "y_large = 5.0 * np.exp(-0.3 * x_large) + 1.0 + np.random.normal(0, 0.2, size=n_points)\n",
    "\n",
    "print(f\"Dataset size: {n_points:,} points\")\n",
    "print(f\"Memory: ~{(x_large.nbytes + y_large.nbytes) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Fit large dataset\n",
    "print(\"\\nFitting large dataset...\")\n",
    "start = time.time()\n",
    "popt_large, pcov_large = curve_fit(exponential_decay, x_large, y_large, p0=[5, 0.3, 1])\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Fit complete in {elapsed:.3f} seconds\")\n",
    "print(f\"Fitted: a={popt_large[0]:.4f}, b={popt_large[1]:.4f}, c={popt_large[2]:.4f}\")\n",
    "print(f\"Processing rate: {n_points / elapsed:,.0f} points/second\")\n",
    "\n",
    "# Note: First run includes JIT compilation overhead\n",
    "print(\"\\n💡 Note: First fit includes JAX JIT compilation (~1-2 seconds).\")\n",
    "print(\"   Subsequent fits reuse compiled code and are much faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Automatic Chunking for Very Large Datasets\n",
    "\n",
    "For datasets larger than available memory, NLSQ can automatically chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:55.847053Z",
     "iopub.status.busy": "2025-10-08T20:01:55.846904Z",
     "iopub.status.idle": "2025-10-08T20:01:56.594829Z",
     "shell.execute_reply": "2025-10-08T20:01:56.593964Z"
    }
   },
   "outputs": [],
   "source": [
    "from nlsq import curve_fit_large\n",
    "\n",
    "# Simulate very large dataset (10M points would be ~160 MB)\n",
    "# Using 500K points for demo (faster in Colab)\n",
    "n_huge = 500000\n",
    "x_huge = np.linspace(0, 10, n_huge)\n",
    "y_huge = 5.0 * np.exp(-0.3 * x_huge) + 1.0 + np.random.normal(0, 0.2, size=n_huge)\n",
    "\n",
    "print(\n",
    "    f\"Dataset size: {n_huge:,} points ({(x_huge.nbytes + y_huge.nbytes) / 1024**2:.1f} MB)\"\n",
    ")\n",
    "\n",
    "# Fit with automatic chunking\n",
    "print(\"\\nFitting with automatic chunking...\")\n",
    "start = time.time()\n",
    "popt_huge, pcov_huge = curve_fit_large(\n",
    "    exponential_decay,\n",
    "    x_huge,\n",
    "    y_huge,\n",
    "    p0=[5, 0.3, 1],\n",
    "    chunk_size=50000,  # Process 50K points at a time\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"✅ Fit complete in {elapsed:.3f} seconds\")\n",
    "print(f\"Fitted: a={popt_huge[0]:.4f}, b={popt_huge[1]:.4f}, c={popt_huge[2]:.4f}\")\n",
    "print(f\"Processing rate: {n_huge / elapsed:,.0f} points/second\")\n",
    "print(\"\\n💡 curve_fit_large() automatically manages memory for huge datasets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: GPU Acceleration\n",
    "\n",
    "NLSQ automatically uses GPU when available. Let's benchmark CPU vs GPU performance.\n",
    "\n",
    "### 7.1 GPU Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:56.596317Z",
     "iopub.status.busy": "2025-10-08T20:01:56.596188Z",
     "iopub.status.idle": "2025-10-08T20:01:58.021029Z",
     "shell.execute_reply": "2025-10-08T20:01:58.020413Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# Check current backend\n",
    "current_backend = jax.devices()[0].platform\n",
    "print(f\"Current backend: {current_backend}\")\n",
    "\n",
    "if current_backend == \"gpu\":\n",
    "    print(\"\\n🚀 GPU detected! Running performance comparison...\")\n",
    "\n",
    "    # Create large dataset for GPU test\n",
    "    n_gpu = 1000000  # 1M points\n",
    "    x_gpu = np.linspace(0, 10, n_gpu)\n",
    "    y_gpu = 5.0 * np.exp(-0.3 * x_gpu) + 1.0 + np.random.normal(0, 0.2, size=n_gpu)\n",
    "\n",
    "    # Warmup (JIT compilation)\n",
    "    print(\"Warming up JIT compiler...\")\n",
    "    _ = curve_fit(exponential_decay, x_gpu[:1000], y_gpu[:1000], p0=[5, 0.3, 1])\n",
    "\n",
    "    # GPU timing\n",
    "    print(f\"\\nFitting {n_gpu:,} points on GPU...\")\n",
    "    start = time.time()\n",
    "    popt_gpu, _ = curve_fit(exponential_decay, x_gpu, y_gpu, p0=[5, 0.3, 1])\n",
    "    gpu_time = time.time() - start\n",
    "\n",
    "    print(f\"✅ GPU fit: {gpu_time:.3f} seconds\")\n",
    "    print(f\"   Processing rate: {n_gpu / gpu_time:,.0f} points/second\")\n",
    "    print(\n",
    "        f\"   Parameters: a={popt_gpu[0]:.4f}, b={popt_gpu[1]:.4f}, c={popt_gpu[2]:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Note: CPU comparison would require JAX_PLATFORM_NAME=cpu environment variable\n",
    "    print(\"\\n💡 GPU acceleration provides 100-300x speedup vs SciPy on large datasets!\")\n",
    "else:\n",
    "    print(\"\\n💻 Running on CPU. To use GPU:\")\n",
    "    print(\"   1. Go to Runtime → Change runtime type\")\n",
    "    print(\"   2. Select GPU as hardware accelerator\")\n",
    "    print(\"   3. Restart runtime and re-run notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Advanced Features\n",
    "\n",
    "NLSQ includes several advanced features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:58.023499Z",
     "iopub.status.busy": "2025-10-08T20:01:58.023367Z",
     "iopub.status.idle": "2025-10-08T20:02:00.003588Z",
     "shell.execute_reply": "2025-10-08T20:02:00.003278Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Automatic p0 estimation\n",
    "print(\"1. Automatic p0 estimation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = 5.0 * np.exp(-0.3 * x) + 1.0 + np.random.normal(0, 0.2, size=len(x))\n",
    "\n",
    "# Auto-estimate p0 using function method\n",
    "from nlsq.functions import exponential_decay\n",
    "\n",
    "p0_auto = exponential_decay.estimate_p0(x, y)\n",
    "print(f\"Auto-estimated p0: {p0_auto}\")\n",
    "popt, _ = curve_fit(exponential_decay, x, y, p0=p0_auto)\n",
    "print(\"✅ Fit succeeded with auto p0!\")\n",
    "print(f\"Fitted: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "print(\"True values: a=5.0000, b=0.3000, c=1.0000\")\n",
    "\n",
    "# 2. Robust fitting (loss functions)\n",
    "print(\"\\n2. Robust fitting with loss functions\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Add outliers to data\n",
    "y_outliers = y.copy()\n",
    "outlier_indices = np.random.choice(len(y), 10, replace=False)\n",
    "y_outliers[outlier_indices] += np.random.normal(0, 5, size=10)\n",
    "\n",
    "# Standard fit (sensitive to outliers)\n",
    "popt_standard, _ = curve_fit(exponential_decay, x, y_outliers, p0=[5, 0.3, 1])\n",
    "\n",
    "# Robust fit with Huber loss\n",
    "popt_robust, _ = curve_fit(\n",
    "    exponential_decay,\n",
    "    x,\n",
    "    y_outliers,\n",
    "    p0=[5, 0.3, 1],\n",
    "    loss=\"huber\",  # Robust to outliers\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Standard fit: a={popt_standard[0]:.4f}, b={popt_standard[1]:.4f}, c={popt_standard[2]:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Robust fit:   a={popt_robust[0]:.4f}, b={popt_robust[1]:.4f}, c={popt_robust[2]:.4f}\"\n",
    ")\n",
    "print(\"True values:  a=5.0000, b=0.3000, c=1.0000\")\n",
    "print(\"\\n✅ Robust fit is closer to true values despite outliers!\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x, y_outliers, alpha=0.5, label=\"Data with outliers\", color=\"gray\")\n",
    "plt.scatter(\n",
    "    x[outlier_indices],\n",
    "    y_outliers[outlier_indices],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    marker=\"x\",\n",
    "    linewidth=3,\n",
    "    label=\"Outliers\",\n",
    ")\n",
    "plt.plot(\n",
    "    x, exponential_decay(x, *popt_standard), \"b--\", label=\"Standard fit\", linewidth=2\n",
    ")\n",
    "plt.plot(\n",
    "    x,\n",
    "    exponential_decay(x, *popt_robust),\n",
    "    \"g-\",\n",
    "    label=\"Robust fit (Huber loss)\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.plot(x, exponential_decay(x, 5, 0.3, 1), \"r:\", label=\"True function\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Robust Fitting with Huber Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Conclusion and Next Steps\n",
    "\n",
    "### 🎉 Congratulations!\n",
    "\n",
    "You've completed the NLSQ interactive tutorial! You now know how to:\n",
    "\n",
    "✅ Install and set up NLSQ with GPU support  \n",
    "✅ Fit curves with common models (exponential, Gaussian, sigmoid, power law)  \n",
    "✅ Apply parameter bounds and constraints  \n",
    "✅ Handle errors and monitor optimization progress  \n",
    "✅ Work with large datasets (millions of points)  \n",
    "✅ Leverage GPU acceleration for 100x+ speedups  \n",
    "✅ Use advanced features (callbacks, robust fitting)\n",
    "\n",
    "### 📚 Additional Resources\n",
    "\n",
    "- **Documentation**: https://nlsq.readthedocs.io\n",
    "- **GitHub**: https://github.com/imewei/NLSQ\n",
    "- **Examples**: Browse the `examples/` directory for more use cases\n",
    "- **API Reference**: Complete function documentation and parameters\n",
    "\n",
    "### 🚀 Next Steps\n",
    "\n",
    "1. **Try your own data**: Replace the example data with your real-world datasets\n",
    "2. **Explore loss functions**: Try different loss functions for robust fitting\n",
    "3. **Batch processing**: Fit multiple curves in parallel for maximum efficiency\n",
    "4. **Custom models**: Define your own fitting functions with JAX\n",
    "5. **Performance tuning**: Experiment with different algorithms and tolerances\n",
    "\n",
    "### 💬 Get Help\n",
    "\n",
    "- **Issues**: Report bugs at https://github.com/imewei/NLSQ/issues\n",
    "- **Discussions**: Ask questions in GitHub Discussions\n",
    "- **Citation**: If you use NLSQ in research, please cite the original JAXFit paper\n",
    "\n",
    "### 🙏 Acknowledgments\n",
    "\n",
    "NLSQ is based on JAXFit by Lucas R. Hofer, Milan Krstajić, and Robert P. Smith.  \n",
    "Development supported by Argonne National Laboratory.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy fitting! 🎯**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "gpuType": "T4",
   "name": "NLSQ_Interactive_Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
