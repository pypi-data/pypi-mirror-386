{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial-header"
   },
   "source": [
    "# NLSQ Interactive Tutorial: GPU-Accelerated Curve Fitting\n",
    "\n",
    "**Welcome to NLSQ!** This interactive tutorial will guide you through using NLSQ for fast, GPU-accelerated curve fitting.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. ‚úÖ Installation and setup (CPU and GPU)\n",
    "2. üìà Basic curve fitting with common models\n",
    "3. üéØ Parameter bounds and constraints\n",
    "4. üîß Error handling and diagnostics\n",
    "5. üíæ Large dataset handling (millions of points)\n",
    "6. ‚ö° GPU acceleration (100x+ speedups)\n",
    "7. üöÄ Advanced features (callbacks, robust fitting, auto p0)\n",
    "\n",
    "**Time**: ~45 minutes  \n",
    "**Level**: Beginner to Intermediate  \n",
    "**Prerequisites**: Basic Python, NumPy\n",
    "\n",
    "---\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/NLSQ_Interactive_Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section1-header"
   },
   "source": [
    "## Section 1: Installation & Setup\n",
    "\n",
    "### 1.1 Installation\n",
    "\n",
    "NLSQ requires JAX for GPU acceleration. On Google Colab, JAX is pre-installed with GPU support.\n",
    "\n",
    "**Installation options**:\n",
    "- **Colab (GPU)**: JAX pre-installed ‚úÖ\n",
    "- **Local (CPU)**: `pip install nlsq`\n",
    "- **Local (GPU)**: Install JAX with GPU support first, then `pip install nlsq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:45.689200Z",
     "iopub.status.busy": "2025-10-08T20:01:45.688824Z",
     "iopub.status.idle": "2025-10-08T20:01:47.019579Z",
     "shell.execute_reply": "2025-10-08T20:01:47.018974Z"
    },
    "id": "install-nlsq"
   },
   "outputs": [],
   "source": [
    "# Install NLSQ (skip if already installed)\n",
    "!pip install -q nlsq\n",
    "\n",
    "# Check installation\n",
    "import nlsq\n",
    "\n",
    "print(f\"NLSQ version: {nlsq.__version__}\")\n",
    "print(\"‚úÖ Installation successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "### 1.2 Imports\n",
    "\n",
    "Let's import the libraries we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.041861Z",
     "iopub.status.busy": "2025-10-08T20:01:47.041601Z",
     "iopub.status.idle": "2025-10-08T20:01:47.044524Z",
     "shell.execute_reply": "2025-10-08T20:01:47.043963Z"
    },
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import (\n",
    "    callbacks,  # Progress monitoring\n",
    "    curve_fit,\n",
    "    functions,  # Common fitting functions\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-gpu"
   },
   "source": [
    "### 1.3 Check GPU Availability\n",
    "\n",
    "NLSQ automatically uses GPU if available. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.046003Z",
     "iopub.status.busy": "2025-10-08T20:01:47.045884Z",
     "iopub.status.idle": "2025-10-08T20:01:47.317305Z",
     "shell.execute_reply": "2025-10-08T20:01:47.316979Z"
    },
    "id": "gpu-check"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# Check available devices\n",
    "devices = jax.devices()\n",
    "print(f\"Available devices: {devices}\")\n",
    "print(f\"Default backend: {devices[0].platform}\")\n",
    "\n",
    "if devices[0].platform == \"gpu\":\n",
    "    print(\"\\nüöÄ GPU detected! NLSQ will use GPU acceleration.\")\n",
    "else:\n",
    "    print(\"\\nüíª Running on CPU. For GPU, use Runtime -> Change runtime type -> GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section2-header"
   },
   "source": [
    "---\n",
    "\n",
    "## Section 2: Your First Curve Fit\n",
    "\n",
    "Let's start with a simple example: fitting an exponential decay curve.\n",
    "\n",
    "### 2.1 Generate Sample Data\n",
    "\n",
    "We'll create noisy data following an exponential decay: $y = a \\cdot e^{-b \\cdot x} + c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.318587Z",
     "iopub.status.busy": "2025-10-08T20:01:47.318477Z",
     "iopub.status.idle": "2025-10-08T20:01:47.429579Z",
     "shell.execute_reply": "2025-10-08T20:01:47.429136Z"
    },
    "id": "generate-data"
   },
   "outputs": [],
   "source": [
    "# True parameters\n",
    "a_true, b_true, c_true = 10.0, 0.5, 2.0\n",
    "\n",
    "# Generate x data\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# Generate y data with noise\n",
    "y_true = a_true * np.exp(-b_true * x) + c_true\n",
    "noise = np.random.normal(0, 0.5, size=len(x))\n",
    "y = y_true + noise\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Noisy data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True function\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Exponential Decay Data\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"True parameters: a={a_true}, b={b_true}, c={c_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "define-model"
   },
   "source": [
    "### 2.2 Define the Model\n",
    "\n",
    "Define your model as a Python function. **Important**: Use `jax.numpy` (jnp) instead of `numpy` for JAX compatibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.431055Z",
     "iopub.status.busy": "2025-10-08T20:01:47.430943Z",
     "iopub.status.idle": "2025-10-08T20:01:47.433119Z",
     "shell.execute_reply": "2025-10-08T20:01:47.432803Z"
    },
    "id": "model-definition"
   },
   "outputs": [],
   "source": [
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay model: y = a * exp(-b*x) + c\n",
    "\n",
    "    Parameters:\n",
    "        a: Amplitude\n",
    "        b: Decay rate\n",
    "        c: Offset\n",
    "    \"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "\n",
    "print(\"‚úÖ Model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fit-model"
   },
   "source": [
    "### 2.3 Fit the Model\n",
    "\n",
    "Now let's fit the model to our data. NLSQ's API is compatible with SciPy's `curve_fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:47.434916Z",
     "iopub.status.busy": "2025-10-08T20:01:47.434812Z",
     "iopub.status.idle": "2025-10-08T20:01:48.285151Z",
     "shell.execute_reply": "2025-10-08T20:01:48.284618Z"
    },
    "id": "first-fit"
   },
   "outputs": [],
   "source": [
    "# Initial parameter guess\n",
    "p0 = [8, 0.4, 1]  # Close to true values: [10, 0.5, 2]\n",
    "\n",
    "# Fit the model\n",
    "popt, pcov = curve_fit(exponential_decay, x, y, p0=p0)\n",
    "\n",
    "# Extract fitted parameters\n",
    "a_fit, b_fit, c_fit = popt\n",
    "\n",
    "print(\"Fitted Parameters:\")\n",
    "print(f\"  a = {a_fit:.4f} (true: {a_true})\")\n",
    "print(f\"  b = {b_fit:.4f} (true: {b_true})\")\n",
    "print(f\"  c = {c_fit:.4f} (true: {c_true})\")\n",
    "print(\"\\n‚úÖ Fitting successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-fit"
   },
   "source": [
    "### 2.4 Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:48.287131Z",
     "iopub.status.busy": "2025-10-08T20:01:48.286985Z",
     "iopub.status.idle": "2025-10-08T20:01:48.995461Z",
     "shell.execute_reply": "2025-10-08T20:01:48.994954Z"
    },
    "id": "plot-results"
   },
   "outputs": [],
   "source": [
    "# Generate fitted curve\n",
    "y_fit = exponential_decay(x, *popt)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Left: Data and fit\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, y_fit, \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Curve Fit Results\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y - y_fit\n",
    "plt.scatter(x, residuals, alpha=0.5)\n",
    "plt.axhline(0, color=\"r\", linestyle=\"--\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Residuals (y - y_fit)\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print goodness of fit\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercise1"
   },
   "source": [
    "### üéØ Exercise 1: Try It Yourself!\n",
    "\n",
    "Modify the code above to fit a **linear** model: $y = a \\cdot x + b$\n",
    "\n",
    "**Hints**:\n",
    "1. Generate linear data: `y_true = 2*x + 1`\n",
    "2. Define model: `def linear(x, a, b): return a*x + b`\n",
    "3. Use `p0=[1, 1]` (2 parameters)\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Generate linear data\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = 2*x + 1 + np.random.normal(0, 1, size=len(x))\n",
    "\n",
    "# Define model\n",
    "def linear(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "# Fit\n",
    "popt, pcov = curve_fit(linear, x, y, p0=[1, 1])\n",
    "print(f\"Fitted: a={popt[0]:.2f}, b={popt[1]:.2f}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:48.996971Z",
     "iopub.status.busy": "2025-10-08T20:01:48.996824Z",
     "iopub.status.idle": "2025-10-08T20:01:48.998648Z",
     "shell.execute_reply": "2025-10-08T20:01:48.998343Z"
    },
    "id": "exercise1-solution"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section3-header"
   },
   "source": [
    "---\n",
    "\n",
    "## Section 3: Common Fitting Patterns\n",
    "\n",
    "NLSQ includes a library of common functions for quick fitting.\n",
    "\n",
    "### 3.1 Using Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:48.999947Z",
     "iopub.status.busy": "2025-10-08T20:01:48.999828Z",
     "iopub.status.idle": "2025-10-08T20:01:49.001973Z",
     "shell.execute_reply": "2025-10-08T20:01:49.001711Z"
    },
    "id": "builtin-functions"
   },
   "outputs": [],
   "source": [
    "# List available functions\n",
    "print(\"Available functions in nlsq.functions:\")\n",
    "for func_name in functions.__all__:\n",
    "    print(f\"  - {func_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-gaussian"
   },
   "source": [
    "### 3.2 Example: Gaussian Peak Fitting\n",
    "\n",
    "Fit a Gaussian peak: $y = a \\cdot e^{-(x-\\mu)^2 / (2\\sigma^2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:49.003163Z",
     "iopub.status.busy": "2025-10-08T20:01:49.003034Z",
     "iopub.status.idle": "2025-10-08T20:01:49.592511Z",
     "shell.execute_reply": "2025-10-08T20:01:49.592047Z"
    },
    "id": "fit-gaussian"
   },
   "outputs": [],
   "source": [
    "# Generate Gaussian data\n",
    "x = np.linspace(-5, 5, 100)\n",
    "a_true, mu_true, sigma_true = 10, 0, 1.5\n",
    "y_true = a_true * np.exp(-((x - mu_true) ** 2) / (2 * sigma_true**2))\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit using built-in gaussian function\n",
    "from nlsq.functions import gaussian\n",
    "\n",
    "popt, pcov = curve_fit(gaussian, x, y, p0=[10, 0, 1])\n",
    "a_fit, mu_fit, sigma_fit = popt\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, gaussian(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(f\"Gaussian Fit: Œº={mu_fit:.2f}, œÉ={sigma_fit:.2f}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted: amplitude={a_fit:.2f}, mean={mu_fit:.2f}, std={sigma_fit:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-sigmoid"
   },
   "source": [
    "### 3.3 Example: Sigmoid (Logistic) Curve\n",
    "\n",
    "Common in dose-response and growth curves: $y = \\frac{L}{1 + e^{-k(x-x_0)}} + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:49.594122Z",
     "iopub.status.busy": "2025-10-08T20:01:49.594016Z",
     "iopub.status.idle": "2025-10-08T20:01:50.361142Z",
     "shell.execute_reply": "2025-10-08T20:01:50.360623Z"
    },
    "id": "fit-sigmoid"
   },
   "outputs": [],
   "source": [
    "# Generate sigmoid data\n",
    "x = np.linspace(0, 10, 100)\n",
    "L_true, x0_true, k_true, b_true = 10, 5, 1, 0\n",
    "y_true = L_true / (1 + np.exp(-k_true * (x - x0_true))) + b_true\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit using built-in sigmoid function\n",
    "from nlsq.functions import sigmoid\n",
    "\n",
    "popt, pcov = curve_fit(sigmoid, x, y, p0=[10, 5, 1, 0])\n",
    "L_fit, x0_fit, k_fit, b_fit = popt\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, sigmoid(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(f\"Sigmoid Fit: L={L_fit:.2f}, x‚ÇÄ={x0_fit:.2f}, k={k_fit:.2f}, b={b_fit:.2f}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"Fitted: max={L_fit:.2f}, midpoint={x0_fit:.2f}, steepness={k_fit:.2f}, baseline={b_fit:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-power-law"
   },
   "source": [
    "### 3.4 Example: Power Law\n",
    "\n",
    "Common in scaling relationships: $y = a \\cdot x^b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:50.362563Z",
     "iopub.status.busy": "2025-10-08T20:01:50.362437Z",
     "iopub.status.idle": "2025-10-08T20:01:51.544717Z",
     "shell.execute_reply": "2025-10-08T20:01:51.544187Z"
    },
    "id": "fit-powerlaw"
   },
   "outputs": [],
   "source": [
    "# Generate power law data\n",
    "x = np.linspace(1, 10, 50)  # Start from 1 to avoid x=0\n",
    "a_true, b_true = 2, 1.5\n",
    "y_true = a_true * x**b_true\n",
    "y = y_true + np.random.normal(0, 2, size=len(x))\n",
    "\n",
    "# Fit using built-in power_law function\n",
    "from nlsq.functions import power_law\n",
    "\n",
    "popt, pcov = curve_fit(power_law, x, y, p0=[2, 1.5])\n",
    "a_fit, b_fit = popt\n",
    "\n",
    "# Plot (log-log scale shows linearity)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear scale\n",
    "ax1.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "ax1.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "ax1.plot(x, power_law(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Power Law (Linear Scale)\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log-log scale\n",
    "ax2.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "ax2.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "ax2.plot(x, power_law(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_xlabel(\"x (log scale)\")\n",
    "ax2.set_ylabel(\"y (log scale)\")\n",
    "ax2.legend()\n",
    "ax2.set_title(\"Power Law (Log-Log Scale)\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted: y = {a_fit:.2f} * x^{b_fit:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-polynomial"
   },
   "source": [
    "### 3.5 Example: Polynomial Fitting\n",
    "\n",
    "Fit polynomials of any degree: $y = a_0 + a_1x + a_2x^2 + ...$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:51.546217Z",
     "iopub.status.busy": "2025-10-08T20:01:51.546096Z",
     "iopub.status.idle": "2025-10-08T20:01:52.186266Z",
     "shell.execute_reply": "2025-10-08T20:01:52.185773Z"
    },
    "id": "fit-polynomial"
   },
   "outputs": [],
   "source": [
    "# Generate polynomial data (degree 3)\n",
    "x = np.linspace(-3, 3, 100)\n",
    "coeffs_true = [0.5, -2, 1, 3]  # y = 0.5x¬≥ - 2x¬≤ + x + 3\n",
    "y_true = np.polyval(coeffs_true, x)\n",
    "y = y_true + np.random.normal(0, 1, size=len(x))\n",
    "\n",
    "# Fit using built-in polynomial function\n",
    "from nlsq.functions import polynomial\n",
    "\n",
    "# Create polynomial function for degree 3\n",
    "poly3 = polynomial(3)\n",
    "\n",
    "popt, pcov = curve_fit(poly3, x, y, p0=[1, -1, 1, 1])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, y_true, \"r--\", label=\"True\", linewidth=2)\n",
    "plt.plot(x, poly3(x, *popt), \"g-\", label=\"Fitted\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Polynomial Fit (Degree 3)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted coefficients: {popt}\")\n",
    "print(f\"True coefficients:   {coeffs_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-functions"
   },
   "source": [
    "### üìã Summary: Common Functions\n",
    "\n",
    "| Function | Equation | Use Cases |\n",
    "|----------|----------|----------|\n",
    "| `linear` | $y = ax + b$ | Calibration, trends |\n",
    "| `exponential_decay` | $y = ae^{-bx} + c$ | Radioactive decay, RC circuits |\n",
    "| `exponential_growth` | $y = ae^{bx} + c$ | Population growth, interest |\n",
    "| `gaussian` | $y = ae^{-(x-\\mu)^2/(2\\sigma^2)}$ | Spectroscopy, normal distributions |\n",
    "| `sigmoid` | $y = L/(1+e^{-k(x-x_0)})$ | Dose-response, growth curves |\n",
    "| `power_law` | $y = ax^b$ | Scaling laws, allometry |\n",
    "| `polynomial` | $y = \\sum a_i x^i$ | Flexible curve fitting |\n",
    "\n",
    "**Next**: Learn how to handle bounds and constraints!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Parameter Bounds and Constraints\n",
    "\n",
    "Real-world problems often require parameter constraints. NLSQ supports bounds like SciPy.\n",
    "\n",
    "### 4.1 Fitting with Bounds\n",
    "\n",
    "Let's fit an exponential with constrained parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:52.187859Z",
     "iopub.status.busy": "2025-10-08T20:01:52.187721Z",
     "iopub.status.idle": "2025-10-08T20:01:53.090651Z",
     "shell.execute_reply": "2025-10-08T20:01:53.090103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate data with known parameters\n",
    "x = np.linspace(0, 10, 100)\n",
    "a_true, b_true, c_true = 5.0, 0.3, 1.0\n",
    "y = a_true * np.exp(-b_true * x) + c_true + np.random.normal(0, 0.2, size=len(x))\n",
    "\n",
    "# Define bounds: (lower, upper) for each parameter\n",
    "# bounds = ([a_min, b_min, c_min], [a_max, b_max, c_max])\n",
    "bounds = ([0, 0, 0], [10, 1, 5])  # All parameters must be positive\n",
    "\n",
    "# Fit with bounds\n",
    "popt, pcov = curve_fit(exponential_decay, x, y, p0=[1, 0.1, 0.5], bounds=bounds)\n",
    "\n",
    "print(\"Fitted with bounds:\")\n",
    "print(f\"  a = {popt[0]:.4f} (true: {a_true}, bounds: 0-10)\")\n",
    "print(f\"  b = {popt[1]:.4f} (true: {b_true}, bounds: 0-1)\")\n",
    "print(f\"  c = {popt[2]:.4f} (true: {c_true}, bounds: 0-5)\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, y, alpha=0.5, label=\"Data\")\n",
    "plt.plot(x, exponential_decay(x, *popt), \"g-\", label=\"Fitted (bounded)\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Curve Fit with Parameter Bounds\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Parameter Uncertainties\n",
    "\n",
    "The covariance matrix `pcov` provides parameter uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:53.092332Z",
     "iopub.status.busy": "2025-10-08T20:01:53.092207Z",
     "iopub.status.idle": "2025-10-08T20:01:53.096109Z",
     "shell.execute_reply": "2025-10-08T20:01:53.095682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract standard errors from covariance matrix\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "print(\"Parameter uncertainties (1œÉ):\")\n",
    "print(f\"  a = {popt[0]:.4f} ¬± {perr[0]:.4f}\")\n",
    "print(f\"  b = {popt[1]:.4f} ¬± {perr[1]:.4f}\")\n",
    "print(f\"  c = {popt[2]:.4f} ¬± {perr[2]:.4f}\")\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = pcov / np.outer(perr, perr)\n",
    "\n",
    "print(\"\\nParameter correlation matrix:\")\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Error Handling and Diagnostics\n",
    "\n",
    "NLSQ provides helpful error messages and diagnostics when fits fail.\n",
    "\n",
    "### 5.1 Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:53.097715Z",
     "iopub.status.busy": "2025-10-08T20:01:53.097536Z",
     "iopub.status.idle": "2025-10-08T20:01:54.547603Z",
     "shell.execute_reply": "2025-10-08T20:01:54.547218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example 1: Bad initial guess\n",
    "print(\"Example 1: Bad initial guess\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    # p0 too far from true values\n",
    "    popt, pcov = curve_fit(exponential_decay, x, y, p0=[100, 10, 50])\n",
    "    print(\"‚úÖ Fit succeeded despite bad p0!\")\n",
    "    print(f\"Fitted: a={popt[0]:.2f}, b={popt[1]:.2f}, c={popt[2]:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fit failed: {e}\")\n",
    "    print(\"üí° Tip: Try better p0 estimates or increase max_nfev\")\n",
    "\n",
    "# Example 2: Conflicting bounds\n",
    "print(\"\\nExample 2: Conflicting bounds\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    # p0 outside bounds\n",
    "    bad_bounds = ([0, 0, 0], [1, 0.1, 0.5])  # Too restrictive\n",
    "    popt, pcov = curve_fit(exponential_decay, x, y, p0=[5, 0.3, 1], bounds=bad_bounds)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fit failed: {type(e).__name__}\")\n",
    "    print(\"üí° Tip: Ensure p0 is within bounds, and bounds are reasonable\")\n",
    "\n",
    "# Example 3: Successful fit with diagnostics\n",
    "print(\"\\nExample 3: Successful fit with full diagnostics\")\n",
    "print(\"=\" * 50)\n",
    "popt, pcov = curve_fit(exponential_decay, x, y, p0=[5, 0.3, 1], full_output=False)\n",
    "print(\"‚úÖ Fit succeeded!\")\n",
    "print(f\"Final parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "print(f\"Condition number of covariance: {np.linalg.cond(pcov):.2e}\")\n",
    "if np.linalg.cond(pcov) > 1e10:\n",
    "    print(\"‚ö†Ô∏è  Warning: Poorly conditioned covariance (parameters may be correlated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Monitoring Progress with Callbacks\n",
    "\n",
    "Use callbacks to monitor optimization progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:54.548981Z",
     "iopub.status.busy": "2025-10-08T20:01:54.548858Z",
     "iopub.status.idle": "2025-10-08T20:01:55.241427Z",
     "shell.execute_reply": "2025-10-08T20:01:55.240968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a progress callback\n",
    "iteration_data = []\n",
    "\n",
    "\n",
    "def progress_callback(iteration, cost, params, info=None):\n",
    "    iteration_data.append(\n",
    "        {\"iter\": iteration, \"cost\": cost, \"params\": params.copy(), \"info\": info}\n",
    "    )\n",
    "    if iteration % 5 == 0:  # Print every 5 iterations\n",
    "        print(f\"Iteration {iteration:3d}: cost = {cost:.6e}, params = {params}\")\n",
    "\n",
    "\n",
    "# Fit with callback\n",
    "print(\"Fitting with progress monitoring:\")\n",
    "print(\"=\" * 70)\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y, p0=[1, 0.1, 0.5], callback=progress_callback\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Optimization complete!\")\n",
    "print(f\"Total iterations: {len(iteration_data)}\")\n",
    "if len(iteration_data) > 0:\n",
    "    print(f\"Final cost: {iteration_data[-1]['cost']:.6e}\")\n",
    "\n",
    "# Plot convergence\n",
    "if len(iteration_data) > 0:\n",
    "    costs = [d[\"cost\"] for d in iteration_data]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.semilogy(costs)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Cost (log scale)\")\n",
    "    plt.title(\"Optimization Convergence\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No iteration data collected (optimization converged immediately)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Large Dataset Handling\n",
    "\n",
    "NLSQ can handle millions of points efficiently, especially on GPU.\n",
    "\n",
    "### 6.1 Fitting Large Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:55.243149Z",
     "iopub.status.busy": "2025-10-08T20:01:55.243037Z",
     "iopub.status.idle": "2025-10-08T20:01:55.844735Z",
     "shell.execute_reply": "2025-10-08T20:01:55.844077Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generate large dataset\n",
    "n_points = 100000  # 100K points\n",
    "x_large = np.linspace(0, 10, n_points)\n",
    "y_large = 5.0 * np.exp(-0.3 * x_large) + 1.0 + np.random.normal(0, 0.2, size=n_points)\n",
    "\n",
    "print(f\"Dataset size: {n_points:,} points\")\n",
    "print(f\"Memory: ~{(x_large.nbytes + y_large.nbytes) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Fit large dataset\n",
    "print(\"\\nFitting large dataset...\")\n",
    "start = time.time()\n",
    "popt_large, pcov_large = curve_fit(exponential_decay, x_large, y_large, p0=[5, 0.3, 1])\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"‚úÖ Fit complete in {elapsed:.3f} seconds\")\n",
    "print(f\"Fitted: a={popt_large[0]:.4f}, b={popt_large[1]:.4f}, c={popt_large[2]:.4f}\")\n",
    "print(f\"Processing rate: {n_points / elapsed:,.0f} points/second\")\n",
    "\n",
    "# Note: First run includes JIT compilation overhead\n",
    "print(\"\\nüí° Note: First fit includes JAX JIT compilation (~1-2 seconds).\")\n",
    "print(\"   Subsequent fits reuse compiled code and are much faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Automatic Chunking for Very Large Datasets\n",
    "\n",
    "For datasets larger than available memory, NLSQ can automatically chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:55.847053Z",
     "iopub.status.busy": "2025-10-08T20:01:55.846904Z",
     "iopub.status.idle": "2025-10-08T20:01:56.594829Z",
     "shell.execute_reply": "2025-10-08T20:01:56.593964Z"
    }
   },
   "outputs": [],
   "source": [
    "from nlsq import curve_fit_large\n",
    "\n",
    "# Simulate very large dataset (10M points would be ~160 MB)\n",
    "# Using 500K points for demo (faster in Colab)\n",
    "n_huge = 500000\n",
    "x_huge = np.linspace(0, 10, n_huge)\n",
    "y_huge = 5.0 * np.exp(-0.3 * x_huge) + 1.0 + np.random.normal(0, 0.2, size=n_huge)\n",
    "\n",
    "print(\n",
    "    f\"Dataset size: {n_huge:,} points ({(x_huge.nbytes + y_huge.nbytes) / 1024**2:.1f} MB)\"\n",
    ")\n",
    "\n",
    "# Fit with automatic chunking\n",
    "print(\"\\nFitting with automatic chunking...\")\n",
    "start = time.time()\n",
    "popt_huge, pcov_huge = curve_fit_large(\n",
    "    exponential_decay,\n",
    "    x_huge,\n",
    "    y_huge,\n",
    "    p0=[5, 0.3, 1],\n",
    "    chunk_size=50000,  # Process 50K points at a time\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"‚úÖ Fit complete in {elapsed:.3f} seconds\")\n",
    "print(f\"Fitted: a={popt_huge[0]:.4f}, b={popt_huge[1]:.4f}, c={popt_huge[2]:.4f}\")\n",
    "print(f\"Processing rate: {n_huge / elapsed:,.0f} points/second\")\n",
    "print(\"\\nüí° curve_fit_large() automatically manages memory for huge datasets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: GPU Acceleration\n",
    "\n",
    "NLSQ automatically uses GPU when available. Let's benchmark CPU vs GPU performance.\n",
    "\n",
    "### 7.1 GPU Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:56.596317Z",
     "iopub.status.busy": "2025-10-08T20:01:56.596188Z",
     "iopub.status.idle": "2025-10-08T20:01:58.021029Z",
     "shell.execute_reply": "2025-10-08T20:01:58.020413Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# Check current backend\n",
    "current_backend = jax.devices()[0].platform\n",
    "print(f\"Current backend: {current_backend}\")\n",
    "\n",
    "if current_backend == \"gpu\":\n",
    "    print(\"\\nüöÄ GPU detected! Running performance comparison...\")\n",
    "\n",
    "    # Create large dataset for GPU test\n",
    "    n_gpu = 1000000  # 1M points\n",
    "    x_gpu = np.linspace(0, 10, n_gpu)\n",
    "    y_gpu = 5.0 * np.exp(-0.3 * x_gpu) + 1.0 + np.random.normal(0, 0.2, size=n_gpu)\n",
    "\n",
    "    # Warmup (JIT compilation)\n",
    "    print(\"Warming up JIT compiler...\")\n",
    "    _ = curve_fit(exponential_decay, x_gpu[:1000], y_gpu[:1000], p0=[5, 0.3, 1])\n",
    "\n",
    "    # GPU timing\n",
    "    print(f\"\\nFitting {n_gpu:,} points on GPU...\")\n",
    "    start = time.time()\n",
    "    popt_gpu, _ = curve_fit(exponential_decay, x_gpu, y_gpu, p0=[5, 0.3, 1])\n",
    "    gpu_time = time.time() - start\n",
    "\n",
    "    print(f\"‚úÖ GPU fit: {gpu_time:.3f} seconds\")\n",
    "    print(f\"   Processing rate: {n_gpu / gpu_time:,.0f} points/second\")\n",
    "    print(\n",
    "        f\"   Parameters: a={popt_gpu[0]:.4f}, b={popt_gpu[1]:.4f}, c={popt_gpu[2]:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Note: CPU comparison would require JAX_PLATFORM_NAME=cpu environment variable\n",
    "    print(\"\\nüí° GPU acceleration provides 100-300x speedup vs SciPy on large datasets!\")\n",
    "else:\n",
    "    print(\"\\nüíª Running on CPU. To use GPU:\")\n",
    "    print(\"   1. Go to Runtime ‚Üí Change runtime type\")\n",
    "    print(\"   2. Select GPU as hardware accelerator\")\n",
    "    print(\"   3. Restart runtime and re-run notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Advanced Features\n",
    "\n",
    "NLSQ includes several advanced features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T20:01:58.023499Z",
     "iopub.status.busy": "2025-10-08T20:01:58.023367Z",
     "iopub.status.idle": "2025-10-08T20:02:00.003588Z",
     "shell.execute_reply": "2025-10-08T20:02:00.003278Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Automatic p0 estimation\n",
    "print(\"1. Automatic p0 estimation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = 5.0 * np.exp(-0.3 * x) + 1.0 + np.random.normal(0, 0.2, size=len(x))\n",
    "\n",
    "# Auto-estimate p0 using function method\n",
    "from nlsq.functions import exponential_decay\n",
    "\n",
    "p0_auto = exponential_decay.estimate_p0(x, y)\n",
    "print(f\"Auto-estimated p0: {p0_auto}\")\n",
    "popt, _ = curve_fit(exponential_decay, x, y, p0=p0_auto)\n",
    "print(\"‚úÖ Fit succeeded with auto p0!\")\n",
    "print(f\"Fitted: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "print(\"True values: a=5.0000, b=0.3000, c=1.0000\")\n",
    "\n",
    "# 2. Robust fitting (loss functions)\n",
    "print(\"\\n2. Robust fitting with loss functions\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Add outliers to data\n",
    "y_outliers = y.copy()\n",
    "outlier_indices = np.random.choice(len(y), 10, replace=False)\n",
    "y_outliers[outlier_indices] += np.random.normal(0, 5, size=10)\n",
    "\n",
    "# Standard fit (sensitive to outliers)\n",
    "popt_standard, _ = curve_fit(exponential_decay, x, y_outliers, p0=[5, 0.3, 1])\n",
    "\n",
    "# Robust fit with Huber loss\n",
    "popt_robust, _ = curve_fit(\n",
    "    exponential_decay,\n",
    "    x,\n",
    "    y_outliers,\n",
    "    p0=[5, 0.3, 1],\n",
    "    loss=\"huber\",  # Robust to outliers\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Standard fit: a={popt_standard[0]:.4f}, b={popt_standard[1]:.4f}, c={popt_standard[2]:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Robust fit:   a={popt_robust[0]:.4f}, b={popt_robust[1]:.4f}, c={popt_robust[2]:.4f}\"\n",
    ")\n",
    "print(\"True values:  a=5.0000, b=0.3000, c=1.0000\")\n",
    "print(\"\\n‚úÖ Robust fit is closer to true values despite outliers!\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x, y_outliers, alpha=0.5, label=\"Data with outliers\", color=\"gray\")\n",
    "plt.scatter(\n",
    "    x[outlier_indices],\n",
    "    y_outliers[outlier_indices],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    marker=\"x\",\n",
    "    linewidth=3,\n",
    "    label=\"Outliers\",\n",
    ")\n",
    "plt.plot(\n",
    "    x, exponential_decay(x, *popt_standard), \"b--\", label=\"Standard fit\", linewidth=2\n",
    ")\n",
    "plt.plot(\n",
    "    x,\n",
    "    exponential_decay(x, *popt_robust),\n",
    "    \"g-\",\n",
    "    label=\"Robust fit (Huber loss)\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.plot(x, exponential_decay(x, 5, 0.3, 1), \"r:\", label=\"True function\", linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Robust Fitting with Huber Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Conclusion and Next Steps\n",
    "\n",
    "### üéâ Congratulations!\n",
    "\n",
    "You've completed the NLSQ interactive tutorial! You now know how to:\n",
    "\n",
    "‚úÖ Install and set up NLSQ with GPU support  \n",
    "‚úÖ Fit curves with common models (exponential, Gaussian, sigmoid, power law)  \n",
    "‚úÖ Apply parameter bounds and constraints  \n",
    "‚úÖ Handle errors and monitor optimization progress  \n",
    "‚úÖ Work with large datasets (millions of points)  \n",
    "‚úÖ Leverage GPU acceleration for 100x+ speedups  \n",
    "‚úÖ Use advanced features (callbacks, robust fitting)\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "- **Documentation**: https://nlsq.readthedocs.io\n",
    "- **GitHub**: https://github.com/imewei/NLSQ\n",
    "- **Examples**: Browse the `examples/` directory for more use cases\n",
    "- **API Reference**: Complete function documentation and parameters\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "1. **Try your own data**: Replace the example data with your real-world datasets\n",
    "2. **Explore loss functions**: Try different loss functions for robust fitting\n",
    "3. **Batch processing**: Fit multiple curves in parallel for maximum efficiency\n",
    "4. **Custom models**: Define your own fitting functions with JAX\n",
    "5. **Performance tuning**: Experiment with different algorithms and tolerances\n",
    "\n",
    "### üí¨ Get Help\n",
    "\n",
    "- **Issues**: Report bugs at https://github.com/imewei/NLSQ/issues\n",
    "- **Discussions**: Ask questions in GitHub Discussions\n",
    "- **Citation**: If you use NLSQ in research, please cite the original JAXFit paper\n",
    "\n",
    "### üôè Acknowledgments\n",
    "\n",
    "NLSQ is based on JAXFit by Lucas R. Hofer, Milan Krstajiƒá, and Robert P. Smith.  \n",
    "Development supported by Argonne National Laboratory.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy fitting! üéØ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "gpuType": "T4",
   "name": "NLSQ_Interactive_Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
