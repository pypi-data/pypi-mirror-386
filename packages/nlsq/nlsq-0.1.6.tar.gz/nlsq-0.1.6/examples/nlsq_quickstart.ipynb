{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLSQ Quickstart\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/NLSQ%20Quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayziQwXnEY_b"
   },
   "source": [
    "## Requirements\n",
    "\n",
    "**Important:** NLSQ requires Python 3.12 or higher. Please ensure your runtime environment meets this requirement before proceeding.\n",
    "\n",
    "## Installing and Importing\n",
    "\n",
    "Make sure your runtime type is set to GPU rather than CPU for optimal performance. Then install NLSQ with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:07.015672Z",
     "iopub.status.busy": "2025-10-08T19:56:07.015025Z",
     "iopub.status.idle": "2025-10-08T19:56:08.032460Z",
     "shell.execute_reply": "2025-10-08T19:56:08.031478Z"
    },
    "executionInfo": {
     "elapsed": 1180,
     "status": "ok",
     "timestamp": 1658309449763,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "rMAsUfuVtr9R",
    "outputId": "53ba2a78-d0bc-49a1-bb99-92b6b946718b"
   },
   "outputs": [],
   "source": [
    "!pip install nlsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX27Wg8QEfCz"
   },
   "source": [
    "Import NLSQ before importing JAX since we need NLSQ to set all the JAX computation to use 64 rather than 32 bit arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:08.036431Z",
     "iopub.status.busy": "2025-10-08T19:56:08.035981Z",
     "iopub.status.idle": "2025-10-08T19:56:10.315213Z",
     "shell.execute_reply": "2025-10-08T19:56:10.314848Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1658309449764,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "8coF-pvXubXp"
   },
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "\n",
    "# Import NLSQ before importing JAX since NLSQ configures JAX to use 64-bit precision\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from nlsq import CurveFit, __version__\n",
    "\n",
    "print(f\"NLSQ version: {__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.316954Z",
     "iopub.status.busy": "2025-10-08T19:56:10.316787Z",
     "iopub.status.idle": "2025-10-08T19:56:10.318619Z",
     "shell.execute_reply": "2025-10-08T19:56:10.318342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's also import some of the new advanced features\n",
    "from nlsq import (\n",
    "    MemoryConfig,\n",
    "    estimate_memory_requirements,\n",
    "    get_memory_config,\n",
    "    memory_context,\n",
    "    set_memory_limits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNMc8LzTEp2i"
   },
   "source": [
    "Now let's define a linear function using jax.numpy. You can construct function just like numpy with a few small caveats (see [current gotchas](https://github.com/Dipolar-Quantum-Gases/nlsq#current-gotchas))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.320053Z",
     "iopub.status.busy": "2025-10-08T19:56:10.319951Z",
     "iopub.status.idle": "2025-10-08T19:56:10.321825Z",
     "shell.execute_reply": "2025-10-08T19:56:10.321516Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1658309449764,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "tgTayxhD74wZ"
   },
   "outputs": [],
   "source": [
    "def linear(x, m, b):\n",
    "    return m * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfq-HUhQE8K6"
   },
   "source": [
    "Using the function we just created, we'll simulate some synthetic fit data and show what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.323375Z",
     "iopub.status.busy": "2025-10-08T19:56:10.323276Z",
     "iopub.status.idle": "2025-10-08T19:56:10.438748Z",
     "shell.execute_reply": "2025-10-08T19:56:10.438396Z"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1658310358415,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "ZXR3TAVeAdZT",
    "outputId": "ca9dbe55-978c-4021-c324-d42478dfbba8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# make the synthetic data\n",
    "length = 1000\n",
    "x = np.linspace(0, 10, length)\n",
    "params = (3, 5)\n",
    "y = linear(x, *params)\n",
    "# add a little noise to the data to make things interesting\n",
    "y += np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Some Noisy Data\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6PpNesO_5iy"
   },
   "source": [
    "Now let's use NLSQ to fit this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Management and Configuration\n",
    "\n",
    "NLSQ now includes sophisticated memory management features that help you optimize performance and handle large datasets more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.440685Z",
     "iopub.status.busy": "2025-10-08T19:56:10.440571Z",
     "iopub.status.idle": "2025-10-08T19:56:10.443749Z",
     "shell.execute_reply": "2025-10-08T19:56:10.443416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check current memory configuration\n",
    "current_config = get_memory_config()\n",
    "print(f\"Current memory limit: {current_config.memory_limit_gb} GB\")\n",
    "print(f\"Mixed precision fallback: {current_config.enable_mixed_precision_fallback}\")\n",
    "\n",
    "# Estimate memory requirements for our dataset\n",
    "n_points = len(x)\n",
    "n_params = 2  # m and b for linear function\n",
    "memory_stats = estimate_memory_requirements(n_points, n_params)\n",
    "print(f\"\\nMemory estimate for {n_points} points, {n_params} parameters:\")\n",
    "print(f\"  Total memory needed: {memory_stats.total_memory_estimate_gb:.4f} GB\")\n",
    "print(f\"  Recommended chunk size: {memory_stats.recommended_chunk_size}\")\n",
    "print(f\"  Number of chunks needed: {memory_stats.n_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.445127Z",
     "iopub.status.busy": "2025-10-08T19:56:10.445024Z",
     "iopub.status.idle": "2025-10-08T19:56:10.447530Z",
     "shell.execute_reply": "2025-10-08T19:56:10.447248Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can temporarily change memory settings using context managers\n",
    "print(\"Default memory limit:\", get_memory_config().memory_limit_gb, \"GB\")\n",
    "\n",
    "# Use a temporary memory configuration\n",
    "temp_config = MemoryConfig(memory_limit_gb=4.0, enable_mixed_precision_fallback=True)\n",
    "with memory_context(temp_config):\n",
    "    print(\"Inside context memory limit:\", get_memory_config().memory_limit_gb, \"GB\")\n",
    "\n",
    "print(\"After context memory limit:\", get_memory_config().memory_limit_gb, \"GB\")\n",
    "\n",
    "# Or you can set global memory limits\n",
    "set_memory_limits(memory_limit_gb=6.0, safety_factor=0.9)\n",
    "print(\"New global memory limit:\", get_memory_config().memory_limit_gb, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.448804Z",
     "iopub.status.busy": "2025-10-08T19:56:10.448697Z",
     "iopub.status.idle": "2025-10-08T19:56:10.451448Z",
     "shell.execute_reply": "2025-10-08T19:56:10.451150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Practical example: Automatically configure memory for large datasets\n",
    "print(\"=== Automatic Memory Management Example ===\")\n",
    "\n",
    "# Simulate a larger dataset scenario\n",
    "large_n_points = 50000\n",
    "large_n_params = 5\n",
    "\n",
    "# Get memory requirements\n",
    "large_stats = estimate_memory_requirements(large_n_points, large_n_params)\n",
    "print(f\"For {large_n_points} points with {large_n_params} parameters:\")\n",
    "print(f\"  Estimated memory: {large_stats.total_memory_estimate_gb:.3f} GB\")\n",
    "\n",
    "# Automatically set appropriate memory limits based on the estimation\n",
    "recommended_limit = max(4.0, large_stats.total_memory_estimate_gb * 1.5)\n",
    "set_memory_limits(memory_limit_gb=recommended_limit)\n",
    "print(f\"  Set memory limit to: {get_memory_config().memory_limit_gb} GB\")\n",
    "\n",
    "# Now you can safely work with larger datasets\n",
    "print(\"âœ“ Memory management configured for large dataset processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:10.452716Z",
     "iopub.status.busy": "2025-10-08T19:56:10.452606Z",
     "iopub.status.idle": "2025-10-08T19:56:12.274068Z",
     "shell.execute_reply": "2025-10-08T19:56:12.273633Z"
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1658310360912,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "jHRYEtBe_rWV",
    "outputId": "1ffe2e39-371a-40f0-9847-ca6b6c7f09cd"
   },
   "outputs": [],
   "source": [
    "jcf = CurveFit()\n",
    "popt, pcov = jcf.curve_fit(linear, x, y, p0=(1, 1))\n",
    "y_fit = linear(x, *popt)\n",
    "\n",
    "print(\"Actual Parameters\", params)\n",
    "print(\"Fit Parameters\", popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5I_AXHQAMDz"
   },
   "source": [
    "Now we'll take a look at NLSQ's speed. We do the same fit as above with $3\\times 10^5$ data points for twenty different sets of data and plot the speed for each of these fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:12.276213Z",
     "iopub.status.busy": "2025-10-08T19:56:12.276052Z",
     "iopub.status.idle": "2025-10-08T19:56:13.848895Z",
     "shell.execute_reply": "2025-10-08T19:56:13.848588Z"
    },
    "executionInfo": {
     "elapsed": 1458,
     "status": "ok",
     "timestamp": 1658310522993,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "-LwtCrpL31RE",
    "outputId": "4ca6a231-a519-4669-9b1b-79f6b7f8989a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def get_random_parameters(mmin=1, mmax=10, bmin=0, bmax=10):\n",
    "    deltam = mmax - mmin\n",
    "    deltab = bmax - bmin\n",
    "    m = mmin + deltam * np.random.random()\n",
    "    b = bmin + deltab * np.random.random()\n",
    "    return m, b\n",
    "\n",
    "\n",
    "length = 3 * 10**5\n",
    "x = np.linspace(0, 10, length)\n",
    "\n",
    "jcf = CurveFit()\n",
    "nlsq_fit_times = []\n",
    "scipy_fit_times = []\n",
    "nsamples = 21\n",
    "for i in range(nsamples):\n",
    "    params = get_random_parameters()\n",
    "    y = linear(x, *params) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    # fit the data\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf.curve_fit(linear, x, y, p0=(1, 1))\n",
    "    nlsq_fit_times.append(time.time() - start_time)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fit Speeds\")\n",
    "plt.plot(nlsq_fit_times, label=\"NLSQ\")\n",
    "plt.xlabel(\"Fit Iteration\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsgRWMrfAqMi"
   },
   "source": [
    "As you can see, the first fit is quite slow as JAX is tracing all the functions in the NLSQ CurveFit object behind the scenes. However, after it has traced them once then it runs extremely quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Fit Data Array Size\n",
    "\n",
    "What happens if we change the size of the data for each of these random fits though. Here we increase the data size from $10^3$ to $10^6$ and look at the fit speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:13.850470Z",
     "iopub.status.busy": "2025-10-08T19:56:13.850357Z",
     "iopub.status.idle": "2025-10-08T19:56:26.168416Z",
     "shell.execute_reply": "2025-10-08T19:56:26.167937Z"
    },
    "executionInfo": {
     "elapsed": 9745,
     "status": "ok",
     "timestamp": 1658311193736,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "EwgOIIWQ1lhj",
    "outputId": "6e8eabf6-c6eb-4763-c07f-12fa5cacedc1"
   },
   "outputs": [],
   "source": [
    "def get_coordinates(length, xmin=0, xmax=10):\n",
    "    return np.linspace(xmin, xmax, length)\n",
    "\n",
    "\n",
    "def get_random_data(length):\n",
    "    xdata = get_coordinates(length)\n",
    "    params = get_random_parameters()\n",
    "    ydata = linear(xdata, *params) + np.random.normal(0, 0.2, size=length)\n",
    "    return xdata, ydata\n",
    "\n",
    "\n",
    "lmin = 10**3\n",
    "lmax = 10**6\n",
    "nlengths = 20\n",
    "lengths = np.linspace(lmin, lmax, nlengths, dtype=int)\n",
    "\n",
    "jcf = CurveFit()\n",
    "nlsq_fit_times = []\n",
    "for length in lengths:\n",
    "    xdata, ydata = get_random_data(length)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf.curve_fit(linear, xdata, ydata, p0=(1, 1))\n",
    "    nlsq_fit_times.append(time.time() - start_time)\n",
    "\n",
    "print(\"Summed Fit Times\", np.sum(nlsq_fit_times))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fit Speeds\")\n",
    "plt.plot(lengths, nlsq_fit_times, label=\"NLSQ\")\n",
    "plt.xlabel(\"Data Length\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D12BzMmqBgQ-"
   },
   "source": [
    "The fit speed is slow for every fit. This is because JAX must retrace a function whenever the size of the input array changes. However, NLSQ has a clever way of getting around this. We set a fixed data size (which should be greater than or equal to the largest data we'll fit) and then we use dummy data behind the scenes to keep the array sizes fixed.\n",
    "\n",
    "We do the same fits as above, but this time we set a fixed array size length when we instantiate the CurveFit object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:26.170460Z",
     "iopub.status.busy": "2025-10-08T19:56:26.170328Z",
     "iopub.status.idle": "2025-10-08T19:56:28.600501Z",
     "shell.execute_reply": "2025-10-08T19:56:28.600054Z"
    },
    "executionInfo": {
     "elapsed": 2046,
     "status": "ok",
     "timestamp": 1658311198401,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "1snHEE-c8RGa",
    "outputId": "7aae497d-c3a0-4b08-fa75-7f5d2a393212"
   },
   "outputs": [],
   "source": [
    "fixed_length = np.amax(lengths)\n",
    "jcf = CurveFit(flength=fixed_length)\n",
    "\n",
    "nlsq_fit_times = []\n",
    "for length in lengths:\n",
    "    xdata, ydata = get_random_data(length)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf.curve_fit(linear, xdata, ydata, p0=(1, 1))\n",
    "    nlsq_fit_times.append(time.time() - start_time)\n",
    "\n",
    "print(\"Summed Fit Times\", np.sum(nlsq_fit_times))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fit Speeds\")\n",
    "plt.plot(lengths, nlsq_fit_times, label=\"NLSQ\")\n",
    "plt.xlabel(\"Data Length\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYTGM1QqCO3A"
   },
   "source": [
    "Our fits now run extremely fast irrespective of the datasize. There is a slight caveat to this in that the speed of the fits is always that of the fixed data size even if our actual data is smaller. \n",
    "\n",
    "If you have two drastically different data sizes in your analysis however, you can instantiate two different CurveFit objects to get an overall fit speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:28.602276Z",
     "iopub.status.busy": "2025-10-08T19:56:28.602105Z",
     "iopub.status.idle": "2025-10-08T19:56:31.661294Z",
     "shell.execute_reply": "2025-10-08T19:56:31.661019Z"
    },
    "executionInfo": {
     "elapsed": 3491,
     "status": "ok",
     "timestamp": 1658311548052,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "3gLRt4LiCNzM",
    "outputId": "a90b59d5-bf4a-499c-8948-0a57bd601130"
   },
   "outputs": [],
   "source": [
    "lmin = 10**3\n",
    "lmax = 10**6\n",
    "nlengths = 20\n",
    "lengths1 = np.linspace(10**3, 5 * 10**4, nlengths, dtype=int)\n",
    "lengths2 = np.linspace(10**5, 10**6, nlengths, dtype=int)\n",
    "\n",
    "fixed_length1 = np.amax(lengths1)\n",
    "fixed_length2 = np.amax(lengths2)\n",
    "\n",
    "jcf1 = CurveFit(flength=fixed_length1)\n",
    "jcf2 = CurveFit(flength=fixed_length2)\n",
    "\n",
    "nlsq_fit_times1 = []\n",
    "nlsq_fit_times2 = []\n",
    "\n",
    "for length1, length2 in zip(lengths1, lengths2, strict=False):\n",
    "    xdata1, ydata1 = get_random_data(length1)\n",
    "    xdata2, ydata2 = get_random_data(length2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf1.curve_fit(linear, xdata1, ydata1, p0=(1, 1))\n",
    "    nlsq_fit_times1.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt2, pcov2 = jcf2.curve_fit(linear, xdata2, ydata2, p0=(1, 1))\n",
    "    nlsq_fit_times2.append(time.time() - start_time)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fit Speeds\")\n",
    "plt.plot(nlsq_fit_times1, label=\"Small Data\")\n",
    "plt.plot(nlsq_fit_times2, label=\"Large Data\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Fit Iteration\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03kIxXmGEvZ1"
   },
   "source": [
    "## Fitting Multiple Functions \n",
    "\n",
    "It's important to instantiate a CurveFit object for each different function you're fitting as well to avoid JAX needing to retrace any underlying functions. First we show what happens if we use the same CurveFit object for two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:31.662855Z",
     "iopub.status.busy": "2025-10-08T19:56:31.662742Z",
     "iopub.status.idle": "2025-10-08T19:56:40.214154Z",
     "shell.execute_reply": "2025-10-08T19:56:40.213665Z"
    },
    "executionInfo": {
     "elapsed": 13028,
     "status": "ok",
     "timestamp": 1658312646834,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "HjORyJoLFimg",
    "outputId": "58264614-3194-4396-dfaa-6bb01e511767"
   },
   "outputs": [],
   "source": [
    "def quad_exp(x, a, b, c, d):\n",
    "    return a * x**2 + b * x + c + jnp.exp(d)\n",
    "\n",
    "\n",
    "length = 3 * 10**5\n",
    "x = np.linspace(0, 10, length)\n",
    "\n",
    "jcf = CurveFit()\n",
    "nsamples = 21\n",
    "\n",
    "all_linear_params = np.random.random(size=(nsamples, 2))\n",
    "all_quad_params = np.random.random(size=(nsamples, 4))\n",
    "\n",
    "linear_fit_times = []\n",
    "quad_fit_times = []\n",
    "for i in range(nsamples):\n",
    "    y_linear = linear(x, *all_linear_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "    y_quad = quad_exp(x, *all_quad_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    # fit the data\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf.curve_fit(\n",
    "        linear,\n",
    "        x,\n",
    "        y_linear,\n",
    "        p0=(\n",
    "            0.5,\n",
    "            0.5,\n",
    "        ),\n",
    "    )\n",
    "    linear_fit_times.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt2, pcov2 = jcf.curve_fit(quad_exp, x, y_quad, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    quad_fit_times.append(time.time() - start_time)\n",
    "\n",
    "print(\"Summed Fit Times\", np.sum(linear_fit_times + quad_fit_times))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(linear_fit_times, label=\"Linear Function\")\n",
    "plt.plot(quad_fit_times, label=\"Quad Function\")\n",
    "plt.xlabel(\"Fit Iteration\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vUYuzpdGkic"
   },
   "source": [
    "And we see that by using the same fit object retracing is occuring for every fit. Now we instantiate two separate CurveFit objects for the two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:40.215740Z",
     "iopub.status.busy": "2025-10-08T19:56:40.215627Z",
     "iopub.status.idle": "2025-10-08T19:56:43.413060Z",
     "shell.execute_reply": "2025-10-08T19:56:43.412777Z"
    },
    "executionInfo": {
     "elapsed": 3931,
     "status": "ok",
     "timestamp": 1658312650756,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "FF_xU3kPGd-m",
    "outputId": "8f579e0c-ba7c-4f8b-bac2-87cb62bdfe96"
   },
   "outputs": [],
   "source": [
    "jcf_linear = CurveFit()\n",
    "jcf_quad = CurveFit()\n",
    "\n",
    "\n",
    "linear_fit_times = []\n",
    "quad_fit_times = []\n",
    "for i in range(nsamples):\n",
    "    y_linear = linear(x, *all_linear_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "    y_quad = quad_exp(x, *all_quad_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    # fit the data\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf_linear.curve_fit(\n",
    "        linear,\n",
    "        x,\n",
    "        y_linear,\n",
    "        p0=(\n",
    "            0.5,\n",
    "            0.5,\n",
    "        ),\n",
    "    )\n",
    "    linear_fit_times.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt2, pcov2 = jcf_quad.curve_fit(quad_exp, x, y_quad, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    quad_fit_times.append(time.time() - start_time)\n",
    "\n",
    "print(\"Summed Fit Times\", np.sum(linear_fit_times + quad_fit_times))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(linear_fit_times, label=\"Linear Function\")\n",
    "plt.plot(quad_fit_times, label=\"Quad Function\")\n",
    "plt.xlabel(\"Fit Iteration\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbbQb27eHwKN"
   },
   "source": [
    "And now retracing is only occuring for the first fit for each CurveFit object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRYFHgN9FOZ6"
   },
   "source": [
    "## NLSQ vs. SciPy Fit Speed\n",
    "\n",
    "Finally, let's compare the speed of NLSQ against SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "execution": {
     "iopub.execute_input": "2025-10-08T19:56:43.414225Z",
     "iopub.status.busy": "2025-10-08T19:56:43.414117Z",
     "iopub.status.idle": "2025-10-08T19:56:48.090653Z",
     "shell.execute_reply": "2025-10-08T19:56:48.090223Z"
    },
    "executionInfo": {
     "elapsed": 11667,
     "status": "ok",
     "timestamp": 1658310201553,
     "user": {
      "displayName": "LUCAS HOFER",
      "userId": "17854158108197347250"
     },
     "user_tz": -60
    },
    "id": "96DbDCYqD6Ej",
    "outputId": "be07d20f-2f11-432b-faab-f2c2a690aa26"
   },
   "outputs": [],
   "source": [
    "def quad_exp_numpy(x, a, b, c, d):\n",
    "    # Clip d to prevent overflow in exp function\n",
    "    d_clipped = np.clip(\n",
    "        d, -700, 700\n",
    "    )  # exp(700) is near max float64, exp(-700) is near 0\n",
    "    return a * x**2 + b * x + c + np.exp(d_clipped)\n",
    "\n",
    "\n",
    "length = 3 * 10**5\n",
    "x = np.linspace(0, 10, length)\n",
    "\n",
    "jcf = CurveFit()\n",
    "nlsq_fit_times = []\n",
    "scipy_fit_times = []\n",
    "nsamples = 21\n",
    "\n",
    "all_params = np.random.random(size=(nsamples, 4))\n",
    "\n",
    "for i in range(nsamples):\n",
    "    params = get_random_parameters()\n",
    "    y = quad_exp(x, *all_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    # fit the data\n",
    "    start_time = time.time()\n",
    "    popt1, pcov1 = jcf.curve_fit(quad_exp, x, y, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    nlsq_fit_times.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt2, pcov2 = curve_fit(quad_exp_numpy, x, y, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    scipy_fit_times.append(time.time() - start_time)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fit Speeds\")\n",
    "plt.plot(nlsq_fit_times, label=\"NLSQ\")\n",
    "plt.plot(scipy_fit_times, label=\"SciPy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Fit Iteration\")\n",
    "plt.ylabel(\"Fit Time (seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmH0vza-Fek7"
   },
   "source": [
    "And we see it's so much faster minus the first fit in which tracing is occuring. Thus, by avoiding retracing and utilizing the GPU we get super fast fitting."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOUf4/0GpTwIBmJixtQY4T8",
   "collapsed_sections": [],
   "name": "NLSQ Quickstart.ipynb",
   "provenance": [
    {
     "file_id": "14D5A2N0FfN1Bw1ZjgXuWbRHuQsR9kWp6",
     "timestamp": 1658306861784
    },
    {
     "file_id": "1XftJIVmd0AhlOt2w-aRCGhId6T7DPKT8",
     "timestamp": 1658158198642
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
