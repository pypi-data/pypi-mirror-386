# LLM Extractinator

![Overview of the LLM Data Extractor](docs/images/doofenshmirtz.jpg)

> âš ï¸ This tool is a prototype in active development and may change significantly. Always verify results!

LLMÂ Extractinator enables efficient extraction of structured data from unstructured text using large language modelsâ€¯(LLMs). It supports configurable task definitions, CLI or Python usage, a pointâ€‘andâ€‘click GUI Studio, and flexible data input/output formats.

ğŸ“˜ **Full documentation**: [https://DIAGNijmegen.github.io/llm\_extractinator/](https://DIAGNijmegen.github.io/llm_extractinator/)

---

## ğŸ”§ Installation

### 1.Â Install **Ollama**

#### On **Linux**

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### On **Windows** or **macOS**

Download the installer from:
[https://ollama.com/download](https://ollama.com/download)

---

### 2.Â Install the Package

Create a fresh conda environment:

```bash
conda create -n llm_extractinator python=3.11
conda activate llm_extractinator
```

Install the package via pip:

```bash
pip install llm_extractinator
```

Or from source:

```bash
git clone https://github.com/DIAGNijmegen/llm_extractinator.git
cd llm_extractinator
pip install -e .
```

> **Tip:** to be able to run the latest models, update the Ollama client regularly:
>
> ```bash
> pip install --upgrade ollama langchain-ollama
> ```

---

## ğŸ–¥ï¸ Interactive Studio GUI 

Starting with **v0.5**, Extractinator ships with a Streamlitâ€‘based Studio for designing, running and monitoring extraction tasks with zero code:

![Studio screenshot](docs/images/GUI.gif)

ğŸš€ To run:

```bash
launch-extractinator  # opens http://localhost:8501 in your browser
```

Features

|                            |                                                                  |
| -------------------------- | ---------------------------------------------------------------- |
| ğŸ—‚ï¸Â Project Manager        | Createâ€¯/â€¯select datasets, parsers and tasks with file previews   |
| ğŸ”§Â Parser Builder          | Visual Pydantic schema designer (nested models supported)        |
| ğŸš€Â Oneâ€‘click Runs          | Configure model, sampling & advanced flags, then watch live logs |
| ğŸ› ï¸Â Task JSON Wizard       | Stepâ€‘byâ€‘step helper to generate valid `TaskXXX.json` files       |
| ğŸ†˜Â Help bubbles everywhere | Inline docs so you never lose context                            |

The Studio is fully optional: anything you configure here can still be executed from the CLI or Python API.

---

## ğŸš€ Quick Usage

### GUI

```bash
launch-extractinator  # recommended for new users
```

### CLI

```bash
extractinate --task_id 001 --model_name "phi4"
```

### Python

```python
from llm_extractinator import extractinate

extractinate(task_id=1, model_name="phi4")
```

---

## ğŸ“ Task Files

Each task is defined by a JSON file stored in `tasks/`.

Filename format:

```bash
TaskXXX_name.json
```

Example:

```json
{
  "Description": "Extract product data from text.",
  "Data_Path": "products.csv",
  "Input_Field": "text",
  "Parser_Format": "product_parser.py"
}
```

`Parser_Format` points to a `.py` file in `tasks/parsers/` that implements a Pydantic `OutputParser` model used to structure the LLMÂ output.

---

## ğŸ› ï¸ Visual Schema Builder (optional)

If you prefer a graphical approach to designing parsers, run:

```bash
build-parser
```

This starts the same builder embedded in the Studio, letting you assemble nested Pydantic models visually. Save the resulting `.py` file in `tasks/parsers/` and reference it via `Parser_Format`.

ğŸ‘‰â€¯Read the [parser docs](https://DIAGNijmegen.github.io/llm_extractinator/parser) for full details.

---

## ğŸ“„ Citation

If you use this tool, please cite: [https://doi.org/10.5281/zenodo.15089764](https://doi.org/10.5281/zenodo.15089764)

---

## ğŸ¤ Contributing

We welcome pull requests! See the [contributing guide](https://DIAGNijmegen.github.io/llm_extractinator/contributing/) for details.
