# Runtime
use_ema: true
find_unused_parameters: True
use_gpu: true
use_xpu: false
use_mlu: false
use_npu: false
log_iter: 20
save_dir: output
snapshot_epoch: 1
print_flops: false
print_params: false

# Dataset
metric: COCO
num_classes: 80

TrainDataset:
  name: COCODataSet
  image_dir: train2017
  anno_path: annotations/instances_train2017.json
  dataset_dir: dataset/coco
  data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

EvalDataset:
  name: COCODataSet
  image_dir: val2017
  anno_path: annotations/instances_val2017.json
  dataset_dir: dataset/coco
  allow_empty: true

TestDataset:
  name: ImageFolder
  anno_path: annotations/instances_val2017.json # also support txt (like VOC's label_list.txt)
  dataset_dir: dataset/coco # if set, anno_path will be 'dataset_dir/anno_path'


# Reader
worker_num: 0
TrainReader:
  sample_transforms:
  - Decode: {}
  - RandomFlip: {prob: 0.5}
  - RandomSelect: { transforms1: [ RandomShortSideResize: { short_side_sizes: [ 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800 ], max_size: 1333 } ],
                    transforms2: [
                        RandomShortSideResize: { short_side_sizes: [ 400, 500, 600 ] },
                        RandomSizeCrop: { min_size: 384, max_size: 600 },
                        RandomShortSideResize: { short_side_sizes: [ 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800 ], max_size: 1333 } ]
  }
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - NormalizeBox: {}
  - BboxXYXY2XYWH: {}
  - Permute: {}
  batch_transforms:
  - PadMaskBatch: {pad_to_stride: -1, return_pad_mask: true}
  batch_size: 2
  shuffle: true
  drop_last: true
  collate_batch: false
  use_shared_memory: false


EvalReader:
  sample_transforms:
  - Decode: {}
  - Resize: {target_size: [800, 1333], keep_ratio: True}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false


TestReader:
  sample_transforms:
  - Decode: {}
  - Resize: {target_size: [800, 1333], keep_ratio: True}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false

# Model
architecture: DETR
pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_vb_normal_pretrained.pdparams
hidden_dim: 256


DETR:
  backbone: ResNet
  transformer: DETRTransformer
  detr_head: DETRHead
  post_process: DETRPostProcess


ResNet:
  # index 0 stands for res2
  depth: 50
  norm_type: bn
  freeze_at: 0
  return_idx: [3]
  lr_mult_list: [0.0, 0.1, 0.1, 0.1]
  num_stages: 4


DETRTransformer:
  num_queries: 100
  position_embed_type: sine
  nhead: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  dim_feedforward: 2048
  dropout: 0.1
  activation: relu


DETRHead:
  num_mlp_layers: 3


DETRLoss:
  loss_coeff: {class: 1, bbox: 5, giou: 2, no_object: 0.1}
  aux_loss: True


HungarianMatcher:
  matcher_coeff: {class: 1, bbox: 5, giou: 2}

# Optimizer
epoch: 500

LearningRate:
  base_lr: 0.0001
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones: [400]
    use_warmup: false

OptimizerBuilder:
  clip_grad_by_norm: 0.1
  regularizer: false
  optimizer:
    type: AdamW
    weight_decay: 0.0001

# Exporting the model
export:
  post_process: True  # Whether post-processing is included in the network when export model.
  nms: True           # Whether NMS is included in the network when export model.
  benchmark: False    # It is used to testing model performance, if set `True`, post-process and NMS will not be exported.
  fuse_conv_bn: False
