epoch: 12
use_gpu: true
use_xpu: false
use_mlu: false
use_npu: false
log_iter: 20
save_dir: output
target_metrics: mask
snapshot_epoch: 1
print_flops: false
print_params: false

# dataset
metric: COCO
num_classes: 80
worker_num: 2

TrainDataset:
  name: COCODataSet
  image_dir: train2017
  anno_path: annotations/instances_train2017.json
  dataset_dir: dataset/coco
  data_fields: ['image', 'gt_bbox', 'gt_class', 'gt_poly', 'is_crowd']

EvalDataset:
  name: COCODataSet
  image_dir: val2017
  anno_path: annotations/instances_val2017.json
  dataset_dir: dataset/coco

TestDataset:
  name: ImageFolder
  anno_path: annotations/instances_val2017.json 
  dataset_dir: dataset/coco 

TrainReader:
  sample_transforms:
  - Decode: {}
  - RandomResize: {target_size: [[640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], interp: 2, keep_ratio: True}
  - RandomFlip: {prob: 0.5}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: -1}
  batch_size: 1
  shuffle: true
  drop_last: true
  collate_batch: false
  use_shared_memory: true


EvalReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2, target_size: [800, 1333], keep_ratio: True}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: -1}
  batch_size: 1
  shuffle: false
  drop_last: false


TestReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2, target_size: [800, 1333], keep_ratio: True}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: -1}
  batch_size: 1
  shuffle: false
  drop_last: false

LearningRate:
  base_lr: 0.01
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones: [8, 11]
  - !LinearWarmup
    start_factor: 0.001
    steps: 1000

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0001
    type: L2

# model
architecture: MaskRCNN
pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_cos_pretrained.pdparams

MaskRCNN:
  backbone: ResNet
  rpn_head: RPNHead
  bbox_head: BBoxHead
  mask_head: MaskHead
  # post process
  bbox_post_process: BBoxPostProcess
  mask_post_process: MaskPostProcess

ResNet:
  # index 0 stands for res2
  depth: 50
  norm_type: bn
  freeze_at: 0
  return_idx: [2]
  num_stages: 3

RPNHead:
  anchor_generator:
    aspect_ratios: [0.5, 1.0, 2.0]
    anchor_sizes: [32, 64, 128, 256, 512]
    strides: [16]
  rpn_target_assign:
    batch_size_per_im: 256
    fg_fraction: 0.5
    negative_overlap: 0.3
    positive_overlap: 0.7
    use_random: True
  train_proposal:
    min_size: 0.0
    nms_thresh: 0.7
    pre_nms_top_n: 12000
    post_nms_top_n: 2000
    topk_after_collect: False
  test_proposal:
    min_size: 0.0
    nms_thresh: 0.7
    pre_nms_top_n: 6000
    post_nms_top_n: 1000


BBoxHead:
  head: Res5Head
  roi_extractor:
    resolution: 14
    sampling_ratio: 0
    aligned: True
  bbox_assigner: BBoxAssigner
  with_pool: true

BBoxAssigner:
  batch_size_per_im: 512
  bg_thresh: 0.5
  fg_thresh: 0.5
  fg_fraction: 0.25
  use_random: True


BBoxPostProcess:
  decode: RCNNBox
  nms:
    name: MultiClassNMS
    keep_top_k: 100
    score_threshold: 0.05
    nms_threshold: 0.5

MaskHead:
  head: MaskFeat
  roi_extractor:
    resolution: 14
    sampling_ratio: 0
    aligned: True
  mask_assigner: MaskAssigner
  share_bbox_feat: true

MaskFeat:
  num_convs: 0
  out_channel: 256

MaskAssigner:
  mask_resolution: 14

MaskPostProcess:
  binary_thresh: 0.5

# Exporting the model
export:
  post_process: True 
  nms: True 
  benchmark: False
  fuse_conv_bn: False
