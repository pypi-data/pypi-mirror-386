---
title: Developer Tooling Ecosystem – Intent & Requirements
status: draft
version: 0.1.0
last_updated: 2025-10-03
---

# Developer Tooling Ecosystem – Intent & Requirements

This document captures problem framing and intent without prescribing an implementation. It describes why an ecosystem of developer tooling is needed, the outcomes it must enable, and the systemic properties required for success. It is intended to guide the `chora-platform` repository and any participating capability providers; any concrete solution should satisfy these statements or supply a rationale for deviations.

## Motivation

- Development teams work across several projects that share concepts (release management, environment control, runtime services) yet evolve independently.
- Duplication of tooling and inconsistent practices increase onboarding time, create security variance, and slow coordinated change.
- Agents (human or automated) need consistent ways to discover capabilities, reason about dependencies, and coordinate work across repositories.

## Primary Objectives

1. **Shared Understanding** – Provide a common vocabulary for lifecycle stages (plan, build, validate, release, operate) and the artifacts that flow between them.
2. **Composable Tooling** – Allow projects to adopt shared components or contribute new ones without central bottlenecks.
3. **Coordinated Change** – Surface cross-project needs early, decide ownership with transparency, and communicate decisions back to every participant.
4. **Runtime Interop** – Support scenarios where projects consume each other’s services dynamically, not only via build-time dependencies.
5. **Trust & Governance** – Maintain security, compatibility, and quality when tooling is reused or composed.

## Actors & Roles

- **Project Maintainers** – steward individual repositories; need clarity on ecosystem expectations and support when changes affect others.
- **Developers** – consume tooling during day-to-day work; prefer predictable UX and self-serve documentation.
- **Automation/Agents** – execute scripts, tests, or operations; require machine-readable manifests, deterministic interfaces, and auditable behavior.
- **Coordinators/Stewards** – mediate cross-project topics, maintain shared infrastructure, and record decisions.

## Glossary (Solution Neutral)

- **Capability** – A unit of value exposed to ecosystem participants (e.g., “Register MCP server”). Capabilities may be offered via CLI, APIs, or runtime services and are traceable through metadata.
- **Behavior** – A verified specification (often BDD) that proves a capability functions as intended, describing preconditions, interactions, and expected outcomes.
- **Manifest** – Machine-readable metadata describing available capabilities, interfaces, dependencies, lifecycle state, and owning parties for a project or service.
- **Integration Contract** – A set of automated checks and expectations (schema validation, protocol tests) that enforce compatibility across project boundaries.
- **Change Signal** – A structured notification that a capability, contract, or dependency needs attention (new feature, breaking change, incident), driving coordination across teams.

## System Capabilities (Solution Neutral)

- **Lifecycle Alignment** – Each project maps its workflows to a shared lifecycle. Tooling can query stage-appropriate actions (e.g., “validate release”).
- **Manifested Capabilities** – Every reusable asset (CLI command, behavior spec, runtime service) declares metadata describing its purpose, interfaces, dependencies, and status.
- **Capability Discovery** – Participants can search the ecosystem to answer “Who provides X?” or “Is there a behavior covering Y?”
- **Documentation & Templates** – Every capability exposes Diátaxis-aligned docs (tutorial/guide/reference/explanation) and reusable templates (CLI help, AGENTS snippets, CI workflows) so humans and LLM agents can onboard quickly.
- **Value Scenarios** – Each capability publishes user-testable scenarios with manual and automated verification paths, linked to change signals and telemetry so outcomes can be proven repeatedly.
- **Repository Overview** – Every repository publishes an autogenerated overview (front page) summarizing current capabilities, value scenarios, signals, and telemetry, making orientation simple for humans and LLM agents.
- **Liminal Capability** – Operators may run a personal or shared control capability (e.g., `chora-liminal`) that consumes manifests, signals, and telemetry from the platform and composes other Chora capabilities (signal adapters, privacy controls, voice/HUD modules). The capability must follow the same standards for manifests, scenarios, templates, and privacy.
- **Change Signaling** – Needs, risks, and proposals flow through a structured channel that captures scope, impact, and resolution status.
- **Integration Contracts** – Automated checks ensure manifests, behaviors, and runtime interfaces remain compatible as projects evolve.
- **Security & Compliance** – Common baselines for dependency audits, secret handling, logging separation, and release approval.
- **Observability & Feedback** – Metrics and qualitative signals reveal which tools are used, which fail, and where to focus investment.

## Minimum Manifest Requirements

Every manifest should at minimum include the following fields so automation and humans can reason about the ecosystem consistently:

- `id` – globally unique identifier for the capability or service.
- `version` – semantic version describing the manifest entry.
- `owner` – accountable team or individual with contact information.
- `lifecycle_stage` – current lifecycle phase (plan, build, validate, release, operate, retired).
- `inputs` / `outputs` – key parameters or artifacts consumed/produced.
- `dependencies` – referenced capabilities, contracts, or external services.
- `security_tier` – classification indicating sensitivity, secret scopes, and required controls.
- `stability` – qualitative status (`experimental`, `beta`, `stable`, `deprecated`).
- `adr_links` – architectural decision records (ADRs) or standards that govern the capability.
- `validation_status` – summary of latest automated checks (date, pass/fail, tooling used).

Any implementation should be able to extend beyond this baseline but must not omit these fields.

### Manifest Entry Example

```yaml
id: MCP.REGISTRY.MANAGE
version: 0.3.1
owner: aurora-mcp-team
lifecycle_stage: operate
inputs:
  - registry_path
  - server_manifest
outputs:
  - registry_state
dependencies:
  - nebula-core@1.x
security_tier: moderate
stability: stable
adr_links:
  - docs/adr/ADR-2025-04-registry-schema.md
validation_status:
  last_run: 2025-10-01T04:12:00Z
  result: pass
  tool: nebula-contract-suite
value_scenarios:
  - id: mcp.registry.manage.create-doc
    guide: docs/how-to/create-doc.md
    automated_test: tests/value-scenarios/test_create_doc.py
    change_signal: SIG-capability-onboard
telemetry:
  signals:
    - name: chora.value_scenario.mcp.registry.manage.create_doc
      status: in_progress
      docs: docs/reference/signals/SIG-capability-onboard.md
```

Value scenarios make user outcomes discoverable and verifiable alongside capability metadata.

## Change Signaling Workflow

To avoid ad hoc coordination, the ecosystem relies on a shared workflow with clear ownership:

- **States**: `proposal` → `review` → `decision` → `rollout` → `closed` (or `superseded`). Each state captures timestamps so SLA breaches are visible.
- **Ownership (RACI)**: the originator is Responsible for drafting; designated stewards and affected owners are Accountable for review/approval; coordinators and impacted teams are Consulted; broader stakeholders stay Informed via automated notifications.
- **SLAs**: proposals acknowledged within 2 business days; reviews concluded within 5 business days (extensions must be documented); decisions recorded within 2 business days of review closure; rollout plans defined before executing breaking changes.
- **Deduplication & Prioritization**: signals must include manifest IDs, capability tags, and impact category (security, reliability, functionality, documentation). Automation groups duplicates and enforces prioritization order security > reliability > functionality > documentation.
- **Publication & Escalation**: workflow transitions are visible through dashboards/CLI. If an SLA is missed twice or a critical (P0) signal lacks action, escalate to the ecosystem council chair.
- **Appeals**: affected owners may trigger an appeal state with a 3-business-day SLA for reconsideration; outcomes are logged alongside the original decision.

### Change Signal Example

```yaml
id: SIG-2025-0012
title: Deprecate legacy MCP registry format
capabilities: ["MCP.REGISTRY.MANAGE"]
state: review
priority: high
impact: breaking
owner: aurora-mcp-team
stewards: ["nebula-core"]
created_at: 2025-09-29T18:30:00Z
sla:
  acknowledge_by: 2025-10-01T18:30:00Z
  decide_by: 2025-10-06T18:30:00Z
links:
  manifests: ["aurora-mcp/star.yaml"]
  behaviors: ["MCP.REGISTRY.MANAGE"]
  adr: ["ADR-2025-07"]
```

## Governance & Decision Flow

- **Council Cadence**: Cross-project council meets bi-weekly with option for asynchronous decisions via documented voting (minimum 3 business days). Emergency meetings can be called for P0 signals.
- **Quorum & Voting**: Simple majority of stewards plus representation from affected projects constitutes quorum. Decisions recorded with outcome, dissent notes, and follow-up owners.
- **Working Groups**: Temporary groups chartered for focused topics (e.g., security baseline). Mandate includes deliverables, timeline, and sunset criteria.
- **RACI Summary**:
  - **Stewards (R/A)** – maintain standards, approve breaking changes.
  - **Project Maintainers (R/A)** – implement changes within their repos.
  - **Coordinators (C)** – ensure communication, track SLAs.
  - **Contributors (I)** – kept informed via change signal updates and documentation.
- **Appeal & Escalation**: Appeals escalate to council chair; unresolved disputes within 5 business days escalate to executive sponsor or governance board.
- **Decision Log**: All outcomes stored in an accessible log referencing related change signals, manifests, and ADRs.

Any solution must make it easy to raise, track, and resolve change signals following this lifecycle.

## Compatibility Policy

- **Versioning Rules**: Capabilities and integration contracts adopt semantic versioning (`MAJOR.MINOR.PATCH`). Major bumps denote breaking change and require council approval plus migration plan; minor bumps add backward-compatible behavior; patch bumps cover fixes or documentation.
- **Backward/Forward Checks**: Automated suites verify backward compatibility with the previous MAJOR.MINOR release and (where possible) forward compatibility so older consumers tolerate newer providers.
- **Grace Periods**: Breaking changes must provide a migration plan with at least two release cycles’ notice (unless addressing a critical security issue). Plans include timelines, fallbacks, and communication strategy.
- **Automated Break Detection**: Integration contracts and smoke suites run across dependency matrices. Failures auto-open high-priority change signals and block release until resolved or waiver granted.
- **Waiver Process**: Temporary waivers require justification, mitigation steps, owner, and expiry date. Expiring waivers trigger alerts; expired waivers default to enforcement.
- **Deprecation Playbook**: Mark capabilities as `deprecated`, reference replacements, track usage via telemetry, and schedule removal with explicit dates. Change signals coordinate decommissioning.
- **Compatibility Matrix**: Maintain machine-readable matrices mapping provider and consumer versions. Update alongside release readiness and expose via discovery APIs.

## Security Baseline

Any ecosystem-wide approach must account for security from the outset:

- **Threat Model**: Document adversaries (external, insider, supply chain). Evaluate attack surfaces for CLI plugins, manifests, runtime services, and observability feeds.
- **Provenance & Signing**: Target SLSA Level 3 builds. Sign artifacts, manifests, and change-signal bundles using Sigstore (Cosign/Fulcio/Rekor) or equivalent; verify signatures before ingestion.
- **SBOM & Vulnerability Gating**: Produce SPDX SBOMs for each release. Integrate scanners (pip-audit, osv-scanner). Block releases on high/critical CVEs unless a council-approved waiver with mitigation exists.
- **Policy-as-Code**: Encode guardrails via OPA/Conftest (dependency policies, secret usage, runtime auth). Enforce in CI and pre-merge.
- **Secret Handling**: Define secret tiers (developer, project, shared). Manifests declare required secrets and scope. Prefer just-in-time issuance and avoid embedding credentials in configs/logs.
- **Service Identity & Auth**: Use workload identities (OIDC, SPIFFE) and mutual TLS where feasible. Deprecate static tokens; enforce rotation.
- **Audit & Logging**: Maintain tamper-evident logs capturing CLI usage, manifest changes, change signals, and runtime access. Retain ≥12 months with controlled access.
- **Incident Response**: Maintain shared playbooks mapping capabilities to response owners; run periodic drills and capture lessons learned.

## Discovery Expectations

- **Architecture**: Hybrid approach—authoritative manifests stay with owning repositories; central indices mirror metadata for search and caching via documented APIs.
- **Location & Distribution**: Require manifests in repo roots and release artifacts; optionally expose via HTTPS. Central index uses ETag/If-Modified-Since to synchronize.
- **Cache & Refresh**: Index refresh cadence is configurable (default daily). Manifests supply `updated_at` and optional `ttl`. Clients warn when TTL exceeded. Offline mirrors package signed bundles (manifest + SBOM + behaviors) for air-gapped use.
- **Authentication/Authorization**: Index queries default to SSO-authenticated users. Security tiers control visibility; automation acquires scoped tokens. Access events are logged for audit.
- **Staleness Detection**: Compare manifest timestamps vs. latest release tags and validation status. Flag stale entries and emit change signals when overdue.
- **Offline Operation**: Provide export/import commands creating signed bundles. Mirror servers verify signatures and manifest versions before syncing. Registry sync policies define required approvals and checksum verification.
- **Capability Catalog**: Generate a consolidated catalog (e.g., `docs/capabilities/index.md`) from the discovery index so humans and agents can enumerate all available capabilities and follow links to manifests and documentation.
- **Manifest Discovery Hints**: Manifests should declare CLI commands, MCP endpoints, and doc references (`discovery.cli_commands`, `discovery.docs`) so automation knows how to invoke the capability after discovery.
- **Value Scenario Catalog**: Generate a catalog of user-testable scenarios alongside capabilities, including manual guides, automated tests, and associated change signals. Agents can query the catalog to run validation flows.

## Observability Requirements

- **Events**: Capture `cli_usage`, `behavior_validation`, `change_signal_transition`, `runtime_invocation`, and `incident` events.
- **Metrics**: Emit counts/durations keyed by `capability_id`, `version`, `owner`, `status`. Include success/failure rates, routing latency, validation latency, adoption ratios.
- **Trace Context**: Each event includes `trace_id` and `span_id` aligned with OpenTelemetry. Change signals propagate a `correlation_id` reused across participating systems.
- **Retention & Privacy**: Operational metrics retained 90 days; audit logs 12 months. PII prohibited; if unavoidable, anonymize and document handling.
- **Access & Tooling**: Provide dashboards and exportable APIs with RBAC. Support offline export for air-gapped review.

## Standards Alignment

- Leverage existing standards to reduce custom tooling and vendor lock-in:
  - **Manifests**: Align with OpenAPI/AsyncAPI for service interfaces, SPDX for SBOMs, and CNCF TAG App Delivery guidance where applicable.
  - **Behavior Specs**: Reference Gherkin/Cucumber BDD conventions; consider Living Documentation tooling for rendering.
  - **Security**: Adopt frameworks like NIST SSDF or OWASP SAMM for maturity benchmarks.
  - **Observability**: Follow OpenTelemetry for metrics and tracing to avoid bespoke instrumentation.
  - **Change Management**: Borrow from ITIL/DevOps change control where beneficial, but automate wherever possible.

## Anti-Goals

- Mandating a single monorepo or central code ownership.
- Forcing all projects to adopt identical technology stacks or languages.
- Centralizing decision making to the point of blocking local autonomy.
- Replacing project-level governance or incident response processes.
- Building proprietary tooling when existing open standards solve the problem.

## Constraints & Non-Goals

- **Autonomy** – Projects retain independent roadmaps; ecosystem guidelines should enable but not monopolize decision making.
- **Incremental Adoption** – New capabilities must be adoptable piecewise. Avoid all-or-nothing migrations.
- **Tool Diversity** – The ecosystem supports multiple languages or frameworks; specifications focus on interfaces, not implementation detail.
- **Minimal Bureaucracy** – Coordination mechanisms should minimize overhead while ensuring traceability of major decisions.

## Success Criteria (Qualitative)

- New contributors can orient themselves within hours using generated documentation and manifests.
- Cross-project changes are anticipated and coordinated, avoiding surprise breakages.
- Automation systems can run lifecycle tasks without bespoke scripts per repository.
- Runtime consumers connect to services using standard discovery information and compatibility checks.
- Governance artifacts (decisions, standards, compatibility matrices) are accessible and up to date.

## Ecosystem Interactions

To ground the intent, consider three recurring interaction loops. Each loop should be supported regardless of the concrete architecture chosen.

- **Plan-to-Build Loop** – A change request surfaces (human or agent). Actors consult capability discovery to determine whether existing functionality satisfies the need. If not, they draft new behaviors and manifests, creating traceable work items.
- **Build-to-Validate Loop** – Implementations publish updated metadata and execute shared validation suites. Integration contracts flag incompatibilities early across the project graph.
- **Release-to-Operate Loop** – Runtime assets register themselves for discovery. Operational tooling monitors health and feeds observations back into planning.

These loops overlap; short feedback cycles reduce systemic risk and keep metadata synchronized with reality.

## Quality Attributes

The ecosystem must exhibit several qualities independent of the specific technical stack:

- **Reliability** – Shared tooling should continue to function when individual projects change. Version negotiation and graceful degradation are required.
- **Scalability** – Adding new projects or capabilities should not exponentially increase coordination costs. Metadata and automation must scale with the constellation count.
- **Observability** – Operators can inspect state (who provides what, which behaviors pass, which signals are unresolved) without manual spelunking.
- **Security & Privacy** – Secrets remain scoped, logs respect boundaries, and third-party contributions cannot subvert shared tooling.
- **Extensibility** – New lifecycle stages or artifact types can be introduced without rewiring the ecosystem. Interfaces focus on contracts rather than implementations.

## Adoption Pathways

Because projects vary in maturity, solution candidates should offer progressive adoption steps:

1. **Documentation Alignment** – Projects map existing workflows to the shared lifecycle vocabulary and publish manifests describing current capabilities. *Acceptance*: manifests include minimum fields; lifecycle mapping reviewed by maintainers.
2. **Validation Integration** – Teams adopt shared integration contracts, running automated checks alongside local tests. *Acceptance*: CI includes contract suite; build fails on incompatibilities without waivers.
3. **Coordination Participation** – Projects begin emitting and responding to change signals, contributing decisions to the shared log. *Acceptance*: change signals follow the standardized workflow with SLA compliance.
4. **Runtime Interoperability** – Services expose runtime discovery metadata, enabling cross-project invocation. *Acceptance*: at least one dependent project successfully consumes runtime metadata with compatibility checks.

Each step yields value on its own and prepares the ground for the next, reducing the risk of large-bang transitions.

## Success Metrics (Illustrative)

To evaluate whether intent is being realized, stakeholders can monitor metrics such as:

- Time from change request to owner identification (“routing latency”) – baseline current average; target 50% reduction within two release cycles.
- Percentage of behaviors with up-to-date metadata and passing automated tests – baseline existing coverage; target ≥90% within one release cycle.
- Number of cross-project incidents caused by incompatibilities – establish quarterly baseline; target downward trend with less than one major incident per quarter.
- Mean time to integrate a new project into the ecosystem – measure first adopter; target <2 weeks once tooling is available.
- Adoption rate of shared runtime discovery (fraction of services exposing standardized endpoints) – baseline 0%; target 60% by end of the runtime interoperability phase.

These metrics do not prescribe tooling but provide signals that any solution should surface.

## Risks & Watchpoints

- **Stale Metadata** – Manifests or behavior registries drifting from reality weaken trust; require validation loops.
- **Fragmented UX** – Without enforced conventions, tooling feels inconsistent; require shared guidelines.
- **Signal Saturation** – Coordination channels may accumulate noise; implement prioritization, deduplication, and ownership assignment.
- **Security Erosion** – Shared tooling can propagate vulnerabilities; invest in automated scanning and timely response processes.

## Open Questions

- What governance cadence (e.g., weekly council, asynchronous voting) balances responsiveness with workload?
- How should runtime discovery authenticate services in multi-tenant or remote scenarios?
- What minimum metadata should behaviors and manifests expose to satisfy both human and agent needs?
- Which artifacts belong in a central repository versus remaining in individual projects?
- How will feedback loops function when some projects operate in offline or restricted environments?
- What escalation path exists when shared standards block urgent local changes?

## Naming Guidelines

- **Repositories**: platform/shared repos use `chora-<platform-domain>` (e.g., `chora-platform`); capability providers use `<domain>-<capability-provider>` (e.g., `mcp-orchestration`).
- **Capability IDs**: `<domain>.<capability>.<action>` (e.g., `mcp.registry.manage`); add a version suffix if multiple versions coexist.
- **Change Signals**: `SIG.<scope>.<subject>.<state>` with optional iteration suffix (`SIG.capability.mcp.registry.update-2`).
- **Packages/CLI**: prefix shared tooling with `chora-` (`chora-cli`, `chora-validator`).
- **Documentation**: place standards under `docs/standards/`, capability references under `docs/capabilities/`, reference snippets under `docs/reference/`.
- **Templates & Workflows**: publish reusable CI pipelines (`.github/workflows/chora-ci.yml`), AGENTS snippets, and CLI scaffolds under predictable paths so capability repos can copy/adopt them.
- **Value Scenario IDs**: use `<domain>.<capability>.<verb>` (e.g., `mcp.registry.manage.create-doc`) for scenario identifiers; store supporting guides under `docs/how-to/` and automated tests under `tests/value-scenarios/` for predictable discovery.

Changes to naming conventions should be recorded through change signals to maintain consistency across projects.

---

Use this intent document as a lens when evaluating or designing ecosystem architecture. Any proposed solution should be able to trace back how it fulfills these objectives and mitigates the outlined risks.
- **Access & Tooling**: Provide dashboards and exportable APIs with RBAC. Support offline export for air-gapped review.

## Offline / Air-Gapped Operation

- **Caching Strategy**: Projects operating offline maintain signed mirrors of manifests, behaviors, SBOMs, and change signals. Mirrors include freshness metadata and checksum files.
- **Sync Policies**: Define minimum sync cadence (e.g., weekly) and approval steps before import. Sync tooling verifies signatures and compatibility before applying updates.
- **Bundle Format**: Standardize bundle archives containing manifests, SBOMs, behaviors, and decision logs with accompanying signatures.
- **Conflict Resolution**: When mirrors diverge, raise change signals with context so maintainers can reconcile differences.
- **Telemetry Backfill**: Offline environments queue observability events locally and replay them once connectivity is restored, preserving correlation IDs.
