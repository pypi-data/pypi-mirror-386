"""
OpenEurOtop - Introduction et Comparaison des M√©thodes
=====================================================

Ce script compare les 3 m√©thodes disponibles :
1. Formules empiriques EurOtop (r√©f√©rence) ‚úÖ
2. Neural Network CLASH (R¬≤ = 0.67) ‚ö†Ô∏è
3. XGBoost optimis√© (R¬≤ = 0.88) üèÜ

Pour convertir en notebook Jupyter :
    jupyter nbconvert --to notebook notebook_01_introduction_comparative.py
"""

# %% [markdown]
# # OpenEurOtop - Introduction et Comparaison des M√©thodes
# 
# ## Objectif
# Comparer les **3 m√©thodes** pour calculer le franchissement :
# 
# 1. **Formules empiriques EurOtop** (r√©f√©rence) ‚úÖ
# 2. **Neural Network CLASH** (R¬≤ = 0.67) ‚ö†Ô∏è
# 3. **XGBoost optimis√©** (R¬≤ = 0.88) üèÜ

# %% [code]
import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.insert(0, '..')

from openeurotop import overtopping
from openeurotop.neural_network_clash import predict_with_clash
from openeurotop.xgboost_model import predict_with_xgboost, compare_all_methods

print("Modules charges avec succes !")

# %% [markdown]
# ## 1. Exemple Simple - Digue √† Talus
# 
# Calculons le franchissement pour une digue standard :
# - Hauteur de vague : Hm0 = 2.5 m
# - P√©riode : Tm-1,0 = 6.0 s
# - Profondeur : h = 10.0 m
# - Revanche : Rc = 3.0 m
# - Pente : Œ± = 35¬∞

# %% [code]
# Param√®tres de la structure
Hm0 = 2.5  # m
Tm_10 = 6.0  # s
h = 10.0  # m
Rc = 3.0  # m
alpha_deg = 35.0  # degr√©s

print("Parametres de la structure:")
print(f"  Hm0 = {Hm0} m")
print(f"  Tm-1,0 = {Tm_10} s")
print(f"  h = {h} m")
print(f"  Rc = {Rc} m")
print(f"  alpha = {alpha_deg} deg")

# %% [code]
# M√©thode 1 : Formule empirique EurOtop (R√âF√âRENCE)
q_eurotop = overtopping.digue_talus(Hm0, Tm_10, h, Rc, alpha_deg)

# M√©thode 2 : Neural Network CLASH
result_nn = predict_with_clash(Hm0, Tm_10, h, Rc, alpha_deg)
q_neural = result_nn['q']

# M√©thode 3 : XGBoost optimis√©
result_xgb = predict_with_xgboost(Hm0, Tm_10, h, Rc, alpha_deg)
q_xgboost = result_xgb['q']

print("\nRESULTATS:")
print("="*60)
print(f"Formule EurOtop (reference):  q = {q_eurotop:.6f} m3/s/m")
print(f"Neural Network CLASH:         q = {q_neural:.6f} m3/s/m  (x{q_neural/q_eurotop:.2f})")
print(f"XGBoost optimise:             q = {q_xgboost:.6f} m3/s/m  (x{q_xgboost/q_eurotop:.2f})")
print("="*60)

# %% [markdown]
# ### Visualisation

# %% [code]
# Graphique de comparaison
methods = ['EurOtop\n(reference)', 'Neural Network\n(R2=0.67)', 'XGBoost\n(R2=0.88)']
debits = [q_eurotop, q_neural, q_xgboost]
colors = ['#2E7D32', '#FF6F00', '#1976D2']

fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(methods, debits, color=colors, alpha=0.7, edgecolor='black', linewidth=2)

# Ajouter les valeurs sur les barres
for i, (bar, q) in enumerate(zip(bars, debits)):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{q:.6f}\nm3/s/m',
            ha='center', va='bottom', fontsize=10, fontweight='bold')

ax.set_ylabel('Debit de franchissement (m3/s/m)', fontsize=12, fontweight='bold')
ax.set_title('Comparaison des 3 methodes - Digue a talus', fontsize=14, fontweight='bold')
ax.grid(axis='y', alpha=0.3, linestyle='--')
plt.tight_layout()
plt.savefig('comparison_methods.png', dpi=150)
plt.show()

print("\nINTERPRETATION:")
print("- EurOtop: formule physique validee (UTILISER POUR DESIGN)")
print(f"- XGBoost: {abs(q_xgboost - q_eurotop)/q_eurotop*100:.1f}% d'ecart (ACCEPTABLE)")
print(f"- Neural Network: {abs(q_neural - q_eurotop)/q_eurotop*100:.1f}% d'ecart (ATTENTION)")

# %% [markdown]
# ## 2. Variation de la Revanche (Rc)
# 
# √âtudions l'influence de la revanche sur le franchissement

# %% [code]
# Variation de Rc
Rc_values = np.linspace(0.5, 5.0, 20)

q_eurotop_list = []
q_neural_list = []
q_xgboost_list = []

for Rc_var in Rc_values:
    # EurOtop
    q_e = overtopping.digue_talus(Hm0, Tm_10, h, Rc_var, alpha_deg)
    q_eurotop_list.append(q_e)
    
    # Neural Network
    result_n = predict_with_clash(Hm0, Tm_10, h, Rc_var, alpha_deg)
    q_neural_list.append(result_n['q'])
    
    # XGBoost
    result_x = predict_with_xgboost(Hm0, Tm_10, h, Rc_var, alpha_deg)
    q_xgboost_list.append(result_x['q'])

# %% [code]
# Graphique
fig, ax = plt.subplots(figsize=(12, 7))

ax.plot(Rc_values, q_eurotop_list, 'o-', color='#2E7D32', linewidth=2.5, 
        markersize=8, label='EurOtop (reference)', alpha=0.8)
ax.plot(Rc_values, q_xgboost_list, 's-', color='#1976D2', linewidth=2.5, 
        markersize=7, label='XGBoost optimise (R2=0.88)', alpha=0.8)
ax.plot(Rc_values, q_neural_list, '^-', color='#FF6F00', linewidth=2, 
        markersize=7, label='Neural Network (R2=0.67)', alpha=0.7)

ax.set_xlabel('Revanche Rc (m)', fontsize=12, fontweight='bold')
ax.set_ylabel('Debit de franchissement q (m3/s/m)', fontsize=12, fontweight='bold')
ax.set_title(f'Influence de la revanche\nHm0={Hm0}m, Tm-1,0={Tm_10}s, h={h}m, alpha={alpha_deg}deg',
             fontsize=14, fontweight='bold')
ax.legend(fontsize=11, loc='upper right')
ax.grid(True, alpha=0.3, linestyle='--')
ax.set_yscale('log')

plt.tight_layout()
plt.savefig('influence_revanche.png', dpi=150)
plt.show()

print("\nOBSERVATIONS:")
print("- XGBoost suit tres bien la tendance EurOtop")
print("- Neural Network montre plus de variabilite")
print("- Plus Rc augmente, moins il y a de franchissement (logique)")

# %% [markdown]
# ## 3. Comparaison sur Plusieurs Sc√©narios

# %% [code]
# D√©finir plusieurs sc√©narios
scenarios = [
    {'name': 'Faible franchissement', 'Hm0': 1.5, 'Tm_10': 5.0, 'h': 8.0, 'Rc': 4.0, 'alpha': 40.0},
    {'name': 'Modere', 'Hm0': 2.5, 'Tm_10': 6.5, 'h': 10.0, 'Rc': 2.5, 'alpha': 30.0},
    {'name': 'Fort franchissement', 'Hm0': 3.5, 'Tm_10': 8.0, 'h': 12.0, 'Rc': 1.0, 'alpha': 25.0},
    {'name': 'Submersion partielle', 'Hm0': 3.0, 'Tm_10': 7.0, 'h': 10.0, 'Rc': 0.5, 'alpha': 35.0},
]

results_table = []

for sc in scenarios:
    # Calculer avec les 3 m√©thodes
    q_e = overtopping.digue_talus(sc['Hm0'], sc['Tm_10'], sc['h'], sc['Rc'], sc['alpha'])
    q_n = predict_with_clash(sc['Hm0'], sc['Tm_10'], sc['h'], sc['Rc'], sc['alpha'])['q']
    q_x = predict_with_xgboost(sc['Hm0'], sc['Tm_10'], sc['h'], sc['Rc'], sc['alpha'])['q']
    
    results_table.append({
        'Scenario': sc['name'],
        'EurOtop': q_e,
        'Neural Net': q_n,
        'XGBoost': q_x,
        'Erreur NN (%)': abs(q_n - q_e) / q_e * 100,
        'Erreur XGB (%)': abs(q_x - q_e) / q_e * 100
    })

# %% [code]
# Afficher tableau
import pandas as pd
df_results = pd.DataFrame(results_table)
print("\nTABLEAU COMPARATIF:")
print("="*80)
print(df_results.to_string(index=False))
print("="*80)

# %% [code]
# Graphique comparatif
x = np.arange(len(scenarios))
width = 0.25

fig, ax = plt.subplots(figsize=(14, 7))

bars1 = ax.bar(x - width, [r['EurOtop'] for r in results_table], width, 
               label='EurOtop', color='#2E7D32', alpha=0.8)
bars2 = ax.bar(x, [r['Neural Net'] for r in results_table], width, 
               label='Neural Network', color='#FF6F00', alpha=0.8)
bars3 = ax.bar(x + width, [r['XGBoost'] for r in results_table], width, 
               label='XGBoost', color='#1976D2', alpha=0.8)

ax.set_xlabel('Scenario', fontsize=12, fontweight='bold')
ax.set_ylabel('Debit de franchissement (m3/s/m)', fontsize=12, fontweight='bold')
ax.set_title('Comparaison des methodes sur differents scenarios', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels([s['name'] for s in scenarios], rotation=15, ha='right')
ax.legend(fontsize=11)
ax.set_yscale('log')
ax.grid(axis='y', alpha=0.3, linestyle='--')

plt.tight_layout()
plt.savefig('comparison_scenarios.png', dpi=150)
plt.show()

print("\nERREURS MOYENNES:")
print(f"Neural Network: {np.mean([r['Erreur NN (%)'] for r in results_table]):.1f}%")
print(f"XGBoost:        {np.mean([r['Erreur XGB (%)'] for r in results_table]):.1f}%")

# %% [markdown]
# ## Conclusions
# 
# ### üèÜ Meilleure m√©thode : XGBoost optimis√©
# - R¬≤ = 0.88 (87.9% de variance expliqu√©e)
# - Erreur moyenne < 20%
# - Plus proche des formules EurOtop
# - Tr√®s stable (variance faible)
# 
# ### ‚ö†Ô∏è Neural Network
# - R¬≤ = 0.67
# - Erreurs plus importantes
# - Peut diverger sur certains cas
# 
# ### ‚úÖ Recommandations
# 1. **Pour le design** : toujours utiliser formules EurOtop
# 2. **Pour l'analyse** : XGBoost acceptable avec v√©rification
# 3. **Pour la recherche** : comparer les 3 m√©thodes

print("\n" + "="*60)
print("SCRIPT TERMINE - Images sauvegardees dans le repertoire courant")
print("="*60)

