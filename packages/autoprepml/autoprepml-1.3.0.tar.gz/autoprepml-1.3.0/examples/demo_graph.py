"""
Demo: Graph Data Preprocessing with AutoPrepML
Example: Social network analysis with node/edge validation
"""
import pandas as pd
from autoprepml.graph import GraphPrepML

# Sample data: Social network (users and friendships)
# Create nodes (users)
nodes_data = {
    'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11],  # Note: duplicate ID 11
    'username': [
        'alice', 'bob', 'charlie', 'david', 'eve',
        'frank', 'grace', 'henry', 'iris', 'jack',
        'kate', 'kate_duplicate'
    ],
    'followers': [120, 85, 200, 45, 150, 30, 95, 110, 70, 180, 60, 61],
}

# Create edges (friendships)
edges_data = {
    'source': [1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 7, 8, 8, 15, 16],  # 15, 16 are dangling
    'target': [2, 3, 4, 3, 5, 4, 5, 5, 5, 6, 7, 7, 8, 9, 10, 99, 100],  # 99, 100 don't exist
    'interaction_count': [25, 40, 15, 30, 20, 35, 45, 10, 10, 50, 25, 30, 40, 20, 35, 1, 1]
}

nodes_df = pd.DataFrame(nodes_data)
edges_df = pd.DataFrame(edges_data)

print("=" * 80)
print("ğŸ•¸ï¸  GRAPH DATA PREPROCESSING DEMO - Social Network Analysis")
print("=" * 80)

# Initialize GraphPrepML
print("\n1ï¸âƒ£  Initializing GraphPrepML...")
prep = GraphPrepML(
    nodes_df=nodes_df,
    edges_df=edges_df,
    node_id_col='id',
    source_col='source',
    target_col='target'
)
print(f"âœ“ Loaded {len(prep.nodes_df)} nodes and {len(prep.edges_df)} edges")

# Detect issues
print("\n2ï¸âƒ£  Detecting graph data quality issues...")
issues = prep.detect_issues()

print("\n   Node Issues:")
print(f"   â€¢ Total nodes: {issues['nodes']['total_nodes']}")
print(f"   â€¢ Duplicate node IDs: {issues['nodes']['duplicate_node_ids']}")
print(f"   â€¢ Missing node IDs: {issues['nodes']['missing_node_ids']}")

print("\n   Edge Issues:")
print(f"   â€¢ Total edges: {issues['edges']['total_edges']}")
print(f"   â€¢ Duplicate edges: {issues['edges']['duplicate_edges']}")
print(f"   â€¢ Self-loops: {issues['edges']['self_loops']}")
print(f"   â€¢ Missing sources: {issues['edges']['missing_sources']}")
print(f"   â€¢ Missing targets: {issues['edges']['missing_targets']}")
print(f"   â€¢ Dangling edges: {issues['edges']['dangling_edges']}")

# Validate node IDs
print("\n3ï¸âƒ£  Validating and cleaning node IDs...")
original_nodes = len(prep.nodes_df)
prep.validate_node_ids()
removed_nodes = original_nodes - len(prep.nodes_df)
print(f"âœ“ Removed {removed_nodes} invalid nodes (duplicates/missing IDs)")
print(f"âœ“ Valid nodes remaining: {len(prep.nodes_df)}")

# Validate edges
print("\n4ï¸âƒ£  Validating and cleaning edges...")
original_edges = len(prep.edges_df)
prep.validate_edges(remove_self_loops=True, remove_dangling=True)
removed_edges = original_edges - len(prep.edges_df)
print(f"âœ“ Removed {removed_edges} invalid edges (self-loops/dangling)")
print(f"âœ“ Valid edges remaining: {len(prep.edges_df)}")

# Remove duplicate edges
print("\n5ï¸âƒ£  Removing duplicate edges...")
original_edges = len(prep.edges_df)
prep.remove_duplicate_edges(keep='first')
removed_edges = original_edges - len(prep.edges_df)
print(f"âœ“ Removed {removed_edges} duplicate edges")

# Add node features
print("\n6ï¸âƒ£  Extracting node-level features...")
prep.add_node_features()
print("âœ“ Added features:")
print("   - out_degree (outgoing connections)")
print("   - in_degree (incoming connections)")
print("   - total_degree (total connections)")
print("   - is_isolated (no connections)")

# Show top connected users
print("\n   Top 5 most connected users:")
top_users = prep.nodes_df.nlargest(5, 'total_degree')[['id', 'username', 'total_degree']]
for _, row in top_users.iterrows():
    print(f"   â€¢ {row['username']}: {row['total_degree']} connections")

# Add edge features
print("\n7ï¸âƒ£  Extracting edge-level features...")
prep.add_edge_features()
print("âœ“ Added edge features: edge_count")

# Identify connected components
print("\n8ï¸âƒ£  Identifying connected components...")
prep.identify_components()
num_components = prep.nodes_df['component_id'].nunique()
print(f"âœ“ Found {num_components} connected component(s)")

# Show component distribution
component_sizes = prep.nodes_df.groupby('component_id').size().sort_values(ascending=False)
print("\n   Component sizes:")
for comp_id, size in component_sizes.items():
    print(f"   â€¢ Component {comp_id}: {size} nodes")

# Check for isolated nodes
isolated_count = prep.nodes_df['is_isolated'].sum()
print(f"\n   Isolated nodes: {isolated_count}")

if isolated_count > 0:
    isolated_users = prep.nodes_df[prep.nodes_df['is_isolated']]['username'].tolist()
    print(f"   Isolated users: {isolated_users}")

# Get graph statistics
print("\n9ï¸âƒ£  Computing graph statistics...")
stats = prep.get_graph_stats()
print("âœ“ Graph metrics:")
print(f"   â€¢ Number of nodes: {stats['num_nodes']}")
print(f"   â€¢ Number of edges: {stats['num_edges']}")
print(f"   â€¢ Graph density: {stats['density']:.4f}")
print(f"   â€¢ Average degree: {stats['avg_degree']:.2f}")

# Convert to different formats
print("\nğŸ”Ÿ Converting to different graph representations...")

# Edge list
edge_list = prep.to_edge_list()
print(f"âœ“ Edge list format: {len(edge_list)} edges")
print(f"   Sample edges: {edge_list[:3]}")

# Adjacency dictionary
adj_dict = prep.to_adjacency_dict()
print(f"âœ“ Adjacency dictionary: {len(adj_dict)} nodes")
print(f"   Sample: Node 1 connects to: {adj_dict.get(1, [])}")

# Display sample network data
print("\nğŸ“Š Sample Network Data:")
print("-" * 80)
print("\nNodes (Top 5):")
print(prep.nodes_df[['id', 'username', 'followers', 'total_degree', 'component_id']].head().to_string(index=False))

print("\nEdges (Top 5):")
print(prep.edges_df[['source', 'target', 'interaction_count']].head().to_string(index=False))

# Generate report
print("\nğŸ“ˆ Generating preprocessing report...")
report = prep.report()
print(f"âœ“ Original nodes shape: {report['original_nodes_shape']}")
print(f"âœ“ Current nodes shape:  {report['current_nodes_shape']}")
print(f"âœ“ Original edges shape: {report['original_edges_shape']}")
print(f"âœ“ Current edges shape:  {report['current_edges_shape']}")
print(f"âœ“ Operations performed: {len(report['logs'])}")

# Save cleaned data
nodes_output = 'social_network_nodes_cleaned.csv'
edges_output = 'social_network_edges_cleaned.csv'
prep.nodes_df.to_csv(nodes_output, index=False)
prep.edges_df.to_csv(edges_output, index=False)
print(f"\nğŸ’¾ Saved cleaned graph data:")
print(f"   â€¢ Nodes: {nodes_output}")
print(f"   â€¢ Edges: {edges_output}")

# Summary
print("\n" + "=" * 80)
print("âœ¨ GRAPH PREPROCESSING COMPLETE!")
print("=" * 80)
print("Network Statistics:")
print(f"   â€¢ Total users: {len(prep.nodes_df)}")
print(f"   â€¢ Total friendships: {len(prep.edges_df)}")
print(f"   â€¢ Connected components: {num_components}")
print(f"   â€¢ Isolated users: {isolated_count}")
print(f"   â€¢ Network density: {stats['density']:.4f}")
print(f"   â€¢ Avg connections per user: {stats['avg_degree']:.2f}")

print("\nğŸ’¡ Use Cases:")
print("   â€¢ Social network analysis")
print("   â€¢ Community detection")
print("   â€¢ Influence analysis")
print("   â€¢ Recommendation systems")
print("   â€¢ Link prediction")

print("\nğŸ“Š Ready for graph algorithms:")
print("   â€¢ PageRank")
print("   â€¢ Centrality measures")
print("   â€¢ Community detection (Louvain, Label Propagation)")
print("   â€¢ Graph Neural Networks (GNN)")
print("   â€¢ Network visualization")
print("=" * 80)
