{
  "ollama/codegeex4": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": false
  },
  "ollama/codegemma": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "completion",
    "output_cost_per_token": 0.0
  },
  "ollama/codellama": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "completion",
    "output_cost_per_token": 0.0
  },
  "ollama/deepseek-coder-v2-base": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "completion",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/deepseek-coder-v2-instruct": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/deepseek-coder-v2-lite-base": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "completion",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/deepseek-coder-v2-lite-instruct": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/internlm2_5-20b-chat": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/llama2": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/llama2-uncensored": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "completion",
    "output_cost_per_token": 0.0
  },
  "ollama/llama2:13b": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/llama2:70b": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/llama2:7b": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/llama3": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/llama3.1": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/llama3:70b": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/llama3:8b": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0
  },
  "ollama/mistral": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "completion",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/mistral-7B-Instruct-v0.1": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/mistral-7B-Instruct-v0.2": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/mistral-large-instruct-2407": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/mixtral-8x22B-Instruct-v0.1": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 65536,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/mixtral-8x7B-Instruct-v0.1": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/orca-mini": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "completion",
    "output_cost_per_token": 0.0
  },
  "ollama/vicuna": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 2048,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "completion",
    "output_cost_per_token": 0.0
  }
}