{
  "gradient_ai/alibaba-qwen3-32b": {
    "litellm_provider": "gradient_ai",
    "max_tokens": 2048,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/anthropic-claude-3-opus": {
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "gradient_ai",
    "max_tokens": 1024,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/anthropic-claude-3.5-haiku": {
    "input_cost_per_token": 8e-07,
    "litellm_provider": "gradient_ai",
    "max_tokens": 1024,
    "mode": "chat",
    "output_cost_per_token": 4e-06,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/anthropic-claude-3.5-sonnet": {
    "input_cost_per_token": 3e-06,
    "litellm_provider": "gradient_ai",
    "max_tokens": 1024,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/anthropic-claude-3.7-sonnet": {
    "input_cost_per_token": 3e-06,
    "litellm_provider": "gradient_ai",
    "max_tokens": 1024,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/deepseek-r1-distill-llama-70b": {
    "input_cost_per_token": 9.9e-07,
    "litellm_provider": "gradient_ai",
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 9.9e-07,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/llama3-8b-instruct": {
    "input_cost_per_token": 2e-07,
    "litellm_provider": "gradient_ai",
    "max_tokens": 512,
    "mode": "chat",
    "output_cost_per_token": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/llama3.3-70b-instruct": {
    "input_cost_per_token": 6.5e-07,
    "litellm_provider": "gradient_ai",
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 6.5e-07,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/mistral-nemo-instruct-2407": {
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gradient_ai",
    "max_tokens": 512,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/openai-gpt-4o": {
    "litellm_provider": "gradient_ai",
    "max_tokens": 16384,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/openai-gpt-4o-mini": {
    "litellm_provider": "gradient_ai",
    "max_tokens": 16384,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/openai-o3": {
    "input_cost_per_token": 2e-06,
    "litellm_provider": "gradient_ai",
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 8e-06,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "gradient_ai/openai-o3-mini": {
    "input_cost_per_token": 1.1e-06,
    "litellm_provider": "gradient_ai",
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 4.4e-06,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false
  },
  "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/QwQ-32B": {
    "input_cost_per_token": 2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/Qwen3-235B-A22B": {
    "input_cost_per_token": 2e-06,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/deepseek-ai/DeepSeek-R1": {
    "input_cost_per_token": 4e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2.5e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/deepseek-ai/DeepSeek-V3": {
    "input_cost_per_token": 2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 2e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
    "input_cost_per_token": 4e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 1.2e-07,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/moonshotai/Kimi-K2-Instruct": {
    "input_cost_per_token": 2e-06,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  }
}