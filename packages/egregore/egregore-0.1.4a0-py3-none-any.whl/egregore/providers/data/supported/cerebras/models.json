{
  "cerebras/llama-3.3-70b": {
    "input_cost_per_token": 8.5e-07,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.2e-06,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "cerebras/llama3.1-70b": {
    "input_cost_per_token": 6e-07,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6e-07,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "cerebras/llama3.1-8b": {
    "input_cost_per_token": 1e-07,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-07,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "cerebras/openai/gpt-oss-120b": {
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "cerebras",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 6.9e-07,
    "source": "https://www.cerebras.ai/blog/openai-gpt-oss-120b-runs-fastest-on-cerebras",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "cerebras/openai/gpt-oss-20b": {
    "input_cost_per_token": 7e-08,
    "litellm_provider": "cerebras",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "source": "https://inference-docs.cerebras.ai/support/pricing",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "cerebras/qwen-3-32b": {
    "input_cost_per_token": 4e-07,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 8e-07,
    "source": "https://inference-docs.cerebras.ai/support/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true
  }
}