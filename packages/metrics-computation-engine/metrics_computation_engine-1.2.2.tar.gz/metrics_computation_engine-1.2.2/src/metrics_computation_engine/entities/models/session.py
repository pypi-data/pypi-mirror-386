# Copyright AGNTCY Contributors (https://github.com/agntcy)
# SPDX-License-Identifier: Apache-2.0

from typing import Any, Dict, List, Optional
from collections import Counter, defaultdict
from pydantic import BaseModel, Field, PrivateAttr

from .span import SpanEntity


class AgentStats(BaseModel):
    """Statistics for a single agent in a session."""

    unique_tool_names: List[str] = Field(
        default_factory=list, description="List of unique tool names used by this agent"
    )
    total_llm_calls: int = Field(
        default=0, description="Total number of LLM calls by this agent"
    )
    total_tool_calls: int = Field(
        default=0, description="Total number of tool calls by this agent"
    )
    llm_calls_failed: int = Field(default=0, description="Number of failed LLM calls")
    tool_calls_failed: int = Field(default=0, description="Number of failed tool calls")
    total_tools_duration: float = Field(
        default=0.0, description="Total duration of tool calls in milliseconds"
    )
    total_llm_duration: float = Field(
        default=0.0, description="Total duration of LLM calls in milliseconds"
    )
    llm_input_tokens: int = Field(
        default=0, description="Total input tokens used by LLM calls"
    )
    llm_output_tokens: int = Field(
        default=0, description="Total output tokens generated by LLM calls"
    )
    llm_total_tokens: int = Field(
        default=0, description="Total tokens (input + output) used by LLM calls"
    )
    tool_total_tokens: int = Field(
        default=0, description="Total tokens used by tools under this agent"
    )
    duration: float = Field(
        default=0.0,
        description="Total duration of the agent's activity in milliseconds",
    )
    completion: bool = Field(
        default=True, description="Whether the agent completed its task"
    )


class ConversationElement(BaseModel):
    """Represents a single turn in a conversation."""

    role: str
    content: str


class ToolCall(BaseModel):
    """Represents a tool call with all necessary information."""

    name: str
    description: str
    input_parameters: Dict[str, Any]
    output: Dict[str, Any]


class SessionEntity(BaseModel):
    """
    Pure data model for session-level entity.
    Contains only the fields that are actually used by metrics.
    """

    # Core session metadata
    session_id: str
    # all the session spans ordered by timestamp (from older to newer)
    spans: List[SpanEntity]

    # Timing information
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    duration: Optional[float] = None  # Duration in milliseconds

    # Private field for optimized entity access (built lazily)
    # Previously: duplication of spans filtered by entity type and one field per type
    # Now: single source of truth (spans) + indices for fast filtering
    _entity_indices: Optional[Dict[str, List[int]]] = PrivateAttr(default=None)

    # Data extracted by transformers (used by metrics)
    conversation_data: Optional[Dict[str, Any]] = None
    workflow_data: Optional[Dict[str, Any]] = None

    # Graph-related attributes extracted from graph entity spans
    graph_determinism: Optional[float] = None
    graph_dynamism: Optional[Any] = None
    graph: Optional[Any] = None

    agent_id: Optional[str] = None
    # Hierarchical execution tree showing parent-child relationships
    execution_tree: Optional[Any] = None
    hierarchy_summary: Optional[Dict[str, Any]] = None

    # Agent interaction data (needed by AgentToAgentInteractions)
    agent_transitions: Optional[List[str]] = None
    agent_transition_counts: Optional[Counter] = None

    # Cache for agent-specific conversation data (shared across all metrics)
    _agent_conversation_cache: Optional[Dict[str, Dict[str, Any]]] = PrivateAttr(
        default=None
    )

    conversation_elements: Optional[List[ConversationElement]] = None

    tool_calls: Optional[List[ToolCall]] = None

    input_query: Optional[str] = None
    final_response: Optional[str] = None

    def _build_entity_indices(self) -> None:
        """Build indices for efficient entity type filtering."""
        # Only build indices if they haven't been built yet
        if self._entity_indices is not None:
            return

        self._entity_indices = defaultdict(list)
        for i, span in enumerate(self.spans):
            self._entity_indices[span.entity_type].append(i)

    @property
    def agent_spans(self) -> List[SpanEntity]:
        """Get agent spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("agent", [])]

    @property
    def workflow_spans(self) -> List[SpanEntity]:
        """Get workflow spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("workflow", [])]

    @property
    def tool_spans(self) -> List[SpanEntity]:
        """Get tool spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("tool", [])]

    @property
    def llm_spans(self) -> List[SpanEntity]:
        """Get LLM spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("llm", [])]

    @property
    def graph_spans(self) -> List[SpanEntity]:
        """Get graph spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("graph", [])]

    @property
    def task_spans(self) -> List[SpanEntity]:
        """Get task spans efficiently using indices."""
        if self._entity_indices is None:
            self._build_entity_indices()
        return [self.spans[i] for i in self._entity_indices.get("task", [])]

    @property
    def time_range(self) -> str:
        """Get the time range of the session."""
        if self.start_time and self.end_time:
            return f"{self.start_time} - {self.end_time}"
        return "Unknown"

    @property
    def total_spans(self) -> int:
        """Get the total number of spans in the session."""
        return len(self.spans)

    @property
    def all_spans(self) -> List[SpanEntity]:
        """Get all spans in the session (alias for spans)."""
        return self.spans

    @property
    def app_name(self) -> str:
        """
        Extract the application name from session spans.

        Looks for common attributes that might contain the app name.
        Returns a default value if not found.
        """
        # Check for common app name attributes in spans
        for span in self.spans:
            # First, check raw span data for application_id in SpanAttributes
            if span.raw_span_data and span.raw_span_data.get("SpanAttributes"):
                attrs = span.raw_span_data["SpanAttributes"]
                app_id = attrs.get("application_id")
                if app_id:
                    return str(app_id).lower()
            # Second, check raw span data for ServiceName
            if span.raw_span_data and span.raw_span_data.get("ServiceName"):
                service_name = str(span.raw_span_data["ServiceName"])
                if service_name and service_name != "unknown":
                    return service_name

            # Then check ResourceAttributes for service.name
            if span.raw_span_data and span.raw_span_data.get("ResourceAttributes"):
                resource_attrs = span.raw_span_data["ResourceAttributes"]
                if isinstance(resource_attrs, dict) and resource_attrs.get(
                    "service.name"
                ):
                    service_name = str(resource_attrs["service.name"])
                    if service_name and service_name != "unknown":
                        return service_name

            # Check span attributes for app name patterns
            if span.attrs:
                # Common patterns for app names
                for attr_key in [
                    "app.name",
                    "service.name",
                    "application.name",
                    "traceloop.workflow.name",
                ]:
                    if span.attrs.get(attr_key):
                        return str(span.attrs[attr_key])

                # Check for workflow names that might indicate app
                workflow_name = span.attrs.get("ioa_workflow.name")
                if workflow_name:
                    return str(workflow_name)

                # Check for agent names as fallback
                if span.entity_type == "agent" and span.entity_name:
                    return str(span.entity_name)

        # Default fallback
        return "unknown-app"

    # Statistics and utility methods

    @property
    def unique_tool_names(self) -> List[str]:
        """Get the list of unique tool names used in the session."""
        tool_names = set()
        for span in self.tool_spans:
            if span.entity_name:
                tool_names.add(span.entity_name)
        return sorted(list(tool_names))

    @property
    def unique_agent_names(self) -> List[str]:
        """Get the list of unique agent names used in the session."""
        agent_names = set()
        for span in self.agent_spans:
            if span.entity_name:
                agent_names.add(span.entity_name)
        return sorted(list(agent_names))

    @property
    def total_llm_calls(self) -> int:
        """Get the total number of LLM calls in the session."""
        return len(self.llm_spans)

    @property
    def total_tool_calls(self) -> int:
        """Get the total number of tool calls in the session."""
        return len(self.tool_spans)

    @property
    def llm_calls_failed(self) -> int:
        """Get the number of failed LLM calls in the session."""
        return sum(1 for span in self.llm_spans if span.contains_error)

    @property
    def tool_calls_failed(self) -> int:
        """Get the number of failed tool calls in the session."""
        return sum(1 for span in self.tool_spans if span.contains_error)

    @property
    def total_tools_duration(self) -> float:
        """Get the total duration of all tool calls in milliseconds."""
        return sum(
            span.duration for span in self.tool_spans if span.duration is not None
        )

    @property
    def total_llm_duration(self) -> float:
        """Get the total duration of all LLM calls in milliseconds."""
        return sum(
            span.duration for span in self.llm_spans if span.duration is not None
        )

    @property
    def llm_input_tokens(self) -> int:
        """Get the total number of input tokens used by all LLM calls."""
        total = 0
        for span in self.llm_spans:
            if span.attrs and span.attrs.get("input_tokens") is not None:
                try:
                    total += int(span.attrs["input_tokens"])
                except (ValueError, TypeError):
                    pass
        return total

    @property
    def llm_output_tokens(self) -> int:
        """Get the total number of output tokens generated by all LLM calls."""
        total = 0
        for span in self.llm_spans:
            if span.attrs and span.attrs.get("output_tokens") is not None:
                try:
                    total += int(span.attrs["output_tokens"])
                except (ValueError, TypeError):
                    pass
        return total

    @property
    def llm_total_tokens(self) -> int:
        """Get the total number of tokens (input + output) used by all LLM calls."""
        total = 0
        for span in self.llm_spans:
            if span.attrs and span.attrs.get("total_tokens") is not None:
                try:
                    total += int(span.attrs["total_tokens"])
                except (ValueError, TypeError):
                    pass
        return total

    @property
    def tool_total_tokens(self) -> int:
        """
        Get the total LLM tokens used by all tools by analyzing the execution tree.

        This method traverses the execution tree to identify LLM calls that are
        descendants of tool spans and aggregates their token usage.

        Returns:
            Total sum of LLM tokens consumed by all tools
        """
        if not self.execution_tree:
            return 0

        tool_tokens = {}

        # Find all tool nodes in the execution tree
        for trace_roots in self.execution_tree.traces.values():
            for root in trace_roots:
                self._collect_tool_llm_tokens(root, tool_tokens)

        # Sum all token values, handling None and -1 values
        total = 0
        for tokens in tool_tokens.values():
            if tokens is not None and tokens >= 0:
                total += tokens

        return total

    @property
    def completion(self) -> bool:
        """Determine if the session completed successfully based on LLM and tool calls."""
        # A session is considered complete if the agents composing the session completed
        # TODO: should use the span status of the global session if available
        for agent, stats in self.agent_stats.items():
            if not stats.completion:
                return False
        return True

    def _collect_tool_llm_tokens(self, node, tool_tokens: Dict[str, int]) -> None:
        """
        Recursively traverse the execution tree to collect LLM tokens used by tools.

        Args:
            node: Current SpanNode being processed
            tool_tokens: Dictionary to accumulate token counts per tool
        """
        # If this is a tool node, collect LLM tokens from all descendants
        if node.span.entity_type == "tool":
            tool_name = node.span.entity_name
            if tool_name not in tool_tokens:
                tool_tokens[tool_name] = 0

            # Collect tokens from all LLM descendants
            llm_tokens = self._get_descendant_llm_tokens(node)
            tool_tokens[tool_name] += llm_tokens

        # Continue traversing children
        for child in node.children:
            self._collect_tool_llm_tokens(child, tool_tokens)

    def _get_descendant_llm_tokens(self, node) -> int:
        """
        Get total LLM tokens from all descendant nodes.

        Args:
            node: SpanNode to start traversal from

        Returns:
            Total tokens from all LLM descendants
        """
        total_tokens = 0

        # If this node is an LLM, add its tokens
        if node.span.entity_type == "llm":
            if node.span.attrs and node.span.attrs.get("total_tokens") is not None:
                try:
                    token_value = int(node.span.attrs["total_tokens"])
                    # Only add positive values, skip None and -1
                    if token_value >= 0:
                        total_tokens += token_value
                except (ValueError, TypeError):
                    # Skip invalid token values
                    pass

        # Recursively check all children
        for child in node.children:
            total_tokens += self._get_descendant_llm_tokens(child)

        return total_tokens

    @property
    def agent_stats(self) -> Dict[str, AgentStats]:
        """
        Get comprehensive statistics for each agent in the session.

        This method analyzes the execution tree to identify spans that belong to each agent
        and calculates the same statistics as the session-level methods.

        Returns:
            Dict mapping agent names to their AgentStats containing:
            - unique_tool_names: List[str] - Tools used by this agent
            - total_llm_calls: int - Number of LLM calls by this agent
            - total_tool_calls: int - Number of tool calls by this agent
            - llm_calls_failed: int - Number of failed LLM calls
            - tool_calls_failed: int - Number of failed tool calls
            - total_tools_duration: float - Total duration of tool calls (ms)
            - total_llm_duration: float - Total duration of LLM calls (ms)
            - llm_input_tokens: int - Total input tokens
            - llm_output_tokens: int - Total output tokens
            - llm_total_tokens: int - Total tokens (input + output)
            - tool_total_tokens: int - Total tokens used by tools under this agent
        """
        if not self.execution_tree:
            return {}

        agent_stats = {}

        # Use single-pass direct span analysis for accurate attribution
        # This approach processes each span exactly once, avoiding double-counting
        agent_span_groups = {}

        # Group spans by identified agent
        for span in self.spans:
            agent_name = self._identify_span_agent(span)
            if agent_name:
                if agent_name not in agent_span_groups:
                    agent_span_groups[agent_name] = []
                agent_span_groups[agent_name].append(span)

        # Calculate stats for each agent
        for agent_name, spans in agent_span_groups.items():
            agent_stats[agent_name] = AgentStats()
            self._calculate_agent_stats(agent_stats[agent_name], spans)

        return agent_stats

    # TODO this is not used anymore, can be removed later
    def _collect_agent_stats(self, node, agent_stats: Dict[str, AgentStats]) -> None:
        """
        Collect statistics for each agent using attribute-first identification.

        This enhanced version prioritizes agent_id attributes over hierarchy,
        ensuring accurate attribution across different trace structures.

        Args:
            node: Current SpanNode being processed
            agent_stats: Dictionary to accumulate statistics per agent
        """
        # Use unified agent identification for current span
        agent_name = self._identify_span_agent(node.span)

        if agent_name:
            # Initialize agent stats if not exists
            if agent_name not in agent_stats:
                agent_stats[agent_name] = AgentStats()

            # For agent spans, collect descendant spans
            if node.span.entity_type in ["agent", "task"]:
                descendant_spans = self._get_descendant_spans(node)
                self._calculate_agent_stats(agent_stats[agent_name], descendant_spans)
                agent_stats[agent_name].duration += (
                    node.span.duration if node.span.duration else 0.0
                )
            else:
                # For individual spans (like tools), count them directly
                self._calculate_agent_stats(agent_stats[agent_name], [node.span])
                agent_stats[agent_name].duration += (
                    node.span.duration if node.span.duration else 0.0
                )

        # Continue traversing children
        for child in node.children:
            self._collect_agent_stats(child, agent_stats)

    def _collect_direct_agent_spans(self, agent_stats: Dict[str, AgentStats]) -> None:
        """
        Scan all spans directly to catch any with agent_id that might be missed
        by tree traversal (e.g., spans in separate traces).

        Args:
            agent_stats: Dictionary to accumulate additional statistics per agent
        """
        # Group spans by agent_id to avoid duplicate counting
        agent_span_groups = {}

        for span in self.spans:
            agent_name = self._identify_span_agent(span)
            if agent_name:
                if agent_name not in agent_span_groups:
                    agent_span_groups[agent_name] = []
                agent_span_groups[agent_name].append(span)

        # Process each agent's spans
        for agent_name, spans in agent_span_groups.items():
            if agent_name not in agent_stats:
                agent_stats[agent_name] = AgentStats()

            # Use set to avoid double-counting spans already processed in tree traversal
            # We'll calculate stats additively and let the calculate method handle deduplication
            self._calculate_agent_stats_additive(agent_stats[agent_name], spans)

    def _calculate_agent_stats_additive(
        self, stats: AgentStats, spans: List[SpanEntity]
    ) -> None:
        """
        Calculate agent statistics additively, avoiding double-counting.
        This is a helper for direct span collection that ensures we don't
        double-count spans already processed in tree traversal.

        Args:
            stats: AgentStats object to update
            spans: List of spans belonging to the agent
        """
        # Track which spans we've seen to avoid double counting
        # For now, we'll use a simple approach - the _calculate_agent_stats method
        # should handle the core logic, this is just to ensure we catch missed spans

        # Create a temporary stats object to calculate new contributions
        temp_stats = AgentStats()
        self._calculate_agent_stats(temp_stats, spans)

        # Merge with existing stats (taking the maximum to avoid double-counting)
        # This is a simplified approach - in practice, you might want more sophisticated merging
        stats.total_tool_calls = max(
            stats.total_tool_calls, temp_stats.total_tool_calls
        )
        stats.total_llm_calls = max(stats.total_llm_calls, temp_stats.total_llm_calls)
        stats.tool_calls_failed = max(
            stats.tool_calls_failed, temp_stats.tool_calls_failed
        )
        stats.llm_calls_failed = max(
            stats.llm_calls_failed, temp_stats.llm_calls_failed
        )

        # For durations and tokens, take the maximum as well to avoid double-counting
        stats.total_tools_duration = max(
            stats.total_tools_duration, temp_stats.total_tools_duration
        )
        stats.total_llm_duration = max(
            stats.total_llm_duration, temp_stats.total_llm_duration
        )
        stats.llm_input_tokens = max(
            stats.llm_input_tokens, temp_stats.llm_input_tokens
        )
        stats.llm_output_tokens = max(
            stats.llm_output_tokens, temp_stats.llm_output_tokens
        )
        stats.llm_total_tokens = max(
            stats.llm_total_tokens, temp_stats.llm_total_tokens
        )
        stats.tool_total_tokens = max(
            stats.tool_total_tokens, temp_stats.tool_total_tokens
        )

        # For unique tool names, merge the lists
        stats.unique_tool_names = list(
            set(stats.unique_tool_names + temp_stats.unique_tool_names)
        )

    def _identify_span_agent(self, span) -> Optional[str]:
        """
        Unified agent identification method that prioritizes agent_id attribute.

        This method replaces hierarchy-based logic with attribute-first identification
        to ensure spans with explicit agent_id are correctly attributed regardless
        of their position in the execution tree.

        Strategy priority:
        1. agent_id attribute from attrs/raw_span_data (most reliable)
        2. Entity path analysis (for agent-like paths)
        3. Entity name patterns (fallback)

        Args:
            span: SpanEntity to identify agent for

        Returns:
            Agent name if found, None otherwise
        """
        if not span:
            return None

        # Strategy 1: Direct agent_id attribute (highest priority)
        # Check in attrs first
        if hasattr(span, "attrs") and span.attrs:
            agent_id = span.attrs.get("agent_id")
            if agent_id and isinstance(agent_id, str) and agent_id.strip():
                return agent_id.strip()

        # Check in raw_span_data as fallback
        if hasattr(span, "raw_span_data") and span.raw_span_data:
            span_attrs = span.raw_span_data.get("SpanAttributes", {})
            agent_id = span_attrs.get("agent_id")
            if agent_id and isinstance(agent_id, str) and agent_id.strip():
                return agent_id.strip()

            # Strategy 2: Entity path analysis (medium priority)
            entity_path = span_attrs.get("traceloop.entity.path")
            if entity_path and isinstance(entity_path, str) and "." in entity_path:
                potential_agent = entity_path.split(".")[0]
                # Only use if it looks like an agent name
                if (
                    "agent" in potential_agent.lower()
                    and potential_agent.lower() != "agent"
                    and len(potential_agent) > 5
                ):  # Avoid too generic names
                    return potential_agent

        # Strategy 3: Entity name patterns (lowest priority)
        entity_name = getattr(span, "entity_name", None)
        if entity_name and isinstance(entity_name, str):
            # Remove common suffixes
            base_name = entity_name.replace(".task", "").replace(".agent", "")

            # Check for agent-like patterns - be more restrictive to avoid false positives
            # Only match if "agent" appears as a separate word or at the end
            lower_name = base_name.lower()
            if (
                lower_name != "agent"
                and len(base_name) > 5
                and
                # More precise agent pattern matching
                (
                    lower_name.endswith("_agent")
                    or lower_name.endswith("-agent")
                    or lower_name.startswith("agent_")
                    or lower_name.startswith("agent-")
                    or "_agent_" in lower_name
                    or "-agent-" in lower_name
                )
                and
                # Exclude common false positives
                not any(
                    word in lower_name
                    for word in ["graph", "workflow", "multi_agent_graph", "service"]
                )
            ):
                return base_name

        return None

    def _extract_agent_from_task(self, span) -> Optional[str]:
        """
        Extract agent name from task span using attributes or name patterns.

        Examples:
        - span with agent_id="documentation_agent" -> "documentation_agent"
        - span with entity_name="documentation_agent.task" -> "documentation_agent"
        - span with entity_name="website_selector_agent" -> "website_selector_agent"
        - span with entity_name="LangGraph" -> None (not an agent task)

        Args:
            span: SpanEntity object

        Returns:
            Agent name if this is an agent task, None otherwise
        """
        # Strategy 1: Use agent_id attribute (most reliable)
        if (
            hasattr(span, "attributes")
            and span.attributes
            and "agent_id" in span.attributes
        ):
            return span.attributes["agent_id"]

        # Strategy 2: Extract from entity path (only if it looks like an agent)
        if (
            hasattr(span, "attributes")
            and span.attributes
            and "traceloop.entity.path" in span.attributes
        ):
            path = span.attributes["traceloop.entity.path"]
            if isinstance(path, str) and "." in path:
                potential_agent = path.split(".")[0]
                # Only use path if it looks like an agent name
                if (
                    "agent" in potential_agent.lower()
                    and potential_agent.lower() != "agent"
                ):
                    return potential_agent

        # Strategy 3: Extract from span name/entity_name (fallback)
        task_name = span.entity_name if hasattr(span, "entity_name") else None
        if not task_name:
            return None

        # Remove .task suffix if present
        base_name = (
            task_name.replace(".task", "") if task_name.endswith(".task") else task_name
        )

        # Skip generic "agent" - it's not specific enough
        if base_name.lower() == "agent":
            return None

        # Check if this looks like an agent name (but not just "agent")
        if (
            "agent" in base_name.lower() and len(base_name) > 5
        ):  # More than just "agent"
            return base_name

        # Check against known agent names from direct agent spans
        known_agents = {span.entity_name for span in self.agent_spans}
        if base_name in known_agents:
            return base_name

        return None

    def _get_descendant_spans(self, node) -> List[SpanEntity]:
        """
        Get all descendant spans from a given node.

        Args:
            node: SpanNode to start traversal from

        Returns:
            List of all descendant SpanEntity objects
        """
        spans = []

        # Add current span
        spans.append(node.span)

        # Recursively collect all children
        for child in node.children:
            spans.extend(self._get_descendant_spans(child))

        return spans

    def _calculate_agent_stats(
        self, stats: AgentStats, spans: List[SpanEntity]
    ) -> None:
        """
        Calculate statistics for an agent from its descendant spans.

        Args:
            stats: AgentStats object to update
            spans: List of spans belonging to this agent
        """
        # Use a set to collect unique tool names, then convert to sorted list at the end
        unique_tools = set(stats.unique_tool_names)

        for span in spans:
            if span.entity_type == "agent":
                stats.duration += span.duration if span.duration else 0.0
            # Tool statistics
            if span.entity_type == "tool":
                stats.total_tool_calls += 1
                if span.contains_error:
                    stats.tool_calls_failed += 1
                if span.entity_name:
                    unique_tools.add(span.entity_name)
                if span.duration is not None:
                    stats.total_tools_duration += span.duration

            # LLM statistics
            elif span.entity_type == "llm":
                stats.total_llm_calls += 1
                if span.contains_error:
                    stats.llm_calls_failed += 1
                if span.duration is not None:
                    stats.total_llm_duration += span.duration

                # Token statistics
                if span.attrs:
                    # Input tokens
                    if span.attrs.get("input_tokens") is not None:
                        try:
                            token_value = int(span.attrs["input_tokens"])
                            if token_value >= 0:
                                stats.llm_input_tokens += token_value
                        except (ValueError, TypeError):
                            pass

                    # Output tokens
                    if span.attrs.get("output_tokens") is not None:
                        try:
                            token_value = int(span.attrs["output_tokens"])
                            if token_value >= 0:
                                stats.llm_output_tokens += token_value
                        except (ValueError, TypeError):
                            pass

                    # Total tokens
                    if span.attrs.get("total_tokens") is not None:
                        try:
                            token_value = int(span.attrs["total_tokens"])
                            if token_value >= 0:
                                stats.llm_total_tokens += token_value
                        except (ValueError, TypeError):
                            pass

        # Update unique tool names as sorted list
        stats.unique_tool_names = sorted(list(unique_tools))

        # Update completion status
        # For now it is based solely on whether there were any failed LLM or Tool calls
        # TODO: we should check with the agent span status directly, if present
        # And also make sure that the last LLM call was successful
        stats.completion = True
        stats.completion = stats.completion and (
            stats.total_llm_calls == 0 or stats.llm_calls_failed < stats.total_llm_calls
        )
        stats.completion = stats.completion and (
            stats.total_tool_calls == 0
            or stats.tool_calls_failed < stats.total_tool_calls
        )

    def get_agent_view(self, agent_name: str) -> "AgentView":
        """
        Get a cached view of spans for a specific agent.

        This method creates and caches AgentView instances for efficient
        agent-level metric computation. The view pre-computes span collections
        to avoid repeated filtering operations.

        Args:
            agent_name: Name of the agent to get view for

        Returns:
            AgentView instance with pre-computed span collections
        """
        if not hasattr(self, "_agent_views"):
            self._agent_views = {}

        if agent_name not in self._agent_views:
            self._agent_views[agent_name] = AgentView(agent_name, self)

        return self._agent_views[agent_name]

    def _get_spans_for_agent(self, agent_name: str) -> List[SpanEntity]:
        """
        Extract all spans belonging to a specific agent using attribute-first identification.

        This method uses both tree traversal and direct span scanning to ensure
        all spans with agent_id attributes are captured, regardless of trace structure.

        Args:
            agent_name: Name of the agent to get spans for

        Returns:
            List of spans belonging to the specified agent
        """
        agent_spans = []

        # Approach 1: Tree traversal (for hierarchical relationships)
        if self.execution_tree:
            for trace_roots in self.execution_tree.traces.values():
                for root in trace_roots:
                    self._collect_spans_for_agent(root, agent_name, agent_spans)

        # Approach 2: Direct span scan (to catch spans missed by tree traversal)
        # This ensures spans with agent_id but in separate traces are included
        for span in self.spans:
            identified_agent = self._identify_span_agent(span)
            if identified_agent == agent_name and span not in agent_spans:
                agent_spans.append(span)

        return agent_spans

    def _collect_spans_for_agent(
        self, node, target_agent_name: str, agent_spans: List[SpanEntity]
    ) -> None:
        """
        Recursively traverse the execution tree to collect spans for a specific agent.

        Args:
            node: Current SpanNode being processed
            target_agent_name: Name of the agent we're collecting spans for
            agent_spans: List to accumulate spans for the target agent
        """
        # Use unified agent identification
        identified_agent = self._identify_span_agent(node.span)

        if identified_agent == target_agent_name:
            # If this is an agent/task span, collect descendants
            if node.span.entity_type in ["agent", "task"]:
                descendant_spans = self._get_descendant_spans(node)
                agent_spans.extend(descendant_spans)
                return  # Don't traverse children as they're already collected
            else:
                # For individual spans (like tools), add them directly
                if node.span not in agent_spans:
                    agent_spans.append(node.span)

        # Continue traversing children if this node doesn't match
        for child in node.children:
            self._collect_spans_for_agent(child, target_agent_name, agent_spans)

    def get_agent_conversation_data(self, agent_name: str) -> Dict[str, Any]:
        """
        Get agent-specific conversation data with session-level caching.

        This method caches conversation data at the SessionEntity level so that
        multiple metrics can reuse the same agent conversation without recomputation.

        Args:
            agent_name: Name of the agent to get conversation data for

        Returns:
            Dictionary containing agent conversation elements and metadata
        """
        # Initialize cache if needed
        if self._agent_conversation_cache is None:
            self._agent_conversation_cache = {}

        # Return cached data if available
        if agent_name in self._agent_conversation_cache:
            return self._agent_conversation_cache[agent_name]

        # Build agent conversation data using existing patterns
        conversation_elements = []
        tool_calls = []

        # Get all spans for this agent (uses existing hierarchical collection)
        agent_spans = self._get_spans_for_agent(agent_name)

        # Process LLM spans (reuse ConversationDataTransformer logic)
        llm_spans = [s for s in agent_spans if s.entity_type == "llm"]
        for span in llm_spans:
            if span.input_payload:
                for key, value in span.input_payload.items():
                    if key.startswith("gen_ai.prompt") and ".content" in key:
                        role_key = key.replace(".content", ".role")
                        role = span.input_payload.get(role_key, "unknown")
                        conversation_elements.append(
                            {
                                "role": role,
                                "content": value,
                                "span_id": span.span_id,
                                "timestamp": span.timestamp,
                                "agent_name": agent_name,
                            }
                        )

            if span.output_payload:
                for key, value in span.output_payload.items():
                    if key.startswith("gen_ai.completion") and ".content" in key:
                        role_key = key.replace(".content", ".role")
                        role = span.output_payload.get(role_key, "assistant")
                        conversation_elements.append(
                            {
                                "role": role,
                                "content": value,
                                "span_id": span.span_id,
                                "timestamp": span.timestamp,
                                "agent_name": agent_name,
                            }
                        )

                    # Extract tool calls
                    if key.startswith("gen_ai.completion") and ".tool_calls" in key:
                        if isinstance(value, dict) or (
                            isinstance(value, str) and value.startswith("{")
                        ):
                            try:
                                import json

                                tool_call_data = (
                                    json.loads(value)
                                    if isinstance(value, str)
                                    else value
                                )
                                tool_calls.append(
                                    {
                                        "data": tool_call_data,
                                        "span_id": span.span_id,
                                        "timestamp": span.timestamp,
                                        "agent_name": agent_name,
                                    }
                                )
                            except (KeyError, AttributeError, TypeError):
                                pass

        # Process agent spans
        agent_entity_spans = [s for s in agent_spans if s.entity_type == "agent"]
        for span in agent_entity_spans:
            if span.input_payload and "value" in span.input_payload:
                conversation_elements.append(
                    {
                        "role": "user",
                        "content": span.input_payload["value"],
                        "span_id": span.span_id,
                        "timestamp": span.timestamp,
                        "agent_name": agent_name,
                    }
                )

            if span.output_payload and "value" in span.output_payload:
                conversation_elements.append(
                    {
                        "role": "assistant",
                        "content": span.output_payload["value"],
                        "span_id": span.span_id,
                        "timestamp": span.timestamp,
                        "agent_name": agent_name,
                    }
                )

        # Include tool interactions for complete context
        tool_spans = [s for s in agent_spans if s.entity_type == "tool"]
        for span in tool_spans:
            if span.input_payload:
                conversation_elements.append(
                    {
                        "role": "tool_input",
                        "content": f"Tool call to {span.entity_name}: {span.input_payload}",
                        "span_id": span.span_id,
                        "timestamp": span.timestamp,
                        "agent_name": agent_name,
                    }
                )

            if span.output_payload:
                conversation_elements.append(
                    {
                        "role": "tool_output",
                        "content": f"Tool {span.entity_name} result: {span.output_payload}",
                        "span_id": span.span_id,
                        "timestamp": span.timestamp,
                        "agent_name": agent_name,
                    }
                )

        # Sort by timestamp
        conversation_elements.sort(key=lambda x: x.get("timestamp", ""))

        # Cache the result
        agent_conversation_data = {
            "elements": conversation_elements,
            "tool_calls": tool_calls,
            "total_elements": len(conversation_elements),
            "total_tool_calls": len(tool_calls),
        }

        self._agent_conversation_cache[agent_name] = agent_conversation_data
        return agent_conversation_data

    def get_agent_conversation_text(self, agent_name: str) -> str:
        """
        Get formatted agent conversation text for metric evaluation.

        Args:
            agent_name: Name of the agent

        Returns:
            Formatted conversation text suitable for LLM evaluation
        """
        conversation_data = self.get_agent_conversation_data(agent_name)
        elements = conversation_data.get("elements", [])

        if not elements:
            return ""

        conversation_lines = []
        for element in elements:
            role = element.get("role", "unknown")
            content = element.get("content", "")

            if role == "user":
                conversation_lines.append(f"User: {content}")
            elif role == "assistant":
                conversation_lines.append(f"Assistant: {content}")
            elif role == "system":
                conversation_lines.append(f"System: {content}")
            elif role == "tool_input":
                conversation_lines.append(f"[{content}]")
            elif role == "tool_output":
                conversation_lines.append(f"[{content}]")

        return "\n".join(conversation_lines)


class AgentView:
    """
    Cached view of agent-specific spans and data for efficient metric computation.

    This class pre-computes and caches span collections for a specific agent,
    avoiding repeated filtering operations during metric computation.
    """

    def __init__(self, agent_name: str, session: "SessionEntity"):
        """
        Initialize AgentView with pre-computed span collections.

        Args:
            agent_name: Name of the agent this view represents
            session: SessionEntity containing the agent data
        """
        self.agent_name = agent_name
        self.session = session
        self.stats = session.agent_stats.get(agent_name, AgentStats())

        # Pre-compute and cache span collections
        agent_spans = session._get_spans_for_agent(agent_name)
        self.all_spans = agent_spans

        # Filter spans by entity type for efficient access
        self.tool_spans = [s for s in agent_spans if s.entity_type == "tool"]
        self.llm_spans = [s for s in agent_spans if s.entity_type == "llm"]
        self.workflow_spans = [s for s in agent_spans if s.entity_type == "workflow"]
        self.task_spans = [s for s in agent_spans if s.entity_type == "task"]

        # Pre-compute commonly needed filtered collections
        self._error_tool_spans = None
        self._successful_tool_spans = None

    @property
    def error_tool_spans(self) -> List[SpanEntity]:
        """Get tool spans with errors for this agent."""
        if self._error_tool_spans is None:
            self._error_tool_spans = [
                span for span in self.tool_spans if span.contains_error
            ]
        return self._error_tool_spans

    @property
    def successful_tool_spans(self) -> List[SpanEntity]:
        """Get successful tool spans (no errors) for this agent."""
        if self._successful_tool_spans is None:
            self._successful_tool_spans = [
                span for span in self.tool_spans if not span.contains_error
            ]
        return self._successful_tool_spans

    @property
    def total_tool_calls(self) -> int:
        """Get total number of tool calls by this agent."""
        return len(self.tool_spans)

    @property
    def total_tool_errors(self) -> int:
        """Get total number of tool errors by this agent."""
        return len(self.error_tool_spans)

    @property
    def tool_error_rate(self) -> float:
        """Calculate tool error rate percentage for this agent."""
        if self.total_tool_calls == 0:
            return 0.0
        return (self.total_tool_errors / self.total_tool_calls) * 100.0

    @property
    def unique_tool_names(self) -> List[str]:
        """Get list of unique tool names used by this agent."""
        tool_names = set()
        for span in self.tool_spans:
            if span.entity_name:
                tool_names.add(span.entity_name)
        return sorted(list(tool_names))

    @property
    def input_query(self) -> Optional[str]:
        """
        Extract the first user input query for this agent from LLM spans.

        Returns:
            The first user query content, or None if not found
        """
        from .conversation_utils import extract_conversation_endpoints

        input_query, _ = extract_conversation_endpoints(
            self.llm_spans,
            min_content_length=3,  # AgentView's current threshold
            support_prompt_format_in_output=True,  # AgentView supports both formats
        )
        return input_query

    @property
    def final_response(self) -> Optional[str]:
        """
        Extract the last meaningful response for this agent from LLM spans.

        Returns:
            The final response content, or None if not found
        """
        from .conversation_utils import extract_conversation_endpoints

        _, final_response = extract_conversation_endpoints(
            self.llm_spans,
            min_content_length=3,  # AgentView's current threshold
            support_prompt_format_in_output=True,  # AgentView supports both formats
        )
        return final_response
