{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example 5: File Logging - Persistent Storage\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "This notebook demonstrates file logging for persistent storage:\n",
        "\n",
        "- **FileHandler** - Write logs to files\n",
        "- **File_ServiceConfig** - Configure file output\n",
        "- **Multiple Formats** - JSON, Text, and CSV\n",
        "- **Append vs Overwrite** - File writing modes\n",
        "- **Real-World Examples** - Production logging scenarios\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup - Imports and Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n",
            "Logs will be written to: example_logs/\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import os\n",
        "from dc_logger.client.Log import LogEntry, LogLevel\n",
        "from dc_logger.client.base import Logger, HandlerInstance, Handler_BufferSettings\n",
        "from dc_logger.logs.services.file import FileHandler, File_ServiceConfig\n",
        "\n",
        "# Create logs directory\n",
        "os.makedirs(\"example_logs\", exist_ok=True)\n",
        "\n",
        "print(\"All imports successful!\")\n",
        "print(\"Logs will be written to: example_logs/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: JSON File Logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "JSON File Logging\n",
            "======================================================================\n",
            "\n",
            "Writing JSON logs...\n",
            "JSON logs written successfully!\n",
            "Check file: example_logs/app.json\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"JSON File Logging\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create JSON file handler\n",
        "json_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/app.json\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"json\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "buffer_settings = Handler_BufferSettings()\n",
        "json_file_handler = FileHandler(\n",
        "    buffer_settings=buffer_settings,\n",
        "    service_config=json_config\n",
        ")\n",
        "\n",
        "# Create handler instance\n",
        "json_handler_instance = HandlerInstance(\n",
        "    service_handler=json_file_handler,\n",
        "    handler_name=\"json_file\"\n",
        ")\n",
        "\n",
        "# Create logger with JSON file handler\n",
        "json_logger = Logger(\n",
        "    app_name=\"json_file_demo\",\n",
        "    handlers=[json_handler_instance]\n",
        ")\n",
        "\n",
        "# Log several entries\n",
        "print(\"\\nWriting JSON logs...\")\n",
        "await json_logger.info(\"Application started\")\n",
        "await json_logger.info(\n",
        "    \"User logged in\",\n",
        "    user_id=\"user_alice\",\n",
        "    tenant_id=\"tenant_acme\"\n",
        ")\n",
        "await json_logger.info(\n",
        "    \"Dataset processed\",\n",
        "    entity={\"type\": \"dataset\", \"id\": \"ds_sales\", \"name\": \"Sales Data\"},\n",
        "    duration_ms=1234,\n",
        "    extra={\"rows\": 5000}\n",
        ")\n",
        "\n",
        "print(\"JSON logs written successfully!\")\n",
        "print(f\"Check file: {json_config.destination}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Text File Logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Text File Logging\n",
            "======================================================================\n",
            "\n",
            "Writing text logs...\n",
            "Text logs written successfully!\n",
            "Check file: example_logs/app.log\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Text File Logging\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create text file handler\n",
        "text_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/app.log\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"text\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "text_buffer_settings = Handler_BufferSettings()\n",
        "text_file_handler = FileHandler(\n",
        "    buffer_settings=text_buffer_settings,\n",
        "    service_config=text_config\n",
        ")\n",
        "\n",
        "text_handler_instance = HandlerInstance(\n",
        "    service_handler=text_file_handler,\n",
        "    handler_name=\"text_file\"\n",
        ")\n",
        "\n",
        "text_logger = Logger(\n",
        "    app_name=\"text_file_demo\",\n",
        "    handlers=[text_handler_instance]\n",
        ")\n",
        "\n",
        "# Log different levels\n",
        "print(\"\\nWriting text logs...\")\n",
        "await text_logger.debug(\"Checking configuration\")\n",
        "await text_logger.info(\"Service initialized\")\n",
        "await text_logger.warning(\"Cache size approaching limit\")\n",
        "await text_logger.error(\"Failed to connect to database\")\n",
        "\n",
        "print(\"Text logs written successfully!\")\n",
        "print(f\"Check file: {text_config.destination}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 3: CSV File Logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CSV File Logging\n",
            "======================================================================\n",
            "\n",
            "Writing CSV logs...\n",
            "CSV logs written successfully!\n",
            "Check file: example_logs/app.csv\n",
            "Note: CSV files can be opened in Excel or any spreadsheet software\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"CSV File Logging\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create CSV file handler\n",
        "csv_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/app.csv\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"csv\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "csv_buffer_settings = Handler_BufferSettings()\n",
        "csv_file_handler = FileHandler(\n",
        "    buffer_settings=csv_buffer_settings,\n",
        "    service_config=csv_config\n",
        ")\n",
        "\n",
        "csv_handler_instance = HandlerInstance(\n",
        "    service_handler=csv_file_handler,\n",
        "    handler_name=\"csv_file\"\n",
        ")\n",
        "\n",
        "csv_logger = Logger(\n",
        "    app_name=\"csv_file_demo\",\n",
        "    handlers=[csv_handler_instance]\n",
        ")\n",
        "\n",
        "# Log several entries\n",
        "print(\"\\nWriting CSV logs...\")\n",
        "await csv_logger.info(\"Application started\")\n",
        "await csv_logger.info(\"User action logged\")\n",
        "await csv_logger.warning(\"System resource warning\")\n",
        "await csv_logger.error(\"Operation failed\")\n",
        "\n",
        "print(\"CSV logs written successfully!\")\n",
        "print(f\"Check file: {csv_config.destination}\")\n",
        "print(\"Note: CSV files can be opened in Excel or any spreadsheet software\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 4: Append vs Overwrite Modes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Append vs Overwrite Modes\n",
            "======================================================================\n",
            "\n",
            "Example 1: Append Mode\n",
            "Appended 3 entries to append_test.log\n",
            "\n",
            "Example 2: Overwrite Mode\n",
            "Overwrote overwrite_test.log\n",
            "\n",
            "Note: Append mode preserves existing logs, overwrite mode clears the file first\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Append vs Overwrite Modes\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Example 1: Append mode (default)\n",
        "print(\"\\nExample 1: Append Mode\")\n",
        "append_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/append_test.log\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"text\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "append_buffer = Handler_BufferSettings()\n",
        "append_handler = FileHandler(\n",
        "    buffer_settings=append_buffer,\n",
        "    service_config=append_config\n",
        ")\n",
        "append_logger = Logger(\n",
        "    app_name=\"append_demo\",\n",
        "    handlers=[HandlerInstance(service_handler=append_handler, handler_name=\"append_file\")]\n",
        ")\n",
        "\n",
        "await append_logger.info(\"First log entry\")\n",
        "await append_logger.info(\"Second log entry\")\n",
        "await append_logger.info(\"Third log entry\")\n",
        "\n",
        "print(\"Appended 3 entries to append_test.log\")\n",
        "\n",
        "# Example 2: Overwrite mode\n",
        "print(\"\\nExample 2: Overwrite Mode\")\n",
        "overwrite_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/overwrite_test.log\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"text\",\n",
        "    append=False  # Overwrite mode\n",
        ")\n",
        "\n",
        "overwrite_buffer = Handler_BufferSettings()\n",
        "overwrite_handler = FileHandler(\n",
        "    buffer_settings=overwrite_buffer,\n",
        "    service_config=overwrite_config\n",
        ")\n",
        "overwrite_logger = Logger(\n",
        "    app_name=\"overwrite_demo\",\n",
        "    handlers=[HandlerInstance(service_handler=overwrite_handler, handler_name=\"overwrite_file\")]\n",
        ")\n",
        "\n",
        "await overwrite_logger.info(\"This will replace any existing content\")\n",
        "\n",
        "print(\"Overwrote overwrite_test.log\")\n",
        "print(\"\\nNote: Append mode preserves existing logs, overwrite mode clears the file first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 5: Nested Directories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Nested Directories - Automatic Creation\n",
            "======================================================================\n",
            "\n",
            "Writing to nested directory...\n",
            "Successfully created nested directories and wrote log!\n",
            "Check file: example_logs/production/api/requests.json\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Nested Directories - Automatic Creation\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# File handler automatically creates nested directories\n",
        "nested_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/production/api/requests.json\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"json\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "nested_buffer = Handler_BufferSettings()\n",
        "nested_handler = FileHandler(\n",
        "    buffer_settings=nested_buffer,\n",
        "    service_config=nested_config\n",
        ")\n",
        "nested_logger = Logger(\n",
        "    app_name=\"nested_demo\",\n",
        "    handlers=[HandlerInstance(service_handler=nested_handler, handler_name=\"nested_file\")]\n",
        ")\n",
        "\n",
        "print(\"\\nWriting to nested directory...\")\n",
        "await nested_logger.info(\n",
        "    \"API request logged\",\n",
        "    method=\"GET\",\n",
        "    url=\"/api/users\",\n",
        "    status_code=200\n",
        ")\n",
        "\n",
        "print(\"Successfully created nested directories and wrote log!\")\n",
        "print(f\"Check file: {nested_config.destination}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 6: Real-World Example - Production Logging\n",
        "\n",
        "Complete example of production-style file logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Real-World Example: Production Logging\n",
            "======================================================================\n",
            "\n",
            "Simulating production events...\n",
            "\n",
            "Production logs written!\n",
            "  JSON: example_logs/production/app.json\n",
            "  Text: example_logs/production/app.log\n",
            "\n",
            "Note: Logs are written to BOTH files simultaneously\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Real-World Example: Production Logging\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Production setup: JSON for detailed logs, Text for quick scanning\n",
        "production_json_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/production/app.json\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"json\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "production_text_config = File_ServiceConfig(\n",
        "    destination=\"example_logs/production/app.log\",\n",
        "    output_mode=\"file\",\n",
        "    format=\"text\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "# Create handlers\n",
        "json_prod_buffer = Handler_BufferSettings()\n",
        "json_prod_handler = FileHandler(\n",
        "    buffer_settings=json_prod_buffer,\n",
        "    service_config=production_json_config\n",
        ")\n",
        "\n",
        "text_prod_buffer = Handler_BufferSettings()\n",
        "text_prod_handler = FileHandler(\n",
        "    buffer_settings=text_prod_buffer,\n",
        "    service_config=production_text_config\n",
        ")\n",
        "\n",
        "# Create logger with BOTH handlers\n",
        "production_logger = Logger(\n",
        "    app_name=\"production_app\",\n",
        "    handlers=[\n",
        "        HandlerInstance(service_handler=json_prod_handler, handler_name=\"prod_json\"),\n",
        "        HandlerInstance(service_handler=text_prod_handler, handler_name=\"prod_text\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Simulate production events\n",
        "print(\"\\nSimulating production events...\\n\")\n",
        "\n",
        "await production_logger.info(\n",
        "    \"Application started\",\n",
        "    extra={\"version\": \"1.2.3\", \"environment\": \"production\"}\n",
        ")\n",
        "\n",
        "await production_logger.info(\n",
        "    \"Database connection established\",\n",
        "    extra={\"host\": \"db.example.com\", \"pool_size\": 20}\n",
        ")\n",
        "\n",
        "await production_logger.info(\n",
        "    \"User authenticated\",\n",
        "    user_id=\"user_alice_123\",\n",
        "    tenant_id=\"tenant_acme\",\n",
        "    session_id=\"sess_xyz789\",\n",
        "    action=\"login\"\n",
        ")\n",
        "\n",
        "await production_logger.warning(\n",
        "    \"High memory usage detected\",\n",
        "    extra={\"memory_percent\": 85, \"threshold\": 80}\n",
        ")\n",
        "\n",
        "await production_logger.error(\n",
        "    \"External API timeout\",\n",
        "    method=\"GET\",\n",
        "    url=\"https://external-api.example.com/data\",\n",
        "    duration_ms=5000,\n",
        "    extra={\"timeout_limit\": 3000, \"retry_count\": 3}\n",
        ")\n",
        "\n",
        "print(\"Production logs written!\")\n",
        "print(f\"  JSON: {production_json_config.destination}\")\n",
        "print(f\"  Text: {production_text_config.destination}\")\n",
        "print(\"\\nNote: Logs are written to BOTH files simultaneously\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 7: View Written Logs\n",
        "\n",
        "Let's verify the logs were written correctly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "View Written Logs\n",
            "======================================================================\n",
            "\n",
            "Sample JSON Log:\n",
            "--------------------------------------------------\n",
            "[\n",
            "\n",
            "\n",
            "Sample Text Logs:\n",
            "--------------------------------------------------\n",
            "[2025-10-22T22:39:41.820793Z] INFO - Service initialized | app_name=text_file_demo, method=COMMENT, status=info, correlation.trace_id=ac1f902f-cd50-44b0-a7c2-a57281a985fe, correlation.span_id=4342c499bd1a453b\n",
            "[2025-10-22T22:39:41.821308Z] WARNING - Cache size approaching limit | app_name=text_file_demo, method=COMMENT, status=info, correlation.trace_id=ac1f902f-cd50-44b0-a7c2-a57281a985fe, correlation.span_id=96adf5b4c8184270, correlation.parent_span_id=4342c499bd1a453b\n",
            "\n",
            "\n",
            "All Log Files Created:\n",
            "--------------------------------------------------\n",
            "example_logs\\app.csv (587 bytes)\n",
            "example_logs\\app.json (1426 bytes)\n",
            "example_logs\\app.log (477 bytes)\n",
            "example_logs\\append_test.log (700 bytes)\n",
            "example_logs\\overwrite_test.log (229 bytes)\n",
            "example_logs\\production\\app.json (1943 bytes)\n",
            "example_logs\\production\\app.log (1153 bytes)\n",
            "example_logs\\production\\api\\requests.json (407 bytes)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"View Written Logs\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Read and display JSON logs\n",
        "print(\"\\nSample JSON Log:\")\n",
        "print(\"-\" * 50)\n",
        "with open(\"example_logs/app.json\", \"r\") as f:\n",
        "    first_line = f.readline()\n",
        "    print(first_line)\n",
        "\n",
        "# Read and display text logs\n",
        "print(\"\\nSample Text Logs:\")\n",
        "print(\"-\" * 50)\n",
        "with open(\"example_logs/app.log\", \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 3:  # Show first 3 lines\n",
        "            break\n",
        "        print(line.strip())\n",
        "\n",
        "# List all log files created\n",
        "print(\"\\n\\nAll Log Files Created:\")\n",
        "print(\"-\" * 50)\n",
        "for root, dirs, files in os.walk(\"example_logs\"):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        size = os.path.getsize(filepath)\n",
        "        print(f\"{filepath} ({size} bytes)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **FileHandler** - Write logs to files for persistent storage\n",
        "2. **File_ServiceConfig** - Configure file paths and formats\n",
        "3. **JSON Format** - Structured logs with full details\n",
        "4. **Text Format** - Human-readable logs for quick scanning\n",
        "5. **CSV Format** - Logs in spreadsheet-compatible format\n",
        "6. **Append vs Overwrite** - Control file writing behavior\n",
        "7. **Nested Directories** - Automatic directory creation\n",
        "8. **Multiple Handlers** - Write to multiple files simultaneously\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **Persistent Storage** - Logs survive application restarts\n",
        "- **Three Formats** - JSON (rich), Text (readable), CSV (spreadsheet)\n",
        "- **Automatic Setup** - Directories created automatically\n",
        "- **Production Ready** - Use multiple handlers for different formats\n",
        "- **Easy Analysis** - JSON for parsing, Text for grep, CSV for Excel\n",
        "\n",
        "### File Format Guide\n",
        "\n",
        "- **JSON**: Best for parsing, querying, and analysis tools\n",
        "- **Text**: Best for quick scanning with grep/tail/less\n",
        "- **CSV**: Best for importing into Excel or data analysis tools\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
