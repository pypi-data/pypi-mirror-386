{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example 7: Multi-Handler Logging - Complete Solution\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "This notebook demonstrates using multiple handlers simultaneously:\n",
        "\n",
        "- **Multiple Handlers** - Console + File + Cloud\n",
        "- **Production Setup** - Real-world logging configuration\n",
        "- **Different Outputs** - Each handler with different format\n",
        "- **Complete Workflow** - From development to production\n",
        "- **Best Practices** - Optimal logging strategy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup - Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import os\n",
        "from dc_logger.client.Log import LogEntry, LogLevel\n",
        "from dc_logger.client.base import Logger, HandlerInstance\n",
        "from dc_logger.services.console.base import ConsoleHandler, Console_ServiceConfig\n",
        "from dc_logger.logs.services.file import FileHandler, File_ServiceConfig\n",
        "\n",
        "# Create logs directory\n",
        "os.makedirs(\"multi_handler_logs\", exist_ok=True)\n",
        "\n",
        "print(\"All imports successful!\")\n",
        "print(\"Logs directory: multi_handler_logs/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Logger with Console + File Handlers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Console + File Logging\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create console handler (text format for readability)\n",
        "console_config = Console_ServiceConfig(\n",
        "    service_name=\"console\",\n",
        "    output_mode=\"console\"\n",
        ")\n",
        "console_handler = ConsoleHandler(config=console_config)\n",
        "\n",
        "# Create file handler (JSON format for detailed logs)\n",
        "file_config = File_ServiceConfig(\n",
        "    service_name=\"file\",\n",
        "    destination=\"multi_handler_logs/app.json\",\n",
        "    format=\"json\",\n",
        "    append=True\n",
        ")\n",
        "file_handler = FileHandler(service_config=file_config)\n",
        "\n",
        "# Create logger with BOTH handlers\n",
        "multi_logger = Logger(\n",
        "    app_name=\"multi_handler_app\",\n",
        "    handlers=[\n",
        "        HandlerInstance(handler=console_handler, output_type=\"text\"),\n",
        "        HandlerInstance(handler=file_handler, output_type=\"json\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\nLogger created with 2 handlers:\")\n",
        "print(\"  1. Console (text format)\")\n",
        "print(\"  2. File (JSON format)\")\n",
        "print(\"\\nLogs will appear in console AND be saved to file\\n\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Log some events\n",
        "await multi_logger.info(\"Application started\")\n",
        "await multi_logger.info(\n",
        "    \"User logged in\",\n",
        "    user_id=\"user_alice\",\n",
        "    tenant_id=\"tenant_acme\"\n",
        ")\n",
        "await multi_logger.warning(\"Cache approaching limit\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"\\nLogs also saved to: {file_config.destination}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Multiple File Formats Simultaneously\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Multiple File Formats: JSON + Text + CSV\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create three file handlers with different formats\n",
        "json_file_config = File_ServiceConfig(\n",
        "    service_name=\"json_file\",\n",
        "    destination=\"multi_handler_logs/detailed.json\",\n",
        "    format=\"json\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "text_file_config = File_ServiceConfig(\n",
        "    service_name=\"text_file\",\n",
        "    destination=\"multi_handler_logs/quick_scan.log\",\n",
        "    format=\"text\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "csv_file_config = File_ServiceConfig(\n",
        "    service_name=\"csv_file\",\n",
        "    destination=\"multi_handler_logs/spreadsheet.csv\",\n",
        "    format=\"csv\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "# Create handlers\n",
        "json_handler = FileHandler(service_config=json_file_config)\n",
        "text_handler = FileHandler(service_config=text_file_config)\n",
        "csv_handler = FileHandler(service_config=csv_file_config)\n",
        "\n",
        "# Create logger with all three\n",
        "format_logger = Logger(\n",
        "    app_name=\"format_demo\",\n",
        "    handlers=[\n",
        "        HandlerInstance(handler=json_handler, output_type=\"json\"),\n",
        "        HandlerInstance(handler=text_handler, output_type=\"text\"),\n",
        "        HandlerInstance(handler=csv_handler, output_type=\"csv\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\nLogger created with 3 file handlers:\")\n",
        "print(\"  1. JSON for analysis tools\")\n",
        "print(\"  2. Text for grep/tail\")\n",
        "print(\"  3. CSV for Excel\")\n",
        "print(\"\\nLogging events...\\n\")\n",
        "\n",
        "await format_logger.info(\"Service initialized\")\n",
        "await format_logger.info(\"Processing batch\", extra={\"items\": 100})\n",
        "await format_logger.warning(\"Slow query detected\", duration_ms=2500)\n",
        "await format_logger.error(\"Connection timeout\", extra={\"host\": \"db.example.com\"})\n",
        "\n",
        "print(\"\\nLogs written to:\")\n",
        "print(f\"  JSON: {json_file_config.destination}\")\n",
        "print(f\"  Text: {text_file_config.destination}\")\n",
        "print(f\"  CSV: {csv_file_config.destination}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Production Setup: Console + JSON File + Text File\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Production-style setup\n",
        "prod_console_config = Console_ServiceConfig(\n",
        "    service_name=\"prod_console\",\n",
        "    output_mode=\"console\"\n",
        ")\n",
        "\n",
        "prod_json_config = File_ServiceConfig(\n",
        "    service_name=\"prod_json\",\n",
        "    destination=\"multi_handler_logs/production/app.json\",\n",
        "    format=\"json\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "prod_text_config = File_ServiceConfig(\n",
        "    service_name=\"prod_text\",\n",
        "    destination=\"multi_handler_logs/production/app.log\",\n",
        "    format=\"text\",\n",
        "    append=True\n",
        ")\n",
        "\n",
        "# Create handlers\n",
        "prod_console = ConsoleHandler(config=prod_console_config)\n",
        "prod_json = FileHandler(service_config=prod_json_config)\n",
        "prod_text = FileHandler(service_config=prod_text_config)\n",
        "\n",
        "# Create production logger\n",
        "production_logger = Logger(\n",
        "    app_name=\"production_app\",\n",
        "    handlers=[\n",
        "        HandlerInstance(handler=prod_console, output_type=\"text\"),\n",
        "        HandlerInstance(handler=prod_json, output_type=\"json\"),\n",
        "        HandlerInstance(handler=prod_text, output_type=\"text\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\nProduction logger with 3 handlers:\")\n",
        "print(\"  1. Console - Real-time monitoring during deployment\")\n",
        "print(\"  2. JSON File - Detailed logs for analysis\")\n",
        "print(\"  3. Text File - Quick scanning with grep/tail\")\n",
        "print(\"  (4. Cloud - Would be Datadog/CloudWatch in real production)\")\n",
        "print(\"\\nSimulating production events...\\n\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Simulate production events\n",
        "await production_logger.info(\n",
        "    \"Application started\",\n",
        "    extra={\"version\": \"2.1.0\", \"environment\": \"production\"}\n",
        ")\n",
        "\n",
        "await production_logger.info(\n",
        "    \"Database pool initialized\",\n",
        "    extra={\"connections\": 20, \"max\": 50}\n",
        ")\n",
        "\n",
        "await production_logger.info(\n",
        "    \"User request\",\n",
        "    user_id=\"user_bob_456\",\n",
        "    tenant_id=\"tenant_startup\",\n",
        "    method=\"POST\",\n",
        "    url=\"/api/projects\",\n",
        "    status_code=201,\n",
        "    duration_ms=145\n",
        ")\n",
        "\n",
        "await production_logger.warning(\n",
        "    \"Cache miss rate high\",\n",
        "    extra={\"miss_rate\": 0.35, \"threshold\": 0.20}\n",
        ")\n",
        "\n",
        "await production_logger.error(\n",
        "    \"External API timeout\",\n",
        "    method=\"GET\",\n",
        "    url=\"https://external-api.example.com/data\",\n",
        "    status_code=504,\n",
        "    duration_ms=5000,\n",
        "    extra={\"retry_count\": 3}\n",
        ")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(\"\\nLogs written to:\")\n",
        "print(f\"  Console (above)\")\n",
        "print(f\"  JSON: {prod_json_config.destination}\")\n",
        "print(f\"  Text: {prod_text_config.destination}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Environment-Specific Logging Strategy\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def create_logger_for_environment(env: str) -> Logger:\n",
        "    \"\"\"Create logger with handlers appropriate for environment.\"\"\"\n",
        "    \n",
        "    handlers = []\n",
        "    \n",
        "    if env == \"development\":\n",
        "        # Dev: Console only for fast feedback\n",
        "        console_config = Console_ServiceConfig(\n",
        "            service_name=f\"console_{env}\",\n",
        "            output_mode=\"console\"\n",
        "        )\n",
        "        console_handler = ConsoleHandler(config=console_config)\n",
        "        handlers.append(\n",
        "            HandlerInstance(handler=console_handler, output_type=\"text\")\n",
        "        )\n",
        "        \n",
        "    elif env == \"staging\":\n",
        "        # Staging: Console + JSON file\n",
        "        console_config = Console_ServiceConfig(\n",
        "            service_name=f\"console_{env}\",\n",
        "            output_mode=\"console\"\n",
        "        )\n",
        "        file_config = File_ServiceConfig(\n",
        "            service_name=f\"file_{env}\",\n",
        "            destination=f\"multi_handler_logs/{env}/app.json\",\n",
        "            format=\"json\",\n",
        "            append=True\n",
        "        )\n",
        "        console_handler = ConsoleHandler(config=console_config)\n",
        "        file_handler = FileHandler(service_config=file_config)\n",
        "        \n",
        "        handlers.extend([\n",
        "            HandlerInstance(handler=console_handler, output_type=\"text\"),\n",
        "            HandlerInstance(handler=file_handler, output_type=\"json\")\n",
        "        ])\n",
        "        \n",
        "    elif env == \"production\":\n",
        "        # Production: JSON file + Text file + Cloud\n",
        "        json_config = File_ServiceConfig(\n",
        "            service_name=f\"json_{env}\",\n",
        "            destination=f\"multi_handler_logs/{env}/app.json\",\n",
        "            format=\"json\",\n",
        "            append=True\n",
        "        )\n",
        "        text_config = File_ServiceConfig(\n",
        "            service_name=f\"text_{env}\",\n",
        "            destination=f\"multi_handler_logs/{env}/app.log\",\n",
        "            format=\"text\",\n",
        "            append=True\n",
        "        )\n",
        "        \n",
        "        json_handler = FileHandler(service_config=json_config)\n",
        "        text_handler = FileHandler(service_config=text_config)\n",
        "        \n",
        "        handlers.extend([\n",
        "            HandlerInstance(handler=json_handler, output_type=\"json\"),\n",
        "            HandlerInstance(handler=text_handler, output_type=\"text\")\n",
        "        ])\n",
        "        # Would add cloud handler here in real production\n",
        "    \n",
        "    return Logger(app_name=f\"app_{env}\", handlers=handlers)\n",
        "\n",
        "# Create loggers for each environment\n",
        "environments = [\"development\", \"staging\", \"production\"]\n",
        "\n",
        "print(\"\\nLogging strategy by environment:\\n\")\n",
        "for env in environments:\n",
        "    logger = create_logger_for_environment(env)\n",
        "    num_handlers = len(logger.handlers)\n",
        "    \n",
        "    print(f\"{env.upper():12} - {num_handlers} handler(s)\")\n",
        "    if env == \"development\":\n",
        "        print(\"             Console only (fast feedback)\")\n",
        "    elif env == \"staging\":\n",
        "        print(\"             Console + JSON file (debugging + persistence)\")\n",
        "    elif env == \"production\":\n",
        "        print(\"             JSON + Text files (+ Cloud in real setup)\")\n",
        "    print()\n",
        "\n",
        "# Test production logger\n",
        "print(\"Testing production logger:\")\n",
        "print(\"-\" * 70)\n",
        "prod_logger = create_logger_for_environment(\"production\")\n",
        "await prod_logger.info(\"Test log from production logger\")\n",
        "print(\"-\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 5: Verify All Logs Were Written\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Verify All Log Files Created\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nAll log files created:\\n\")\n",
        "for root, dirs, files in os.walk(\"multi_handler_logs\"):\n",
        "    level = root.replace(\"multi_handler_logs\", \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = \" \" * 2 * (level + 1)\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        size = os.path.getsize(filepath)\n",
        "        print(f\"{sub_indent}{file} ({size} bytes)\")\n",
        "\n",
        "# Show sample content from one file\n",
        "print(\"\\n\\nSample from production JSON log:\")\n",
        "print(\"-\" * 70)\n",
        "try:\n",
        "    with open(\"multi_handler_logs/production/app.json\", \"r\") as f:\n",
        "        first_line = f.readline()\n",
        "        if first_line:\n",
        "            import json\n",
        "            log_entry = json.loads(first_line)\n",
        "            print(f\"Level: {log_entry.get('level')}\")\n",
        "            print(f\"Message: {log_entry.get('message')}\")\n",
        "            print(f\"Timestamp: {log_entry.get('timestamp')}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found (expected if running without all examples)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **Multiple Handlers** - Use console, file, and cloud handlers together\n",
        "2. **Different Formats** - Each handler can use different format (JSON/Text/CSV)\n",
        "3. **Environment Strategy** - Different handlers for dev/staging/production\n",
        "4. **Production Setup** - Best practices for real applications\n",
        "5. **Flexibility** - Mix and match handlers based on needs\n",
        "\n",
        "### Handler Combinations\n",
        "\n",
        "Common combinations by use case:\n",
        "\n",
        "**Development**\n",
        "- Console (text) - Fast feedback\n",
        "\n",
        "**Staging**\n",
        "- Console (text) - Real-time monitoring\n",
        "- JSON file - Debugging\n",
        "\n",
        "**Production**\n",
        "- JSON file - Detailed logs for analysis\n",
        "- Text file - Quick scanning\n",
        "- Cloud (Datadog) - Centralized monitoring and alerts\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **One Logger, Many Outputs** - Single log call writes to all handlers\n",
        "- **No Extra Code** - Same logging code works across environments\n",
        "- **Format Flexibility** - Choose best format for each destination\n",
        "- **Easy Configuration** - Just add/remove handlers\n",
        "- **Environment Aware** - Different handlers per environment\n",
        "\n",
        "### Benefits of Multi-Handler Logging\n",
        "\n",
        "1. **Redundancy** - If cloud fails, still have file logs\n",
        "2. **Different Audiences** - Console for devs, cloud for ops\n",
        "3. **Cost Optimization** - Local files for debug, cloud for critical\n",
        "4. **Flexibility** - Easy to add/remove handlers without code changes\n",
        "\n",
        "### Production Checklist\n",
        "\n",
        "- [ ] Console handler for deployment monitoring\n",
        "- [ ] JSON file handler for detailed logs\n",
        "- [ ] Text file handler for quick grep/tail\n",
        "- [ ] Cloud handler (Datadog) for alerts and dashboards\n",
        "- [ ] Log rotation configured for file handlers\n",
        "- [ ] Environment-specific handler selection\n",
        "- [ ] Secure storage for log files\n",
        "- [ ] Backup strategy for critical logs\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "You now have complete knowledge of the dc_logger library:\n",
        "\n",
        "1. **Basic Logs** - LogEntry, LogLevel, context objects\n",
        "2. **Extractors** - Automatic context extraction\n",
        "3. **Decorators** - Automatic function logging\n",
        "4. **Console Logging** - Real-time output\n",
        "5. **File Logging** - Persistent storage (JSON/Text/CSV)\n",
        "6. **Cloud Logging** - Datadog integration\n",
        "7. **Multi-Handler** - Complete production setup\n",
        "\n",
        "Start logging!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
