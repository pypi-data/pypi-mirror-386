import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

import uuid

from src.autoagents_graph import NL2Workflow, DifyConfig
from src.autoagents_graph.engine.dify import DifyStartState, DifyLLMState, DifyEndState, START, END


def main():
    # ç”Ÿæˆå”¯ä¸€ID
    llm_node_1_id = str(uuid.uuid4())  # GenerateCoT-1
    llm_node_2_id = str(uuid.uuid4())  # GenerateCoT-2  
    llm_node_3_id = str(uuid.uuid4())  # GenerateCoT-3
    llm_summary_id = str(uuid.uuid4())  # ScEnsembleé›†æˆ

    # åˆ›å»ºDifyå¹³å°å·¥ä½œæµ
    workflow = NL2Workflow(
        platform="dify",
        config=DifyConfig(
            app_name="Multi-CoT Ensembleå·¥ä½œæµ",
            app_description="åŸºäºaflowæ¡†æ¶çš„å¤šè½®æ€ç»´é“¾é›†æˆå·¥ä½œæµ",
            app_icon="ğŸ¤–",
            app_icon_background="#FFEAD5"
        )
    )

    # æ·»åŠ å¼€å§‹èŠ‚ç‚¹
    workflow.add_node(
        id=START,
        position={"x": 0, "y": 200},
        state=DifyStartState(title="å¼€å§‹"),
    )

    # æ·»åŠ LLMèŠ‚ç‚¹ - GenerateCoT
    workflow.add_node(
        id=llm_node_1_id,
        state=DifyLLMState(
            title="GenerateCoT-1",
            prompt_template=[{"role": "system", "text": """ä½¿ç”¨æ€ç»´é“¾æ¨ç†æ–¹æ³•åˆ†æé—®é¢˜ï¼Œé€æ­¥æ¨ç†å¹¶ç»™å‡ºç»“è®ºã€‚

ç”¨æˆ·è¾“å…¥ï¼š{{#start.sys_input#}}

è¯·è¿›è¡Œè¯¦ç»†çš„æ€ç»´é“¾æ¨ç†åˆ†æã€‚"""}],
            model={
                "completion_params": {"temperature": 0.7},
                "mode": "chat",
                "name": "gpt-4",
                "provider": ""
            }
        ),
        position={"x": 276, "y": 263}
    )

    # æ·»åŠ LLMèŠ‚ç‚¹ - GenerateCoT
    workflow.add_node(
        id=llm_node_2_id,
        state=DifyLLMState(
            title="GenerateCoT-2",
            prompt_template=[{"role": "system", "text": """ä½¿ç”¨æ€ç»´é“¾æ¨ç†æ–¹æ³•åˆ†æé—®é¢˜ï¼Œé€æ­¥æ¨ç†å¹¶ç»™å‡ºç»“è®ºã€‚

ç”¨æˆ·è¾“å…¥ï¼š{{#start.sys_input#}}

è¯·è¿›è¡Œè¯¦ç»†çš„æ€ç»´é“¾æ¨ç†åˆ†æã€‚"""}],
            model={
                "completion_params": {"temperature": 0.7},
                "mode": "chat",
                "name": "gpt-4",
                "provider": ""
            }
        ),
        position={"x": 276, "y": 82}
    )

    # æ·»åŠ LLMèŠ‚ç‚¹ - GenerateCoT
    workflow.add_node(
        id=llm_node_3_id,
        state=DifyLLMState(
            title="GenerateCoT-3",
            prompt_template=[{"role": "system", "text": """ä½¿ç”¨æ€ç»´é“¾æ¨ç†æ–¹æ³•åˆ†æé—®é¢˜ï¼Œé€æ­¥æ¨ç†å¹¶ç»™å‡ºç»“è®ºã€‚

ç”¨æˆ·è¾“å…¥ï¼š{{#start.sys_input#}}

è¯·è¿›è¡Œè¯¦ç»†çš„æ€ç»´é“¾æ¨ç†åˆ†æã€‚"""}],
            model={
                "completion_params": {"temperature": 0.7},
                "mode": "chat",
                "name": "gpt-4",
                "provider": ""
            }
        ),
        position={"x": 276, "y": 459}
    )

    # æ·»åŠ ScEnsembleé›†æˆèŠ‚ç‚¹
    workflow.add_node(
        id=llm_summary_id,
        state=DifyLLMState(
            title="ScEnsemble",
            prompt_template=[{"role": "system", "text": f"""
            ä½¿ç”¨Self-Consistency Ensembleæ–¹æ³•ï¼Œå¯¹å¤šä¸ªæ€ç»´é“¾æ¨ç†ç»“æœè¿›è¡Œé›†æˆåˆ†æï¼Œé€‰æ‹©æœ€ä¸€è‡´å’Œå¯é çš„ç­”æ¡ˆã€‚
            
            åŸå§‹é—®é¢˜ï¼š{{{{#start.sys_input#}}}}
            
            æ–¹æ¡ˆAï¼š{{{{#{llm_node_1_id}.text#}}}}
            
            æ–¹æ¡ˆBï¼š{{{{#{llm_node_2_id}.text#}}}}
            
            æ–¹æ¡ˆCï¼š{{{{#{llm_node_3_id}.text#}}}}
            
            è¯·åˆ†æè¿™ä¸‰ä¸ªæ–¹æ¡ˆçš„ä¸€è‡´æ€§ï¼Œå¹¶é€‰æ‹©æœ€å¯é çš„ç­”æ¡ˆæˆ–è¿›è¡Œåˆç†çš„é›†æˆã€‚
            """}],
            model={
                "completion_params": {"temperature": 0.7},
                "mode": "chat",
                "name": "gpt-4o",
                "provider": "langgenius/openai/openai"
            },
            structured_output={
                "schema": {
                    "additionalProperties": False,
                    "properties": {
                        "selected_solution": {
                            "type": "string",
                            "description": "é€‰æ‹©çš„æœ€ä½³æ–¹æ¡ˆæ ‡è¯†(A/B/C)"
                        },
                        "reasoning": {
                            "type": "string", 
                            "description": "é€‰æ‹©è¯¥æ–¹æ¡ˆçš„æ¨ç†è¿‡ç¨‹"
                        },
                        "final_answer": {
                            "type": "string",
                            "description": "æœ€ç»ˆé›†æˆåçš„ç­”æ¡ˆ"
                        }
                    },
                    "required": ["selected_solution", "reasoning", "final_answer"],
                    "type": "object"
                }
            },
            structured_output_enabled=True
        ),
        position={"x": 572, "y": 254}
    )

    # æ·»åŠ ç»“æŸèŠ‚ç‚¹
    workflow.add_node(
        id=END,
        state=DifyEndState(title="å¤„ç†å®Œæˆ"),
        position={"x": 852, "y": 254}
    )

    # æ·»åŠ è¿æ¥è¾¹
    workflow.add_edge(START, llm_node_1_id)
    workflow.add_edge(START, llm_node_2_id)
    workflow.add_edge(START, llm_node_3_id)
    workflow.add_edge(llm_node_1_id, llm_summary_id)
    workflow.add_edge(llm_node_2_id, llm_summary_id)
    workflow.add_edge(llm_node_3_id, llm_summary_id)
    workflow.add_edge(llm_summary_id, END)

    # ç¼–è¯‘å¹¶ä¿å­˜
    yaml_result = workflow.compile()
    workflow.save("playground/dify/dify_workflow_output-Parallel.yaml")

    print(f"Multi-CoT Ensembleå·¥ä½œæµç”Ÿæˆå®Œæˆï¼ŒYAMLé•¿åº¦: {len(yaml_result)} å­—ç¬¦")


if __name__ == "__main__":
    main()