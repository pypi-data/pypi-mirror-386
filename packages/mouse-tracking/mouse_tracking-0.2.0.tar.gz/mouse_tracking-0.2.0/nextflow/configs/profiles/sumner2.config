// sumner2 configuration file

workDir = "/flashscratch/${USER}/nextflow-work"

params {
    /*
     * Additional Parameters for the sumner2 profile
     * These parameters generally shouldn't be manually changed by the user
     * - tracking_code_dir: prefix for the tracking code directory
     * - gaits_code_dir: prefix for the gait analysis code directory
     * - vfi_code_dir: prefix for the vfi code directory
     * - support_code_dir: prefix for the support code directory
     * - heuristic_classifier_folder: prefix for the heuristic classifier folder
     * - filter_processed: whether to filter processed files in the batch

     * - jabs_version: version of JABS used for the classifiers
     * - classifier_window_sizes: window sizes cached for use in classifiers
     * - single_mouse_classifiers: classifiers for single mouse behavior. Each classifier is described as
         behavior name (identical key used in JABS): [
             project_folder_name: folder name containing this classifier
             stitch_value: stitch value for postprocessing this classifier
             filter_value: filter value for postprocessing this classifier
         ]
     * - heuristic_classifiers: classifiers for heuristic behaviors
     * - feature_bins: number of 5-minute bins for transforming summary tables into features
     * - default_feature_input: default input for feature generation
     * - default_manual_correction_input: default input for manual correction
     */
    tracking_code_dir = "/kumar_lab_models/mouse-tracking-runtime/"
    gait_code_dir = "/gait-analysis/"
    vfi_code_dir = "/vfi/Code/"
    support_code_dir = "/workspace/support_code/"
    heuristic_classifier_folder = "/opt/JABS-postprocess/src/jabs_postprocess/heuristic_classifiers/"
    filter_processed = false
    model_dir = "/projects/kumar-lab/multimouse-pipeline/nextflow-artifacts/neural_net_models/"

    jabs_version = "v0.37.0"
    classifier_window_sizes = [2, 5, 10, 20, 30, 60]
    // Classifiers are described as behavior_name: project_folder
    single_mouse_classifiers = [
        'Jumping': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Jumping/f0682b0fdde9bd59280336d8878e06be7446d31074d8edd53736557ea8c66a0d.pickle',
            stitch_value: 2,
            filter_value: 13
        ],
        'Freezing': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Freezing/8a9027123af796b937744d6fa5dd00b19714c93df7dcd142e5e5777d26404789.pickle',
            stitch_value: 2,
            filter_value: 13
        ],
        'SAP': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/SAP/02ae83290d652e54c73210a7f53fa814466dca5616969ad17edd589f7c417769.pickle',
            stitch_value: 2,
            filter_value: 13
        ],
        'grooming': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/grooming/12199145d31213f79e23669d211cfa2fd33cedb9f11197b44f90a4b71297b6d2.pickle',
            stitch_value: 300,
            filter_value: 90
        ],
        'Side_seizure': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Side_seizure/50e865cfb045ff5b0c6bbad1dabf6465de43ef52ab4e13900b915986a51e9a0c.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'scratch': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/scratch/261f1c21f015d47d30154fbbec98cb8860a40fbe383d3d86d6778e3da0f88a18.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Tail_jerk': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Tail_jerk/34313467d88e7fc64ee90e10549eb48cfb9782d5e7a246fe106188c8ae50cdff.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Wild_jumping': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Wild_jumping/7f114ce1b23a978afe82b4d9b7ec94c20982a2d5e7d16aefe4c5e0383324096a.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Escape': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Escape/0fa6b28e58fcc873f0c4ef053f5118566589d62d8e445b34ceaf1f962b5f8915.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Rearing_unsupported': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Rearing_unsupported/562453b77d1a681a75c49bd774b5451e79e9e5f8784b48978f0f8cabbd90721e.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Rearing_supported': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Rearing_supported/09ce1ed47e12556866045306bd221328454a8ccb5bc7ea7778a97e4882b386b6.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Turn_left': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Turn_left/4779947116201f5fab5f2ec04f0ad4ee97a1e83649b6089d64354a7b07c42e4b.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
        'Turn_right': [
            classifier_path: '/projects/kumar-lab/data/jabs/classifiers/v0.37.0/Turn_right/b6fe24481513b87b757a61ad9495f7a9af270fad3cbec5d6b25556ece5f9c50a.pickle',
            stitch_value: 5,
            filter_value: 5
        ],
    ]

    heuristic_classifiers = ["corner", "corner_facing", "freeze", "locomotion", "periphery", "wall_facing", "locomotion_corner", "locomotion_periphery"]

    // Number of 5-minute bins for transforming summary tables into bins
    // 1 = 5 minutes, 4 = 20 minutes, etc.
    feature_bins = [1, 4, 11]
    
    // Some default parameters for branches in the pipeline
    default_feature_input = ["/projects/kumar-lab/meta/default-data/DEFAULT_VIDEO.mp4", "/projects/kumar-lab/meta/default-data/DEFAULT_VIDEO_pose_est_v6.h5"]
    default_manual_correction_input = default_feature_input

    // Remote storage parameters
    globus_compute_endpoint = "b8377de1-47c2-11e7-bd5c-22000b9a448b" // JAX endpoint where compute filesystem is visible
    globus_remote_endpoint = "70850914-722d-11e7-aa01-22000bf2d287" // JAX T2 storage endpoint
    globus_remote_folder = "/tier2/vkumar/"
    dropbox_prefix = "labdropbox:\"/KumarLab's shared workspace/VideoData/MDS_Tests/\""
    rclone_config = "/projects/kumar-lab/meta/secrets/tokens/rclone_dropbox.conf"
}

apptainer {
   enabled = true
   autoMounts = true
 }

process {
    executor = 'slurm'
    module = 'slurm'

    /*
     * JAX cluster options
     */
    withLabel: "gpu" {
        // This is the profile that batch processing should use
        queue = "gpu_a100_mig"
        // -q has options
        // gpu_inference: 6hr limit, 24gpu/user
        // gpu_dev: 8hr limit, 1gpu/user
        // gpu_training: 14day limit, 16gpu/user
        clusterOptions = '-q gpu_inference --gres gpu:1 --nice=64000000'
        containerOptions = "--nv"
        // Fair sharing of memory should be 63GB, but full node has 2TB
        resourceLimits = [ cpus: 6, memory: 128.GB, time: 6.h ]
    }
    withLabel: "gpu_long" {
        queue = "gpu_a100_mig"
        clusterOptions = '-q gpu_training --gres gpu:1 --nice=64000000'
        containerOptions = "--nv"
        // Fair sharing of memory should be 63GB, but full node has 2TB
        resourceLimits = [ cpus: 6, memory: 128.GB, time: 14.d ]
    }
    // Alternative GPU profiles available on the cluster
    withLabel: "gpu_a100" {
        // 8-gpu nodes
        queue = "gpu_a100"
        clusterOptions = '-q gpu_inference --gres gpu:1'
        containerOptions = "--nv"
        // resourceLimits = [ cpus: 192, memory: 2000.GB, time: 6.h ]
        resourceLimits = [ cpus: 24, memory: 250.GB, time: 6.h ]
    }
    withLabel: "gpu_v100" {
        // 4-gpu nodes
        queue = "gpu_v100"
        clusterOptions = '-q gpu_inference --gres gpu:1'
        containerOptions = "--nv"
        // resourceLimits = [ cpus: 48, memory: 192.GB, time: 6.h ]
        resourceLimits = [ cpus: 12, memory: 48.GB, time: 6.h ]
    }
    withLabel: "gpu_a100_mig" {
        queue = "gpu_a100_mig"
        clusterOptions = '-q gpu_inference --gres gpu:1'
        containerOptions = "--nv"
        // This divides the limits for 20GB mig slices (1g.20gb x4 profile, 32x total)
        resourceLimits = [ cpus: 6, memory: 32.GB, time: 6.h ]
    }
    withLabel: "cpu" {
        queue = "compute"
        resourceLimits = [ cpus: 72, memory: 772.GB, time: 72.h ]
    }
    withLabel: "xfer" {
        queue = "xfer"
        resourceLimits = [ cpus: 1, memory: 4.GB, time: 48.h]
    }

    /*
     * Runtime options
     */
    withLabel: "tracking" {
        container = "/projects/kumar-lab/meta/images/mouse-tracking-runtime/runtime/v${params.version}/latest.sif"
    }
    withLabel: "jabs_classify" {
        container = "/projects/kumar-lab/meta/images/JABS-behavior-classifier/headless/v0.36.1/latest.sif"
    }
    withLabel: "jabs_postprocess" {
        container = "/projects/kumar-lab/meta/images/JABS-postprocess/jabs-postprocess/v0.5.1/latest.sif"
    }
    withLabel: "jabs_table_convert" {
        container = "/projects/kumar-lab/meta/images/mouse-tracking-runtime/RBase/v${params.version}/latest.sif"
    }
    withLabel: "gait" {
        container = "/projects/kumar-lab/multimouse-pipeline/nextflow-containers/gait-pipeline-2025-03-27.sif"
    }
    withLabel: "frailty" {
        container = "/projects/kumar-lab/multimouse-pipeline/nextflow-containers/vfi-2025-03-27.sif"
    }
    withLabel: "sleap" {
        container = "/projects/kumar-lab/meta/images/mouse-tracking-runtime/sleap-1.4.1/v${params.version}/latest.sif"
    }
    withLabel: "sleap_io" {
        container = "/projects/kumar-lab/meta/images/mouse-tracking-runtime/sleap-io-0.2.0/v${params.version}/latest.sif"
    }
    withLabel: "rclone" {
        // executor.queueSize = 1
        container = "/projects/kumar-lab/meta/images/mouse-tracking-runtime/rclone/v${params.version}/latest.sif"
        cpus = 1
        time = '48h'
        memory = '12GB'
        queue = 'xfer'
        clusterOptions = '-q xfer'
    }

    /* 
     * Resource scaling labels
     * Values were estimated from test runs including a 5, 10, 20, and 30 minute test video
     * Equations are included as comments where appropriate
     * Dynamic directive assigned adds a 1.5x buffer with some tasks getting a 2.5x buffer
     * Minimums:
     * - cpus: 1
     * - memory: 1GB
     * - time: 10 second
     * - array: 200
     *
     * TODO:
     * - Add handling of maximum values
     *
     * Variables in equations are:
     * - t_min: duration of the video in minutes
     * Results are in units:
     * - cpus: number of CPUs
     * - memory: GB of memory
     * - time: seconds of walltime
    */

    // Fecal boli resources
    withLabel: "r_fboli_extract" {
        cpus = 1
        memory = { 1.GB * task.attempt }
        // 0.5 * t_min + 10.5
        time = {
            def r_value = Math.max(60, ((0.5 * (params.clip_duration / 30 / 60) + 10.5) * 1.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_fboli_predict" {
        cpus = 2
        memory = { 4.GB * task.attempt }
        // 2.5 * t_min + 5
        time = {
            def r_value = Math.max(60, ((2.5 * (params.clip_duration / 30 / 60) + 5) * 1.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // Frailty Resources
    withLabel: "r_flexibility" {
        cpus = 1
        // 0.0048 * t_min + 0.080
        memory = {
            def r_value = Math.max(1, ((0.0048 * (params.clip_duration / 30 / 60) + 0.08) * 1.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        // 0.6 * t_min + 30
        time = {
            def r_value = Math.max(10, ((0.6 * (params.clip_duration / 30 / 60) + 30) * 1.5 * task.attempt).toInteger())
            return r_value + '.min'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_rearpaw" {
        cpus = 1
        // 0.0047 * t_min + 0.0801
        memory = {
            def r_value = Math.max(1, ((0.0047 * (params.clip_duration / 30 / 60) + 0.0801) * 1.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        time = { 10.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // Gait Resources
    withLabel: "r_gait_h5" {
        cpus = 1
        // 0.0009 * t_min + 0.727
        memory = {
            def r_value = Math.max(1, ((0.0009 * (params.clip_duration / 30 / 60) + 0.727) * 1.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        time = { 10.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_gait_bin" {
        cpus = 1
        // 0.000005 * t_min + 0.0095
        memory = {
            def r_value = Math.max(1, ((0.000005 * (params.clip_duration / 30 / 60) + 0.0095) * 1.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        time = { 5.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // JABS Resources
    withLabel: "r_jabs_features" {
        // This equation was not scaled for number of window sizes
        // Adding more window sizes should scale linearly, since window features (calculated once per window size)
        // are more computationally expensive than per-frame features (calculated once per pose file)
        cpus = 1
        // 0.182 * t_min - 0.273 for 6 windows
        memory = {
            def r_value = Math.max(1, ((0.182 * (params.clip_duration / 30 / 60) - 0.273) * 2.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        // 162 * t_min + 4.6 for 6 windows
        time = {
            def r_value = Math.max(1, ((162 * (params.clip_duration / 30 / 60) + 4.6) * 2.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_jabs_classify" {
        // This equation was not scaled for number of classifiers
        // Adding more classifiers will scale linearly
        cpus = 1
        // 0.429 * t_min + 0.3 for 10 classifiers
        memory = {
            def r_value = Math.max(1, ((0.429 * (params.clip_duration / 30 / 60) + 0.3) * 2.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        // 30 * t_min + 127 for 10 classifiers
        time = {
            def r_value = Math.max(1, ((127 + 30 * (params.clip_duration / 30 / 60)) * 2.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_jabs_tablegen" {
        cpus = 1
        memory = { 1.GB * task.attempt }
        time = { 5.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_jabs_heuristic" {
        // This equation was not scaled for number of classifiers
        // Adding more classifiers will scale linearly
        cpus = 1
        memory = { 1.GB * task.attempt }
        // 0.111 * t_min + 37 for 6 classifiers
        time = {
            def r_value = Math.max(1, ((0.111 * (params.clip_duration / 30 / 60) + 37) * 2.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_jabs_table_convert" {
        cpus = 1
        memory = { 1.GB * task.attempt }
        // This task scales with events, not video duration
        // High value in experiments was 1-minute for a 1-hr video
        time = { 20.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // Single Mouse Resources
    withLabel: "r_single_seg" {
        cpus = 2
        // Segmentation is less predictable for shorter videos
        // because the shape of matrices grows by the prediction data
        // Equation provided, but numbers were manually increased
        // 0.06 * t_min + 1.86
        memory = {
            def r_value = Math.max(1, ((0.06 * (params.clip_duration / 30 / 60) + 1.86) * 2.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        // 15 * t_min - 63
        time = {
            def r_value = Math.max(1, ((15 * (params.clip_duration / 30 / 60) - 63) * 2.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_single_keypoints" {
        // Note: This process is run before the clipping (to find the mouse entering the arena)
        // This process will scale with input video duration, but not clip duration
        // Therefore, these tasks are on the slightly higher end
        cpus = 2
        memory = { 64.GB * task.attempt }
        time = { 6.hours * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_single_qc" {
        // This task scales with number of videos in the batch, but is still small
        cpus = 1
        memory = { 4.GB * task.attempt }
        time = { 20.min * task.attempt }
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_clip_video" {
        cpus = 2
        // 0.0000003 * t_min + 0.35
        memory = {
            def r_value = Math.max(1, ((0.0000003 * (params.clip_duration / 30 / 60) + 0.35) * 2.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        // 19.8 * t_min + 52
        time = {
            def r_value = Math.max(1, ((52 + 19.8 * (params.clip_duration / 30 / 60)) * 2.5 * task.attempt).toInteger())
            return r_value + '.sec'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // Multi Mouse Resources
    // These processes assume the input video is 1hr and scale with number of animals
    withLabel: "r_multi_seg" {
        cpus = 2
        // 8.53 GB * num_mice
        memory = {
            def per_mouse_gb = 10
            def base = params.num_mice * per_mouse_gb
            def retry_factor = 1 + (0.5 * (task.attempt - 1))
            def uncapped_memory = (base * retry_factor).toInt
            return Math.min(uncapped_memory, 128) + '.GB'
        }
        time = { 5.hours * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_multi_keypoints" {
        cpus = 2
        // 2.26 GB * num_mice + 2.47 GB
        memory = {
            def r_value = Math.max(1, ((2.26 * params.num_mice + 2.47) * 2.5 * task.attempt).toInteger())
            return r_value + '.GB'
        }
        // 6 * num_mice + 3
        time = {
            def r_value = Math.max(1, ((3 + 6 * params.num_mice) * 2.5 * task.attempt).toInteger())
            return r_value + '.hours'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_multi_identity" {
        cpus = 2
        memory = { 2.GB * task.attempt }
        // 0.1 * num_mice + 0.16
        time = {
            def r_value = Math.max(1, ((0.1 * params.num_mice + 0.16) * 2.5 * task.attempt).toInteger())
            return r_value + '.hours'
        }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_multi_tracklets" {
        cpus = 1
        // TODO: Tune these numbers based on number of mice
        // First video suggested ~16GB and ~30min for 3 mice
        memory = { 16.GB * task.attempt }
        time = { 2.hours * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // Static Object Resources
    // These do not scale with clip duration
    withLabel: "r_arena_corners" {
        cpus = 2
        memory = { 4.GB * task.attempt }
        time = { 10.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_food_hopper" {
        cpus = 2
        memory = { 8.GB * task.attempt }
        time = { 10.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_lixit" {
        cpus = 2
        memory = { 4.GB * task.attempt }
        time = { 10.min * task.attempt }
        array = 200
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    // Utility Resources
    withLabel: "r_util" {
        cpus = 1
        memory = { 1.GB * task.attempt }
        time = { 5.min * task.attempt }
        array = 500
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_gen_vid" {
        cpus = 1
        memory = { 1.GB * task.attempt }
        time = { 1.hours * task.attempt }
        errorStrategy = { task.attempt <= 3 ? 'retry' : 'ignore' }
        maxRetries = 3
    }
    withLabel: "r_compression" {
        // Note: These resources are enough for 1-hour 800x800 videos.
        // TODO: These values should scale to duration and size of video.
        cpus = 2
        memory = 2.GB
        time = 2.hours
        array = 200
        errorStrategy = 'ignore'
    }
}

executor {
    name = 'slurm'
    // The number of tasks the executor will handle in a parallel manner
    // TODO: This limit is set low to be a good GPU-cluster citizen. CPUs don't need to be as restricted.
    queueSize = 24
    submitRateLimit = '1 s'
    // Determines the max rate of job submission per time unit, for example '10sec' eg. max 10 jobs per second or '1/2 s' i.e. 1 job submissions every 2 seconds.
}
