"""Voice Activity Detection utilities using the Silero VAD model."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/silero_vad.ipynb.

# %% auto 0
__all__ = ['prepare_audio_and_vad']

# %% ../nbs/silero_vad.ipynb 3
import numpy as np
from silero_vad import (
    load_silero_vad,
    read_audio,
    get_speech_timestamps,
    save_audio,
    VADIterator,
    collect_chunks
)

from cjm_transcription_utils.librosa import (
    load_audio
)
from .chunking import generate_chunks_with_vad

# %% ../nbs/silero_vad.ipynb 4
def prepare_audio_and_vad(
    audio_path: str,  # Path to audio file
    max_chunk_seconds: float,  # Maximum chunk duration in seconds
    max_silence_threshold: float,  # Maximum silence duration before creating a new chunk
    include_timestamps: bool,  # Whether timestamps will be needed
    verbose: bool = True  # Whether to print progress
) -> tuple[np.ndarray, int, float, list, list, list]:  # Tuple of (audio array, sample rate, duration, speech timestamps, chunks, chunk timestamps)
    """Load audio and prepare VAD timestamps if needed."""
    # Load audio
    y, sr = load_audio(audio_path)
    duration = len(y) / sr
    
    if verbose:
        print(f"Audio duration: {duration:.2f} seconds")
    
    # Get VAD timestamps if needed
    speech_timestamps = None
    if duration > max_chunk_seconds or include_timestamps:
        from silero_vad import load_silero_vad, get_speech_timestamps
        silero_model = load_silero_vad(onnx=True, opset_version=16)
        speech_timestamps = get_speech_timestamps(
            audio=y,
            model=silero_model,
            threshold=0.5,
            sampling_rate=16000,
            min_speech_duration_ms=250,
            max_speech_duration_s=np.inf,
            min_silence_duration_ms=100,
            speech_pad_ms=30,
            return_seconds=True,
            time_resolution=1,
            visualize_probs=False,
            progress_tracking_callback=None,
            neg_threshold=None,
            window_size_samples=512,
            min_silence_at_max_speech=98,
            use_max_poss_sil_at_max_speech=True,
        )
    
    # Generate chunks with silence threshold
    chunks, chunk_timestamps = generate_chunks_with_vad(
        y, duration, max_chunk_seconds,
        speech_timestamps=speech_timestamps,
        max_silence_threshold=max_silence_threshold
    )
    
    if verbose:
        print(f"Generated {len(chunks)} chunks")
        if max_silence_threshold:
            print(f"Using max silence threshold of {max_silence_threshold} seconds")
    
    return y, sr, duration, speech_timestamps, chunks, chunk_timestamps
