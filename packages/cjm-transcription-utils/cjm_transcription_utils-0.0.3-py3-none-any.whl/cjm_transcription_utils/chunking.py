"""Utilities for splitting audio into chunks using VAD timestamps and merging transcripts with overlap correction."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/chunking.ipynb.

# %% auto 0
__all__ = ['get_extended_timestamp_boundaries', 'get_extended_chunk_boundaries', 'generate_chunks_with_vad',
           'generate_intermediate_chunks', 'generate_intermediate_chunk_tuples', 'merge_transcripts_with_overlaps']

# %% ../nbs/chunking.ipynb 3
from typing import Dict, List, Tuple, Optional

import numpy as np

# %% ../nbs/chunking.ipynb 4
#| export


# %% ../nbs/chunking.ipynb 5
def get_extended_timestamp_boundaries(
    timestamps: List[Dict[str, float]], 
    index: int  # Index of the current timestamp
) -> Tuple[float, float]:
    """Get extended boundaries for a timestamp using adjacent timestamps."""
    current = timestamps[index]
    
    # Use previous timestamp's end if available, otherwise use current start
    if index > 0:
        extended_start = timestamps[index - 1]['end']
    else:
        extended_start = current['start']
    
    # Use next timestamp's start if available, otherwise use current end
    if index < len(timestamps) - 1:
        extended_end = timestamps[index + 1]['start']
    else:
        extended_end = current['end']
    
    return extended_start, extended_end

# %% ../nbs/chunking.ipynb 6
def get_extended_chunk_boundaries(
    chunks: List[Tuple[float, float]], 
    index: int  # Index of the current chunk
) -> Tuple[float, float]:
    """Get extended boundaries for a chunk using adjacent chunks."""
    current_start, current_end = chunks[index]
    
    # Use previous chunk's end if available, otherwise use current start
    if index > 0:
        extended_start = chunks[index - 1][1]  # End of previous chunk
    else:
        extended_start = current_start
    
    # Use next chunk's start if available, otherwise use current end
    if index < len(chunks) - 1:
        extended_end = chunks[index + 1][0]  # Start of next chunk
    else:
        extended_end = current_end
    
    return extended_start, extended_end

# %% ../nbs/chunking.ipynb 7
def generate_chunks_with_vad(
    audio_array: np.ndarray,  # Audio array
    duration: float,  # Total duration of audio in seconds
    max_chunk_seconds: float = 120,  # Maximum chunk duration in seconds
    max_chunk_seconds_offset: float = 0,  # Offset for chunk duration calculation
    speech_timestamps: Optional[List[Dict]] = None,  # List of speech timestamp dictionaries with 'start' and 'end' keys
    max_silence_threshold: float = 2.0  # Maximum silence duration (in seconds) before creating a new chunk
) -> Tuple[List[Tuple[float, float]], List[List[Dict]]]:
    """Generate chunks using VAD timestamps with silence-based splitting"""
    chunks = []
    chunk_timestamps = []
    current_time = 0.0
    current_timestamps = []
    
    if duration > max_chunk_seconds and speech_timestamps:
        for i, timestamp in enumerate(speech_timestamps):
            start = timestamp['start']
            end = timestamp['end']
            
            # Check if there's a long silence between this timestamp and the next one
            create_chunk_due_to_silence = False
            if i < len(speech_timestamps) - 1:
                next_start = speech_timestamps[i + 1]['start']
                silence_duration = next_start - end
                
                # If silence is longer than threshold, end the chunk here
                if silence_duration > max_silence_threshold:
                    create_chunk_due_to_silence = True
            
            current_timestamps.append(timestamp)
            
            # Create a new chunk if:
            # 1. We've reached the max chunk duration, OR
            # 2. There's a long silence after this timestamp
            if (end - current_time + max_chunk_seconds_offset >= max_chunk_seconds) or create_chunk_due_to_silence:
                chunks.append((current_time, end))
                chunk_timestamps.append(current_timestamps)
                current_time = end
                current_timestamps = []
        
        # Handle remaining timestamps
        if current_timestamps:
            if chunks and duration - chunks[-1][1] < max_chunk_seconds:
                # If the remaining part is short, merge with previous chunk
                chunks[-1] = (chunks[-1][0], duration)
                chunk_timestamps[-1].extend(current_timestamps)
            else:
                # Create a new chunk for the remaining timestamps
                chunks.append((chunks[-1][1] if chunks else current_time, duration))
                chunk_timestamps.append(current_timestamps)
    else:
        # Single chunk for short audio or no timestamps
        chunks.append((0, duration))
        chunk_timestamps.append(speech_timestamps if speech_timestamps else [])
    
    return chunks, chunk_timestamps

# %% ../nbs/chunking.ipynb 8
def generate_intermediate_chunks(
    chunks: List[Tuple[float, float]],
    chunk_timestamps: List[List[Dict]],  # List of timestamp dictionaries for each chunk
    use_extended_boundaries: bool  # Whether to use extended boundaries from adjacent timestamps
) -> List[Tuple[float, float]]:  # List of tuples representing time intervals for intermediate chunks
    """Generate overlapping chunks between consecutive chunk boundaries"""
    intermediate_chunks = []
    
    if len(chunks) > 1 and len(chunk_timestamps) > 1:
        for i in range(len(chunks) - 1):
            if chunk_timestamps[i] and chunk_timestamps[i+1]:
                if use_extended_boundaries and i > 1:
                    intermediate_start = chunk_timestamps[i][-2]['end']
                else:
                    # last_timestamp = chunk_timestamps[i][-1]
                    intermediate_start = chunk_timestamps[i][-1]['start']
                if use_extended_boundaries and i < len(chunks)-2:
                    intermediate_end = chunk_timestamps[i+1][1]['start']
                else:
                    # first_timestamp = chunk_timestamps[i+1][0]
                    intermediate_end = chunk_timestamps[i+1][0]['end']
                
                intermediate_chunks.append((intermediate_start, intermediate_end))
    
    return intermediate_chunks

# %% ../nbs/chunking.ipynb 9
def generate_intermediate_chunk_tuples(
    chunks: List[Tuple[float, float]],
    chunk_timestamps: List[List[Dict]],  # List of timestamp dictionaries for each chunk
    use_extended_boundaries: bool  # Whether to use extended boundaries from adjacent timestamps
) -> List[Tuple[Dict, Dict]]:
    """Generate tuples of (last_timestamp, first_timestamp) from consecutive chunks."""
    intermediate_tuples = []
    
    if len(chunks) > 1 and len(chunk_timestamps) > 1:
        for i in range(len(chunks) - 1):
            if chunk_timestamps[i] and chunk_timestamps[i+1]:
                if use_extended_boundaries and i > 1:
                    last_timestamp = {'start': chunk_timestamps[i][-2]['end'], 'end': chunk_timestamps[i+1][0]['start']}
                else:
                    last_timestamp = chunk_timestamps[i][-1]
                if use_extended_boundaries and i < len(chunks)-2:
                    first_timestamp = {'start': chunk_timestamps[i][-1]['end'], 'end': chunk_timestamps[i+1][1]['start']}
                else:
                    first_timestamp = chunk_timestamps[i+1][0]
                
                intermediate_tuples.append((last_timestamp, first_timestamp))
    
    return intermediate_tuples

# %% ../nbs/chunking.ipynb 10
def merge_transcripts_with_overlaps(
    normal_transcripts: List[str],  # List of transcripts for normal chunks
    intermediate_transcripts: List[str],  # List of transcripts for intermediate chunks
    segment_transcripts: List[Tuple[str, str]],
    verbose: bool = True  # Whether to print debug information
) -> str:
    """Merge normal and intermediate transcripts with overlap correction"""
    if len(normal_transcripts) == 1:
        # No overlap correction needed for single chunk
        return normal_transcripts[0]
    
    # Process each intermediate transcript and its segments
    trimmed_intermediates = []
    segment_word_counts = []
    
    for i, (intermediate, (last_seg, first_seg)) in enumerate(zip(intermediate_transcripts, segment_transcripts)):
        # Trim first and last words from intermediate transcript
        intermediate_words = intermediate.strip().split()
        if len(intermediate_words) > 2:
            trimmed_intermediate = ' '.join(intermediate_words[1:-1])
        else:
            trimmed_intermediate = ""
        trimmed_intermediates.append(trimmed_intermediate)
        
        # Trim first word from last segment and last word from first segment
        last_seg_words = last_seg.strip().split()
        first_seg_words = first_seg.strip().split()
        
        # Count words after trimming
        last_word_count = len(last_seg_words[1:]) if len(last_seg_words) > 1 else 0
        first_word_count = len(first_seg_words[:-1]) if len(first_seg_words) > 1 else 0
        
        segment_word_counts.append((last_word_count, first_word_count))
        
    # Build the final transcript
    final_parts = []
    
    for i in range(len(normal_transcripts)):
        normal_words = normal_transcripts[i].strip().split()
        
        if i == 0:
            # First chunk - only trim end if there's an intermediate after it
            if i < len(segment_word_counts):
                words_to_remove_end = segment_word_counts[i][0]
                if words_to_remove_end > 0 and len(normal_words) > words_to_remove_end:
                    final_parts.append(' '.join(normal_words[:-words_to_remove_end]))
                else:
                    final_parts.append(normal_transcripts[i].strip())
                # Add the trimmed intermediate
                if trimmed_intermediates[i]:
                    final_parts.append(trimmed_intermediates[i])
            else:
                final_parts.append(normal_transcripts[i].strip())
                
        elif i == len(normal_transcripts) - 1:
            # Last chunk - only trim beginning
            if i - 1 < len(segment_word_counts):
                words_to_remove_start = segment_word_counts[i-1][1]
                if words_to_remove_start > 0 and len(normal_words) > words_to_remove_start:
                    final_parts.append(' '.join(normal_words[words_to_remove_start:]))
                else:
                    final_parts.append(normal_transcripts[i].strip())
            else:
                final_parts.append(normal_transcripts[i].strip())
                
        else:
            # Middle chunk - trim both beginning and end
            words_to_remove_start = segment_word_counts[i-1][1] if i - 1 < len(segment_word_counts) else 0
            words_to_remove_end = segment_word_counts[i][0] if i < len(segment_word_counts) else 0
            
            if words_to_remove_start > 0 or words_to_remove_end > 0:
                start_idx = words_to_remove_start
                end_idx = len(normal_words) - words_to_remove_end if words_to_remove_end > 0 else len(normal_words)
                
                if end_idx > start_idx:
                    final_parts.append(' '.join(normal_words[start_idx:end_idx]))
                else:
                    if verbose:
                        print(f"Warning: Chunk {i} heavily trimmed")
            else:
                final_parts.append(normal_transcripts[i].strip())
            
            # Add the trimmed intermediate after this chunk
            if i < len(trimmed_intermediates) and trimmed_intermediates[i]:
                final_parts.append(trimmed_intermediates[i])
    
    # Join all parts with spaces
    final_transcript = ' '.join(final_parts)
    
    # Clean up multiple spaces
    final_transcript = ' '.join(final_transcript.split())
    
    return final_transcript
