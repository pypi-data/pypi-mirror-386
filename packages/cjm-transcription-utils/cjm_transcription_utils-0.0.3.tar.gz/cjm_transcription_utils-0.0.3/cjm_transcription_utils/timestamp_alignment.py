"""Utilities for aligning VAD timestamps to corrected transcripts using fuzzy matching."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/timestamp_alignment.ipynb.

# %% auto 0
__all__ = ['TranscriptAligner', 'align_timestamps_to_transcript']

# %% ../nbs/timestamp_alignment.ipynb 3
import re
from rapidfuzz import fuzz
from typing import List, Dict, Tuple, Optional, Set
from difflib import SequenceMatcher

# %% ../nbs/timestamp_alignment.ipynb 4
class TranscriptAligner:
    """Aligns VAD timestamps to a corrected transcript using fuzzy matching."""
    def __init__(self, 
                 correct_transcript: str, # The full, correct transcript text
                 segment_transcripts: List[str], # List of individual segment transcriptions (may have errors)
                 timestamps: List[Dict[str, float]], # List of timestamp dictionaries with 'start' and 'end' keys
                 confidence_threshold: int = 70 # Minimum confidence score to accept an alignment
                ):
        """
        Initialize the transcript aligner with complete coverage and correction mechanisms.
        """
        self.correct_transcript = correct_transcript
        self.segment_transcripts = segment_transcripts
        self.timestamps = timestamps
        self.confidence_threshold = confidence_threshold
        
        # Tokenize transcripts
        self.correct_words = self._tokenize(correct_transcript)
        self.segment_words = [self._tokenize(self._normalize_for_comparison(seg)) for seg in segment_transcripts]
        
        # Track alignment quality
        self.alignment_scores = []
        
    def _tokenize(
        self,
        text: str  # Text to split into words
    ) -> List[str]:  # List of word tokens
        """Split text into words, preserving punctuation."""
        return text.split()
    
    def _normalize_for_comparison(
        self,
        text: str  # Text to normalize
    ) -> str:  # Normalized text for comparison
        """
        Normalize text for comparison by converting all number variations to digits
        and removing punctuation.
        """
        try:
            # Convert to lowercase
            normalized = text.lower()

            # Remove punctuation and extra spaces for comparison
            normalized = re.sub(r'[^\w\s]', '', normalized)
            normalized = ' '.join(normalized.split())  # Normalize whitespace

            return normalized
        except Exception:
            # If numerizer fails, just return cleaned text
            return re.sub(r'[^\w\s]', '', text.lower())
    
    def _find_best_match_in_range(self, seg_words: List[str], start_idx: int, 
                                   search_range: int = 50) -> Tuple[int, int, float]:
        """
        Find the best match for a segment within a specific range of the correct transcript.
        Returns (best_start, best_end, score).
        """
        seg_text = ' '.join(seg_words)
        seg_normalized = self._normalize_for_comparison(seg_text)
        
        best_start = start_idx
        best_end = start_idx + len(seg_words)
        best_score = 0
        
        # Allow for word count variation
        min_length = max(1, len(seg_words) - 3)
        max_length = len(seg_words) + 3
        
        # Search within the specified range
        search_start = max(0, start_idx - 5)
        search_end = min(len(self.correct_words), start_idx + search_range)
        
        for start in range(search_start, search_end):
            for length in range(min_length, min(max_length + 1, len(self.correct_words) - start + 1)):
                if start + length > len(self.correct_words):
                    break
                
                correct_segment = ' '.join(self.correct_words[start:start + length])
                correct_normalized = self._normalize_for_comparison(correct_segment)
                
                # Calculate similarity score
                if seg_normalized == correct_normalized:
                    score = 100  # Perfect match after normalization
                else:
                    # Use fuzzy matching on normalized text
                    score = fuzz.ratio(seg_normalized, correct_normalized)
                
                if score > best_score:
                    best_score = score
                    best_start = start
                    best_end = start + length
        
        return best_start, best_end, best_score
    
    def _find_best_alignment_with_recovery(
        self
    ) -> List[Tuple[int, int, int, float]]:  # List of (segment_idx, correct_start, correct_end, confidence_score) tuples
        """
        Find alignment with recovery mechanism for when alignment gets lost.
        Returns list of (segment_idx, correct_start, correct_end, confidence_score).
        """
        alignments = []
        correct_idx = 0
        consecutive_low_scores = 0
        
        for seg_idx, seg_words in enumerate(self.segment_words):
            seg_text = ' '.join(seg_words)
            
            # First try normal sequential alignment
            best_start, best_end, best_score = self._find_best_match_in_range(
                seg_words, correct_idx, search_range=30
            )
            
            # If confidence is too low, we might be misaligned - try a broader search
            if best_score < self.confidence_threshold:
                consecutive_low_scores += 1
                
                # After 3 consecutive low scores, do a global search to recover
                if consecutive_low_scores >= 3:
                    print(f"Attempting recovery at segment {seg_idx}...")
                    
                    # Search more broadly to find where we should be
                    recovery_start = max(0, correct_idx - 50)
                    recovery_best_start, recovery_best_end, recovery_score = self._find_best_match_in_range(
                        seg_words, recovery_start, search_range=200
                    )
                    
                    if recovery_score > best_score + 20:  # Significantly better match found
                        best_start = recovery_best_start
                        best_end = recovery_best_end
                        best_score = recovery_score
                        print(f"  Recovery successful! Score improved from {best_score:.1f} to {recovery_score:.1f}")
                        consecutive_low_scores = 0
            else:
                consecutive_low_scores = 0
            
            # Store alignment score for analysis
            self.alignment_scores.append(best_score)
            
            # Warn about low confidence alignments
            if best_score < self.confidence_threshold:
                print(f"Warning: Low confidence for segment {seg_idx} (score: {best_score:.1f})")
                print(f"  Segment: '{seg_text[:50]}...'")
                print(f"  Matched: '{' '.join(self.correct_words[best_start:min(best_end, best_start+10)])}...'")
            
            alignments.append((seg_idx, best_start, best_end, best_score))
            correct_idx = best_end
        
        return alignments
    
    def align_timestamps_to_correct_transcript(
        self
    ) -> List[Dict]:  # List of alignment dictionaries with timestamp, text, and confidence info
        """
        Align timestamps to the correct transcript with optional corrections.
        """
        alignments = self._find_best_alignment_with_recovery()
        
        result = []
        for seg_idx, correct_start, correct_end, score in alignments:
            # Ensure we don't go out of bounds
            correct_end = min(correct_end, len(self.correct_words))
            correct_text = ' '.join(self.correct_words[correct_start:correct_end])
            original_text = ' '.join(self.segment_words[seg_idx])
            
            result.append({
                'timestamp': self.timestamps[seg_idx],
                'correct_text': correct_text,
                'original_text': original_text,
                'word_indices': (correct_start, correct_end),
                'confidence': score,
                'was_corrected': score == 100.0 and original_text != correct_text  # Mark if it was corrected
            })
        
        return result

# %% ../nbs/timestamp_alignment.ipynb 6
def align_timestamps_to_transcript(
    final_transcript: str,  # The final merged transcript
    timestamp_transcripts: List[str],  # List of transcripts for each timestamp segment
    speech_timestamps: List[Dict],  # List of speech timestamp dictionaries
    verbose: bool = True  # Whether to print alignment details
) -> List[Dict]:
    """Align timestamp segments to the final transcript."""
    # Create aligner and process
    aligner = TranscriptAligner(final_transcript, timestamp_transcripts, speech_timestamps)
    
    # Get aligned transcript
    aligned = aligner.align_timestamps_to_correct_transcript()
    
    return aligned
