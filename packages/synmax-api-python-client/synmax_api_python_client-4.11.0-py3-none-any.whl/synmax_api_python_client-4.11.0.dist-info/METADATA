Metadata-Version: 2.1
Name: synmax-api-python-client
Version: 4.11.0
Summary: Synmax API client
Home-page: https://github.com/SynMaxDev/synmax-api-python-client.git
Author: SynMax Inc.
Author-email: support@synmax.com
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: aiohttp>=3.11.14
Requires-Dist: aioretry>=6.3.1
Requires-Dist: matplotlib>=3.10.1
Requires-Dist: packaging>=24.2
Requires-Dist: pandas>=2.2.3
Requires-Dist: pydantic>=2.10.6
Requires-Dist: pydantic-core<2.32.0,>=2.27.2
Requires-Dist: requests>=2.32.3
Requires-Dist: tenacity>=9.0.0
Requires-Dist: tqdm>=4.67.1
Requires-Dist: urllib3>=2.3.0
Requires-Dist: prance>=25.4.8.0
Requires-Dist: openapi-spec-validator>=0.7.1
Requires-Dist: httpx>=0.28.1

# Synmax API Client

## Installation

If you just want to use the package, run:

```bash
pip install --upgrade synmax-api-python-client


```

### Requirements

Make sure you have [Python 3.10+](https://docs.python.org/3/) and [pip](https://pypi.org/project/pip/) installed.

## Quickstart

    Hyperion API Swagger doc: https://hyperion.api.synmax.com/apidocs/#/default

### Jupyter notebook setting
    run this block of code at the beggining of synmax api client
```python

!pip install nest_asyncio

import nest_asyncio
nest_asyncio.apply()

After this run your code as usual.
```
### Configuring synmax client

```python

import logging
from synmax.hyperion import HyperionApiClient, ApiPayload

# enable debug if required.
logging.basicConfig(level=logging.DEBUG)

# two ways to pass access token.
# 1. Set environment variables: os.environ['access_token'] = 'your token'
# OR
# 2. pass to HyperionApiClient instance
access_token = 'your access token goes here'
hyperion_client = HyperionApiClient(access_token=access_token)

```

#### Fetching data based on your subscription key (access_key)

```python
from synmax.hyperion import HyperionApiClient, ApiPayload

hyperion_client = HyperionApiClient(access_token='....')
# fetch regions
region_df = hyperion_client.fetch_regions()
print(region_df.count())


```

#### Paginated data

```python

import logging
from synmax.hyperion import HyperionApiClient, ApiPayload

# enable debug if required.
logging.basicConfig(level=logging.DEBUG)

# two ways to pass access token.
# 1. Set environment variables: os.environ['access_token'] = 'your token'
# 2. pass to HyperionApiClient instance
access_token = 'your access token goes here'
hyperion_client = HyperionApiClient(access_token=access_token)

# well completion based on input filters of type ApiPayload;
# fetch_all = True will paginate all of rows and return accumulation of each page result. True by default
# set fetch_all=False to get first page or any single page starting row with payload.pagination_start = <start row index, default to 0>
payload = ApiPayload(start_date='2022-06-1', end_date='2022-06-25', state_code='TX')

# return result is in pandas.DataFrame
completions_df = hyperion_client.well_completion(payload)
print(completions_df.count())
# output is in pandas.DataFrame
# Querying API pages: 100%|██████████| 8/8 [00:06<00:00,  1.14it/s]

# with optional payload to fetch full dataset
result_df = hyperion_client.wells()
print(result_df.count())
# Querying API wells pages:   0%|          | 4/7225 [00:16<8:51:17,  4.41s/it]


## Well data
result_df = hyperion_client.wells(payload)

## Product by Country and Operator
result_df = hyperion_client.production_by_county_and_operator(payload)

## Available api methods on hyperion_client
dir(hyperion_client)
# output: ['ducs_by_operator', 'fetch_regions', 'frac_crews', 'production_by_county_and_operator', 'production_by_well', 'rigs', 'well_completion', 'wells']

```

## publishing package

```shell
pip install twine
pip install wheel

python setup.py bdist_wheel

twine upload dist/*


python setup.py clean --all


```

## pre-commit hooks
   ```bash

      pip install pre-commit
      run 'pre-commit install'

      # Run one time to fix any existing files
      pre-commit run --all-files


   ```
