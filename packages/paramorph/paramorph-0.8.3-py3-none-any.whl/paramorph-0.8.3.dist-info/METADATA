Metadata-Version: 2.4
Name: paramorph
Version: 0.8.3
Summary: Inephany client library to use Paramorph Agents.
Author-email: Inephany <info@inephany.com>
License: Apache 2.0
Keywords: paramorph,agents,client
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch<2.9.0,>=2.1.0
Requires-Dist: numpy<2.0.0,>=1.24.0
Requires-Dist: loguru<0.8.0,>=0.7.0
Requires-Dist: plotly<6.0.0,>=5.15.0
Requires-Dist: requests<3.0.0,>=2.28.0
Requires-Dist: pydantic<3.0.0,>=2.5.0
Requires-Dist: urllib3<3.0.0,>=2.0.0
Requires-Dist: PyYAML<7.0.0,>=6.0.0
Requires-Dist: libinephany<1.0.0,>=0.13.0
Provides-Extra: dev
Requires-Dist: pytest<9.0.0,>=7.0.0; extra == "dev"
Requires-Dist: pytest-mock<4.0.0,>=3.10.0; extra == "dev"
Requires-Dist: bump-my-version==0.11.0; extra == "dev"
Requires-Dist: black==24.4.2; extra == "dev"
Requires-Dist: isort==5.9.3; extra == "dev"
Requires-Dist: flake8==7.1.0; extra == "dev"
Requires-Dist: pre-commit==4.0.1; extra == "dev"
Requires-Dist: mypy==1.13.0; extra == "dev"
Requires-Dist: types-PyYAML>=6.0.12; extra == "dev"
Requires-Dist: types-redis>=4.5.0; extra == "dev"
Requires-Dist: types-requests>=2.28.0; extra == "dev"
Requires-Dist: types-cachetools>=6.1.0; extra == "dev"
Requires-Dist: typeguard==4.3.0; extra == "dev"
Requires-Dist: lightning<3.0.0,>=2.0.0; extra == "dev"
Provides-Extra: lightning
Requires-Dist: lightning<3.0.0,>=2.0.0; extra == "lightning"
Dynamic: license-file

# Paramorph Client Library

Paramorph is a client library that provides automated hyperparameter tuning for neural network training. It integrates seamlessly with Hugging Face Transformers and other PyTorch-based training frameworks to dynamically adjust learning rates, weight decay, and other hyperparameters during training.

## Features

- **Automated Hyperparameter Tuning**: Dynamically adjusts learning rates, weight decay, and other optimizer parameters
- **Hugging Face Integration**: Built-in support for Hugging Face Transformers with minimal code changes
- **Multi-Agent Architecture**: Uses specialized agents for different parameter groups (embeddings, attention, linear layers, convolutions)
- **Real-time Monitoring**: Integrates with Weights & Biases for experiment tracking
- **Flexible Configuration**: Easy-to-use YAML configuration system

## Installation

### Prerequisites

- Python 3.10+
- PyTorch
- Hugging Face Transformers (for HF integration)
- [Optional] Weights & Biases account and API key (for experiment tracking and logging)

### Setup

Paramorph depends on the `libinephany` package, which provides core utilities and data models. Installation instructions differ based on your use case:

Ensure that python3.12 and make is installed:

#### Ubuntu / Debian
```commandline
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.12
```

#### MacOS with brew
```commandline
brew install python@3.12
```

#### For Developers (Monorepo)
If you're working within the Inephany monorepo, the `libinephany` package is already available and will be installed into the venv created for this package when you run `make install-dev`.

#### For Clients (Standalone Installation)
Both `libinephany` and `paramorph` are available on PyPI and can be installed directly:

# Optional but recommended
```bash
python -m pip install --upgrade pip
```

# Install paramorph (libinephany will be installed as a depencency)
```bash
python -m pip install paramorph
```

For development installations with additional dependencies:

```bash
pip install libinephany[dev] paramorph[dev]
```

Then generate an API key in the portal and export it:
```commandline
export PARAMORPH_API_KEY=YOUR_API_KEY
```

### Getting Help

- Check the example scripts in the repository
- Review the configuration file format
- Ensure all dependencies are installed correctly
- Verify your model architecture matches the agent module mapping

## License

This package is licensed under the Apache License, Version 2.0. See the LICENSE file for details.
