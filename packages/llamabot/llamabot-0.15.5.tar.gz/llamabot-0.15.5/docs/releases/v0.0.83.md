## Version 0.0.83

This new version introduces more flexibility and control over the token budget and chunk sizes used in the chatbot. It also includes a new attribute to store the model name used by the bot and a bug fix to ensure multiple document paths are handled correctly.

### New Features

- Added support for `response_tokens` and `history_tokens` parameters in the `QueryBot` class. These parameters allow the user to specify the number of tokens to use for the response and history in the chatbot. Also, a `chunk_sizes` parameter has been added to the `make_or_load_vector_index` function to specify a list of chunk sizes to use for the LlamaIndex TokenTextSplitter (a1de812) (Eric Ma)
- Introduced a new attribute 'model_name' to both QueryBot and SimpleBot classes. This attribute will be used to store the name of the model used by the bot (d5d684) (Eric Ma)

### Bug Fixes

- Modified the `doc_paths` parameter in the chat function of the llamabot/cli/doc.py file to receive a list of doc_paths, ensuring that the function can handle multiple document paths correctly (c763327) (Eric Ma)
- Changed the variable name in the chat function from `doc_path` to `doc_paths` for better clarity and consistency (11111e) (Eric Ma)

### Deprecations

- No deprecations in this release.
