{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# LLaMaBot's `StructuredBot` in under 5 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "When using LLMs, an ideal goal would be to \n",
    "pull structured data out of unstructured text. \n",
    "When the data is structured, \n",
    "we can then use it programmatically in later steps.\n",
    "\n",
    "In this example, we'll look at a small dataset of SciPy videos uploaded to YouTube. \n",
    "The videos are given a title and a description. \n",
    "We want to extract the name of the speaker giving the talk, \n",
    "and the topics the talk is about.\n",
    "We also want to be able to validate the data we've extracted \n",
    "not only matches the structured format we expect, \n",
    "but that it also meets some custom requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read video descriptions\n",
    "\n",
    "Firstly, let's look at the video descriptions file. \n",
    "It is stored as a JSON file.\n",
    "We can read it into pandas by using `pd.read_json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "# load in unstructured text data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"../scipy_videos.json\", orient=\"index\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Let's now define a Pydantic schema for the data that we wish to extract from movie entry.\n",
    "This is doen by defining a BaseModel class and field validators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "\n",
    "class TopicExtract(BaseModel):\n",
    "    \"\"\"This object stores the name of the speaker presenting the video.\n",
    "\n",
    "    It also generates a list of topics\n",
    "    that best describe what this talk is about.\n",
    "    \"\"\"\n",
    "\n",
    "    speaker_name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"The name of the speaker giving this talk. \"\n",
    "            \"If there is no speaker named, leave empty.\"\n",
    "        ),\n",
    "    )\n",
    "    topics: List[str] = Field(\n",
    "        description=(\n",
    "            \"A list of upto 5 topics that this text is about. \"\n",
    "            \"Each topic should be at most 1 or 2 word descriptions. \"\n",
    "            \"All lowercase.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    @field_validator(\"topics\")\n",
    "    def validate_num_topics(cls, topics):\n",
    "        # validate that the list of topics contains atleast 1, and no more than 5 topics\n",
    "        if len(topics) <= 0 or len(topics) > 5:\n",
    "            raise ValueError(\"The list of topics can be no more than 5 items\")\n",
    "        return topics\n",
    "\n",
    "    @field_validator(\"topics\")\n",
    "    def validate_num_topic_words(cls, topics):\n",
    "        # for each topic the model generated, ensure that the topic contains no more than 2 words\n",
    "        for topic in topics:\n",
    "            if len(topic.split()) > 2:\n",
    "                # make the validation message helpful to the LLM.\n",
    "                # Here we repeat which topic is failing validation, and remind it what it must do to pass the validation.\n",
    "                raise ValueError(\n",
    "                    f'The topic \"{topic}\" has too many words, A topic can contain AT MOST 2 words'\n",
    "                )\n",
    "        return topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize the PydanticBot and assign this model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot import prompt, StructuredBot\n",
    "\n",
    "\n",
    "@prompt\n",
    "def topicbot_sysprompt() -> str:\n",
    "    \"\"\"You are an expert topic labeller.\n",
    "    You read a video title and description\n",
    "    and extract the speakers name and the topics the video is about.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Will use the OpenAI API by default, which requires an API key.\n",
    "# If you want to, you can change this to a local LLM (from Ollama)\n",
    "# by specifying, say, `model_name=\"ollama/mistral\"`.\n",
    "bot = StructuredBot(\n",
    "    system_prompt=topicbot_sysprompt(),\n",
    "    temperature=0,\n",
    "    pydantic_model=TopicExtract,\n",
    "    # model_name=\"ollama/mistral\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Now we can pass in our text, and extract the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "video_extracts = []\n",
    "for index, video_row in df.iterrows():\n",
    "    video_text = f\"video title: {video_row['name']}\\nvideo description: {video_row['description']}\"\n",
    "\n",
    "    extract = bot(video_text)\n",
    "\n",
    "    video_extracts.append(extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect what the topics looked like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in video_extracts:\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's pretty accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "keep_output": true,
   "language": "python",
   "name": "llamabot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
