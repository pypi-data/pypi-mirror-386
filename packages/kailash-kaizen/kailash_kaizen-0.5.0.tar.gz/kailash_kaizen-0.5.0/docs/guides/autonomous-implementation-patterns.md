# Autonomous Implementation Patterns

**Author**: Kaizen Framework Team
**Date**: 2025-10-22
**Purpose**: Complete implementation guide for autonomous agents in Kaizen

---

## Executive Summary

This guide provides production-ready patterns for implementing autonomous agents that follow Claude Code's `while(tool_call_exists)` architecture. All patterns are battle-tested in Kaizen's production agents.

**Core Pattern**: MultiCycleStrategy + Objective Convergence Detection

---

## ðŸŽ¯ Production-Ready Autonomous Agents (NEW v0.2.0)

Kaizen now provides three production-ready autonomous agent implementations based on proven patterns from Claude Code and Codex:

### BaseAutonomousAgent
**Purpose**: Foundation for all autonomous agents with core agent loop pattern.
- Multi-cycle autonomous execution (20 cycles default)
- TODO-based planning system
- JSONL checkpoint format for recovery
- Objective convergence detection (ADR-013)
- Configurable max cycles

**Implementation**: `src/kaizen/agents/autonomous/base.py` (532 lines)
**Tests**: 26 passing tests
**Documentation**: [autonomous-patterns.md](autonomous-patterns.md)

### ClaudeCodeAgent
**Purpose**: Implements Claude Code's proven 15-tool autonomous coding architecture.
- 15-tool ecosystem (file, search, execution, web, workflow)
- Diff-first workflow (show changes before applying)
- System reminders (combat model drift)
- Context management (92% compression trigger)
- CLAUDE.md project memory
- 100+ cycle sessions (30+ hours)

**Implementation**: `src/kaizen/agents/autonomous/claude_code.py` (691 lines)
**Tests**: 38 passing tests
**Documentation**: [claude-code-agent.md](claude-code-agent.md)

### CodexAgent
**Purpose**: Implements Codex's container-based PR generation architecture.
- Container-based execution (isolated environment)
- AGENTS.md configuration (project conventions)
- Test-driven iteration (run â†’ parse â†’ fix â†’ repeat)
- Professional PR generation
- Logging and evidence system
- 1-30 minute one-shot workflows

**Implementation**: `src/kaizen/agents/autonomous/codex.py` (690 lines)
**Tests**: 36 passing tests
**Documentation**: [codex-agent.md](codex-agent.md)

### Quick Start

```python
# 1. BaseAutonomousAgent - General purpose
from kaizen.agents.autonomous import BaseAutonomousAgent, AutonomousConfig

config = AutonomousConfig(llm_provider="openai", model="gpt-4", max_cycles=20)
agent = BaseAutonomousAgent(config, signature, registry)
result = await agent.execute_autonomously("Research quantum computing applications")

# 2. ClaudeCodeAgent - Long coding sessions
from kaizen.agents.autonomous import ClaudeCodeAgent, ClaudeCodeConfig

config = ClaudeCodeConfig(llm_provider="openai", model="gpt-4", max_cycles=100)
agent = ClaudeCodeAgent(config, signature, registry)
result = await agent.execute_autonomously("Refactor authentication module")

# 3. CodexAgent - PR generation
from kaizen.agents.autonomous import CodexAgent, CodexConfig

config = CodexConfig(llm_provider="openai", model="gpt-4", timeout_minutes=30)
agent = CodexAgent(config, signature, registry)
result = await agent.execute_autonomously("Fix bug #123 and add tests")
```

### Examples

Working examples available in `examples/autonomy/`:
- `01_base_autonomous_agent_demo.py` - BaseAutonomousAgent with 3 demos
- `02_claude_code_agent_demo.py` - ClaudeCodeAgent with 4 demos
- `03_codex_agent_demo.py` - CodexAgent with 5 demos

### Building Custom Agents

See [build-autonomous-agent.md](../tutorials/build-autonomous-agent.md) for a comprehensive tutorial on building custom autonomous agents.

---

## Pattern Library

The following sections provide implementation patterns that can be applied when building custom autonomous agents. These patterns are demonstrated in the production-ready agents above.

---

## Table of Contents

1. [Basic Autonomous Agent](#basic-autonomous-agent)
2. [Convergence Detection Patterns](#convergence-detection-patterns)
3. [Tool-Calling Autonomous Agent](#tool-calling-autonomous-agent)
4. [Research & Refinement Agent](#research--refinement-agent)
5. [Code Generation & Testing Agent](#code-generation--testing-agent)
6. [Multi-Agent Autonomous Coordination](#multi-agent-autonomous-coordination)
7. [Error Handling & Recovery](#error-handling--recovery)
8. [Testing Autonomous Agents](#testing-autonomous-agents)

---

## Basic Autonomous Agent

### Minimal Implementation

```python
from kaizen.core.base_agent import BaseAgent
from kaizen.signatures import Signature, InputField, OutputField
from kaizen.strategies.multi_cycle import MultiCycleStrategy
from dataclasses import dataclass
from typing import Dict, Any

# 1. Define configuration with max_cycles
@dataclass
class AutonomousConfig:
    llm_provider: str = "openai"
    model: str = "gpt-4"
    temperature: float = 0.7
    max_cycles: int = 10  # CRITICAL for autonomous execution

# 2. Define signature with tool_calls field
class AutonomousSignature(Signature):
    task: str = InputField(desc="Task to accomplish")
    thought: str = OutputField(desc="Agent reasoning")
    action: str = OutputField(desc="Action to take")
    tool_calls: list = OutputField(desc="Tools to call (empty = done)")

# 3. Implement autonomous agent
class BasicAutonomousAgent(BaseAgent):
    """Minimal autonomous agent with convergence detection."""

    def __init__(self, config: AutonomousConfig):
        # Create multi-cycle strategy
        strategy = MultiCycleStrategy(
            max_cycles=config.max_cycles,
            convergence_check=self._check_convergence
        )

        # Initialize BaseAgent
        super().__init__(
            config=config,
            signature=AutonomousSignature(),
            strategy=strategy  # CRITICAL
        )

        self.config_obj = config

    def _check_convergence(self, result: Dict[str, Any]) -> bool:
        """
        Objective convergence detection.

        Returns:
            True if converged (stop), False if continue
        """
        # Check tool_calls field
        tool_calls = result.get("tool_calls", [])

        if not isinstance(tool_calls, list):
            return True  # Invalid format â†’ stop

        if tool_calls:
            return False  # Has tools â†’ continue

        return True  # Empty tools â†’ converged

    def solve(self, task: str) -> Dict[str, Any]:
        """Execute autonomous task solving."""
        return self.run(task=task)
```

### Usage

```python
# Create agent
config = AutonomousConfig(max_cycles=10)
agent = BasicAutonomousAgent(config)

# Execute autonomously
result = agent.solve("Research quantum computing applications")

# Result contains:
# - thought: Agent's reasoning
# - action: Action taken
# - tool_calls: [] (empty = converged)
# - cycles_used: Actual cycles (e.g., 5)
# - total_cycles: Max cycles (10)
```

---

## Convergence Detection Patterns

### Pattern 1: Objective Convergence (Preferred)

**Best For**: Tool-calling agents (ReAct, RAGResearch, CodeGen)

```python
def _check_convergence(self, result: Dict[str, Any]) -> bool:
    """
    Objective convergence via tool_calls field.

    Claude Code pattern: while(tool_call_exists)

    Advantages:
    - Deterministic (no hallucination)
    - JSON-structured
    - 100% reliable
    """
    tool_calls = result.get("tool_calls", [])

    # Validation
    if not isinstance(tool_calls, list):
        return True  # Malformed â†’ stop

    # Objective check
    if tool_calls:
        return False  # Has pending tools â†’ continue

    return True  # No tools â†’ converged
```

**Accuracy**: 100% (vs 85-95% for subjective)

### Pattern 2: Subjective Convergence (Legacy)

**Best For**: Non-tool agents (SelfReflection, Debate)

```python
def _check_convergence(self, result: Dict[str, Any]) -> bool:
    """
    Subjective convergence via LLM output fields.

    Disadvantages:
    - LLM can hallucinate "finish"
    - Confidence scores unreliable
    - 85-95% accuracy
    """
    # Check action field
    if result.get("action") == "finish":
        return True

    # Check confidence threshold
    confidence = result.get("confidence", 0)
    if confidence >= 0.85:
        return True

    return False  # Continue
```

**Accuracy**: 85-95% (LLM-dependent)

### Pattern 3: Hybrid Convergence (Recommended)

**Best For**: All autonomous agents

```python
def _check_convergence(self, result: Dict[str, Any]) -> bool:
    """
    Hybrid: objective preferred, subjective fallback.

    Priority order:
    1. OBJECTIVE: Check tool_calls (if present)
    2. SUBJECTIVE: Check action/confidence (if tool_calls missing)
    3. DEFAULT: Converged (safe fallback)
    """
    # 1. OBJECTIVE (preferred)
    if "tool_calls" in result:
        tool_calls = result.get("tool_calls", [])
        if isinstance(tool_calls, list):
            if tool_calls:
                return False  # Has tools â†’ continue
            return True  # Empty tools â†’ converged

    # 2. SUBJECTIVE (fallback)
    if result.get("action") == "finish":
        return True

    confidence = result.get("confidence", 0)
    if confidence >= 0.85:
        return True

    # 3. DEFAULT (safe)
    return True  # Assume converged if uncertain
```

**Accuracy**: 95-100% (best of both)

---

## Tool-Calling Autonomous Agent

### Implementation

```python
from kaizen.tools import ToolRegistry
from kaizen.tools.builtin import register_builtin_tools

class ToolCallingAgent(BaseAgent):
    """Autonomous agent with tool calling."""

    def __init__(self, config):
        # Setup tool registry
        self.tool_registry = ToolRegistry()
        register_builtin_tools(self.tool_registry)  # 12 builtin tools

        # Multi-cycle strategy
        strategy = MultiCycleStrategy(
            max_cycles=config.max_cycles,
            convergence_check=self._check_convergence
        )

        # Initialize with tools
        super().__init__(
            config=config,
            signature=ToolSignature(),
            strategy=strategy,
            tool_registry=self.tool_registry  # Enable tool calling
        )

    def _check_convergence(self, result: Dict[str, Any]) -> bool:
        """Converge when no more tools needed."""
        tool_calls = result.get("tool_calls", [])
        return len(tool_calls) == 0 if isinstance(tool_calls, list) else True

    async def execute_with_tools(self, task: str):
        """
        Autonomous execution with tool calling.

        Cycle 1: Plan â†’ tool_calls = [read_file]
        Cycle 2: Observe result â†’ tool_calls = [write_file]
        Cycle 3: Verify â†’ tool_calls = []
        """
        return await self.run_async(task=task)
```

### Tool Execution Flow

```
Cycle 1:
  Input: task = "Read config.yaml and create backup"
  LLM: thought = "Need to read file first"
       action = "tool_use"
       tool_calls = [{"name": "read_file", "params": {"path": "config.yaml"}}]
  â†’ NOT converged (has tool_calls)
  â†’ Execute read_file
  â†’ Feed result to next cycle

Cycle 2:
  Input: task + previous_result
  LLM: thought = "File read successfully, now backup"
       action = "tool_use"
       tool_calls = [{"name": "write_file", "params": {...}}]
  â†’ NOT converged (has tool_calls)
  â†’ Execute write_file
  â†’ Feed result to next cycle

Cycle 3:
  Input: task + all_previous_results
  LLM: thought = "Backup created successfully"
       action = "finish"
       tool_calls = []
  â†’ CONVERGED (empty tool_calls)
  â†’ Return final result
```

---

## Research & Refinement Agent

### Use Case

Iterative research: query â†’ fetch â†’ analyze â†’ refine â†’ repeat

### Implementation

```python
class RAGResearchAgent(BaseAgent):
    """Autonomous research agent with iterative refinement."""

    def __init__(self, config):
        strategy = MultiCycleStrategy(
            max_cycles=config.max_cycles,  # 10-15 for research
            convergence_check=self._check_convergence
        )

        super().__init__(
            config=config,
            signature=ResearchSignature(),
            strategy=strategy,
            tool_registry=tool_registry  # web_search, fetch_url, etc.
        )

    def _check_convergence(self, result: Dict[str, Any]) -> bool:
        """
        Research-specific convergence.

        Converge when:
        1. No more tools needed (objective)
        2. Research depth sufficient (subjective)
        3. Max cycles reached (safety)
        """
        # Objective: no more tools
        tool_calls = result.get("tool_calls", [])
        if isinstance(tool_calls, list) and len(tool_calls) == 0:
            return True

        # Subjective: confidence in research completeness
        confidence = result.get("confidence", 0)
        depth = result.get("research_depth", "shallow")

        if confidence >= 0.9 and depth == "comprehensive":
            return True

        return False  # Continue researching

    async def research(self, query: str) -> Dict[str, Any]:
        """
        Autonomous research with iterative refinement.

        Cycle 1: Plan search strategy
        Cycle 2: Execute web_search
        Cycle 3: Fetch top results
        Cycle 4: Analyze content
        Cycle 5: Identify gaps
        Cycle 6: Additional queries
        ...
        Cycle N: Synthesize comprehensive report
        """
        return await self.run_async(query=query)
```

### Research Flow

```
Cycle 1: Plan
  thought: "Need to research quantum computing applications"
  tool_calls: [web_search("quantum computing applications 2024")]

Cycle 2: Initial Search
  thought: "Found 10 results, fetch top 3"
  tool_calls: [fetch_url(url1), fetch_url(url2), fetch_url(url3)]

Cycle 3: Analyze
  thought: "Missing information on cryptography, search deeper"
  tool_calls: [web_search("quantum cryptography applications")]

Cycle 4: Deeper Search
  thought: "Now have comprehensive coverage"
  tool_calls: []  # Converged

Result: Comprehensive research report
```

---

## Code Generation & Testing Agent

### Use Case

Generate â†’ Test â†’ Fix cycles until code works

### Implementation

```python
class CodeGenerationAgent(BaseAgent):
    """Autonomous code generation with testing."""

    def __init__(self, config):
        strategy = MultiCycleStrategy(
            max_cycles=config.max_cycles,  # 5-10 for code gen
            convergence_check=self._check_convergence
        )

        super().__init__(
            config=config,
            signature=CodeGenSignature(),
            strategy=strategy,
            tool_registry=tool_registry  # write_file, bash_command, etc.
        )

    def _check_convergence(self, result: Dict[str, Any]) -> bool:
        """
        Code-specific convergence.

        Converge when:
        1. No more tools needed (objective)
        2. Tests passing (verification)
        3. No syntax errors (validation)
        """
        # Objective: no pending actions
        tool_calls = result.get("tool_calls", [])
        if isinstance(tool_calls, list):
            if len(tool_calls) == 0:
                # Verify tests passed
                test_status = result.get("test_status", "unknown")
                if test_status == "passed":
                    return True  # Tests pass â†’ done

        return False  # Continue refining

    async def generate_code(self, task: str) -> Dict[str, Any]:
        """
        Autonomous code generation with testing.

        Cycle 1: Generate initial code
        Cycle 2: Write to file
        Cycle 3: Run tests (bash_command)
        Cycle 4: Observe failures
        Cycle 5: Fix code
        Cycle 6: Re-run tests
        ...
        Cycle N: Tests pass â†’ converged
        """
        return await self.run_async(task_description=task)
```

### Code Gen Flow

```
Cycle 1: Generate
  thought: "Creating fibonacci function"
  tool_calls: [write_file("fibonacci.py", code)]

Cycle 2: Test
  thought: "Testing implementation"
  tool_calls: [bash_command("python -m pytest test_fibonacci.py")]

Cycle 3: Fix (test failed)
  thought: "Off-by-one error, fixing"
  tool_calls: [write_file("fibonacci.py", fixed_code)]

Cycle 4: Re-test
  thought: "Running tests again"
  tool_calls: [bash_command("python -m pytest test_fibonacci.py")]

Cycle 5: Verify
  thought: "All tests passed"
  tool_calls: []  # Converged
  test_status: "passed"

Result: Working code with passing tests
```

---

## Multi-Agent Autonomous Coordination

### Use Case

Supervisor coordinates autonomous workers

### Implementation

```python
from kaizen.agents.coordination import SupervisorWorkerPattern

class AutonomousSupervisor(BaseAgent):
    """Supervisor coordinating autonomous worker agents."""

    def __init__(self, config, workers):
        self.workers = workers

        strategy = MultiCycleStrategy(
            max_cycles=config.max_cycles,
            convergence_check=self._check_convergence
        )

        super().__init__(
            config=config,
            signature=SupervisorSignature(),
            strategy=strategy
        )

    def _check_convergence(self, result: Dict[str, Any]) -> bool:
        """
        Supervisor converges when all workers complete.
        """
        # Check if more delegation needed
        pending_tasks = result.get("pending_tasks", [])
        if pending_tasks:
            return False  # More work to delegate

        # Check worker status
        workers_done = result.get("workers_done", False)
        if not workers_done:
            return False  # Workers still running

        return True  # All workers done

    async def coordinate(self, task: str):
        """
        Autonomous multi-agent coordination.

        Cycle 1: Analyze task, select workers
        Cycle 2: Delegate to worker A (autonomous)
        Cycle 3: Observe worker A result
        Cycle 4: Delegate to worker B (autonomous)
        Cycle 5: Observe worker B result
        Cycle 6: Merge results
        Cycle 7: Verify completeness â†’ converged
        """
        return await self.run_async(task=task)
```

### Coordination Flow

```
Supervisor Cycle 1:
  thought: "Complex task, need DataAgent and CodeAgent"
  action: "delegate"
  pending_tasks: ["analyze_data", "generate_code"]

Supervisor Cycle 2:
  DataAgent (autonomous, 5 cycles):
    â†’ Cycle 1: Read data
    â†’ Cycle 2: Analyze
    â†’ Cycle 3: Generate insights
    â†’ Cycle 4: Verify
    â†’ Cycle 5: Converged
  thought: "DataAgent completed"
  pending_tasks: ["generate_code"]

Supervisor Cycle 3:
  CodeAgent (autonomous, 7 cycles):
    â†’ Cycle 1-7: Generate â†’ Test â†’ Fix â†’ ...
  thought: "CodeAgent completed"
  pending_tasks: []

Supervisor Cycle 4:
  thought: "All workers done, merging results"
  workers_done: true
  â†’ Converged
```

---

## Error Handling & Recovery

### Resilient Autonomous Agent

```python
class ResilientAgent(BaseAgent):
    """Autonomous agent with error recovery."""

    def __init__(self, config):
        strategy = MultiCycleStrategy(
            max_cycles=config.max_cycles,
            convergence_check=self._check_convergence
        )

        super().__init__(
            config=config,
            signature=ResilientSignature(),
            strategy=strategy
        )

        self.retry_attempts = config.retry_attempts
        self.error_history = []

    def _check_convergence(self, result: Dict[str, Any]) -> bool:
        """Converge on success OR max retries."""
        # Success convergence
        if result.get("status") == "success":
            return True

        # Error convergence (max retries)
        if len(self.error_history) >= self.retry_attempts:
            return True  # Give up after max retries

        # Continue retrying
        return False

    async def execute_with_retry(self, task: str):
        """
        Autonomous execution with exponential backoff.

        Cycle 1: Attempt task
        Cycle 2: Error â†’ wait 1s â†’ retry
        Cycle 3: Error â†’ wait 2s â†’ retry
        Cycle 4: Success â†’ converged
        """
        result = await self.run_async(task=task)

        if result.get("status") == "success":
            return result
        else:
            # Return partial result with error history
            result["error_history"] = self.error_history
            return result
```

---

## Testing Autonomous Agents

### Test Pattern

```python
import pytest

class TestAutonomousAgent:
    """Comprehensive tests for autonomous agents."""

    @pytest.fixture
    def agent(self):
        config = AutonomousConfig(max_cycles=10)
        return BasicAutonomousAgent(config)

    def test_convergence_early_stopping(self, agent):
        """Test that agent converges before max cycles."""
        result = agent.solve("Simple task")

        # Should converge early
        assert result["cycles_used"] < 10, "Should converge before max"

        # Should have empty tool_calls
        assert len(result.get("tool_calls", [])) == 0, "Should converge with no tools"

    def test_max_cycles_enforcement(self, agent):
        """Test that agent stops at max cycles."""
        # Complex task that won't converge
        result = agent.solve("Impossible task")

        # Should hit max cycles
        assert result["cycles_used"] == 10, "Should enforce max cycles"

    def test_objective_convergence_accuracy(self, agent):
        """Test convergence detection accuracy."""
        results = []

        for i in range(100):
            result = agent.solve(f"Task {i}")

            # Check convergence consistency
            has_tools = len(result.get("tool_calls", [])) > 0
            converged = result.get("converged", False)

            # If converged, should have no tools
            if converged:
                assert not has_tools, "Converged but has tools"

            results.append(converged)

        # Convergence accuracy should be > 95%
        accuracy = sum(results) / len(results)
        assert accuracy > 0.95, f"Convergence accuracy {accuracy} < 95%"

    @pytest.mark.integration
    async def test_real_tool_calling(self, agent):
        """Integration test with real tools."""
        # Agent should call tools and converge
        result = await agent.execute_with_tools("Read test.txt and summarize")

        # Verify tools were called
        assert result.get("tools_called", 0) > 0, "Should call tools"

        # Verify convergence
        assert len(result.get("tool_calls", [])) == 0, "Should converge"

        # Verify cycles
        assert 1 < result["cycles_used"] < 10, "Should use multiple cycles"
```

---

## Summary

**Essential Patterns**:

1. âœ… **MultiCycleStrategy** - Always use for autonomous agents
2. âœ… **Objective Convergence** - Prefer tool_calls field over subjective checks
3. âœ… **Hybrid Convergence** - Best of objective + subjective
4. âœ… **max_cycles** - Always enforce upper limit (5-15 cycles)
5. âœ… **Early Stopping** - Converge as soon as task complete

**Decision Tree**:
```
Agent needs iteration?
  â”œâ”€ YES â†’ MultiCycleStrategy
  â”‚        â”œâ”€ Has tools? â†’ Objective convergence (tool_calls)
  â”‚        â””â”€ No tools? â†’ Subjective convergence (action/confidence)
  â””â”€ NO â†’ Default single-shot
```

**References**:
- ADR-013: Objective Convergence Detection
- Claude Code: `while(tool_call_exists)` pattern
- MultiCycleStrategy: `src/kaizen/strategies/multi_cycle.py`
- ReActAgent: Reference implementation

---

**Last Updated**: 2025-10-22
**Version**: 1.0.0
