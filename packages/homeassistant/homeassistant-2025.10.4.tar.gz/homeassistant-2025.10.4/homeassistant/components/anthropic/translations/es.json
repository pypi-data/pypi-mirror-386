{
    "config": {
        "abort": {
            "already_configured": "El servicio ya est\u00e1 configurado"
        },
        "error": {
            "authentication_error": "Autenticaci\u00f3n no v\u00e1lida",
            "cannot_connect": "No se pudo conectar",
            "timeout_connect": "Tiempo de espera agotado mientras se establec\u00eda la conexi\u00f3n",
            "unknown": "Error inesperado"
        },
        "step": {
            "user": {
                "data": {
                    "api_key": "Clave API"
                }
            }
        }
    },
    "config_subentries": {
        "conversation": {
            "abort": {
                "entry_not_loaded": "No se pueden a\u00f1adir cosas mientras la configuraci\u00f3n est\u00e1 desactivada.",
                "reconfigure_successful": "Se volvi\u00f3 a configurar correctamente"
            },
            "entry_type": "Agente de conversaci\u00f3n",
            "error": {
                "thinking_budget_too_large": "El n\u00famero de tokens m\u00e1ximos deben ser superior que el presupuesto estimado."
            },
            "initiate_flow": {
                "reconfigure": "Volver a configurar el agente de conversaci\u00f3n",
                "user": "A\u00f1adir agente de conversaci\u00f3n"
            },
            "step": {
                "set_options": {
                    "data": {
                        "chat_model": "Modelo",
                        "llm_hass_api": "Controla Home Assistant",
                        "max_tokens": "M\u00e1ximo de tokens para devolver en respuesta",
                        "name": "Nombre",
                        "prompt": "Instrucciones",
                        "recommended": "Ajustes recomendados del modelo",
                        "temperature": "Temperatura",
                        "thinking_budget_tokens": "Presupuesto del pensamiento"
                    },
                    "data_description": {
                        "prompt": "Indica c\u00f3mo debe responder el LLM. Puede ser una plantilla.",
                        "thinking_budget_tokens": "El n\u00famero de tokens que el modelo puede usar para pensar en la respuesta, del m\u00e1ximo total. Se establece en 1024 o m\u00e1s para permitir el pensamiento extendido."
                    }
                }
            }
        }
    }
}