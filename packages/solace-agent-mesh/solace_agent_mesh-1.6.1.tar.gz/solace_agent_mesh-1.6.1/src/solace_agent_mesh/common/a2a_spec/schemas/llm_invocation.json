{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "LlmInvocationData",
    "description": "Schema for the data part of an LLM invocation signal.",
    "type": "object",
    "properties": {
        "type": {
            "type": "string",
            "const": "llm_invocation",
            "description": "The constant type for this data part."
        },
        "request": {
            "type": "object",
            "description": "A sanitized representation of the LlmRequest object sent to the model."
        },
        "usage": {
            "type": "object",
            "description": "Token usage information for this LLM call.",
            "properties": {
                "input_tokens": {
                    "type": "integer",
                    "description": "Number of input/prompt tokens."
                },
                "output_tokens": {
                    "type": "integer",
                    "description": "Number of output/completion tokens."
                },
                "cached_input_tokens": {
                    "type": "integer",
                    "description": "Number of cached input tokens (optional)."
                },
                "model": {
                    "type": "string",
                    "description": "Model identifier used for this call."
                }
            },
            "required": ["input_tokens", "output_tokens", "model"]
        }
    },
    "required": ["type", "request"]
}
