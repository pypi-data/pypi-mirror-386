"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _SparkAppType:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _SparkAppTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SparkAppType.ValueType], builtins.type):  # noqa: F821
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    SPARK_APP_TYPE_INVALID: _SparkAppType.ValueType  # 0
    SPARK_APP_TYPE_BATCH_INGESTION: _SparkAppType.ValueType  # 1
    SPARK_APP_TYPE_BATCH_BACKFILL: _SparkAppType.ValueType  # 2
    SPARK_APP_TYPE_BATCH_DELETION: _SparkAppType.ValueType  # 3
    SPARK_APP_TYPE_STREAMING_ONLINE: _SparkAppType.ValueType  # 4
    SPARK_APP_TYPE_STREAMING_OFFLINE: _SparkAppType.ValueType  # 5
    SPARK_APP_TYPE_STREAMING_BACKFILL: _SparkAppType.ValueType  # 6
    SPARK_APP_TYPE_STREAMING_DELETION: _SparkAppType.ValueType  # 7
    SPARK_APP_TYPE_STREAMING_AGGR_ROWLEVEL: _SparkAppType.ValueType  # 8
    SPARK_APP_TYPE_STREAMING_AGGR_COMPACTION: _SparkAppType.ValueType  # 9
    SPARK_APP_TYPE_STREAMING_AGGR_BACKFILL: _SparkAppType.ValueType  # 10
    SPARK_APP_TYPE_STREAMING_AGGR_DELETION: _SparkAppType.ValueType  # 11

class SparkAppType(_SparkAppType, metaclass=_SparkAppTypeEnumTypeWrapper): ...

SPARK_APP_TYPE_INVALID: SparkAppType.ValueType  # 0
SPARK_APP_TYPE_BATCH_INGESTION: SparkAppType.ValueType  # 1
SPARK_APP_TYPE_BATCH_BACKFILL: SparkAppType.ValueType  # 2
SPARK_APP_TYPE_BATCH_DELETION: SparkAppType.ValueType  # 3
SPARK_APP_TYPE_STREAMING_ONLINE: SparkAppType.ValueType  # 4
SPARK_APP_TYPE_STREAMING_OFFLINE: SparkAppType.ValueType  # 5
SPARK_APP_TYPE_STREAMING_BACKFILL: SparkAppType.ValueType  # 6
SPARK_APP_TYPE_STREAMING_DELETION: SparkAppType.ValueType  # 7
SPARK_APP_TYPE_STREAMING_AGGR_ROWLEVEL: SparkAppType.ValueType  # 8
SPARK_APP_TYPE_STREAMING_AGGR_COMPACTION: SparkAppType.ValueType  # 9
SPARK_APP_TYPE_STREAMING_AGGR_BACKFILL: SparkAppType.ValueType  # 10
SPARK_APP_TYPE_STREAMING_AGGR_DELETION: SparkAppType.ValueType  # 11
global___SparkAppType = SparkAppType

class _SparkAppStateType:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _SparkAppStateTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SparkAppStateType.ValueType], builtins.type):  # noqa: F821
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    SPARK_APP_STATE_INVALID: _SparkAppStateType.ValueType  # 0
    SPARK_APP_STATE_COMPLETED: _SparkAppStateType.ValueType  # 1
    SPARK_APP_STATE_FAILED: _SparkAppStateType.ValueType  # 2
    SPARK_APP_STATE_SUBMISSION_FAILED: _SparkAppStateType.ValueType  # 3
    SPARK_APP_STATE_FAILING: _SparkAppStateType.ValueType  # 4
    SPARK_APP_STATE_INVALIDATING: _SparkAppStateType.ValueType  # 5
    SPARK_APP_STATE_EMPTY: _SparkAppStateType.ValueType  # 6
    """corresponds to "" in sparkoperator.k8s.io/v1beta2.ApplicationStateType"""
    SPARK_APP_STATE_PENDING_RERUN: _SparkAppStateType.ValueType  # 7
    SPARK_APP_STATE_RUNNING: _SparkAppStateType.ValueType  # 8
    SPARK_APP_STATE_SUBMITTED: _SparkAppStateType.ValueType  # 9
    SPARK_APP_STATE_SUCCEEDING: _SparkAppStateType.ValueType  # 10
    SPARK_APP_STATE_UNKNOWN: _SparkAppStateType.ValueType  # 11

class SparkAppStateType(_SparkAppStateType, metaclass=_SparkAppStateTypeEnumTypeWrapper): ...

SPARK_APP_STATE_INVALID: SparkAppStateType.ValueType  # 0
SPARK_APP_STATE_COMPLETED: SparkAppStateType.ValueType  # 1
SPARK_APP_STATE_FAILED: SparkAppStateType.ValueType  # 2
SPARK_APP_STATE_SUBMISSION_FAILED: SparkAppStateType.ValueType  # 3
SPARK_APP_STATE_FAILING: SparkAppStateType.ValueType  # 4
SPARK_APP_STATE_INVALIDATING: SparkAppStateType.ValueType  # 5
SPARK_APP_STATE_EMPTY: SparkAppStateType.ValueType  # 6
"""corresponds to "" in sparkoperator.k8s.io/v1beta2.ApplicationStateType"""
SPARK_APP_STATE_PENDING_RERUN: SparkAppStateType.ValueType  # 7
SPARK_APP_STATE_RUNNING: SparkAppStateType.ValueType  # 8
SPARK_APP_STATE_SUBMITTED: SparkAppStateType.ValueType  # 9
SPARK_APP_STATE_SUCCEEDING: SparkAppStateType.ValueType  # 10
SPARK_APP_STATE_UNKNOWN: SparkAppStateType.ValueType  # 11
global___SparkAppStateType = SparkAppStateType

class SparkExecutionState(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class ApplicationLabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        value: builtins.str
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: builtins.str = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...

    APPLICATION_ID_FIELD_NUMBER: builtins.int
    SPARK_APPLICATION_TYPE_FIELD_NUMBER: builtins.int
    SPARK_APP_STATE_FIELD_NUMBER: builtins.int
    APPLICATIONLABELS_FIELD_NUMBER: builtins.int
    application_id: builtins.str
    """spark application ID"""
    spark_application_type: global___SparkAppType.ValueType
    """Type of spark Application"""
    @property
    def spark_app_state(self) -> global___SparkAppState:
        """directly mimics sparkoperator.k8s.io/v1beta2.ApplicationState"""
    @property
    def applicationLabels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
        """Labels set on the application itself"""
    def __init__(
        self,
        *,
        application_id: builtins.str = ...,
        spark_application_type: global___SparkAppType.ValueType = ...,
        spark_app_state: global___SparkAppState | None = ...,
        applicationLabels: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["spark_app_state", b"spark_app_state", "state_descriptor", b"state_descriptor"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["applicationLabels", b"applicationLabels", "application_id", b"application_id", "spark_app_state", b"spark_app_state", "spark_application_type", b"spark_application_type", "state_descriptor", b"state_descriptor"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["state_descriptor", b"state_descriptor"]) -> typing_extensions.Literal["spark_app_state"] | None: ...

global___SparkExecutionState = SparkExecutionState

class SparkAppState(google.protobuf.message.Message):
    """directly mimics sparkoperator.k8s.io/v1beta2.ApplicationState"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    STATE_TYPE_FIELD_NUMBER: builtins.int
    ERROR_MESSAGE_FIELD_NUMBER: builtins.int
    state_type: global___SparkAppStateType.ValueType
    error_message: builtins.str
    def __init__(
        self,
        *,
        state_type: global___SparkAppStateType.ValueType = ...,
        error_message: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["error_message", b"error_message", "state_type", b"state_type"]) -> None: ...

global___SparkAppState = SparkAppState
