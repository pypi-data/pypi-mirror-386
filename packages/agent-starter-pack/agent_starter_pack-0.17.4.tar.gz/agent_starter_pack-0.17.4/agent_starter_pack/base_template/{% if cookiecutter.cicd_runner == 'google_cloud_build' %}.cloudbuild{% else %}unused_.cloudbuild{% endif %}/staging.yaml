# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
{%- if cookiecutter.data_ingestion %}
  - name: "python:3.12-slim"
    id: deploy-data-ingestion-pipeline-staging
    entrypoint: bash
    args:
      - -c
      - |
        cd data_ingestion && pip install uv==0.8.13 --user && cd data_ingestion_pipeline && \
        uv sync --locked && uv run python submit_pipeline.py
    env:
      - "PIPELINE_ROOT=${_PIPELINE_GCS_ROOT_STAGING}"
      - "REGION=${_REGION}"
{%- if cookiecutter.datastore_type == "vertex_ai_search" %}
      - "DATA_STORE_REGION=${_DATA_STORE_REGION}"
      - "DATA_STORE_ID=${_DATA_STORE_ID_STAGING}"
{%- elif cookiecutter.datastore_type == "vertex_ai_vector_search" %}
      - "VECTOR_SEARCH_INDEX=${_VECTOR_SEARCH_INDEX_STAGING}"
      - "VECTOR_SEARCH_INDEX_ENDPOINT=${_VECTOR_SEARCH_INDEX_ENDPOINT_STAGING}"
      - "VECTOR_SEARCH_BUCKET=${_VECTOR_SEARCH_BUCKET_STAGING}"
{%- endif %}
      - "PROJECT_ID=${_STAGING_PROJECT_ID}"
      - "SERVICE_ACCOUNT=${_PIPELINE_SA_EMAIL_STAGING}"
      - "PIPELINE_NAME=${_PIPELINE_NAME}"
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
{%- endif %}
{%- if cookiecutter.deployment_target == 'cloud_run' %}
  # Build and Push
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "build",
        "-t",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
        "--build-arg",
        "COMMIT_SHA=$COMMIT_SHA",
        ".",
      ]
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
      ]

  # Deploy to Staging
  - name: "gcr.io/cloud-builders/gcloud"
    id: deploy-staging
    entrypoint: gcloud
    args:
      - "run"
      - "deploy"
      - "{{cookiecutter.project_name}}"
      - "--image"
      - "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME"
      - "--region"
      - "${_REGION}"
      - "--project"
      - "${_STAGING_PROJECT_ID}"

  # Fetch Staging Service URL
  - name: "gcr.io/cloud-builders/gcloud"
    id: fetch-staging-url
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud run services describe {{cookiecutter.project_name}} \
        --region ${_REGION} --project ${_STAGING_PROJECT_ID} --format="value(status.url)") > staging_url.txt

  # Fetch ID Token
  - name: gcr.io/cloud-builders/gcloud
    id: fetch-id-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud auth print-identity-token -q) > id_token.txt
{%- elif cookiecutter.deployment_target == 'agent_engine' %}
  - name: "python:3.12-slim"
    id: install-dependencies
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        pip install uv==0.8.13 --user && uv sync --locked
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'

  - name: "python:3.12-slim"
    id: deploy-staging
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        uv export --no-hashes --no-sources --no-header --no-dev --no-emit-project --no-annotate --locked > .requirements.txt
        uv run {{cookiecutter.agent_directory}}/agent_engine_app.py \
          --project ${_STAGING_PROJECT_ID} \
          --location ${_REGION} \
          --artifacts-bucket-name ${_LOGS_BUCKET_NAME_STAGING} \
          --set-env-vars="COMMIT_SHA=${COMMIT_SHA}{%- if cookiecutter.data_ingestion %}{%- if cookiecutter.datastore_type == "vertex_ai_search" %},DATA_STORE_ID=${_DATA_STORE_ID_STAGING},DATA_STORE_REGION=${_DATA_STORE_REGION}{%- elif cookiecutter.datastore_type == "vertex_ai_vector_search" %},VECTOR_SEARCH_INDEX=${_VECTOR_SEARCH_INDEX_STAGING},VECTOR_SEARCH_INDEX_ENDPOINT=${_VECTOR_SEARCH_INDEX_ENDPOINT_STAGING},VECTOR_SEARCH_BUCKET=${_VECTOR_SEARCH_BUCKET_STAGING}{%- endif %}{%- endif %}"
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'


  - name: gcr.io/cloud-builders/gcloud
    id: fetch-auth-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud auth print-access-token -q) > auth_token.txt
{%- endif %}

  # Load Testing
{%- if cookiecutter.deployment_target == 'cloud_run' and cookiecutter.agent_name == 'adk_live' %}
  - name: "europe-west4-docker.pkg.dev/production-ai-template/starter-pack/e2e-tests"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        # Install load test dependencies
        pip install locust==2.31.1 websockets

        # Install Cloud Run proxy component
        apt-get update && apt-get install -y google-cloud-cli-cloud-run-proxy

        # Start Cloud Run proxy in background
        gcloud run services proxy {{cookiecutter.project_name}} \
        --port=8080 \
        --region ${_REGION} \
        --project ${_STAGING_PROJECT_ID} \
        --quiet &
        _PROXY_PID=$$!

        # Wait for proxy to be ready
        echo "Waiting for proxy to start..."
        sleep 10

        # Run load test and capture exit code
        locust -f tests/load_test/load_test.py \
        --headless \
        -H http://127.0.0.1:8080 \
        -t 30s -u 2 -r 2 \
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
        _LOAD_TEST_EXIT_CODE=$$?

        # Clean up proxy
        kill $$_PROXY_PID || true

        # Exit with load test result to fail build if tests failed
        exit $$_LOAD_TEST_EXIT_CODE
{%- elif cookiecutter.deployment_target == 'cloud_run' %}
  - name: "python:3.12-slim"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _ID_TOKEN=$(cat id_token.txt)
        export _STAGING_URL=$(cat staging_url.txt)
        pip install locust==2.31.1 --user
        locust -f tests/load_test/load_test.py \
        --headless \
        -H $$_STAGING_URL \
        -t 30s -u 10 -r 0.5 \
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
{%- elif cookiecutter.deployment_target == 'agent_engine' and cookiecutter.is_adk_live %}
  - name: "python:3.12-slim"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        # Start expose app in remote mode (uses deployment_metadata.json by default)
        uv run python -m {{cookiecutter.agent_directory}}.utils.expose_app --mode remote &
        EXPOSE_PID=$$!

        # Wait for expose app to be ready
        sleep 10

        # Run load test against local expose app
        uv run --with locust==2.31.1 --with websockets locust -f tests/load_test/load_test.py \
        -H http://127.0.0.1:8000 \
        --headless \
        -t 30s -u 2 -r 1 \
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
        LOCUST_EXIT_CODE=$$?

        # Stop expose app
        kill $$EXPOSE_PID

        # Exit with error if locust test failed
        if [ $$LOCUST_EXIT_CODE -ne 0 ]; then
          echo "Load test failed with exit code $$LOCUST_EXIT_CODE"
          exit $$LOCUST_EXIT_CODE
        fi
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
{%- elif cookiecutter.deployment_target == 'agent_engine' %}
  - name: "python:3.12-slim"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _AUTH_TOKEN=$(cat auth_token.txt)
        pip install locust==2.31.1 --user
        locust -f tests/load_test/load_test.py \
        --headless \
        -t 30s -u 2 -r 0.5 \
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
{%- endif %}

  # Export Load Test Results to GCS
  - name: gcr.io/cloud-builders/gcloud
    id: export-results-to-gcs
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        gsutil -m cp -r tests/load_test/.results gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}
        echo "_________________________________________________________________________"
        echo "Load test results copied to gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "HTTP link: https://console.cloud.google.com/storage/browser/${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "_________________________________________________________________________"

  # Trigger Prod Deployment
  - name: gcr.io/cloud-builders/gcloud
    id: trigger-prod-deployment
    entrypoint: gcloud
    args:
      - "beta"
      - "builds"
      - "triggers"
      - "run"
      - "deploy-{{cookiecutter.project_name}}"
      - "--region"
      - "$LOCATION"
      - "--project"
      - "$PROJECT_ID"
      - "--sha"
      - $COMMIT_SHA

  - name: gcr.io/cloud-builders/gcloud
    id: echo-view-build-trigger-link
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo "_________________________________________________________________________"
        echo "Production deployment triggered. View progress and / or approve on the Cloud Build Console:"
        echo "https://console.cloud.google.com/cloud-build/builds;region=$LOCATION"
        echo "_________________________________________________________________________"

substitutions:
  _STAGING_PROJECT_ID: YOUR_STAGING_PROJECT_ID
  _REGION: us-central1

logsBucket: gs://${PROJECT_ID}-{{ cookiecutter.project_name | replace('_', '-') }}-logs/build-logs
options:
  substitutionOption: ALLOW_LOOSE
  defaultLogsBucketBehavior: REGIONAL_USER_OWNED_BUCKET
