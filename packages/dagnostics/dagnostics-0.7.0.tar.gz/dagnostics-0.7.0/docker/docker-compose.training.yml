# Docker Compose for DAGnostics Training Infrastructure
# Optimized for remote server deployment with GPU support

version: '3.8'

services:
  dagnostics-trainer:
    build:
      context: ..
      dockerfile: docker/Dockerfile.training
      args:
        USER_ID: ${USER_ID:-1000}
        GROUP_ID: ${GROUP_ID:-1000}
    container_name: dagnostics-training-server
    restart: unless-stopped

    # GPU configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Environment variables
    environment:
      # HuggingFace configuration
      - HF_HOME=/app/huggingface_cache
      - TRANSFORMERS_CACHE=/app/huggingface_cache
      - HF_TOKEN=${HF_TOKEN:-}  # Optional: for private models

      # Training optimization
      - CUDA_VISIBLE_DEVICES=0  # Use first GPU
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

      # Logging
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=info

    # Port mapping
    ports:
      - "8001:8001"

    # Volume mounts for persistence
    volumes:
      # Model storage (persistent)
      - ./server_data/models:/app/server_data/models

      # Dataset storage (persistent)
      - ./server_data/datasets:/app/server_data/datasets

      # HuggingFace cache (persistent)
      - ./cache/huggingface:/app/huggingface_cache

      # PyTorch cache (persistent)
      - ./cache/torch:/app/torch_cache

      # Training data (bind mount)
      - ./data:/app/data

      # Evaluation results (persistent)
      - ./evaluations:/app/evaluations

      # Configuration files
      - ./config:/app/config:ro

    # Resource limits
    ulimits:
      memlock: -1
      stack: 67108864

    # Shared memory for PyTorch DataLoader
    shm_size: '2gb'

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # Optional: Add monitoring service
  # dagnostics-monitor:
  #   image: prom/prometheus
  #   container_name: dagnostics-monitor
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro

volumes:
  # Named volumes for better management
  huggingface_cache:
  torch_cache:
  model_storage:
  evaluation_results:

networks:
  default:
    name: dagnostics-training
