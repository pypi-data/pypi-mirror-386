{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Collinear Red Team - Custom Target Model\n",
    "\n",
    "This notebook shows how to test your own custom model with red-team evaluation.\n",
    "\n",
    "Red-teaming tests whether LLMs can be manipulated into violating safety policies through adversarial prompting.\n",
    "\n",
    "**Note:** The attack plan is loaded automatically on the server. You only need to specify which model you want to test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Install SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install collinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the client and set your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collinear.client import Client\n",
    "\n",
    "# Set your API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
    "os.environ[\"COLLINEAR_API_KEY\"] = \"your-collinear-key-here\"\n",
    "os.environ[\"COLLINEAR_BACKEND_URL\"] = \"https://stage.collinear.ai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "\n",
    "The client needs your default API credentials. These will be used for the attacker and evaluator models (running on Collinear's side):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\n",
    "    assistant_model_url=\"https://api.openai.com/v1\",\n",
    "    assistant_model_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    assistant_model_name=\"gpt-4o-mini\",\n",
    "    collinear_api_key=os.environ[\"COLLINEAR_API_KEY\"],\n",
    ")\n",
    "\n",
    "print(\"✓ Client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Test Your Custom Model\n",
    "\n",
    "Specify the model you want to test using the `target_model` parameter.\n",
    "\n",
    "The target model will use the same API endpoint and credentials from the client initialization above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "max_turns = 3\nmax_workers = 2\ntarget_model = \"gpt-4o\"\n\nevaluation = client.redteam(\n    target_model=target_model,\n    max_turns=max_turns,\n    max_workers=max_workers,\n)\n\nprint(f\"✓ Started: {evaluation.id}\")\nprint(f\"\\n   Target Model:\")\nprint(f\"      Model:    {target_model}\")\nprint(f\"      Endpoint: https://api.openai.com/v1\")\nprint(f\"\\n   Attacker Model:\")\nprint(f\"      Model:    gpt-4o-mini\")\nprint(f\"      Endpoint: https://api.openai.com/v1\")\nprint(f\"\\n   Max turns: {max_turns} | Workers: {max_workers}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Alternative: Use a Different API Endpoint for Your Target Model\n",
    "\n",
    "If your target model is hosted at a different endpoint (e.g., Azure OpenAI, a custom deployment, or a different provider), use `ModelConfig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "from collinear.redteam import ModelConfig\n\nmax_turns = 3\nmax_workers = 2\n\nmy_target = ModelConfig(\n    provider=\"openai_compat\",\n    model=\"gpt-4o\",\n    base_url=\"https://api.openai.com/v1\",\n    api_key=\"your-api-key-here\",\n    temperature=0.0,\n    max_retries=10,\n)\n\nevaluation = client.redteam(\n    target_config=my_target,\n    max_turns=max_turns,\n    max_workers=max_workers,\n)\n\nprint(f\"✓ Started: {evaluation.id}\")\nprint(f\"\\n   Target Model:\")\nprint(f\"      Model:    {my_target.model}\")\nprint(f\"      Endpoint: {my_target.base_url}\")\nprint(f\"\\n   Attacker Model:\")\nprint(f\"      Model:    gpt-4o-mini\")\nprint(f\"      Endpoint: https://api.openai.com/v1\")\nprint(f\"\\n   Max turns: {max_turns} | Workers: {max_workers}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": "## Poll for Results with Real-time Updates\n\nWait for the evaluation to complete with status updates:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "import time\n\nstart = time.time()\nlast_status = None\nlast_print = 0\n\nwhile True:\n    result = evaluation.status(refresh=True)\n    current_status = result.get(\"status\", \"PENDING\")\n    elapsed = time.time() - start\n\n    if current_status != last_status or elapsed - last_print >= 30:\n        elapsed_mins = int(elapsed / 60)\n        print(f\"[{elapsed_mins:3d}m] {current_status}\")\n        last_status = current_status\n        last_print = elapsed\n\n    if current_status in {\"COMPLETED\", \"FAILED\"}:\n        break\n\n    time.sleep(15)\n\nsummary = evaluation.summary()\nprint(f\"\\nSummary:\")\nprint(f\"  Total behaviors: {summary['total_behaviors']}\")\nprint(f\"  Successful: {summary['successful']}\")\nprint(f\"  Failed: {summary['failed']}\")\n\nif summary['errors_by_type']:\n    print(f\"  Errors: {summary['errors_by_type']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": "## Save and View Results\n\nSave results to a file and display them:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "import json\n\noutput_file = f\"redteam_results_{evaluation.id}.json\"\nwith open(output_file, \"w\") as f:\n    json.dump(result, f, indent=2)\n\nprint(f\"✓ Results saved to: {output_file}\")\nprint(f\"\\nFull results:\")\nprint(json.dumps(result, indent=2))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}