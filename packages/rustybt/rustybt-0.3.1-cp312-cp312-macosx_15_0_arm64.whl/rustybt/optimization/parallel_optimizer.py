"""Parallel optimization wrapper for search algorithms."""

import multiprocessing
import time
import warnings
from collections.abc import Callable
from dataclasses import dataclass
from decimal import Decimal
from threading import Lock
from typing import Any

import structlog
from tqdm import tqdm

from rustybt.optimization.base import SearchAlgorithm
from rustybt.optimization.persistent_worker_pool import PersistentWorkerPool

logger = structlog.get_logger()


@dataclass
class WorkerStats:
    """Statistics for a single worker process.

    Args:
        worker_id: Worker process identifier
        evaluations_completed: Number of successful evaluations
        evaluations_failed: Number of failed evaluations
        total_duration_seconds: Total time spent on evaluations
        last_active_time: Timestamp of last activity
    """

    worker_id: int
    evaluations_completed: int = 0
    evaluations_failed: int = 0
    total_duration_seconds: Decimal = Decimal(0)
    last_active_time: float = 0.0

    @property
    def throughput(self) -> Decimal:
        """Calculate worker throughput in evaluations per second.

        Returns:
            Evaluations per second, or 0 if no evaluations completed
        """
        if self.total_duration_seconds <= 0:
            return Decimal(0)
        return Decimal(self.evaluations_completed) / self.total_duration_seconds

    @property
    def success_rate(self) -> float:
        """Calculate worker success rate.

        Returns:
            Success rate as ratio between 0.0 and 1.0
        """
        total = self.evaluations_completed + self.evaluations_failed
        if total == 0:
            return 0.0
        return self.evaluations_completed / total


@dataclass
class TaskResult:
    """Result from worker evaluation.

    Args:
        params: Parameter configuration that was evaluated
        score: Objective function score (higher is better)
        duration_seconds: Evaluation duration in seconds
        error: Error message if evaluation failed (None if successful)
        worker_id: ID of worker that completed the task
    """

    params: dict[str, Any]
    score: Decimal
    duration_seconds: Decimal
    error: str | None = None
    worker_id: int = -1

    @property
    def is_success(self) -> bool:
        """Check if evaluation was successful.

        Returns:
            True if successful, False if failed
        """
        return self.error is None


def _evaluate_params_worker(
    params: dict[str, Any],
    objective_function: Callable[[dict[str, Any]], Decimal],
    worker_id: int,
    max_eval_time: float | None,
) -> TaskResult:
    """Worker function to evaluate single parameter configuration.

    This function is executed in separate process by multiprocessing.Pool.

    Args:
        params: Parameter configuration to evaluate
        objective_function: Function to evaluate parameters
        worker_id: ID of worker process
        max_eval_time: Maximum evaluation time in seconds (None for unlimited)

    Returns:
        TaskResult with score or error
    """
    start_time = time.time()

    try:
        # Execute objective function with timeout if specified
        if max_eval_time is not None:
            # Note: multiprocessing.Pool handles timeout at pool level
            # This is just for documentation
            pass

        score = objective_function(params)

        # Validate score is Decimal
        if not isinstance(score, Decimal):
            score = Decimal(str(score))

        duration = Decimal(str(time.time() - start_time))

        return TaskResult(
            params=params,
            score=score,
            duration_seconds=duration,
            error=None,
            worker_id=worker_id,
        )

    except Exception as e:  # noqa: BLE001 - Need to catch all exceptions from user objective
        duration = Decimal(str(time.time() - start_time))
        logger.error(
            "worker_evaluation_failed",
            worker_id=worker_id,
            params=params,
            error=str(e),
            duration=str(duration),
        )

        return TaskResult(
            params=params,
            score=Decimal("-Infinity"),
            duration_seconds=duration,
            error=str(e),
            worker_id=worker_id,
        )


class ParallelOptimizer:
    """Parallel optimization wrapper for SearchAlgorithm instances.

    Distributes parameter evaluations across multiple CPU cores to achieve
    significant speedup for optimization campaigns.

    Best for:
        - CPU-bound objective functions (backtests)
        - Large optimization campaigns (100+ evaluations)
        - Multi-core machines (4+ cores)

    Performance expectations:
        - 2 workers: ~1.9x speedup (95% efficiency)
        - 4 workers: ~3.7x speedup (92% efficiency)
        - 8 workers: ~6.5x speedup (81% efficiency)

    Example:
        >>> from rustybt.optimization import RandomSearchAlgorithm, ParallelOptimizer
        >>> from rustybt.optimization.parameter_space import ParameterSpace, ContinuousParameter
        >>> param_space = ParameterSpace(parameters=[
        ...     ContinuousParameter(name='lookback', min_value=10, max_value=100, prior='uniform')
        ... ])
        >>> algorithm = RandomSearchAlgorithm(parameter_space=param_space, n_iter=100)
        >>> parallel_opt = ParallelOptimizer(algorithm, n_jobs=8)
        >>> def objective(params):
        ...     return run_backtest(**params)['sharpe_ratio']
        >>> parallel_opt.run(objective)
        >>> best_params = parallel_opt.get_best_params()

    Example with caching (Story X4.4 - 70% speedup for optimization workflows):
        >>> from rustybt.optimization import RandomSearchAlgorithm, ParallelOptimizer
        >>> from rustybt.optimization.caching import get_cached_assets, get_cached_grouped_data
        >>> from rustybt.optimization.cache_invalidation import get_bundle_version
        >>> from rustybt.data.bundles.core import load
        >>>
        >>> # Get bundle version for cache invalidation
        >>> bundle_version = get_bundle_version('quandl')
        >>> bundle_hash = bundle_version.computed_hash
        >>>
        >>> def objective_with_caching(params):
        ...     # Use cached asset list (99% faster than loading each time)
        ...     assets = get_cached_assets('quandl', bundle_hash)
        ...
        ...     # Load OHLCV data
        ...     bundle = load('quandl')
        ...     data = bundle.load_data(assets, start_date, end_date)
        ...
        ...     # Use cached pre-grouped data (100% faster filtering/grouping)
        ...     grouped_data = get_cached_grouped_data(data, bundle_hash)
        ...
        ...     # Run backtest with cached data
        ...     return run_backtest(params, grouped_data)['sharpe_ratio']
        >>>
        >>> # Caching provides 70%+ cumulative speedup for 100+ backtests
        >>> parallel_opt.run(objective_with_caching)
        >>> best_params = parallel_opt.get_best_params()

    Args:
        algorithm: SearchAlgorithm instance (Grid, Random, Bayesian, Genetic)
        n_jobs: Number of parallel workers (default: cpu_count(), -1 for all cores)
        backend: Parallelization backend ('multiprocessing' or 'ray')
        max_eval_time: Timeout per evaluation in seconds (None for unlimited)
        batch_size: Number of tasks to submit per batch (default: 2 * n_jobs)
        verbose: Show progress bar (default: True)
        maxtasksperchild: Restart workers after N tasks to prevent memory leaks (default: 100)
        use_persistent_pool: Use PersistentWorkerPool for 74.97% speedup (default: True, Story X4.7)

    Raises:
        ValueError: If configuration is invalid
        ImportError: If backend='ray' but ray is not installed
    """

    def __init__(
        self,
        algorithm: SearchAlgorithm,
        n_jobs: int = -1,
        backend: str = "multiprocessing",
        max_eval_time: float | None = None,
        batch_size: int | None = None,
        verbose: bool = True,
        maxtasksperchild: int = 100,
        use_persistent_pool: bool = True,
    ):
        """Initialize parallel optimizer.

        Args:
            algorithm: SearchAlgorithm instance to parallelize
            n_jobs: Number of parallel workers (-1 for all cores)
            backend: 'multiprocessing' or 'ray'
            max_eval_time: Timeout per evaluation in seconds (None for unlimited)
            batch_size: Tasks to submit per batch (None for 2 * n_jobs)
            verbose: Show progress bar
            maxtasksperchild: Restart workers after N tasks
            use_persistent_pool: Use PersistentWorkerPool for worker reuse (default: True)

        Raises:
            ValueError: If configuration is invalid
            ImportError: If backend='ray' but ray not installed
        """
        # Validate inputs
        if backend not in ("multiprocessing", "ray"):
            raise ValueError(f"backend must be 'multiprocessing' or 'ray', got '{backend}'")

        if backend == "ray":
            try:
                import ray  # noqa: F401
            except ImportError as e:
                raise ImportError(
                    "Ray backend requires ray package. Install with: pip install ray[default]"
                ) from e

        if max_eval_time is not None and max_eval_time <= 0:
            raise ValueError("max_eval_time must be positive")

        if maxtasksperchild <= 0:
            raise ValueError("maxtasksperchild must be positive")

        # Determine number of workers
        cpu_count = multiprocessing.cpu_count()
        if n_jobs == -1:
            n_jobs = cpu_count
        elif n_jobs <= 0:
            raise ValueError("n_jobs must be positive or -1 for all cores")
        elif n_jobs > cpu_count:
            warnings.warn(
                f"n_jobs={n_jobs} exceeds available CPU cores ({cpu_count}). "
                f"Performance may degrade.",
                UserWarning,
                stacklevel=2,
            )

        self.algorithm = algorithm
        self.n_jobs = n_jobs
        self.backend = backend
        self.max_eval_time = max_eval_time
        self.batch_size = batch_size if batch_size is not None else 2 * n_jobs
        self.verbose = verbose
        self.maxtasksperchild = maxtasksperchild
        self.use_persistent_pool = use_persistent_pool

        # Thread safety for algorithm access
        self._lock = Lock()

        # Worker statistics
        self._worker_stats: dict[int, WorkerStats] = {
            i: WorkerStats(worker_id=i) for i in range(n_jobs)
        }

        # Global statistics
        self._total_evaluations = 0
        self._failed_evaluations = 0
        self._best_score: Decimal | None = None
        self._best_params: dict[str, Any] | None = None

        logger.info(
            "parallel_optimizer_initialized",
            algorithm=algorithm.__class__.__name__,
            n_jobs=n_jobs,
            backend=backend,
            batch_size=self.batch_size,
            max_eval_time=max_eval_time,
        )

    def run(self, objective_function: Callable[[dict[str, Any]], Decimal]) -> None:
        """Run optimization with parallel execution.

        Args:
            objective_function: Function that takes params dict and returns Decimal score

        Raises:
            ValueError: If optimization fails completely
        """
        if self.backend == "multiprocessing":
            self._run_multiprocessing(objective_function)
        elif self.backend == "ray":
            self._run_ray(objective_function)
        else:
            raise ValueError(f"Unsupported backend: {self.backend}")

    def _run_multiprocessing(self, objective_function: Callable[[dict[str, Any]], Decimal]) -> None:
        """Run optimization using multiprocessing backend.

        Args:
            objective_function: Function to evaluate parameters
        """
        # Determine total iterations for progress bar
        total_iterations = self._estimate_total_iterations()

        # Create progress bar
        pbar = None
        if self.verbose:
            pbar = tqdm(
                total=total_iterations,
                desc="Parallel Optimization",
                unit="eval",
                dynamic_ncols=True,
            )

        try:
            # Create worker pool (use PersistentWorkerPool by default for 74.97% speedup)
            pool_class = PersistentWorkerPool if self.use_persistent_pool else multiprocessing.Pool
            with pool_class(
                processes=self.n_jobs,
                maxtasksperchild=self.maxtasksperchild,
            ) as pool:
                # Task queue: list of (params, AsyncResult) tuples
                pending_tasks: list[tuple[dict[str, Any], Any]] = []

                while not self._is_complete():
                    # Submit new tasks to keep queue full
                    while len(pending_tasks) < self.batch_size and not self._is_complete():
                        with self._lock:
                            if self.algorithm.is_complete():
                                break
                            params = self.algorithm.suggest()

                        # Assign worker ID (round-robin)
                        worker_id = self._total_evaluations % self.n_jobs

                        # Submit task
                        async_result = pool.apply_async(
                            _evaluate_params_worker,
                            args=(params, objective_function, worker_id, self.max_eval_time),
                        )
                        pending_tasks.append((params, async_result))

                    # Check for completed tasks
                    completed_tasks = []
                    for params, async_result in pending_tasks:
                        if async_result.ready():
                            try:
                                # Get result with timeout
                                result = async_result.get(timeout=0.1)
                                self._process_result(result)
                                completed_tasks.append((params, async_result))

                                # Update progress bar
                                if pbar is not None:
                                    best_score_str = (
                                        f"{self._best_score:.4f}"
                                        if self._best_score is not None
                                        else "N/A"
                                    )
                                    pbar.update(1)
                                    pbar.set_postfix(
                                        {
                                            "best": best_score_str,
                                            "failed": self._failed_evaluations,
                                            "workers": self.n_jobs,
                                        }
                                    )

                            except multiprocessing.TimeoutError:
                                # Task timed out
                                logger.warning(
                                    "worker_timeout",
                                    params=params,
                                    max_eval_time=self.max_eval_time,
                                )
                                # Create failed result
                                result = TaskResult(
                                    params=params,
                                    score=Decimal("-Infinity"),
                                    duration_seconds=Decimal(str(self.max_eval_time or 0)),
                                    error="Evaluation timeout",
                                    worker_id=-1,
                                )
                                self._process_result(result)
                                completed_tasks.append((params, async_result))

                            except Exception as e:  # noqa: BLE001 - Catch worker crash/timeout
                                # Worker crashed
                                logger.error("worker_crashed", params=params, error=str(e))
                                result = TaskResult(
                                    params=params,
                                    score=Decimal("-Infinity"),
                                    duration_seconds=Decimal(0),
                                    error=f"Worker crashed: {e!s}",
                                    worker_id=-1,
                                )
                                self._process_result(result)
                                completed_tasks.append((params, async_result))

                    # Remove completed tasks from pending queue
                    for task in completed_tasks:
                        pending_tasks.remove(task)

                    # Sleep briefly to avoid busy-waiting
                    if pending_tasks and not self._is_complete():
                        time.sleep(0.01)

                # Process remaining tasks
                for params, async_result in pending_tasks:
                    try:
                        result = async_result.get(timeout=self.max_eval_time)
                        self._process_result(result)
                        if pbar is not None:
                            pbar.update(1)
                    except Exception as e:  # noqa: BLE001 - Catch final task failures
                        logger.error("final_task_failed", params=params, error=str(e))
                        result = TaskResult(
                            params=params,
                            score=Decimal("-Infinity"),
                            duration_seconds=Decimal(0),
                            error=str(e),
                            worker_id=-1,
                        )
                        self._process_result(result)

        finally:
            if pbar is not None:
                pbar.close()

        # Log final statistics
        self._log_final_statistics()

    def _run_ray(self, objective_function: Callable[[dict[str, Any]], Decimal]) -> None:
        """Run optimization using Ray distributed backend.

        Args:
            objective_function: Function to evaluate parameters

        Raises:
            ImportError: If ray is not installed
        """
        try:
            import ray
        except ImportError as e:
            raise ImportError(
                "Ray backend requires ray package. Install with: pip install ray[default]"
            ) from e

        # Initialize Ray if not already initialized
        if not ray.is_initialized():
            ray.init(ignore_reinit_error=True)

        logger.info("ray_optimization_started", n_jobs=self.n_jobs)

        # Convert objective function to Ray remote function
        @ray.remote
        def evaluate_params_ray(
            params: dict[str, Any],
            worker_id: int,
        ) -> TaskResult:
            """Ray remote function for parameter evaluation."""
            return _evaluate_params_worker(
                params, objective_function, worker_id, self.max_eval_time
            )

        # Determine total iterations for progress bar
        total_iterations = self._estimate_total_iterations()

        # Create progress bar
        pbar = None
        if self.verbose:
            pbar = tqdm(
                total=total_iterations,
                desc="Ray Parallel Optimization",
                unit="eval",
                dynamic_ncols=True,
            )

        try:
            # Task queue: list of (params, ObjectRef) tuples
            pending_tasks: list[tuple[dict[str, Any], Any]] = []

            while not self._is_complete():
                # Submit new tasks to keep queue full
                while len(pending_tasks) < self.batch_size and not self._is_complete():
                    with self._lock:
                        if self.algorithm.is_complete():
                            break
                        params = self.algorithm.suggest()

                    # Assign worker ID
                    worker_id = self._total_evaluations % self.n_jobs

                    # Submit Ray task
                    object_ref = evaluate_params_ray.remote(params, worker_id)
                    pending_tasks.append((params, object_ref))

                # Wait for at least one task to complete
                if pending_tasks:
                    # Get completed task (non-blocking check)
                    ready_refs, remaining_refs = ray.wait(
                        [ref for _, ref in pending_tasks],
                        num_returns=1,
                        timeout=0.1,
                    )

                    # Process completed tasks
                    for ready_ref in ready_refs:
                        # Find corresponding params
                        params = None
                        for p, ref in pending_tasks:
                            if ref == ready_ref:
                                params = p
                                pending_tasks.remove((p, ref))
                                break

                        # Get result
                        try:
                            result = ray.get(ready_ref)
                            self._process_result(result)

                            # Update progress bar
                            if pbar is not None:
                                best_score_str = (
                                    f"{self._best_score:.4f}"
                                    if self._best_score is not None
                                    else "N/A"
                                )
                                pbar.update(1)
                                pbar.set_postfix(
                                    {
                                        "best": best_score_str,
                                        "failed": self._failed_evaluations,
                                    }
                                )

                        except ray.exceptions.RayTaskError as e:
                            logger.error("ray_task_failed", params=params, error=str(e))
                            result = TaskResult(
                                params=params or {},
                                score=Decimal("-Infinity"),
                                duration_seconds=Decimal(0),
                                error=str(e),
                                worker_id=-1,
                            )
                            self._process_result(result)

            # Process remaining tasks
            if pending_tasks:
                remaining_refs = [ref for _, ref in pending_tasks]
                results = ray.get(remaining_refs)
                for result in results:
                    self._process_result(result)
                    if pbar is not None:
                        pbar.update(1)

        finally:
            if pbar is not None:
                pbar.close()

        # Log final statistics
        self._log_final_statistics()

    def _process_result(self, result: TaskResult) -> None:
        """Process completed task result.

        Args:
            result: TaskResult from worker
        """
        with self._lock:
            # Update worker statistics
            if result.worker_id >= 0 and result.worker_id in self._worker_stats:
                worker_stat = self._worker_stats[result.worker_id]
                if result.is_success:
                    worker_stat.evaluations_completed += 1
                else:
                    worker_stat.evaluations_failed += 1
                worker_stat.total_duration_seconds += result.duration_seconds
                worker_stat.last_active_time = time.time()

            # Update global statistics
            self._total_evaluations += 1
            if not result.is_success:
                self._failed_evaluations += 1

            # Update algorithm with result
            self.algorithm.update(result.params, result.score)

            # Track best result
            if result.is_success and (self._best_score is None or result.score > self._best_score):
                self._best_score = result.score
                self._best_params = result.params.copy()
                logger.info(
                    "new_best_parallel_result",
                    score=str(result.score),
                    params=result.params,
                )

    def _is_complete(self) -> bool:
        """Check if optimization should terminate.

        Returns:
            True if optimization is complete
        """
        with self._lock:
            return self.algorithm.is_complete()

    def _estimate_total_iterations(self) -> int:
        """Estimate total iterations for progress bar.

        Returns:
            Estimated total iterations (best effort)
        """
        # Try to get n_iter from algorithm if available
        if hasattr(self.algorithm, "n_iter"):
            return self.algorithm.n_iter
        elif hasattr(self.algorithm, "_total_combinations"):
            # Grid search
            return self.algorithm._total_combinations
        elif hasattr(self.algorithm, "max_generations"):
            # Genetic algorithm
            population_size = getattr(self.algorithm, "population_size", 50)
            return self.algorithm.max_generations * population_size
        else:
            # Unknown - return large number
            return 1000

    def _log_final_statistics(self) -> None:
        """Log final optimization statistics."""
        # Calculate overall throughput
        total_duration = sum(ws.total_duration_seconds for ws in self._worker_stats.values())
        overall_throughput = (
            Decimal(self._total_evaluations) / total_duration if total_duration > 0 else Decimal(0)
        )

        # Calculate success rate
        success_rate = (
            (self._total_evaluations - self._failed_evaluations) / self._total_evaluations
            if self._total_evaluations > 0
            else 0.0
        )

        logger.info(
            "parallel_optimization_completed",
            total_evaluations=self._total_evaluations,
            failed_evaluations=self._failed_evaluations,
            success_rate=f"{success_rate:.2%}",
            overall_throughput=str(overall_throughput),
            best_score=str(self._best_score) if self._best_score is not None else None,
            n_jobs=self.n_jobs,
        )

        # Log per-worker statistics
        for worker_id, stats in self._worker_stats.items():
            if stats.evaluations_completed > 0 or stats.evaluations_failed > 0:
                logger.info(
                    "worker_statistics",
                    worker_id=worker_id,
                    completed=stats.evaluations_completed,
                    failed=stats.evaluations_failed,
                    throughput=str(stats.throughput),
                    success_rate=f"{stats.success_rate:.2%}",
                )

    def get_best_params(self) -> dict[str, Any]:
        """Get best parameters found.

        Returns:
            Best parameter configuration

        Raises:
            ValueError: If no successful results available
        """
        if self._best_params is None:
            raise ValueError("No successful results available yet")
        return self._best_params.copy()

    def get_best_result(self) -> tuple[dict[str, Any], Decimal]:
        """Get best result found.

        Returns:
            Tuple of (best_params, best_score)

        Raises:
            ValueError: If no successful results available
        """
        if self._best_params is None or self._best_score is None:
            raise ValueError("No successful results available yet")
        return self._best_params.copy(), self._best_score

    def get_worker_statistics(self) -> dict[int, WorkerStats]:
        """Get per-worker statistics.

        Returns:
            Dictionary mapping worker_id to WorkerStats
        """
        return self._worker_stats.copy()

    def get_progress(self) -> float:
        """Get optimization progress.

        Returns:
            Progress ratio between 0.0 and 1.0
        """
        if hasattr(self.algorithm, "progress"):
            return self.algorithm.progress
        else:
            # Estimate based on iterations
            total = self._estimate_total_iterations()
            if total == 0:
                return 1.0
            return min(1.0, self._total_evaluations / total)
