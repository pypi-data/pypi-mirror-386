{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Infusion Robustness Testing\n",
    "\n",
    "This notebook demonstrates using Monte Carlo noise infusion to test strategy robustness and detect overfitting to specific historical price patterns.\n",
    "\n",
    "## Concept\n",
    "\n",
    "Noise infusion tests if a strategy is overfit to noise-free historical data by:\n",
    "1. Adding synthetic noise to price data (perturbing OHLCV)\n",
    "2. Re-running the backtest on noisy data\n",
    "3. Repeating N times with different noise realizations\n",
    "4. Measuring performance degradation\n",
    "\n",
    "**Interpretation:**\n",
    "- **Robust strategy**: Small degradation (< 20%) → Generalizes well\n",
    "- **Fragile strategy**: Large degradation (> 50%) → Overfit to specific patterns\n",
    "\n",
    "This is analogous to regularization in machine learning - testing generalization beyond training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from rustybt.optimization import NoiseInfusionSimulator\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample OHLCV Data\n",
    "\n",
    "Create synthetic price data with realistic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 500 bars of daily price data\n",
    "n_bars = 500\n",
    "\n",
    "# Generate price series with trend + noise\n",
    "returns = np.random.normal(0.0005, 0.02, n_bars)  # Daily returns\n",
    "close_prices = 100 * np.exp(np.cumsum(returns))\n",
    "\n",
    "# Generate OHLC with proper relationships\n",
    "high_prices = close_prices * np.random.uniform(1.001, 1.02, n_bars)\n",
    "low_prices = close_prices * np.random.uniform(0.98, 0.999, n_bars)\n",
    "open_prices = close_prices * np.random.uniform(0.99, 1.01, n_bars)\n",
    "\n",
    "# Ensure OHLCV constraints\n",
    "high_prices = np.maximum.reduce([high_prices, open_prices, close_prices])\n",
    "low_prices = np.minimum.reduce([low_prices, open_prices, close_prices])\n",
    "\n",
    "volume = np.random.uniform(1_000_000, 5_000_000, n_bars)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pl.DataFrame(\n",
    "    {\n",
    "        \"timestamp\": pl.datetime_range(\n",
    "            start=pl.datetime(2022, 1, 1),\n",
    "            end=pl.datetime(2023, 5, 15),\n",
    "            interval=\"1d\",\n",
    "            eager=True,\n",
    "        ),\n",
    "        \"open\": open_prices,\n",
    "        \"high\": high_prices,\n",
    "        \"low\": low_prices,\n",
    "        \"close\": close_prices,\n",
    "        \"volume\": volume,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data[\"close\"].to_numpy(), linewidth=1.5)\n",
    "plt.title(\"Synthetic Price Data (500 Days)\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Day\", fontsize=12)\n",
    "plt.ylabel(\"Price ($)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Strategies\n",
    "\n",
    "We'll test two strategies:\n",
    "\n",
    "### A. Robust Strategy (Trend Following)\n",
    "Simple moving average crossover - captures broad trends, not sensitive to noise.\n",
    "\n",
    "### B. Fragile Strategy (Pattern Matching)\n",
    "Over-tuned pattern detector - overfit to specific price sequences, highly noise-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_trend_following_backtest(data: pl.DataFrame) -> dict[str, Decimal]:\n",
    "    \"\"\"\n",
    "    Robust trend-following strategy: Simple moving average crossover.\n",
    "\n",
    "    Signal: Buy when fast MA crosses above slow MA, sell when crosses below.\n",
    "    This strategy captures broad trends and is not sensitive to minor price noise.\n",
    "    \"\"\"\n",
    "    # Calculate moving averages\n",
    "    fast_window = 20\n",
    "    slow_window = 50\n",
    "\n",
    "    close = data[\"close\"].to_numpy()\n",
    "\n",
    "    # Calculate MAs\n",
    "    fast_ma = np.convolve(close, np.ones(fast_window) / fast_window, mode=\"valid\")\n",
    "    slow_ma = np.convolve(close, np.ones(slow_window) / slow_window, mode=\"valid\")\n",
    "\n",
    "    # Align arrays\n",
    "    alignment_offset = slow_window - fast_window\n",
    "    fast_ma = fast_ma[alignment_offset:]\n",
    "\n",
    "    # Generate signals\n",
    "    signals = np.where(fast_ma > slow_ma, 1, -1)  # 1 = long, -1 = short\n",
    "\n",
    "    # Calculate returns\n",
    "    price_returns = np.diff(close[-len(signals) :]) / close[-len(signals) : -1]\n",
    "    strategy_returns = signals[:-1] * price_returns\n",
    "\n",
    "    # Calculate metrics\n",
    "    if len(strategy_returns) > 1:\n",
    "        mean_return = np.mean(strategy_returns)\n",
    "        std_return = np.std(strategy_returns, ddof=1)\n",
    "        sharpe = mean_return / std_return * np.sqrt(252) if std_return > 0 else 0.0\n",
    "    else:\n",
    "        sharpe = 0.0\n",
    "\n",
    "    total_return = np.prod(1 + strategy_returns) - 1\n",
    "\n",
    "    return {\n",
    "        \"sharpe_ratio\": Decimal(str(sharpe)),\n",
    "        \"total_return\": Decimal(str(total_return)),\n",
    "    }\n",
    "\n",
    "\n",
    "def fragile_pattern_matching_backtest(data: pl.DataFrame) -> dict[str, Decimal]:\n",
    "    \"\"\"\n",
    "    Fragile pattern-matching strategy: Over-tuned to specific sequences.\n",
    "\n",
    "    This strategy looks for very specific price patterns that are likely\n",
    "    overfit to historical noise. It will fail when noise is added.\n",
    "    \"\"\"\n",
    "    close = data[\"close\"].to_numpy()\n",
    "\n",
    "    # Look for very specific pattern: 3-day sequence with exact relationships\n",
    "    # This is intentionally overfit!\n",
    "    signals = []\n",
    "    for i in range(3, len(close)):\n",
    "        # Check if last 3 days match a specific pattern\n",
    "        r1 = (close[i - 2] - close[i - 3]) / close[i - 3]\n",
    "        r2 = (close[i - 1] - close[i - 2]) / close[i - 2]\n",
    "        r3 = (close[i] - close[i - 1]) / close[i - 1]\n",
    "\n",
    "        # Overfit condition: very specific thresholds\n",
    "        if 0.001 < r1 < 0.003 and -0.002 < r2 < 0.001 and 0.002 < r3 < 0.005:\n",
    "            signals.append(1)  # Buy\n",
    "        elif r1 < -0.001 and r2 > 0.002:\n",
    "            signals.append(-1)  # Sell\n",
    "        else:\n",
    "            signals.append(0)  # Hold\n",
    "\n",
    "    # Calculate returns when signal is non-zero\n",
    "    price_returns = np.diff(close[3:]) / close[3:-1]\n",
    "    signals = np.array(signals)\n",
    "\n",
    "    # Only take positions when signal is non-zero\n",
    "    mask = signals[:-1] != 0\n",
    "    if mask.sum() > 0:\n",
    "        strategy_returns = signals[:-1][mask] * price_returns[mask]\n",
    "    else:\n",
    "        strategy_returns = np.array([0.0])\n",
    "\n",
    "    # Calculate metrics\n",
    "    if len(strategy_returns) > 1:\n",
    "        mean_return = np.mean(strategy_returns)\n",
    "        std_return = np.std(strategy_returns, ddof=1)\n",
    "        sharpe = mean_return / std_return * np.sqrt(252) if std_return > 0 else 0.0\n",
    "    else:\n",
    "        sharpe = 0.0\n",
    "\n",
    "    total_return = np.prod(1 + strategy_returns) - 1 if len(strategy_returns) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"sharpe_ratio\": Decimal(str(sharpe)),\n",
    "        \"total_return\": Decimal(str(total_return)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Original Backtests (Noise-Free)\n",
    "\n",
    "First, evaluate both strategies on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test both strategies on original data\n",
    "robust_result = robust_trend_following_backtest(data)\n",
    "fragile_result = fragile_pattern_matching_backtest(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Noise Infusion Test: Robust Strategy\n",
    "\n",
    "Test if the trend-following strategy maintains performance with noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize noise infusion simulator\n",
    "simulator = NoiseInfusionSimulator(\n",
    "    n_simulations=1000,  # 1000 noise realizations\n",
    "    std_pct=0.01,  # 1% noise amplitude\n",
    "    noise_model=\"gaussian\",  # Gaussian noise\n",
    "    seed=42,  # Reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "# Run simulation\n",
    "robust_noise_result = simulator.run(data, robust_trend_following_backtest)\n",
    "\n",
    "# Display summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "robust_noise_result.plot_distribution(\"sharpe_ratio\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Noise Infusion Test: Fragile Strategy\n",
    "\n",
    "Test if the pattern-matching strategy fails with noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "fragile_noise_result = simulator.run(data, fragile_pattern_matching_backtest)\n",
    "\n",
    "# Display summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "fragile_noise_result.plot_distribution(\"sharpe_ratio\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison: Robust vs Fragile\n",
    "\n",
    "Compare degradation between the two strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare degradation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Different Noise Levels\n",
    "\n",
    "How does degradation change with noise amplitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple noise levels\n",
    "noise_levels = [0.005, 0.01, 0.02, 0.03]\n",
    "robust_degradations = []\n",
    "fragile_degradations = []\n",
    "\n",
    "\n",
    "for std_pct in noise_levels:\n",
    "    sim = NoiseInfusionSimulator(\n",
    "        n_simulations=500,  # Fewer sims for speed\n",
    "        std_pct=std_pct,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    robust_res = sim.run(data, robust_trend_following_backtest)\n",
    "    fragile_res = sim.run(data, fragile_pattern_matching_backtest)\n",
    "\n",
    "    robust_degradations.append(float(robust_res.degradation_pct[\"sharpe_ratio\"]))\n",
    "    fragile_degradations.append(float(fragile_res.degradation_pct[\"sharpe_ratio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot degradation vs noise level\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "noise_pct = [n * 100 for n in noise_levels]\n",
    "\n",
    "ax.plot(\n",
    "    noise_pct, robust_degradations, marker=\"o\", linewidth=2, label=\"Robust Strategy\", color=\"green\"\n",
    ")\n",
    "ax.plot(\n",
    "    noise_pct, fragile_degradations, marker=\"s\", linewidth=2, label=\"Fragile Strategy\", color=\"red\"\n",
    ")\n",
    "\n",
    "# Add threshold lines\n",
    "ax.axhline(20, color=\"orange\", linestyle=\"--\", alpha=0.5, label=\"20% Threshold (Robust/Moderate)\")\n",
    "ax.axhline(50, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"50% Threshold (Moderate/Fragile)\")\n",
    "\n",
    "ax.set_xlabel(\"Noise Amplitude (%)\", fontsize=12)\n",
    "ax.set_ylabel(\"Performance Degradation (%)\", fontsize=12)\n",
    "ax.set_title(\"Strategy Robustness: Degradation vs Noise Level\", fontsize=14, fontweight=\"bold\")\n",
    "ax.legend(loc=\"upper left\", fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bootstrap Noise Model\n",
    "\n",
    "Compare Gaussian noise with bootstrap noise (preserves return distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test robust strategy with bootstrap noise\n",
    "sim_bootstrap = NoiseInfusionSimulator(\n",
    "    n_simulations=1000,\n",
    "    std_pct=0.01,\n",
    "    noise_model=\"bootstrap\",  # Bootstrap instead of Gaussian\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "robust_bootstrap_result = sim_bootstrap.run(data, robust_trend_following_backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Robust strategies** (trend following) maintain performance with noise\n",
    "   - Low degradation (< 20%)\n",
    "   - Capture broad market patterns\n",
    "   - Generalize beyond historical data\n",
    "\n",
    "2. **Fragile strategies** (pattern matching) fail with noise\n",
    "   - High degradation (> 50%)\n",
    "   - Overfit to specific price sequences\n",
    "   - Don't generalize well\n",
    "\n",
    "3. **Use noise infusion before live trading** to validate robustness\n",
    "   - Similar to regularization in ML\n",
    "   - Tests strategy generalization\n",
    "   - Identifies overfitting\n",
    "\n",
    "4. **Noise models**:\n",
    "   - **Gaussian**: Simple, symmetric noise\n",
    "   - **Bootstrap**: Preserves empirical return distribution (fat tails)\n",
    "\n",
    "5. **Interpretation guidelines**:\n",
    "   - Degradation < 20%: **Robust** ✅\n",
    "   - Degradation 20-50%: **Moderate** ⚠️\n",
    "   - Degradation > 50%: **Fragile** ❌ (likely overfit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
