# Story X4.7 Re-evaluation Guidance

**Date**: 2025-10-23
**QA Reviewer**: Quinn (Test Architect)
**Developer**: James (Full Stack Developer)
**Status**: IN PROGRESS - Requires Re-evaluation

## Executive Summary

QA review identified **critical testing methodology issues** that require re-evaluation before story completion:

1. **BOHB Multi-Fidelity**: Tested on 36-combination parameter space (SMALL) when story scope explicitly targets "heavy operations" and "large-scale optimization workflows"
2. **SharedBundleContext**: Rejected due to pickle serialization without exploring alternative implementations

This document provides detailed guidance for proper re-evaluation with heavy workflow scope.

---

## Issue 1: BOHB Multi-Fidelity Testing Methodology

### Problem Statement

**Current Test Configuration:**
```python
# Parameter space: 36 combinations (4×3×3)
short_window: [5, 10, 15, 20]      # 4 values
long_window: [30, 45, 60]           # 3 values
threshold: [0.01, 0.03, 0.05]       # 3 values
Total: 36 combinations
```

**Why This Is Invalid:**
- Story explicitly targets "**heavy operations**" and "**large-scale optimization workflows**"
- BOHB designed for **100-1000+ combinations** (documented in own rejection rationale)
- Small parameter space causes BOHB overhead to dominate (nameserver, Bayesian optimization, multi-fidelity scheduling)
- Testing outside design parameters invalidates rejection

### Required Re-evaluation

#### Option 1: Large Synthetic Parameter Space (Recommended)

Create a parameter space with **100-1000 combinations** to match story scope:

```python
# Example: 1000 combinations (10×10×10)
param_space = ParameterSpace(
    parameters=[
        DiscreteParameter(name="short_window", min_value=5, max_value=50, step=5),     # 10 values
        DiscreteParameter(name="long_window", min_value=50, max_value=200, step=15),   # 11 values
        DiscreteParameter(name="threshold", min_value=1, max_value=10, step=1),        # 10 values
    ]
)
# Total: 10 × 11 × 10 = 1,100 combinations
```

**Rationale:**
- Matches "large-scale optimization workflows" from story scope
- BOHB's multi-fidelity approach can demonstrate value
- Overhead becomes acceptable proportion of total time

#### Option 2: Real-World Strategy Optimization

Use a realistic strategy with many parameters:

```python
# Example: Real momentum strategy with 8 parameters
param_space = ParameterSpace(
    parameters=[
        DiscreteParameter(name="lookback_period", min_value=10, max_value=100, step=10),        # 10
        DiscreteParameter(name="holding_period", min_value=1, max_value=20, step=2),            # 10
        DiscreteParameter(name="rebalance_frequency", min_value=1, max_value=10, step=1),       # 10
        CategoricalParameter(name="weighting_scheme", choices=["equal", "market_cap", "risk_parity"]),  # 3
        DiscreteParameter(name="top_n_assets", min_value=5, max_value=20, step=5),              # 4
        ContinuousParameter(name="volatility_threshold", min_value=0.1, max_value=0.5, step=0.1),  # 5
        DiscreteParameter(name="min_position_size", min_value=1, max_value=10, step=1),         # 10
        DiscreteParameter(name="max_position_size", min_value=10, max_value=50, step=5),        # 9
    ]
)
# Total: 10 × 10 × 10 × 3 × 4 × 5 × 10 × 9 = 5,400,000 combinations
# BOHB would evaluate ~1000 with multi-fidelity, Grid Search infeasible
```

**Rationale:**
- Demonstrates BOHB's true value proposition
- Grid Search becomes impractical (5M+ combinations)
- Realistic use case for "heavy operations"

### Benchmark Configuration

**Bundle**: Use same mag-7 bundle for consistency
**Date Range**: 2020-01-01 to 2024-12-31
**BOHB Config**:
- `min_budget=0.05` (5% of data for fast low-fidelity)
- `max_budget=1.0` (100% of data for accurate high-fidelity)
- `eta=3` (successive halving factor)
- `n_iterations=10` (more iterations for large space)
- `n_workers=8` (parallel evaluation)

**Comparison**: Grid Search (exhaustive on small subset OR sampling on large space)

### Success Criteria

**Accept BOHB if:**
- Speedup ≥5% vs. exhaustive Grid Search (for 100-1000 combinations), OR
- BOHB finds solution within 10% of optimal using 10% of evaluations (for 1000+ combinations)
- Statistical significance: p<0.05, 95% CI, ≥10 runs
- Functional equivalence: Best solution quality comparable

**Reject BOHB if:**
- Still slower than Grid Search with proper heavy workflow
- Solution quality significantly worse (>20% below optimal)
- Infrastructure overhead still dominates

### Implementation Steps

1. **Update benchmark script**: `scripts/benchmarks/benchmark_phase6b_bohb_heavy.py`
2. **Increase parameter space**: ≥100 combinations minimum
3. **Run benchmark**: 10+ runs with statistical validation
4. **Compare results**: BOHB time vs. Grid Search time
5. **Validate solution quality**: BOHB best vs. Grid Search best
6. **Update decision document**: Based on heavy-workflow results

### Expected Timeline

- Benchmark script update: 2-4 hours
- Benchmark execution: 4-8 hours (depends on parameter space size)
- Analysis and documentation: 2-3 hours
- **Total**: 1-2 days

---

## Issue 2: SharedBundleContext Alternative Implementations

### Problem Statement

**Current Implementation:**
```python
# Line 154: rustybt/optimization/shared_bundle_context.py
serialized_data = pickle.dumps(bundle_data, protocol=pickle.HIGHEST_PROTOCOL)
# Fails: TypeError: cannot pickle 'sqlite3.Connection' object
```

**Why This Failed:**
- Bundle contains non-picklable sqlite3.Connection objects
- Pickle serialization is required for `multiprocessing.shared_memory` in spawn mode
- Rejected without exploring alternatives

### Alternative 1: Fork-Based Multiprocessing (Recommended)

**Approach**: Use `fork()` instead of `spawn()` to avoid serialization entirely.

**Implementation**:
```python
import multiprocessing
import os

# In SharedBundleContext or ParallelOptimizer initialization
if os.name != 'nt':  # Not Windows
    multiprocessing.set_start_method('fork', force=True)
    # Workers inherit bundle connections via copy-on-write
    # No serialization needed!
```

**Advantages**:
- ✅ No pickle serialization (connections inherited directly)
- ✅ Fast startup (copy-on-write memory sharing)
- ✅ Minimal code changes
- ✅ Works with existing SharedBundleContext implementation

**Disadvantages**:
- ❌ Unix/macOS/Linux only (not Windows)
- ❌ Workers share file descriptors (need read-only access)

**Validation Steps**:
1. Modify `SharedBundleContext.__init__()` to use fork mode
2. Test on macOS/Linux (current platform: darwin)
3. Ensure Windows gracefully falls back to per-worker loading
4. Run functional equivalence tests
5. Run performance benchmarks

**Expected Impact**: 13% speedup (original estimate) if fork mode works

### Alternative 2: Read-Only Data Extraction

**Approach**: Extract serializable data from bundle, let workers recreate connections.

**Implementation**:
```python
class SharedBundleContext:
    def initialize(self):
        # Load bundle
        bundle_data = load(self.bundle_name)

        # Extract ONLY serializable data
        serializable_data = {
            'assets': bundle_data.asset_finder.retrieve_all(bundle_data.asset_finder.sids),
            'calendar_sessions': bundle_data.trading_calendar.all_sessions,
            'adjustments': self._extract_adjustments(bundle_data),
            'bundle_path': bundle_data.root,  # Path to recreate connections
            # ... other metadata
        }

        # Serialize ONLY the extracted data
        serialized_data = pickle.dumps(serializable_data, protocol=pickle.HIGHEST_PROTOCOL)

        # Store in shared memory
        # ...

    def get_bundle(self):
        # Deserialize metadata from shared memory
        metadata = pickle.loads(self._shm.buf[8:])

        # Recreate lightweight bundle with connections
        # Each worker creates own sqlite3.Connection
        bundle = self._recreate_bundle(metadata)
        return bundle

    def _recreate_bundle(self, metadata):
        """Recreate bundle with local connections using shared metadata."""
        # Worker creates new BundleData with local SQLite connections
        # using shared asset/calendar metadata
        pass
```

**Advantages**:
- ✅ Works on all platforms (Windows, macOS, Linux)
- ✅ Avoids pickle serialization issue
- ✅ Reduces memory footprint (metadata only)

**Disadvantages**:
- ❌ More complex implementation
- ❌ Workers still create lightweight connections (some overhead)
- ❌ May not achieve full 13% speedup

**Expected Impact**: 5-10% speedup (lower than original estimate)

### Alternative 3: Memory-Mapped Files

**Approach**: Store asset metadata in memory-mapped files, multiple processes read simultaneously.

**Implementation**:
```python
import mmap
import json

class SharedBundleContext:
    def initialize(self):
        bundle_data = load(self.bundle_name)

        # Serialize metadata to JSON
        metadata = {
            'assets': [asset.to_dict() for asset in bundle_data.assets],
            'calendar': bundle_data.calendar.to_dict(),
        }
        metadata_json = json.dumps(metadata).encode('utf-8')

        # Write to memory-mapped file
        with open('/tmp/bundle_metadata.mmap', 'wb') as f:
            f.write(metadata_json)

        self._mmap_file = open('/tmp/bundle_metadata.mmap', 'r+b')
        self._mmap = mmap.mmap(self._mmap_file.fileno(), 0)

    def get_bundle(self):
        # Read from mmap (zero-copy across processes)
        metadata_json = self._mmap.read()
        metadata = json.loads(metadata_json)
        # Recreate bundle...
```

**Advantages**:
- ✅ Cross-platform
- ✅ Zero-copy reads
- ✅ No serialization overhead

**Disadvantages**:
- ❌ Requires file I/O
- ❌ More complex implementation
- ❌ Still requires connection recreation

**Expected Impact**: 3-8% speedup

### Alternative 4: Socket-Based Connection Pooling

**Approach**: Manager process holds connections, workers request data via IPC.

**Advantages**:
- ✅ Clean separation of concerns
- ✅ Works on all platforms

**Disadvantages**:
- ❌ IPC overhead for every data request
- ❌ Likely slower than current per-worker approach
- ❌ High complexity

**Recommendation**: Do NOT pursue (likely negative speedup)

### Recommended Evaluation Order

1. **Try Alternative 1 (fork()) FIRST** - Simplest, highest success probability
2. **If fork() works**: Run benchmarks, document, ACCEPT if ≥5% speedup
3. **If fork() fails or Windows required**: Try Alternative 2 (read-only data)
4. **If Alternative 2 works**: Run benchmarks, ACCEPT if ≥5% speedup
5. **If both fail**: Document architectural constraint, REJECT with proper rationale

### Implementation Steps

**Phase 1: Fork-based approach (1-2 days)**
1. Modify `SharedBundleContext` to use fork mode on Unix
2. Add platform detection (graceful fallback on Windows)
3. Run functional equivalence tests
4. Run performance benchmarks (≥10 runs, 95% CI, p<0.05)
5. If ≥5% speedup: ACCEPT and document
6. If <5% or fails: Proceed to Phase 2

**Phase 2: Read-only data extraction (2-3 days if needed)**
1. Implement serializable metadata extraction
2. Implement bundle recreation from metadata
3. Run functional equivalence tests
4. Run performance benchmarks
5. If ≥5% speedup: ACCEPT and document
6. If <5%: REJECT with comprehensive rationale

### Expected Timeline

- Fork approach: 1-2 days
- Read-only approach (if needed): 2-3 days
- **Total**: 1-5 days depending on success

---

## Summary of Re-evaluation Work

### Required Tasks

1. **BOHB Re-evaluation**:
   - ✅ Implementation already complete (BOHBOptimizer class)
   - [ ] Create new benchmark with ≥100 parameter combinations
   - [ ] Run 10+ benchmark runs with statistical validation
   - [ ] Document results with heavy-workflow evidence

2. **SharedBundleContext Re-evaluation**:
   - ✅ Implementation already complete (basic approach)
   - [ ] Modify to use fork() multiprocessing
   - [ ] Test functional equivalence
   - [ ] Run 10+ benchmark runs with statistical validation
   - [ ] Document results or proceed to Alternative 2

### Acceptance Criteria (Unchanged from Story)

- Functional equivalence validated BEFORE performance testing (BLOCKING)
- ≥10 runs, 95% CI, p<0.05 statistical significance
- ≥5% speedup threshold for acceptance
- Comprehensive decision documentation

### Decision Framework

**ACCEPT optimization if:**
- Tested with proper heavy-workflow scope
- Functional equivalence validated
- ≥5% speedup with statistical significance
- Implementation stable and maintainable

**REJECT optimization if:**
- Still fails with heavy-workflow scope
- Alternatives all fail or impractical
- <5% speedup even with proper testing
- Implementation too complex/risky

---

## Developer Action Items

### Immediate Next Steps

1. **Review this guidance document** thoroughly
2. **Choose evaluation approach**:
   - BOHB: Decide on parameter space size (Option 1 or 2)
   - SharedBundleContext: Start with fork() approach (Alternative 1)
3. **Update benchmark scripts** with heavy-workflow configuration
4. **Execute benchmarks** with statistical validation
5. **Document results** in decision files
6. **Update story tasks** with completion status

### Questions for Product Owner (if needed)

- Is 100-1000 combinations sufficient for "heavy operations" scope?
- Should we support Windows for SharedBundleContext (affects fork() approach)?
- Can we defer one optimization if timeline becomes concern?

### Support Available

- QA (Quinn): Available for methodology review, statistical validation
- Architecture team: Available for bundle refactoring guidance (if needed)
- DevOps: Available for benchmark infrastructure scaling (if needed)

---

## Expected Outcomes

### Best Case
- Both optimizations pass with heavy-workflow scope
- Combined speedup: 13% (SharedBundleContext) + 40% (BOHB) = 53% additional
- Total Phase 6B: 74.97% (PersistentWorkerPool) + 53% = **127.97%** cumulative

### Realistic Case
- One optimization passes (e.g., fork() SharedBundleContext works)
- Additional speedup: 13%
- Total Phase 6B: 74.97% + 13% = **87.97%** cumulative

### Worst Case
- Both optimizations still fail with proper testing
- Comprehensive documentation of architectural constraints
- Total Phase 6B: **74.97%** (PersistentWorkerPool only)
- Ray Distributed remains skipped (diminishing returns)

All outcomes acceptable IF testing methodology is proper.

---

## References

- Original Story: `docs/internal/stories/X4.7.heavy-operations-optimization.story.md`
- QA Gate: `docs/internal/qa/gates/X4.7-heavy-operations-optimization.yml`
- BOHB Implementation: `rustybt/optimization/bohb_optimizer.py`
- SharedBundleContext Implementation: `rustybt/optimization/shared_bundle_context.py`
- Current Benchmarks: `scripts/benchmarks/benchmark_phase6b_*.py`

---

**Document Status**: APPROVED for Developer Implementation
**QA Sign-off**: Quinn (Test Architect)
**Date**: 2025-10-23
