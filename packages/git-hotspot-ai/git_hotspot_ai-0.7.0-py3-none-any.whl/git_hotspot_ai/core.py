"""
Gitçƒ­ç‚¹åˆ†æå·¥å…·çš„æ ¸å¿ƒé€»è¾‘æ¨¡å—

è¯¥æ¨¡å—æä¾›äº†åˆ†æGitä»“åº“ä»¥è¯†åˆ«ä»£ç çƒ­ç‚¹çš„æ ¸å¿ƒåŠŸèƒ½ã€‚ä»£ç çƒ­ç‚¹æ˜¯æŒ‡é¢‘ç¹ä¿®æ”¹çš„æ–‡ä»¶ï¼Œ
è¿™äº›æ–‡ä»¶é€šå¸¸æ˜¯é‡æ„ã€æ–‡æ¡£åŒ–æˆ–å…¶ä»–æ”¹è¿›çš„å€™é€‰ç›®æ ‡ã€‚è¯¥æ¨¡å—é›†æˆäº†AIä»£ç†ï¼Œ
å¯¹è¯†åˆ«å‡ºçš„çƒ­ç‚¹æ–‡ä»¶æ‰§è¡Œå„ç§åˆ†æä»»åŠ¡ã€‚

ä¸»è¦åŠŸèƒ½ç‰¹æ€§:
- Gitæ—¥å¿—åˆ†æï¼šè·Ÿè¸ªæ–‡ä»¶ä¿®æ”¹é¢‘ç‡å’Œä»£ç è¡Œå˜æ›´
- çƒ­ç‚¹è¯„åˆ†ç®—æ³•ï¼šåŸºäºæäº¤æ¬¡æ•°å’Œä»£ç è¡Œå˜æ›´è®¡ç®—è¯„åˆ†
- ä¸cursor-agenté›†æˆï¼šæä¾›AIé©±åŠ¨çš„ä»£ç åˆ†æ
- å¯é…ç½®çš„è¿‡æ»¤å’Œé€‰æ‹©ï¼šç­›é€‰å‡ºé¡¶çº§çƒ­ç‚¹æ–‡ä»¶
- æ”¯æŒå¤šç§åˆ†æä»»åŠ¡ï¼šæ³¨é‡Šã€ç»“æ„åˆ†æã€æ€§èƒ½åˆ†æç­‰
"""

from __future__ import annotations

import dataclasses
import fnmatch
import json
import os
import re
import subprocess
import sys
import time
from collections import Counter
from pathlib import Path
from typing import Iterable


@dataclasses.dataclass()
class AnalyzerConfig:
    """
    çƒ­ç‚¹åˆ†æå™¨çš„é…ç½®ç±»

    è¯¥dataclassç±»å°è£…äº†æ§åˆ¶ä»“åº“æ£€æŸ¥å’Œä¸‹æ¸¸AIä»»åŠ¡æ‰§è¡Œçš„æ‰€æœ‰è¿è¡Œæ—¶å‚æ•°ã€‚
    é€šè¿‡é…ç½®è¿™äº›å‚æ•°ï¼Œå¯ä»¥çµæ´»æ§åˆ¶åˆ†æè¡Œä¸ºã€‚

    å±æ€§è¯´æ˜:
        repo_path: æŒ‡å‘Gitä»“åº“æ ¹ç›®å½•çš„ç»å¯¹æˆ–ç›¸å¯¹è·¯å¾„
        top_selector: çƒ­ç‚¹æ–‡ä»¶é€‰æ‹©ç­–ç•¥ï¼Œæ¥å—æ•´æ•°å­—ç¬¦ä¸²æˆ–ç™¾åˆ†æ¯”å­—ç¬¦ä¸²
        tasks: å¯¹é€‰ä¸­æ–‡ä»¶æ‰§è¡Œçš„ä»»åŠ¡æ ‡è¯†ç¬¦çš„æœ‰åºåˆ—è¡¨
        since: å¯é€‰çš„ISO-8601æ—¥æœŸå­—ç¬¦ä¸²ï¼Œä¼ é€’ç»™Gitçš„--sinceå‚æ•°
        dry_run: ä¸ºtrueæ—¶è·³è¿‡cursor-agentè°ƒç”¨ï¼Œä½†ä»ç”ŸæˆæŠ¥å‘Š
        ignore_patterns: shellé£æ ¼çš„globæ¨¡å¼ï¼Œç”¨äºè·³è¿‡åŒ¹é…çš„æ–‡ä»¶
        min_commits: æ–‡ä»¶åŒ…å«åœ¨çƒ­ç‚¹åˆ—è¡¨ä¸­çš„æœ€å°æäº¤æ¬¡æ•°é˜ˆå€¼
        cursor_agent_path: cursor-agentäºŒè¿›åˆ¶æ–‡ä»¶çš„æ˜¾å¼è·¯å¾„ï¼Œè¦†ç›–ç¯å¢ƒå˜é‡å‘ç°
        force_approve: å½“éœ€è¦ç»•è¿‡å®¡æ‰¹æ—¶ï¼Œå‘cursor-agentæ·»åŠ --forceå‚æ•°
        task_prompt_overrides: ä»»åŠ¡æ ‡è¯†ç¬¦åˆ°è‡ªå®šä¹‰æç¤ºæ–‡æœ¬çš„æ˜ å°„
    """

    repo_path: Path
    top_selector: str
    tasks: list[str]
    since: str | None = None
    dry_run: bool = False
    ignore_patterns: list[str] | None = None
    min_commits: int = 1
    cursor_agent_path: str | None = None
    force_approve: bool = False
    task_prompt_overrides: dict[str, str] | None = None


class ProcessingCache:
    """
    file processing cache manager
    
    this class manages a cache file that tracks which files have been processed
    by AI tasks. it helps avoid redundant processing by keeping a record of
    completed files and their associated tasks.
    
    attributes:
        cache_path: path to the cache file in the repository
        cache_data: dictionary storing file processing information
    """

    def __init__(self, repo_root: Path) -> None:
        """
        initialize the cache manager
        
        args:
            repo_root: root directory of the git repository
        """
        self.cache_path = repo_root / ".git_hotspot_cache"
        self.cache_data: dict[str, dict] = {}
        self._load_cache()

    def _load_cache(self) -> None:
        """load cache data from file if it exists"""
        if not self.cache_path.exists():
            return
        
        try:
            with open(self.cache_path, "r", encoding="utf-8") as f:
                self.cache_data = json.load(f)
        except (json.JSONDecodeError, IOError) as e:
            print(f"âš ï¸  warning: failed to load cache file, starting fresh: {e}")
            self.cache_data = {}

    def _save_cache(self) -> None:
        """save cache data to file"""
        try:
            with open(self.cache_path, "w", encoding="utf-8") as f:
                json.dump(self.cache_data, f, indent=2, ensure_ascii=False)
        except IOError as e:
            print(f"âš ï¸  warning: failed to save cache file: {e}")

    def is_processed(self, file_path: str, tasks: list[str]) -> bool:
        """
        check if a file has been processed with all specified tasks
        
        args:
            file_path: relative path to the file
            tasks: list of task identifiers to check
        
        returns:
            bool: true if all tasks have been completed for this file
        """
        if file_path not in self.cache_data:
            return False
        
        cached_tasks = self.cache_data[file_path].get("tasks_completed", [])
        return all(task in cached_tasks for task in tasks)

    def mark_processed(self, file_path: str, tasks: list[str]) -> None:
        """
        mark a file as processed with specified tasks
        
        args:
            file_path: relative path to the file
            tasks: list of task identifiers that were completed
        """
        if file_path not in self.cache_data:
            self.cache_data[file_path] = {
                "tasks_completed": [],
                "first_processed": time.time(),
            }
        
        existing_tasks = set(self.cache_data[file_path].get("tasks_completed", []))
        existing_tasks.update(tasks)
        self.cache_data[file_path]["tasks_completed"] = list(existing_tasks)
        self.cache_data[file_path]["last_processed"] = time.time()
        
        self._save_cache()

    def get_stats(self) -> dict:
        """
        get cache statistics
        
        returns:
            dict: statistics about cached files
        """
        return {
            "total_files": len(self.cache_data),
            "cache_path": str(self.cache_path),
        }


@dataclasses.dataclass()
class FileHotspot:
    """
    è¡¨ç¤ºæ–‡ä»¶çƒ­ç‚¹åŠå…¶ä¿®æ”¹æŒ‡æ ‡çš„æ•°æ®ç±»

    è¯¥dataclassç±»æ•è·äº†åœ¨çƒ­ç‚¹åˆ†ææœŸé—´å¯¹æ–‡ä»¶è¿›è¡Œæ’åæ‰€éœ€çš„æ´»åŠ¨ä¿¡å·ï¼Œ
    å¹¶æä¾›äº†ç”¨äºæ’åºçš„è¯„åˆ†è¾…åŠ©æ–¹æ³•ã€‚

    å±æ€§è¯´æ˜:
        path: Gitåœ¨git logè¾“å‡ºä¸­äº§ç”Ÿçš„ä»“åº“ç›¸å¯¹æ–‡ä»¶è·¯å¾„
        commit_count: åœ¨æ£€æŸ¥çª—å£å†…è§¦åŠè¯¥æ–‡ä»¶çš„æäº¤æ¬¡æ•°
        line_changes: ä»--numstatæ”¶é›†çš„æ·»åŠ å’Œåˆ é™¤è¡Œçš„èšåˆæ•°é‡

    æ–¹æ³•è¯´æ˜:
        score: è®¡ç®—ç”¨äºçƒ­ç‚¹æ’åçš„ç»¼åˆè¯„åˆ†
    """

    path: Path
    commit_count: int
    line_changes: int

    def score(self) -> float:
        """
        è®¡ç®—æ–‡ä»¶çš„çƒ­ç‚¹è¯„åˆ†ç”¨äºæ’å

        è¯„åˆ†å…¬å¼ç»¼åˆè€ƒè™‘äº†æäº¤é¢‘ç‡å’Œä»£ç å˜æ›´é‡ï¼Œå…¶ä¸­æäº¤æ¬¡æ•°æƒé‡æ›´é«˜ï¼Œ
        å› ä¸ºé¢‘ç¹ä¿®æ”¹é€šå¸¸æ¯”å¤§é‡ä¿®æ”¹æ›´èƒ½åæ˜ ä»£ç çš„æ´»è·ƒåº¦ã€‚

        Returns:
            float: ç»¼åˆè¯„åˆ†å€¼ï¼Œå®šä¹‰ä¸ºcommit_count + 0.1 * line_changesã€‚
                æ›´é«˜çš„å€¼åæ˜ æ›´é¢‘ç¹æˆ–æ›´å¤§çš„å˜æ›´ï¼Œå°†æ–‡ä»¶æ¨å‘çƒ­ç‚¹æ’åºçš„é¡¶éƒ¨ã€‚
        """
        return self.commit_count + 0.1 * self.line_changes


# ä¸åŒAIåˆ†æä»»åŠ¡çš„ä»»åŠ¡æç¤ºæ¨¡æ¿
# è¿™äº›æ¨¡æ¿å®šä¹‰äº†å„ç§åˆ†æä»»åŠ¡çš„å…·ä½“æŒ‡ä»¤ï¼Œç”¨äºæŒ‡å¯¼AIå¯¹çƒ­ç‚¹æ–‡ä»¶è¿›è¡Œåˆ†æ
TASK_PROMPTS = {
    "annotate": "è¯·ä¸ºè¿™ä¸ªæ–‡ä»¶æ·»åŠ è¯¦ç»†çš„ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£ã€‚åˆ†æä»£ç çš„åŠŸèƒ½ã€å‚æ•°ã€è¿”å›å€¼ï¼Œå¹¶æ·»åŠ é€‚å½“çš„æ³¨é‡Šæ¥æé«˜ä»£ç å¯è¯»æ€§ã€‚",
    "structure": "è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶çš„ä»£ç ç»“æ„ï¼Œè¯†åˆ«æ½œåœ¨çš„é‡æ„æœºä¼šï¼Œæå‡ºæ”¹è¿›ä»£ç ç»„ç»‡å’Œæ¶æ„çš„å»ºè®®ã€‚",
    "skills": "è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶éœ€è¦çš„æŠ€èƒ½å’Œä¸“ä¸šçŸ¥è¯†ï¼Œè¯†åˆ«ä»£ç ä¸­ä½¿ç”¨çš„æŠ€æœ¯æ ˆã€è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µã€‚",
    "performance": "è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶çš„æ€§èƒ½ç‰¹å¾ï¼Œè¯†åˆ«æ½œåœ¨çš„æ€§èƒ½ç“¶é¢ˆï¼Œæå‡ºä¼˜åŒ–å»ºè®®å’Œæ”¹è¿›æ–¹æ¡ˆã€‚",
    "mvp": "è¯·åŸºäºè¿™ä¸ªæ–‡ä»¶ç”Ÿæˆ MVPï¼ˆæœ€å°å¯è¡Œäº§å“ï¼‰å»ºè®®ï¼Œåˆ†ææ ¸å¿ƒåŠŸèƒ½å’Œç®€åŒ–æ–¹æ¡ˆã€‚",
}


class HotspotAnalyzer:
    """
    ç”¨äºè¯†åˆ«å’Œå¤„ç†Gitä»£ç çƒ­ç‚¹çš„ä¸»è¦åˆ†æå™¨ç±»

    è¯¥ç±»åè°ƒæ•´ä¸ªçƒ­ç‚¹åˆ†ææµç¨‹ï¼Œä»æ”¶é›†Gitæ—¥å¿—æ•°æ®åˆ°åœ¨æœ€æ´»è·ƒçš„æ–‡ä»¶ä¸Šåˆ†æ´¾AIä»»åŠ¡ã€‚
    å®ƒåœ¨æ•°æ®æ”¶é›†ã€åˆ†æå’ŒAIä»»åŠ¡æ‰§è¡Œä¹‹é—´æä¾›äº†æ¸…æ™°çš„åˆ†ç¦»ã€‚

    å±æ€§è¯´æ˜:
        config: åŒ…å«åˆ†æå‚æ•°çš„é…ç½®å¯¹è±¡
        analysis_path: åˆ†æç›®æ ‡çš„è§£æè·¯å¾„
        repo_root: Gitä»“åº“çš„æ ¹ç›®å½•
        git_cwd: Gitå‘½ä»¤çš„å·¥ä½œç›®å½•
        analysis_rel: ä»ä»“åº“æ ¹ç›®å½•åˆ°åˆ†æç›®æ ‡çš„ç›¸å¯¹è·¯å¾„
        cursor_agent_path: ç»è¿‡éªŒè¯çš„cursor-agentå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
    """

    def __init__(self, config: AnalyzerConfig) -> None:
        """
        ä½¿ç”¨ç»™å®šé…ç½®åˆå§‹åŒ–çƒ­ç‚¹åˆ†æå™¨

        è¯¥æ–¹æ³•ä¼šéªŒè¯é…ç½®å‚æ•°ï¼Œè§£æè·¯å¾„ï¼Œå¹¶ç¡®ä¿cursor-agentå¯æ‰§è¡Œæ–‡ä»¶å¯ç”¨ã€‚
        å¦‚æœéªŒè¯å¤±è´¥ï¼Œä¼šç«‹å³é€€å‡ºç¨‹åºä»¥é¿å…åç»­è¿è¡Œæ—¶é”™è¯¯ã€‚

        Args:
            config: å®Œå…¨å¡«å……çš„AnalyzerConfigå®ä¾‹ï¼Œæ§åˆ¶è¿è¡Œæ—¶è¡Œä¸º

        Raises:
            SystemExit: å½“cursor-agentéªŒè¯æ— æ³•ç¡®è®¤å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„æ—¶
        """
        # å­˜å‚¨åŸå§‹é…ç½®ä»¥ä¾›åç»­ä½¿ç”¨
        self.config = config
        # å°†åˆ†æç›®æ ‡è§£æä¸ºç»å¯¹è·¯å¾„ï¼Œé¿å…ç›¸å¯¹è·¯å¾„æ­§ä¹‰
        self.analysis_path = config.repo_path.resolve()
        # ä½¿ç”¨Gitå…ƒæ•°æ®å®šä½ä»“åº“æ ¹ç›®å½•ï¼Œç¡®ä¿æ­£ç¡®æ€§
        self.repo_root = self._resolve_repo_root(self.analysis_path)
        # Gitå‘½ä»¤ä»ä»“åº“æ ¹ç›®å½•æ“ä½œï¼Œç¡®ä¿è·¯å¾„å¤„ç†çš„ä¸€è‡´æ€§
        self.git_cwd = self.repo_root
        # è®¡ç®—åˆ†æç›®æ ‡ç›¸å¯¹äºä»“åº“æ ¹ç›®å½•çš„è·¯å¾„ï¼Œç”¨äºè¿‡æ»¤
        self.analysis_rel = self._compute_analysis_relative_path()
        # ç«‹å³éªŒè¯cursor-agentå¯ç”¨æ€§ï¼Œå¦‚æœé…ç½®é”™è¯¯åˆ™å¿«é€Ÿå¤±è´¥
        self.cursor_agent_path = self._validate_cursor_agent_path()
        # initialize processing cache for tracking processed files
        self.processing_cache = ProcessingCache(self.repo_root)

    # region public API
    def run(self) -> None:
        """
        æ‰§è¡Œå®Œæ•´çš„çƒ­ç‚¹åˆ†æå·¥ä½œæµç¨‹

        è¯¥æ–¹æ³•æŒ‰é¡ºåºåè°ƒæ•°æ®æ”¶é›†ã€é€‰æ‹©ã€æŠ¥å‘Šå’Œå¯é€‰çš„AIæ‰§è¡Œã€‚
        æ¯ä¸ªé˜¶æ®µéƒ½ä¾èµ–è¾…åŠ©æ–¹æ³•ï¼Œä½¿æ§åˆ¶æµç¨‹ä¿æŒæ˜“äºå®¡è®¡ã€‚

        Returns:
            None.
        """
        # æ”¶é›†æ‰€æœ‰çƒ­ç‚¹æ–‡ä»¶æ•°æ®
        hotspots = self._collect_hotspots()
        # æ ¹æ®é…ç½®é€‰æ‹©é¡¶çº§çƒ­ç‚¹æ–‡ä»¶
        selected = self._select_top(hotspots)
        # æ‰“å°åˆ†ææ‘˜è¦æŠ¥å‘Š
        self._print_summary(hotspots, selected)
        # å¦‚æœä¸æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œåˆ™åˆ†æ´¾AIä»»åŠ¡
        if not self.config.dry_run:
            self._dispatch_ai_tasks(selected)

    # endregion

    # region hotspot computation
    def _collect_hotspots(self) -> list[FileHotspot]:
        """
        é€šè¿‡åˆ†æGitæ—¥å¿—ä¿¡æ¯æ”¶é›†çƒ­ç‚¹æ•°æ®

        è¯¥æ–¹æ³•æ‰§è¡Œgit logå‘½ä»¤è·å–æ–‡ä»¶ä¿®æ”¹å†å²ï¼Œè§£ænumstatè¾“å‡ºè®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„
        æäº¤æ¬¡æ•°å’Œä»£ç è¡Œå˜æ›´ï¼Œç„¶åæ ¹æ®è¯„åˆ†å¯¹æ–‡ä»¶è¿›è¡Œæ’åºã€‚

        Returns:
            list[FileHotspot]: åœ¨ä»“åº“èŒƒå›´å†…å‘ç°çš„çƒ­ç‚¹æ–‡ä»¶æ’åºåˆ—è¡¨ï¼ˆæŒ‰è¯„åˆ†é™åºï¼‰

        Raises:
            subprocess.CalledProcessError: å½“Gitæ— æ³•æˆåŠŸæ‰§è¡Œæ—¶ä¼ æ’­å¼‚å¸¸
        """
        # æ„å»ºgit logå‘½ä»¤ï¼Œä½¿ç”¨numstatè·å–ä»£ç è¡Œå˜æ›´æ•°æ®
        git_cmd = ["git", "log", "--numstat", "--pretty=format:%H"]

        # å¦‚æœæŒ‡å®šäº†æ—¶é—´èŒƒå›´ï¼Œæ·»åŠ --sinceå‚æ•°
        if self.config.since:
            git_cmd.append(f"--since={self.config.since}")

        # å¦‚æœæŒ‡å®šäº†åˆ†æèŒƒå›´ï¼Œé™åˆ¶åˆ°ç‰¹å®šç›®å½•
        if self.analysis_rel:
            git_cmd.extend(["--", self.analysis_rel])

        # åœ¨ä»“åº“æ ¹ç›®å½•æ‰§è¡Œgitå‘½ä»¤
        result = subprocess.run(
            git_cmd,
            cwd=self.git_cwd,
            capture_output=True,
            text=True,
            check=True,
        )

        # ç”¨äºè·Ÿè¸ªæ–‡ä»¶ç»Ÿè®¡æ•°æ®çš„è®¡æ•°å™¨
        commit_counts: Counter[Path] = Counter()
        line_changes: Counter[Path] = Counter()

        # é€è¡Œå¤„ç†git logè¾“å‡º
        for line in result.stdout.splitlines():
            stripped = line.strip()
            if not stripped:
                continue
            # è·³è¿‡æäº¤å“ˆå¸Œè¡Œ
            if re.fullmatch(r"[0-9a-fA-F]{40}", stripped):
                continue

            # è§£ænumstatæ ¼å¼ï¼šæ·»åŠ è¡Œæ•°\tåˆ é™¤è¡Œæ•°\tæ–‡ä»¶å
            parts = stripped.split("\t")
            if len(parts) != 3:
                continue
            added, deleted, filename = parts
            if not filename:
                continue
            # æ ‡å‡†åŒ–æ–‡ä»¶åï¼Œå¤„ç†é‡å‘½åç­‰æƒ…å†µ
            normalized_filename = self._normalize_git_filename(filename)
            if not normalized_filename:
                continue
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥æ­¤æ–‡ä»¶
            if self._should_ignore(normalized_filename):
                continue
            rel_path = Path(normalized_filename)
            # å¦‚æœæŒ‡å®šäº†åˆ†æèŒƒå›´ï¼Œè¿‡æ»¤æ–‡ä»¶
            if self.analysis_rel and not rel_path.is_relative_to(self.analysis_rel):
                continue

            # å¢åŠ æ­¤æ–‡ä»¶çš„æäº¤è®¡æ•°
            commit_counts[rel_path] += 1
            # å®‰å…¨è§£æä»£ç è¡Œå˜æ›´æ•°å­—ï¼›äºŒè¿›åˆ¶å·®å¼‚ä½¿ç”¨'-'ï¼Œåº”è§†ä¸ºé›¶
            additions = int(added) if added.isdigit() else 0
            deletions = int(deleted) if deleted.isdigit() else 0
            line_changes[rel_path] += additions + deletions

        # åˆ›å»ºçƒ­ç‚¹å¯¹è±¡å¹¶æŒ‰æœ€å°æäº¤æ¬¡æ•°è¿‡æ»¤
        hotspots = [
            FileHotspot(path, commit_counts[path], line_changes[path])
            for path in commit_counts
            if commit_counts[path] >= self.config.min_commits
        ]
        # æŒ‰è¯„åˆ†é™åºæ’åºï¼Œä½¿ä¸‹æ¸¸é€‰æ‹©ä¿æŒç®€å•
        hotspots.sort(key=lambda item: item.score(), reverse=True)
        return hotspots

    def _select_top(self, hotspots: list[FileHotspot]) -> list[FileHotspot]:
        """
        æ ¹æ®é…ç½®çš„é€‰æ‹©å™¨é€‰æ‹©é¡¶çº§æ–‡ä»¶

        æ”¯æŒä¸¤ç§é€‰æ‹©æ¨¡å¼ï¼š
        1. ç»å¯¹æ•°é‡ï¼šå¦‚"10"è¡¨ç¤ºé€‰æ‹©å‰10ä¸ªæ–‡ä»¶
        2. ç™¾åˆ†æ¯”ï¼šå¦‚"20%"è¡¨ç¤ºé€‰æ‹©å‰20%çš„æ–‡ä»¶

        Args:
            hotspots: æŒ‰è¯„åˆ†æ’åºçš„æ‰€æœ‰çƒ­ç‚¹æ–‡ä»¶åˆ—è¡¨

        Returns:
            list[FileHotspot]: ä»top_selectoræ´¾ç”Ÿçš„çƒ­ç‚¹æ–‡ä»¶é€‰æ‹©

        Raises:
            ValueError: å¦‚æœé€‰æ‹©å™¨æ— æ³•è§£æä¸ºæœ‰æ•ˆçš„æ•°é‡æˆ–ç™¾åˆ†æ¯”å€¼
        """
        # å¦‚æœæ²¡æœ‰çƒ­ç‚¹æ–‡ä»¶ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not hotspots:
            return []
        selector = self.config.top_selector.strip()
        if not selector:
            raise ValueError("top_selector must not be empty")

        if selector.endswith("%"):
            # åŸºäºç™¾åˆ†æ¯”çš„é€‰æ‹©ï¼Œå¸¦æ˜¾å¼éªŒè¯
            percentage_value = selector.rstrip("%")
            try:
                percentage = float(percentage_value)
            except ValueError as exc:
                raise ValueError(f"invalid percentage selector: '{selector}'") from exc
            if percentage <= 0:
                raise ValueError("percentage selector must be positive")
            selection_size = int(len(hotspots) * (percentage / 100.0))
        else:
            # ç»å¯¹æ•°é‡é€‰æ‹©ï¼Œå¸¦æ˜¾å¼éªŒè¯
            try:
                selection_size = int(selector)
            except ValueError as exc:
                raise ValueError(f"invalid numeric selector: '{selector}'") from exc
            if selection_size <= 0:
                raise ValueError("numeric selector must be positive")

        # ç¡®ä¿é€‰æ‹©å¤§å°åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if selection_size < 1:
            selection_size = 1
        if selection_size > len(hotspots):
            selection_size = len(hotspots)
        return hotspots[:selection_size]

    # endregion

    # region reporting & AI dispatch
    def _print_summary(
        self,
        hotspots: list[FileHotspot],
        selected: list[FileHotspot],
    ) -> None:
        """æ˜¾ç¤ºåˆ†æç»“æœçš„è¯¦ç»†æ‘˜è¦

        è¯¥æ–¹æ³•ç”Ÿæˆæ ¼å¼åŒ–çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
        - åˆ†æé…ç½®ä¿¡æ¯
        - æ•°æ®æ”¶é›†ç»Ÿè®¡
        - å®Œæ•´çš„çƒ­ç‚¹æ–‡ä»¶æ’åè¡¨
        - é€‰ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        - å¾…æ‰§è¡Œçš„AIä»»åŠ¡ä¿¡æ¯

        Args:
            hotspots: ä»gitå†å²ç”Ÿæˆçš„å®Œæ•´çƒ­ç‚¹æ–‡ä»¶æ’å
            selected: ä¸ºAIä»»åŠ¡æ‰§è¡Œé€‰æ‹©çš„çƒ­ç‚¹æ–‡ä»¶å­é›†

        Returns:
            None.
        """
        # æ‰“å°æŠ¥å‘Šå¤´éƒ¨ä¿¡æ¯
        print("=" * 80)
        print("ğŸ”¥ Git Hotspot Analysis Report")
        print("=" * 80)
        print(f"ğŸ“ Repository: {self.repo_root}")
        if self.analysis_rel:
            print(f"ğŸ“‚ Analysis Scope: {self.analysis_rel}")
        if self.config.since:
            print(f"ğŸ“… Time Filter: since {self.config.since}")
        if self.config.ignore_patterns:
            print(f"ğŸš« Ignored Patterns: {', '.join(self.config.ignore_patterns)}")
        print(f"ğŸ“Š Minimum Commits: {self.config.min_commits}")
        
        # display cache statistics
        cache_stats = self.processing_cache.get_stats()
        print(f"ğŸ’¾ Cache: {cache_stats['total_files']} files tracked in {cache_stats['cache_path']}")
        print()

        # æ˜¾ç¤ºå®Œæ•´çš„æ•°æ®æ”¶é›†æ‘˜è¦
        print("ğŸ“ˆ Data Collection Summary:")
        print(f"   â€¢ Total files analyzed: {len(hotspots)}")
        print(f"   â€¢ Files selected for AI analysis: {len(selected)}")
        print(f"   â€¢ Selection criteria: {self.config.top_selector}")
        print()

        # æ˜¾ç¤ºæ‰€æœ‰çƒ­ç‚¹æ–‡ä»¶çš„è¯¦ç»†æŒ‡æ ‡
        if hotspots:
            print("ğŸ“‹ Complete Hotspot Ranking:")
            print("-" * 80)
            print(
                f"{'Rank':<6} {'File Path':<50} {'Commits':<8} {'Lines':<10} {'Score':<8}"
            )
            print("-" * 80)

            for idx, item in enumerate(hotspots, start=1):
                # åœ¨è¡¨æ ¼ä¸­é«˜äº®æ˜¾ç¤ºé€‰ä¸­çš„æ–‡ä»¶ï¼Œä¾¿äºå¿«é€Ÿæ‰«æ
                marker = "ğŸ¯" if item in selected else "  "
                print(
                    f"{marker}{idx:>3}. {str(item.path):<50} {item.commit_count:>6} {item.line_changes:>8} {item.score():>6.1f}"
                )
            print("-" * 80)

        # æ˜¾ç¤ºä¸ºAIåˆ†æé€‰ä¸­çš„æ–‡ä»¶
        if selected:
            print()
            print("ğŸ¯ Selected Files for AI Analysis:")
            print("-" * 60)
            for idx, item in enumerate(selected, start=1):
                print(f"{idx:>3}. {item.path}")
                print(
                    f"     ğŸ“Š Metrics: {item.commit_count} commits, {item.line_changes} line changes, score: {item.score():.1f}"
                )
            print("-" * 60)

        # æ˜¾ç¤ºä»»åŠ¡ä¿¡æ¯
        if not self.config.dry_run and selected:
            print()
            print("ğŸ¤– AI Tasks to Execute:")
            for task in self.config.tasks:
                try:
                    task_desc = self._resolve_task_prompt(task)
                except KeyError:
                    task_desc = "task prompt not defined"
                print(f"   â€¢ {task}: {task_desc[:60]}...")

        if self.config.dry_run:
            print()
            print("ğŸ” (Dry-run mode: AI tasks will be skipped)")

        print("=" * 80)

    def _dispatch_ai_tasks(self, files: list[FileHotspot]) -> None:
        """
        ä¸ºé€‰ä¸­çš„çƒ­ç‚¹æ–‡ä»¶åˆ†æ´¾AIåˆ†æä»»åŠ¡

        è¯¥æ–¹æ³•åè°ƒæ‰€æœ‰é…ç½®çš„AIä»»åŠ¡åœ¨æ¯ä¸ªé€‰ä¸­çš„çƒ­ç‚¹æ–‡ä»¶ä¸Šçš„æ‰§è¡Œã€‚
        å®ƒæä¾›è¯¦ç»†çš„è¿›åº¦è·Ÿè¸ªå’Œé”™è¯¯å¤„ç†ï¼Œç¡®ä¿å³ä½¿ä¸ªåˆ«ä»»åŠ¡å¤±è´¥ä¹Ÿèƒ½ç¨³å¥æ‰§è¡Œã€‚

        Args:
            files: è¦ç”¨AIä»»åŠ¡å¤„ç†çš„çƒ­ç‚¹æ–‡ä»¶åˆ—è¡¨
        """
        if not files:
            print("\nâš ï¸  No files selected for AI analysis.")
            return

        # filter out already processed files based on cache
        files_to_process: list[FileHotspot] = []
        skipped_files: list[FileHotspot] = []
        
        for hotspot in files:
            file_path_str = str(hotspot.path)
            if self.processing_cache.is_processed(file_path_str, self.config.tasks):
                skipped_files.append(hotspot)
            else:
                files_to_process.append(hotspot)

        # print information about skipped files
        if skipped_files:
            print(f"\nâ­ï¸  Skipping {len(skipped_files)} already processed file(s):")
            print("=" * 80)
            for idx, hotspot in enumerate(skipped_files, 1):
                print(f"   {idx}. {hotspot.path}")
                print(f"      ğŸ“Š Metrics: {hotspot.commit_count} commits, {hotspot.line_changes} line changes")
                cached_info = self.processing_cache.cache_data.get(str(hotspot.path), {})
                completed_tasks = cached_info.get("tasks_completed", [])
                print(f"      âœ… Completed tasks: {', '.join(completed_tasks)}")
            print("=" * 80)

        if not files_to_process:
            print("\nâœ… All selected files have already been processed!")
            return

        total_files = len(files_to_process)
        total_tasks = len(self.config.tasks) * total_files

        print(f"\nğŸš€ Starting AI Analysis...")
        print(
            f"ğŸ“Š Progress Overview: {total_files} files Ã— {len(self.config.tasks)} tasks = {total_tasks} total operations"
        )
        if skipped_files:
            print(f"   ({len(skipped_files)} file(s) skipped from cache)")
        print("=" * 80)

        completed_tasks = 0

        # process each file with all configured tasks
        for file_idx, hotspot in enumerate(files_to_process, 1):
            print(f"\nğŸ“„ Processing File {file_idx}/{total_files}: {hotspot.path}")
            print(
                f"   ğŸ“Š File Metrics: {hotspot.commit_count} commits, {hotspot.line_changes} line changes, score: {hotspot.score():.1f}"
            )

            file_tasks_completed = 0
            file_tasks_total = len(self.config.tasks)
            successfully_completed_tasks: list[str] = []

            # execute each task for the current file
            for task_idx, task in enumerate(self.config.tasks, 1):
                if not self._has_task_prompt(task):
                    print(
                        f"   âš ï¸  Task {task_idx}/{file_tasks_total}: Unknown task '{task}', skipping..."
                    )
                    continue

                print(f"   ğŸ¤– Task {task_idx}/{file_tasks_total}: {task}")

                try:
                    success = self._invoke_cursor_agent_for_task(
                        str(self.repo_root / hotspot.path), task, hotspot
                    )
                    if success:
                        file_tasks_completed += 1
                        completed_tasks += 1
                        successfully_completed_tasks.append(task)
                        print(f"      âœ… Completed successfully")
                    else:
                        print(f"      âŒ Failed")
                except Exception as e:
                    print(f"      ğŸ’¥ Error: {e}")

                # show overall progress; protect against division by zero indirectly by checking total_tasks earlier
                progress_pct = (completed_tasks / total_tasks) * 100
                print(
                    f"      ğŸ“ˆ Overall Progress: {completed_tasks}/{total_tasks} ({progress_pct:.1f}%)"
                )

            # update cache with successfully completed tasks
            if successfully_completed_tasks:
                file_path_str = str(hotspot.path)
                self.processing_cache.mark_processed(file_path_str, successfully_completed_tasks)
                print(f"   ğŸ’¾ Cache updated for {len(successfully_completed_tasks)} completed task(s)")

            # file completion summary
            file_success_rate = (
                (file_tasks_completed / file_tasks_total) * 100
                if file_tasks_total > 0
                else 0
            )
            print(
                f"   ğŸ“‹ File Summary: {file_tasks_completed}/{file_tasks_total} tasks completed ({file_success_rate:.1f}%)"
            )

        # final summary
        print("\n" + "=" * 80)
        print("ğŸ‰ AI Analysis Complete!")
        final_success_rate = (
            (completed_tasks / total_tasks) * 100 if total_tasks > 0 else 0
        )
        print(
            f"ğŸ“Š Final Results: {completed_tasks}/{total_tasks} tasks completed ({final_success_rate:.1f}%)"
        )
        if skipped_files:
            print(f"   ({len(skipped_files)} file(s) were skipped from cache)")
        print("=" * 80)

    def _invoke_cursor_agent_for_task(
        self, file_path: str, task: str, hotspot: FileHotspot
    ) -> bool:
        """
        Invoke cursor-agent for a specific task on a file.

        Args:
            file_path: Absolute path string for the file passed to cursor-agent.
            task: Task identifier expected to exist inside ``TASK_PROMPTS``.
            hotspot: Metrics instance providing contextual information for the prompt.

        Returns:
            bool: ``True`` when cursor-agent exits successfully, ``False`` otherwise.
        """

        prompt = self._build_task_prompt(file_path, task, hotspot)

        # construct cursor-agent command
        cmd = [
            self.cursor_agent_path,
            "--print",  # print responses to console for non-interactive use
        ]

        # add --force flag only if explicitly requested and allowed
        if self.config.force_approve:
            cmd.append("--force")

        cmd.append(prompt)

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=3000,  # 3000 seconds timeout for safety
                check=False,  # don't raise exception on non-zero exit
            )

            if result.returncode == 0:
                if result.stdout.strip():
                    # show a preview of the output so the operator can skim without opening separate tools
                    output_preview = result.stdout.strip()[:150]
                    if len(result.stdout.strip()) > 150:
                        output_preview += "..."
                    print(f"      ğŸ’¬ Output: {output_preview}")
                return True
            else:
                if result.stderr.strip():
                    error_msg = result.stderr.strip()[:100]
                    if len(result.stderr.strip()) > 100:
                        error_msg += "..."
                    print(f"      ğŸš¨ Error (code {result.returncode}): {error_msg}")
                return False

        except subprocess.TimeoutExpired:
            print(f"      â° Task timed out after 5 minutes")
            return False
        except Exception as e:
            print(f"      ğŸ’¥ Exception: {str(e)[:100]}")
            return False

    def _build_task_prompt(
        self, file_path: str, task: str, hotspot: FileHotspot
    ) -> str:
        """
        Build a comprehensive prompt for cursor-agent based on task type and file metrics.

        Args:
            file_path: Absolute path string to include inside the AI context block.
            task: Key that maps to the stored Chinese-language instructions.
            hotspot: Activity data to embed inside the generated prompt.

        Returns:
            str: Fully formatted prompt string assembled for cursor-agent consumption.
        """
        base_prompt = self._resolve_task_prompt(task)

        context = f"""
æ–‡ä»¶è·¯å¾„: {file_path}
Git çƒ­ç‚¹æŒ‡æ ‡:
- æäº¤æ¬¡æ•°: {hotspot.commit_count}
- ä»£ç å˜æ›´è¡Œæ•°: {hotspot.line_changes}
- çƒ­ç‚¹è¯„åˆ†: {hotspot.score():.1f}

{base_prompt}

è¯·åˆ†ææ–‡ä»¶ {file_path} å¹¶æä¾›ç›¸åº”çš„å»ºè®®ã€‚
"""
        return context.strip()

    def _resolve_task_prompt(self, task: str) -> str:
        """resolve prompt text for a task identifier."""
        overrides = self.config.task_prompt_overrides or {}
        if task in overrides:
            return overrides[task]
        if task in TASK_PROMPTS:
            return TASK_PROMPTS[task]
        raise KeyError(task)

    def _has_task_prompt(self, task: str) -> bool:
        """check whether a prompt is defined for the given task."""
        overrides = self.config.task_prompt_overrides or {}
        if task in overrides:
            return True
        return task in TASK_PROMPTS

    # endregion

    # region helpers
    def _should_ignore(self, filename: str) -> bool:
        """
        Check if a filename should be ignored based on configured patterns.

        Args:
            filename: Repo-relative path string extracted from ``git log`` output.

        Returns:
            bool: ``True`` when any ignore pattern matches the file, otherwise ``False``.
        """
        patterns = self.config.ignore_patterns or []
        for pattern in patterns:
            if fnmatch.fnmatch(filename, pattern):
                return True
        return False

    def _normalize_git_filename(self, raw_filename: str) -> str | None:
        """normalize filename tokens emitted by git numstat output."""
        candidate = raw_filename.strip()
        if not candidate:
            return None

        if " => " not in candidate:
            return candidate

        brace_pattern = re.compile(r"\{([^{}]+?) => ([^{}]+?)\}")
        previous = None
        normalized = candidate

        while previous != normalized:
            previous = normalized
            normalized = brace_pattern.sub(lambda match: match.group(2), normalized)

        if " => " in normalized:
            normalized_segments = normalized.split(" => ")
            normalized = normalized_segments[-1]

        normalized = normalized.strip()
        if not normalized:
            return None
        return normalized

    def _resolve_repo_root(self, path: Path) -> Path:
        """
        Resolve the Git repository root directory from a given path.

        Args:
            path: Path within the repository to start from.

        Returns:
            Path: Repository root produced by ``git rev-parse --show-toplevel``.

        Raises:
            subprocess.CalledProcessError: If the path is not within a Git repository
        """
        # rely on git metadata instead of manual parent traversal to avoid false positives
        result = subprocess.run(
            ["git", "rev-parse", "--show-toplevel"],
            cwd=path,
            capture_output=True,
            text=True,
            check=True,
        )
        return Path(result.stdout.strip())

    def _compute_analysis_relative_path(self) -> str | None:
        """
        Compute the relative path from repository root to analysis target.

        Returns:
            str | None: Relative subpath when restricting analysis, otherwise ``None``.
        """
        if self.analysis_path == self.repo_root:
            return None
        return str(self.analysis_path.relative_to(self.repo_root))

    def _validate_cursor_agent_path(self) -> str:
        """Validate and return cursor-agent executable path.

        Returns:
            str: Verified file-system path pointing to the cursor-agent executable.

        Raises:
            SystemExit: When the path cannot be discovered or verified as a file.
        """
        # first check if provided in config
        if self.config.cursor_agent_path:
            cursor_path = self.config.cursor_agent_path
        else:
            # check environment variable
            cursor_path = os.environ.get("CURSOR_AGENT_PATH")

        if not cursor_path:
            print("Error: CURSOR_AGENT_PATH environment variable is not set!")
            print(
                "Please set the environment variable to point to your cursor-agent executable:"
            )
            print("  export CURSOR_AGENT_PATH=/path/to/cursor-agent")
            print("  # or")
            print("  export CURSOR_AGENT_PATH=$(which cursor-agent)")
            sys.exit(1)

        # check if the path exists and is executable
        cursor_path_obj = Path(cursor_path)
        if not cursor_path_obj.exists():
            print(f"Error: cursor-agent not found at: {cursor_path}")
            print("Please check your CURSOR_AGENT_PATH environment variable.")
            sys.exit(1)

        if not cursor_path_obj.is_file():
            print(f"Error: {cursor_path} is not a file")
            sys.exit(1)

        # try to verify it's actually cursor-agent by running --version
        try:
            result = subprocess.run(
                [cursor_path, "--version"],
                capture_output=True,
                text=True,
                timeout=10,
                check=False,
            )
            if result.returncode != 0:
                print(
                    f"Warning: {cursor_path} may not be a valid cursor-agent executable"
                )
                print(f"Version check failed with return code: {result.returncode}")
        except Exception as e:
            print(f"Warning: Could not verify cursor-agent executable: {e}")

        return cursor_path

    # endregion
