{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f935234",
   "metadata": {},
   "source": [
    "# Pruning MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c079a023",
   "metadata": {},
   "source": [
    "In this demo we will show you how to: \n",
    "* Wrap a PyTorch model with the `PruningMLP` class\n",
    "* Set up a pruning schedule and train the pruning MLP\n",
    "* Perform symbolic regression on a pruned MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b5f78",
   "metadata": {},
   "source": [
    "## Pruning Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f29635",
   "metadata": {},
   "source": [
    "For interpretability purposes, it is good to reduce the dimensionality of deep learning models. High-dimensional representations often entangle multiple features, making it difficult to extract clear, human-understandable relationships. By encouraging a sparse representation, we encourage the network to compress information into a smaller set of meaningful components. This may also make symbolic regression possible on these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d849f2",
   "metadata": {},
   "source": [
    "The SymTorch pruning class allows you to dynamically reduce the output dimensionality of MLPs by zero-masking the unimportant dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18ba6a",
   "metadata": {},
   "source": [
    "**Important dimensions**: The dimensions that the model uses the most in predicting the output. These would vary most with differences in the input. Hence we choose the important dimensions as the ones with the highest standard deviation across the datapoints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b0f14",
   "metadata": {},
   "source": [
    "We pass some input data through the model (usually a subset of the validation set) and analyse the outputs of the MLP. We choose the output dimensions that have the highest standard deviation across the datapoints, as shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36902e01",
   "metadata": {},
   "source": [
    "<img src=\"../_static/choosing_important_dims.png\" width=\"450\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f4a7a",
   "metadata": {},
   "source": [
    "## Wrapping a PyTorch model\n",
    "Create a simple PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model with MLP f_net and linear g_net.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, output_dim_f=32, hidden_dim=128):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.f_net = MLP(input_dim, output_dim_f, hidden_dim)\n",
    "        # g is linear - only learns to combine the 2 pruned outputs from f\n",
    "        self.g_net = nn.Linear(output_dim_f, output_dim)  # Will use first 2 dims of f after pruning\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f_net(x)\n",
    "        x = self.g_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941215c",
   "metadata": {},
   "source": [
    "Train the model on some data. We have a composite function $y=g(f(\\mathbf{x}))$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& f_0 = x_0^2\\\\\n",
    "& f_1 = \\sin{x_4}\n",
    "\\end{aligned}\n",
    "$$\n",
    "and $g$ is just a linear transformation of $f_0$ and $f_1$\n",
    "\n",
    "$$\n",
    "g(\\mathbf{f}) = 2.5f_0 -1.3f_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f363579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make the dataset \n",
    "x = np.array([np.random.uniform(0, 1, 10_000) for _ in range(5)]).T\n",
    "\n",
    "def f_func(x):\n",
    "    f0 = x[:, 0]**2 \n",
    "    f1 = np.sin(x[:, 4])  \n",
    "    return np.stack([f0, f1], axis=1)\n",
    "\n",
    "def g_func(f_output):\n",
    "    a, b = 2.5, -1.3  \n",
    "    return a * f_output[:, 0] + b * f_output[:, 1]\n",
    "\n",
    "# Generate ground truth data\n",
    "f_true = f_func(x)\n",
    "y = g_func(f_true)\n",
    "\n",
    "noise = np.array([np.random.normal(0, 0.05*np.std(y)) for _ in range(len(y))])\n",
    "y = y + noise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d25b3e",
   "metadata": {},
   "source": [
    "We need to set up the pruning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8028b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from symtorch import PruningMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with pruning for f, linear g_net\n",
    "model = SimpleModel(input_dim=x.shape[1], output_dim=1, output_dim_f=32)\n",
    "model.f_net = PruningMLP(model.f_net,\n",
    "                      initial_dim=32, # Initial dimensionality of the MLP\n",
    "                      target_dim=2, # Target dimensionality - final output dim after pruning\n",
    "                      mlp_name=\"f_net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f5b8b",
   "metadata": {},
   "source": [
    "## Training our model and dynamically reducing dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c0007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pruning schedule\n",
    "epochs = 100\n",
    "model.f_net.set_schedule(total_epochs=epochs, \n",
    "                     end_epoch_frac=0.7 # End pruning after 70% of epochs\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f495823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(model, dataloader, X_val, opt, criterion, epochs=100):\n",
    "    \"\"\"\n",
    "    Train model with MLP f (with pruning) and linear g_net.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        dataloader: DataLoader for training data\n",
    "        X_val, y_val: Validation data for pruning\n",
    "        opt: Optimizer\n",
    "        criterion: Loss function\n",
    "        epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, loss_tracker, active_dims_tracker)\n",
    "    \"\"\"\n",
    "    loss_tracker = []\n",
    "    active_dims_tracker = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        loss_tracker.append(epoch_loss)\n",
    "        active_dims_tracker.append(model.f_net.pruning_mask.sum().item())\n",
    "\n",
    "        model.f_net.prune(epoch, sample_data = X_val, # Pass in the validation set (or a subset of) to the model\n",
    "                          parent_model = model) # Pass in the parent model to get the correct inputs to the layer\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            active_dims = model.f_net.pruning_mask.sum().item()\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.6f}, Active dims: {active_dims}')\n",
    "            \n",
    "    return model, loss_tracker, active_dims_tracker\n",
    "\n",
    "# Set up training\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x, y.reshape(-1,1), test_size=0.1, random_state=290402)\n",
    "\n",
    "# Set up dataset - only x as input now\n",
    "dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add838bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [10/100], Avg Loss: 0.002634, Active dims: 30\n",
      "Epoch [20/100], Avg Loss: 0.002262, Active dims: 26\n",
      "Epoch [30/100], Avg Loss: 0.002287, Active dims: 20\n",
      "Epoch [40/100], Avg Loss: 0.002101, Active dims: 14\n",
      "Epoch [50/100], Avg Loss: 0.001869, Active dims: 8\n",
      "Epoch [60/100], Avg Loss: 0.001745, Active dims: 3\n",
      "Epoch [70/100], Avg Loss: 0.001758, Active dims: 2\n",
      "Epoch [80/100], Avg Loss: 0.001797, Active dims: 2\n",
      "Epoch [90/100], Avg Loss: 0.001820, Active dims: 2\n",
      "Epoch [100/100], Avg Loss: 0.001689, Active dims: 2\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the weights\n",
    "print(\"Starting training...\")\n",
    "model, losses, active_dims = train_model(model, dataloader, torch.FloatTensor(X_val), opt, criterion, 100)\n",
    "print(\"Training completed!\")\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b32eb",
   "metadata": {},
   "source": [
    "Let's see how the number of active dimensions decrease as training progesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63359981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(active_dims)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of active dimensions for the f MLP output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c9804",
   "metadata": {},
   "source": [
    "You can pass a `decay_rate` parameter into the `.set_schedule` method of a `Pruning_MLP`. The default is a cosine decay (as shown above). The other options are `exp` and `linear`. \n",
    "\n",
    "<img src=\"../_static/pruning_decay_schedules.png\">\n",
    "In the above image, the pruning finishes at epoch 75 and we prune 100 dimensions to 2 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db5df8",
   "metadata": {},
   "source": [
    "## Interpret the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05200922",
   "metadata": {},
   "source": [
    "The `.distill` function only takes into account the active (non-masked) dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d637d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running symbolic regression on pruned f...\n",
      "🛠️ Running SR on active dimension 6 (1/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡Best equation for active dimension 6: (x0 * ((x0 * 7.7608647) + 0.2976528)) + ((sin(x4) * -4.277788) + 0.08879602)\n",
      "🛠️ Running SR on active dimension 30 (2/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡Best equation for active dimension 30: ((sin(x4) * 3.9845026) + -0.17296898) + (x0 * ((x0 * -8.416115) + (x4 * 0.458543)))\n",
      "❤️ SR on f_net active dimensions complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{6: PySRRegressor.equations_ = [\n",
       " \t    pick         score                                           equation  \\\n",
       " \t0         0.000000e+00                                                 x0   \n",
       " \t1         1.148194e-01                                            x0 + x0   \n",
       " \t2         1.271427e-01                                     x0 * 3.2849653   \n",
       " \t3         2.345212e-01                          inv(inv(x0) + -0.8688543)   \n",
       " \t4         5.343127e-01                       (x0 * 8.063941) + -3.1791587   \n",
       " \t5         4.663378e-01                (x0 * 6.900445) + (x4 * -4.8166494)   \n",
       " \t6         2.113907e+00          (x4 * -3.653175) + ((x0 * x0) * 8.049369)   \n",
       " \t7         8.123289e-02      (sin(x4) * -4.088221) + ((x0 * 8.13758) * x0)   \n",
       " \t8         2.161893e-01  x0 + (((x0 * 7.092151) * x0) + (x4 * (x4 + -4....   \n",
       " \t9         5.076185e-01  (((x0 * x0) * 8.042379) + ((x4 + -4.6605554) *...   \n",
       " \t10        4.154584e-02  ((x0 * x0) * 8.0415535) + ((sin(x4) + -0.03354...   \n",
       " \t11        6.472069e-08  (((x0 * inv(inv(x0))) * 8.041551) + (sin(x4) *...   \n",
       " \t12  >>>>  1.648806e-01  (x0 * ((x0 * 7.7608647) + 0.2976528)) + ((sin(...   \n",
       " \t13        8.078139e-02  ((sin(x4) * -4.25507) + (x3 * 0.10091582)) + (...   \n",
       " \t14        1.518269e-03  (sin(x4) * -4.2544355) + ((((x0 + -0.07688601)...   \n",
       " \t15        6.710315e-02  (((sin(x4) * -4.2783914) + (x3 * 0.07972249)) ...   \n",
       " \t\n",
       " \t        loss  complexity  \n",
       " \t0   5.755526           1  \n",
       " \t1   4.574611           3  \n",
       " \t2   4.028439           4  \n",
       " \t3   2.520196           6  \n",
       " \t4   1.477016           7  \n",
       " \t5   0.581205           9  \n",
       " \t6   0.008476          11  \n",
       " \t7   0.006643          14  \n",
       " \t8   0.005352          15  \n",
       " \t9   0.003221          16  \n",
       " \t10  0.003090          17  \n",
       " \t11  0.003090          19  \n",
       " \t12  0.002620          20  \n",
       " \t13  0.002230          22  \n",
       " \t14  0.002223          24  \n",
       " \t15  0.002079          25  \n",
       " ],\n",
       " 30: PySRRegressor.equations_ = [\n",
       " \t    pick     score                                           equation  \\\n",
       " \t0         0.000000                                                 x4   \n",
       " \t1         0.216649                                         -1.0053014   \n",
       " \t2         0.301529                                    x0 * -3.5791383   \n",
       " \t3         0.023528                               inv(x0 + -1.1379426)   \n",
       " \t4         0.442987                             x0 * (x0 * -5.3691025)   \n",
       " \t5         0.473870                        (x0 * -8.190969) + 3.067833   \n",
       " \t6         0.192947                       ((x0 * -6.202196) * x0) + x4   \n",
       " \t7         0.732085               ((x0 * -1.5106912) + x4) * 4.7091055   \n",
       " \t8         0.269098               (x4 + x4) + (x0 * (x0 * -7.0352945))   \n",
       " \t9         3.592479         ((x0 * x0) * -8.289148) + (x4 * 3.5051167)   \n",
       " \t10        0.067453  ((x0 * x0) * -8.643189) + (x4 * (x0 + 3.1848803))   \n",
       " \t11        0.092275  (x4 * 3.6391747) + ((x0 * (x0 * -8.2041645)) +...   \n",
       " \t12        0.229331  (x0 * (x0 * (x4 + -8.746835))) + (sin(x4) * 3....   \n",
       " \t13        0.257579  ((sin(x4) * 4.2511096) + ((x0 * x0) * -8.20132...   \n",
       " \t14        0.065088  (x0 * ((x0 * -8.23074) + -0.44418868)) + (sin(...   \n",
       " \t15  >>>>  0.108796  ((sin(x4) * 3.9845026) + -0.17296898) + (x0 * ...   \n",
       " \t16        0.000002  (((x0 * (x0 * -8.416535)) + ((x0 * 0.45921513)...   \n",
       " \t17        0.004325  (x0 * ((x0 * -8.431358) + (sin(x4) * 0.5344693...   \n",
       " \t18        0.040500  (((x0 * ((((x4 * -1.8388528) + x3) * -0.224555...   \n",
       " \t19        0.005379  ((x0 * x0) * ((((x4 * -1.8433444) + sin(x3)) *...   \n",
       " \t\n",
       " \t        loss  complexity  \n",
       " \t0   8.849294           1  \n",
       " \t1   7.125564           2  \n",
       " \t2   3.898655           4  \n",
       " \t3   3.807996           5  \n",
       " \t4   2.445173           6  \n",
       " \t5   1.522336           7  \n",
       " \t6   1.255205           8  \n",
       " \t7   0.603635           9  \n",
       " \t8   0.461218          10  \n",
       " \t9   0.012697          11  \n",
       " \t10  0.011095          13  \n",
       " \t11  0.010117          14  \n",
       " \t12  0.006395          16  \n",
       " \t13  0.004943          17  \n",
       " \t14  0.004340          19  \n",
       " \t15  0.003131          22  \n",
       " \t16  0.003131          24  \n",
       " \t17  0.003118          25  \n",
       " \t18  0.002875          27  \n",
       " \t19  0.002829          30  \n",
       " ]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nRunning symbolic regression on pruned f...\")\n",
    "\n",
    "sr_params = {'complexity_of_operators':  {\"sin\":3, \"exp\":3},\n",
    "             'complexity_of_constants': 2, \n",
    "             'constraints': {\"sin\": 3, \"exp\":3},\n",
    "             'parsimony': 0.01,\n",
    "             'verbosity': 0, \n",
    "             'niterations': 100}\n",
    "\n",
    "model.f_net.distill(torch.FloatTensor(X_train), \n",
    "                       sr_params=sr_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718de0df",
   "metadata": {},
   "source": [
    "You can see that the outputs of the `f_net` NN are linear combinations of the f function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0952d48",
   "metadata": {},
   "source": [
    "We can even perform SR on the `g_net` to show that this layer is just a linear transformation of the inputs.\\\n",
    "Because `g_net` is an intermediate layer of the MLP, we need to pass in the `parent_model` (the whole model) to get the correct inputs to `g_net` for symbolic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f3941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Running SR on output dimension 0 of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡Best equation for output 0 found to be ((x6 * 0.15878753) + ((x4 + -0.1508674) * x30)) + -0.054746866.\n",
      "❤️ SR on g_net complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: PySRRegressor.equations_ = [\n",
       " \t   pick         score                                           equation  \\\n",
       " \t0        0.000000e+00                                                x13   \n",
       " \t1        7.502494e-02                                          0.2288776   \n",
       " \t2        3.282677e+00                                    x6 * 0.30864543   \n",
       " \t3        5.280330e-08                              (x6 * 0.3086454) + x8   \n",
       " \t4        2.166498e+00                   (x6 * 0.31196678) + -0.030368205   \n",
       " \t5        2.765098e-08            ((x6 + -0.09734457) * 0.31196684) + x17   \n",
       " \t6        8.271199e+00  ((x30 * -0.15086766) + -0.054746903) + (x6 * 0...   \n",
       " \t7  >>>>  3.989052e-01  ((x6 * 0.15878753) + ((x4 + -0.1508674) * x30)...   \n",
       " \t\n",
       " \t           loss  complexity  \n",
       " \t0  7.247515e-01           1  \n",
       " \t1  6.723667e-01           2  \n",
       " \t2  9.469105e-04           4  \n",
       " \t3  9.469104e-04           6  \n",
       " \t4  1.084952e-04           7  \n",
       " \t5  1.084952e-04           9  \n",
       " \t6  1.815527e-15          12  \n",
       " \t7  8.175571e-16          14  \n",
       " ]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from symtorch import SymbolicMLP\n",
    "\n",
    "model.g_net = SymbolicMLP(model.g_net, mlp_name='g_net')\n",
    "model.g_net.distill(torch.FloatTensor(X_train), \n",
    "                     parent_model=model, # Pass in the parent_model because g_net is an intermediate layer\n",
    "                     sr_params = sr_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5805a",
   "metadata": {},
   "source": [
    "The variables used in this NN are just the active dimensions of the `f_net` NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db788500",
   "metadata": {},
   "source": [
    "## Switch to Using the Equation Instead in the Forwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abef72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully switched f_net to symbolic equations for 2 active dimensions:\n",
      "   Dimension 6: (x0 * ((x0 * 7.7608647) + 0.2976528)) + ((sin(x4) * -4.277788) + 0.08879602)\n",
      "   Variables: ['x0', 'x4']\n",
      "   Dimension 30: ((sin(x4) * 3.9845026) + -0.17296898) + (x0 * ((x0 * -8.416115) + (x4 * 0.458543)))\n",
      "   Variables: ['x0', 'x4']\n",
      "🎯 Active dimensions [6, 30] now using symbolic equations.\n",
      "🔒 Inactive dimensions will output zeros.\n"
     ]
    }
   ],
   "source": [
    "model.f_net.switch_to_equation() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49460cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully switched g_net to symbolic equations for all 1 dimensions:\n",
      "   Dimension 0: ((x6 * 0.15878753) + ((x4 + -0.1508674) * x30)) + -0.054746866\n",
      "   Variables: ['x30', 'x4', 'x6']\n",
      "🎯 All 1 output dimensions now using symbolic equations.\n"
     ]
    }
   ],
   "source": [
    "model.g_net.switch_to_equation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7cfd0",
   "metadata": {},
   "source": [
    "Now when running the forwards pass through the model, it uses the symbolic equation instead of the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e526154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8045],\n",
       "        [ 1.6867],\n",
       "        [-0.6418],\n",
       "        ...,\n",
       "        [ 1.1081],\n",
       "        [ 2.4498],\n",
       "        [-0.1047]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretable_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "interpretable_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835dd8e",
   "metadata": {},
   "source": [
    "## Switch to Using the MLP in the Forwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34291a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Switched f_net back to MLP\n",
      "✅ Switched g_net back to MLP\n"
     ]
    }
   ],
   "source": [
    "model.f_net.switch_to_mlp()\n",
    "model.g_net.switch_to_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79e43dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8138],\n",
       "        [ 1.6825],\n",
       "        [-0.6388],\n",
       "        ...,\n",
       "        [ 1.1276],\n",
       "        [ 2.4231],\n",
       "        [-0.0940]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e258b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up \n",
    "import os\n",
    "import shutil\n",
    "if os.path.exists('SR_output'):\n",
    "    shutil.rmtree('SR_output')\n",
    "os.remove('model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symtorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
