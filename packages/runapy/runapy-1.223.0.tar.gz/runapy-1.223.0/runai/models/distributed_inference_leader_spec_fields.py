# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create an **Application** through the NVIDIA Run:ai user interface. To create an application, in your UI, go to `Settings & Tools`, `Application` and create a new Application.  After you have created a new application, you will need to assign it access rules. To assign access rules to the application, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your application. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field
from typing import Any, ClassVar, Dict, List, Optional
from runai.models.distributed_inference_leader_worker_spec1 import (
    DistributedInferenceLeaderWorkerSpec1,
)
from typing import Optional, Set
from typing_extensions import Self


class DistributedInferenceLeaderSpecFields(BaseModel):
    """
    Pydantic class model representing DistributedInferenceLeaderSpecFields.

    Parameters:
        ```python
        leader: Optional[DistributedInferenceLeaderWorkerSpec1]
        ```
        leader: Defines the pod specification for the leader. Must always be provided, regardless of the number of workers.
    Example:
        ```python
        DistributedInferenceLeaderSpecFields(
            leader=runai.models.distributed_inference_leader_worker_spec1.DistributedInferenceLeaderWorkerSpec1(
                    annotations = [
                        runai.models.annotation.Annotation(
                            name = 'billing',
                            value = 'my-billing-unit',
                            exclude = False, )
                        ],
                    args = '-x my-script.py',
                    command = 'python',
                    compute = runai.models.superset_spec_all_of_compute.SupersetSpec_allOf_compute(
                        cpu_core_limit = 2,
                        cpu_core_request = 0.5,
                        cpu_memory_limit = '30M',
                        cpu_memory_request = '20M',
                        extended_resources = [
                            runai.models.extended_resource.ExtendedResource(
                                resource = 'hardware-vendor.example/foo',
                                quantity = '2',
                                exclude = False, )
                            ],
                        gpu_devices_request = 1,
                        gpu_memory_limit = '10M',
                        gpu_memory_request = '10M',
                        gpu_portion_limit = 0.5,
                        gpu_portion_request = 0.5,
                        gpu_request_type = 'portion',
                        large_shm_request = False,
                        mig_profile = null, ),
                    create_home_dir = True,
                    environment_variables = [
                        runai.models.environment_variable.EnvironmentVariable(
                            name = 'HOME',
                            value = '/home/my-folder',
                            secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                                name = 'postgress_secret',
                                key = 'POSTGRES_PASSWORD', ),
                            config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                                name = 'my-config-map',
                                key = 'MY_POSTGRES_SCHEMA', ),
                            pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                                path = 'metadata.name', ),
                            exclude = False,
                            description = 'Home directory of the user.', )
                        ],
                    image = 'python:3.8',
                    image_pull_policy = 'Always',
                    image_pull_secrets = [
                        runai.models.image_pull_secret.ImagePullSecret(
                            name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                            user_credential = True,
                            exclude = False, )
                        ],
                    labels = [
                        runai.models.label.Label(
                            name = 'stage',
                            value = 'initial-research',
                            exclude = False, )
                        ],
                    node_affinity_required = runai.models.node_affinity_required.NodeAffinityRequired(
                        node_selector_terms = [
                            runai.models.node_selector_term.NodeSelectorTerm(
                                match_expressions = [
                                    runai.models.match_expression.MatchExpression(
                                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                        operator = 'In',
                                        values = [
                                            'jUR,rZ#UM/?R,Fp^l6$ARj'
                                            ], )
                                    ], )
                            ], ),
                    node_type = 'my-node-type',
                    pod_affinity = runai.models.pod_affinity.PodAffinity(
                        type = 'Required',
                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                    probes = runai.models.probes.Probes(
                        readiness = runai.models.probe.Probe(
                            initial_delay_seconds = 0,
                            period_seconds = 1,
                            timeout_seconds = 1,
                            success_threshold = 1,
                            failure_threshold = 1,
                            handler = runai.models.probe_handler.ProbeHandler(
                                http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                    path = '/',
                                    port = 1,
                                    host = 'example.com',
                                    scheme = 'HTTP', ), ), ), ),
                    security = runai.models.inference_policy_defaults_v2_all_of_security.InferencePolicyDefaultsV2_allOf_security(
                        capabilities = ["CHOWN","KILL"],
                        read_only_root_filesystem = False,
                        run_as_gid = 30,
                        run_as_non_root = True,
                        run_as_uid = 500,
                        seccomp_profile_type = 'RuntimeDefault',
                        supplemental_groups = '2,3,5,8',
                        uid_gid_source = 'fromTheImage', ),
                    storage = runai.models.distributed_inference_leader_worker_spec1_storage.DistributedInferenceLeaderWorkerSpec1_storage(
                        config_map_volume = [
                            runai.models.config_map_instance.ConfigMapInstance()
                            ],
                        empty_dir_volume = [
                            runai.models.empty_dir_instance.EmptyDirInstance()
                            ],
                        pvc = [
                            runai.models.pvc_instance.PvcInstance()
                            ],
                        secret_volume = [
                            runai.models.secret_instance2.SecretInstance2()
                            ], ),
                    tolerations = [
                        runai.models.toleration.Toleration(
                            name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                            key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            effect = 'NoSchedule',
                            seconds = 1,
                            exclude = False, )
                        ],
                    working_dir = '/home/myfolder', )
        )
        ```
    """  # noqa: E501

    leader: Optional[DistributedInferenceLeaderWorkerSpec1] = Field(
        default=None,
        description="Defines the pod specification for the leader. Must always be provided, regardless of the number of workers.",
    )
    __properties: ClassVar[List[str]] = ["leader"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedInferenceLeaderSpecFields from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of leader
        if self.leader:
            _dict["leader"] = self.leader.to_dict()
        # set to None if leader (nullable) is None
        # and model_fields_set contains the field
        if self.leader is None and "leader" in self.model_fields_set:
            _dict["leader"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedInferenceLeaderSpecFields from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "leader": (
                    DistributedInferenceLeaderWorkerSpec1.from_dict(obj["leader"])
                    if obj.get("leader") is not None
                    else None
                )
            }
        )
        return _obj
