# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create an **Application** through the NVIDIA Run:ai user interface. To create an application, in your UI, go to `Settings & Tools`, `Application` and create a new Application.  After you have created a new application, you will need to assign it access rules. To assign access rules to the application, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your application. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool
from typing import Any, ClassVar, Dict, List, Optional
from runai.models.distributed_spec_spec import DistributedSpecSpec
from runai.models.master_spec import MasterSpec
from typing import Optional, Set
from typing_extensions import Self


class DistributedSpec(BaseModel):
    """
    Pydantic class model representing The specifications of the training to be created..

    Parameters:
        ```python
        spec: DistributedSpecSpec
        master_spec_same_as_worker: Optional[bool]
        master_spec: Optional[MasterSpec]
        ```
        spec: See model DistributedSpecSpec for more information.
        master_spec_same_as_worker: used for distributed workloads to indicate that the master spec should be the same as the worker spec. in this case, masterSpec should not be specified.
        master_spec: See model MasterSpec for more information.
    Example:
        ```python
        DistributedSpec(
            spec="example",
                        master_spec_same_as_worker=True,
                        master_spec=runai.models.master_spec.MasterSpec(
                    annotations = [
                        runai.models.annotation.Annotation(
                            name = 'billing',
                            value = 'my-billing-unit',
                            exclude = False, )
                        ],
                    args = '-x my-script.py',
                    auto_deletion_time_after_completion_seconds = 15,
                    backoff_limit = 3,
                    category = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                    command = 'python',
                    compute = runai.models.superset_spec_all_of_compute.SupersetSpec_allOf_compute(
                        cpu_core_limit = 2,
                        cpu_core_request = 0.5,
                        cpu_memory_limit = '30M',
                        cpu_memory_request = '20M',
                        extended_resources = [
                            runai.models.extended_resource.ExtendedResource(
                                resource = 'hardware-vendor.example/foo',
                                quantity = '2',
                                exclude = False, )
                            ],
                        gpu_devices_request = 1,
                        gpu_memory_limit = '10M',
                        gpu_memory_request = '10M',
                        gpu_portion_limit = 0.5,
                        gpu_portion_request = 0.5,
                        gpu_request_type = 'portion',
                        large_shm_request = False,
                        mig_profile = null, ),
                    create_home_dir = True,
                    environment_variables = [
                        runai.models.environment_variable.EnvironmentVariable(
                            name = 'HOME',
                            value = '/home/my-folder',
                            secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                                name = 'postgress_secret',
                                key = 'POSTGRES_PASSWORD', ),
                            config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                                name = 'my-config-map',
                                key = 'MY_POSTGRES_SCHEMA', ),
                            pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                                path = 'metadata.name', ),
                            exclude = False,
                            description = 'Home directory of the user.', )
                        ],
                    exposed_urls = [
                        runai.models.exposed_url.ExposedUrl(
                            container = 8080,
                            url = 'https://my-url.com',
                            authorized_users = ["user-a","user-b"],
                            authorized_groups = ["group-a","group-b"],
                            tool_type = 'jupyter',
                            tool_name = 'my-pytorch',
                            name = 'url-instance-a',
                            exclude = False, )
                        ],
                    image = 'python:3.8',
                    image_pull_policy = 'Always',
                    image_pull_secrets = [
                        runai.models.image_pull_secret.ImagePullSecret(
                            name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                            user_credential = True,
                            exclude = False, )
                        ],
                    labels = [
                        runai.models.label.Label(
                            name = 'stage',
                            value = 'initial-research',
                            exclude = False, )
                        ],
                    node_affinity_required = runai.models.node_affinity_required.NodeAffinityRequired(
                        node_selector_terms = [
                            runai.models.node_selector_term.NodeSelectorTerm(
                                match_expressions = [
                                    runai.models.match_expression.MatchExpression(
                                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                        operator = 'In',
                                        values = [
                                            'jUR,rZ#UM/?R,Fp^l6$ARj'
                                            ], )
                                    ], )
                            ], ),
                    node_pools = ["my-node-pool-a","my-node-pool-b"],
                    node_type = 'my-node-type',
                    pod_affinity = runai.models.pod_affinity.PodAffinity(
                        type = 'Required',
                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                    ports = [
                        runai.models.port.Port(
                            container = 8080,
                            service_type = 'LoadBalancer',
                            external = 30080,
                            tool_type = 'pytorch',
                            tool_name = 'my-pytorch',
                            name = 'port-instance-a',
                            exclude = False, )
                        ],
                    priority_class = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                    probes = runai.models.probes.Probes(
                        readiness = runai.models.probe.Probe(
                            initial_delay_seconds = 0,
                            period_seconds = 1,
                            timeout_seconds = 1,
                            success_threshold = 1,
                            failure_threshold = 1,
                            handler = runai.models.probe_handler.ProbeHandler(
                                http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                    path = '/',
                                    port = 1,
                                    host = 'example.com',
                                    scheme = 'HTTP', ), ), ), ),
                    related_urls = [
                        runai.models.related_url.RelatedUrl(
                            url = 'https://my-url.com',
                            name = 'url-instance-a',
                            exclude = False, )
                        ],
                    restart_policy = 'Always',
                    security = runai.models.superset_spec_all_of_security.SupersetSpec_allOf_security(
                        allow_privilege_escalation = False,
                        capabilities = ["CHOWN","KILL"],
                        host_ipc = False,
                        host_network = False,
                        read_only_root_filesystem = False,
                        run_as_gid = 30,
                        run_as_non_root = True,
                        run_as_uid = 500,
                        seccomp_profile_type = 'RuntimeDefault',
                        supplemental_groups = '2,3,5,8',
                        uid_gid_source = 'fromTheImage', ),
                    stdin = True,
                    storage = runai.models.superset_spec_all_of_storage.SupersetSpec_allOf_storage(
                        config_map_volume = [
                            runai.models.config_map_instance.ConfigMapInstance()
                            ],
                        data_volume = [
                            runai.models.data_volume_instance.DataVolumeInstance()
                            ],
                        empty_dir_volume = [
                            runai.models.empty_dir_instance.EmptyDirInstance()
                            ],
                        git = [
                            runai.models.git_instance.GitInstance()
                            ],
                        host_path = [
                            runai.models.host_path_instance.HostPathInstance()
                            ],
                        nfs = [
                            runai.models.nfs_instance.NfsInstance()
                            ],
                        pvc = [
                            runai.models.pvc_instance.PvcInstance()
                            ],
                        s3 = [
                            runai.models.s3_instance.S3Instance()
                            ],
                        secret_volume = [
                            runai.models.secret_instance2.SecretInstance2()
                            ], ),
                    terminate_after_preemption = False,
                    termination_grace_period_seconds = 20,
                    tolerations = [
                        runai.models.toleration.Toleration(
                            name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                            key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            effect = 'NoSchedule',
                            seconds = 1,
                            exclude = False, )
                        ],
                    tty = True,
                    working_dir = '/home/myfolder', )
        )
        ```
    """  # noqa: E501

    spec: Optional[DistributedSpecSpec] = None
    master_spec_same_as_worker: Optional[StrictBool] = Field(
        default=None,
        description="used for distributed workloads to indicate that the master spec should be the same as the worker spec. in this case, masterSpec should not be specified.",
        alias="masterSpecSameAsWorker",
    )
    master_spec: Optional[MasterSpec] = Field(default=None, alias="masterSpec")
    __properties: ClassVar[List[str]] = ["spec", "masterSpecSameAsWorker", "masterSpec"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedSpec from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of spec
        if self.spec:
            _dict["spec"] = self.spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of master_spec
        if self.master_spec:
            _dict["masterSpec"] = self.master_spec.to_dict()
        # set to None if master_spec_same_as_worker (nullable) is None
        # and model_fields_set contains the field
        if (
            self.master_spec_same_as_worker is None
            and "master_spec_same_as_worker" in self.model_fields_set
        ):
            _dict["masterSpecSameAsWorker"] = None

        # set to None if master_spec (nullable) is None
        # and model_fields_set contains the field
        if self.master_spec is None and "master_spec" in self.model_fields_set:
            _dict["masterSpec"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedSpec from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "spec": (
                    DistributedSpecSpec.from_dict(obj["spec"])
                    if obj.get("spec") is not None
                    else None
                ),
                "masterSpecSameAsWorker": obj.get("masterSpecSameAsWorker"),
                "masterSpec": (
                    MasterSpec.from_dict(obj["masterSpec"])
                    if obj.get("masterSpec") is not None
                    else None
                ),
            }
        )
        return _obj
