# coding: utf-8

"""
NVIDIA Run:ai

# Introduction  The NVIDIA Run:ai Control-Plane API reference is a guide that provides an easy-to-use programming interface for adding various tasks to your application, including workload submission, resource management, and administrative operations.  NVIDIA Run:ai APIs are accessed using *bearer tokens*. To obtain a token, you need to create an **Application** through the NVIDIA Run:ai user interface. To create an application, in your UI, go to `Settings & Tools`, `Application` and create a new Application.  After you have created a new application, you will need to assign it access rules. To assign access rules to the application, see [Create access rules](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/accessrules#create-or-delete-rules). Make sure you assign the correct rules to your application. Use the [Roles](https://run-ai-docs.nvidia.com/saas/infrastructure-setup/authentication/roles) to assign the correct access rules.  To get your access token, follow the instructions in [Request a token](https://run-ai-docs.nvidia.com/saas/reference/api/rest-auth/#request-an-api-token).

The version of the OpenAPI document: latest
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    StrictBool,
    StrictStr,
    field_validator,
)
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from runai.models.distributed_spec_spec import DistributedSpecSpec
from runai.models.master_spec import MasterSpec
from runai.models.phase import Phase
from runai.models.workload_desired_phase import WorkloadDesiredPhase
from typing import Optional, Set
from typing_extensions import Self


class DistributedWorkload(BaseModel):
    """
    Pydantic class model representing DistributedWorkload.

    Parameters:
        ```python
        name: str
        requested_name: str
        workload_id: str
        project_id: str
        department_id: str
        cluster_id: str
        created_by: str
        created_at: datetime
        deleted_at: Optional[datetime]
        desired_phase: WorkloadDesiredPhase
        actual_phase: Phase
        spec: DistributedSpecSpec
        master_spec_same_as_worker: Optional[bool]
        master_spec: Optional[MasterSpec]
        ```
        name: The name of the workload.
        requested_name: The name as was requested for the workload. If useGivenNameAsPrefix, in the creation request, is false, name and requestedName should be identical. Otherwise, name should be composed of requestedName followed by a suffix of random characters.
        workload_id: A unique ID of the workload.
        project_id: The id of the project.
        department_id: The id of the department.
        cluster_id: The id of the cluster.
        created_by: The user who created the workload
        created_at: The creation time of the workload.
        deleted_at: The deletion time of the workload.
        desired_phase: See model WorkloadDesiredPhase for more information.
        actual_phase: See model Phase for more information.
        spec: See model DistributedSpecSpec for more information.
        master_spec_same_as_worker: used for distributed workloads to indicate that the master spec should be the same as the worker spec. in this case, masterSpec should not be specified.
        master_spec: See model MasterSpec for more information.
    Example:
        ```python
        DistributedWorkload(
            name='my-workload-name',
                        requested_name='',
                        workload_id='',
                        project_id='1',
                        department_id='2',
                        cluster_id='71f69d83-ba66-4822-adf5-55ce55efd210',
                        created_by='test@lab.com',
                        created_at='2022-01-01T03:49:52.531Z',
                        deleted_at='2022-01-01T03:49:52.531Z',
                        desired_phase='Running',
                        actual_phase='Creating',
                        spec="example",
                        master_spec_same_as_worker=True,
                        master_spec=runai.models.master_spec.MasterSpec(
                    annotations = [
                        runai.models.annotation.Annotation(
                            name = 'billing',
                            value = 'my-billing-unit',
                            exclude = False, )
                        ],
                    args = '-x my-script.py',
                    auto_deletion_time_after_completion_seconds = 15,
                    backoff_limit = 3,
                    category = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                    command = 'python',
                    compute = runai.models.superset_spec_all_of_compute.SupersetSpec_allOf_compute(
                        cpu_core_limit = 2,
                        cpu_core_request = 0.5,
                        cpu_memory_limit = '30M',
                        cpu_memory_request = '20M',
                        extended_resources = [
                            runai.models.extended_resource.ExtendedResource(
                                resource = 'hardware-vendor.example/foo',
                                quantity = '2',
                                exclude = False, )
                            ],
                        gpu_devices_request = 1,
                        gpu_memory_limit = '10M',
                        gpu_memory_request = '10M',
                        gpu_portion_limit = 0.5,
                        gpu_portion_request = 0.5,
                        gpu_request_type = 'portion',
                        large_shm_request = False,
                        mig_profile = null, ),
                    create_home_dir = True,
                    environment_variables = [
                        runai.models.environment_variable.EnvironmentVariable(
                            name = 'HOME',
                            value = '/home/my-folder',
                            secret = runai.models.environment_variable_secret.EnvironmentVariableSecret(
                                name = 'postgress_secret',
                                key = 'POSTGRES_PASSWORD', ),
                            config_map = runai.models.environment_variable_config_map.EnvironmentVariableConfigMap(
                                name = 'my-config-map',
                                key = 'MY_POSTGRES_SCHEMA', ),
                            pod_field_ref = runai.models.environment_variable_pod_field_reference.EnvironmentVariablePodFieldReference(
                                path = 'metadata.name', ),
                            exclude = False,
                            description = 'Home directory of the user.', )
                        ],
                    exposed_urls = [
                        runai.models.exposed_url.ExposedUrl(
                            container = 8080,
                            url = 'https://my-url.com',
                            authorized_users = ["user-a","user-b"],
                            authorized_groups = ["group-a","group-b"],
                            tool_type = 'jupyter',
                            tool_name = 'my-pytorch',
                            name = 'url-instance-a',
                            exclude = False, )
                        ],
                    image = 'python:3.8',
                    image_pull_policy = 'Always',
                    image_pull_secrets = [
                        runai.models.image_pull_secret.ImagePullSecret(
                            name = 'w1c2v7s6djuy1zmetozkhdomha1bae37b8ocvx8o53ow2eg7p6qw9qklp6l4y010fogx',
                            user_credential = True,
                            exclude = False, )
                        ],
                    labels = [
                        runai.models.label.Label(
                            name = 'stage',
                            value = 'initial-research',
                            exclude = False, )
                        ],
                    node_affinity_required = runai.models.node_affinity_required.NodeAffinityRequired(
                        node_selector_terms = [
                            runai.models.node_selector_term.NodeSelectorTerm(
                                match_expressions = [
                                    runai.models.match_expression.MatchExpression(
                                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                                        operator = 'In',
                                        values = [
                                            'jUR,rZ#UM/?R,Fp^l6$ARj'
                                            ], )
                                    ], )
                            ], ),
                    node_pools = ["my-node-pool-a","my-node-pool-b"],
                    node_type = 'my-node-type',
                    pod_affinity = runai.models.pod_affinity.PodAffinity(
                        type = 'Required',
                        key = 'jUR,rZ#UM/?R,Fp^l6$ARj', ),
                    ports = [
                        runai.models.port.Port(
                            container = 8080,
                            service_type = 'LoadBalancer',
                            external = 30080,
                            tool_type = 'pytorch',
                            tool_name = 'my-pytorch',
                            name = 'port-instance-a',
                            exclude = False, )
                        ],
                    priority_class = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                    probes = runai.models.probes.Probes(
                        readiness = runai.models.probe.Probe(
                            initial_delay_seconds = 0,
                            period_seconds = 1,
                            timeout_seconds = 1,
                            success_threshold = 1,
                            failure_threshold = 1,
                            handler = runai.models.probe_handler.ProbeHandler(
                                http_get = runai.models.probe_handler_http_get.ProbeHandler_httpGet(
                                    path = '/',
                                    port = 1,
                                    host = 'example.com',
                                    scheme = 'HTTP', ), ), ), ),
                    related_urls = [
                        runai.models.related_url.RelatedUrl(
                            url = 'https://my-url.com',
                            name = 'url-instance-a',
                            exclude = False, )
                        ],
                    restart_policy = 'Always',
                    security = runai.models.superset_spec_all_of_security.SupersetSpec_allOf_security(
                        allow_privilege_escalation = False,
                        capabilities = ["CHOWN","KILL"],
                        host_ipc = False,
                        host_network = False,
                        read_only_root_filesystem = False,
                        run_as_gid = 30,
                        run_as_non_root = True,
                        run_as_uid = 500,
                        seccomp_profile_type = 'RuntimeDefault',
                        supplemental_groups = '2,3,5,8',
                        uid_gid_source = 'fromTheImage', ),
                    stdin = True,
                    storage = runai.models.superset_spec_all_of_storage.SupersetSpec_allOf_storage(
                        config_map_volume = [
                            runai.models.config_map_instance.ConfigMapInstance()
                            ],
                        data_volume = [
                            runai.models.data_volume_instance.DataVolumeInstance()
                            ],
                        empty_dir_volume = [
                            runai.models.empty_dir_instance.EmptyDirInstance()
                            ],
                        git = [
                            runai.models.git_instance.GitInstance()
                            ],
                        host_path = [
                            runai.models.host_path_instance.HostPathInstance()
                            ],
                        nfs = [
                            runai.models.nfs_instance.NfsInstance()
                            ],
                        pvc = [
                            runai.models.pvc_instance.PvcInstance()
                            ],
                        s3 = [
                            runai.models.s3_instance.S3Instance()
                            ],
                        secret_volume = [
                            runai.models.secret_instance2.SecretInstance2()
                            ], ),
                    terminate_after_preemption = False,
                    termination_grace_period_seconds = 20,
                    tolerations = [
                        runai.models.toleration.Toleration(
                            name = 'jUR,rZ#UM/?R,Fp^l6$ARj0',
                            key = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            value = 'jUR,rZ#UM/?R,Fp^l6$ARj',
                            effect = 'NoSchedule',
                            seconds = 1,
                            exclude = False, )
                        ],
                    tty = True,
                    working_dir = '/home/myfolder', )
        )
        ```
    """  # noqa: E501

    name: Annotated[str, Field(min_length=1, strict=True)] = Field(
        description="The name of the workload."
    )
    requested_name: StrictStr = Field(
        description="The name as was requested for the workload. If useGivenNameAsPrefix, in the creation request, is false, name and requestedName should be identical. Otherwise, name should be composed of requestedName followed by a suffix of random characters.",
        alias="requestedName",
    )
    workload_id: StrictStr = Field(
        description="A unique ID of the workload.", alias="workloadId"
    )
    project_id: Annotated[str, Field(strict=True)] = Field(
        description="The id of the project.", alias="projectId"
    )
    department_id: Optional[Annotated[str, Field(min_length=1, strict=True)]] = Field(
        default=None, description="The id of the department.", alias="departmentId"
    )
    cluster_id: StrictStr = Field(
        description="The id of the cluster.", alias="clusterId"
    )
    created_by: StrictStr = Field(
        description="The user who created the workload", alias="createdBy"
    )
    created_at: datetime = Field(
        description="The creation time of the workload.", alias="createdAt"
    )
    deleted_at: Optional[datetime] = Field(
        default=None,
        description="The deletion time of the workload.",
        alias="deletedAt",
    )
    desired_phase: WorkloadDesiredPhase = Field(alias="desiredPhase")
    actual_phase: Optional[Phase] = Field(default=None, alias="actualPhase")
    spec: Optional[DistributedSpecSpec] = None
    master_spec_same_as_worker: Optional[StrictBool] = Field(
        default=None,
        description="used for distributed workloads to indicate that the master spec should be the same as the worker spec. in this case, masterSpec should not be specified.",
        alias="masterSpecSameAsWorker",
    )
    master_spec: Optional[MasterSpec] = Field(default=None, alias="masterSpec")
    __properties: ClassVar[List[str]] = [
        "name",
        "requestedName",
        "workloadId",
        "projectId",
        "departmentId",
        "clusterId",
        "createdBy",
        "createdAt",
        "deletedAt",
        "desiredPhase",
        "actualPhase",
        "spec",
        "masterSpecSameAsWorker",
        "masterSpec",
    ]

    @field_validator("name")
    def name_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("project_id")
    def project_id_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    @field_validator("department_id")
    def department_id_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".*", value):
            raise ValueError(r"must validate the regular expression /.*/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DistributedWorkload from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of spec
        if self.spec:
            _dict["spec"] = self.spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of master_spec
        if self.master_spec:
            _dict["masterSpec"] = self.master_spec.to_dict()
        # set to None if deleted_at (nullable) is None
        # and model_fields_set contains the field
        if self.deleted_at is None and "deleted_at" in self.model_fields_set:
            _dict["deletedAt"] = None

        # set to None if master_spec_same_as_worker (nullable) is None
        # and model_fields_set contains the field
        if (
            self.master_spec_same_as_worker is None
            and "master_spec_same_as_worker" in self.model_fields_set
        ):
            _dict["masterSpecSameAsWorker"] = None

        # set to None if master_spec (nullable) is None
        # and model_fields_set contains the field
        if self.master_spec is None and "master_spec" in self.model_fields_set:
            _dict["masterSpec"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DistributedWorkload from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "name": obj.get("name"),
                "requestedName": obj.get("requestedName"),
                "workloadId": obj.get("workloadId"),
                "projectId": obj.get("projectId"),
                "departmentId": obj.get("departmentId"),
                "clusterId": obj.get("clusterId"),
                "createdBy": obj.get("createdBy"),
                "createdAt": obj.get("createdAt"),
                "deletedAt": obj.get("deletedAt"),
                "desiredPhase": obj.get("desiredPhase"),
                "actualPhase": obj.get("actualPhase"),
                "spec": (
                    DistributedSpecSpec.from_dict(obj["spec"])
                    if obj.get("spec") is not None
                    else None
                ),
                "masterSpecSameAsWorker": obj.get("masterSpecSameAsWorker"),
                "masterSpec": (
                    MasterSpec.from_dict(obj["masterSpec"])
                    if obj.get("masterSpec") is not None
                    else None
                ),
            }
        )
        return _obj
