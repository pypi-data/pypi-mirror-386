{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0deec887",
   "metadata": {},
   "source": [
    "# playNano Demonstration Notebook\n",
    "\n",
    "This notebook walks through the core functionality of **playNano**, a Python library for time-series AFM (Atomic Force Microscopy) data analysis. We will cover:\n",
    "\n",
    "1. **Loading**: Importing AFM data into an `AFMImageStack`\n",
    "2. **Processing**: Demonstration and visualisations of flattening and filtering operations\n",
    "3. **Analysis**: Feature detection, tracking, and linking results into a tabular form\n",
    "4. **Exporting**: Saving processed data and results using both I/O functions and analysis utilities\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üöÄ Setup and Imports\n",
    "\n",
    "Start by installing any dependencies and importing all required packages for AFM video analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If playNano isn't installed ensure this notebook is opened from the\n",
    "# repository root and uncomment the installation line.\n",
    "# Install in editable mode if developing:\n",
    "# !pip install -e .\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "from playNano.afm_stack import AFMImageStack\n",
    "from playNano.processing.pipeline import ProcessingPipeline\n",
    "from playNano.analysis.pipeline import AnalysisPipeline\n",
    "\n",
    "from playNano.io.export_data import (\n",
    "    save_ome_tiff_stack,\n",
    "    save_npz_bundle,\n",
    "    save_h5_bundle,\n",
    ")\n",
    "from playNano.analysis.export import export_analysis_to_json\n",
    "from playNano.analysis.utils.particles import (\n",
    "    flatten_particle_features,\n",
    "    plot_particle_labels_3d,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff5dd1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Tip**: Run each cell sequentially to see outputs inline.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. üóÇÔ∏è Loading Data\n",
    "\n",
    "Next, we‚Äôll load our AFM dataset into an `AFMImageStack` so we can begin processing. `load_data()` builds a AFMImageStack object with the video frames as a 3D numpy array with dimensions height, width and frame index. The pixel to 'real' length scale conversion is read and stored in the `pixel_size_nm` attribute, scan rate is also read from the files and timestamps generated and stored in the `frame_metadata` attribute which contains an ordered list of the all the frames with metadata for each. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4544564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# This block find the repo root so the test data can be accessed\n",
    "\n",
    "def find_repo_root(marker=\".git\"):\n",
    "    \"\"\"Walk up parent directories until we find the repo root (marked by .git folder).\"\"\"\n",
    "    path = Path.cwd()\n",
    "    for parent in [path] + list(path.parents):\n",
    "        if (parent / marker).exists():\n",
    "            return parent\n",
    "    raise FileNotFoundError(\"Could not find the repository root (no .git directory found).\")\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "\n",
    "# The demo path opens demo data from the test suit, to use your own data uncomment the your_path line.\n",
    "# Then comment out the line that loads demo_path and uncomment the line that loads your_path. \n",
    "\n",
    "demo_path = repo_root / \"tests\" / \"resources\" / \"sample_0.h5-jpk\"\n",
    "# your_path = Path(r\"\\path\\to\\your\\data.h5-jpk\")\n",
    "\n",
    "channel = 'height_trace'  # common HS-AFM height channel\n",
    "\n",
    "stack = AFMImageStack.load_data(demo_path, channel=channel)\n",
    "# stack = AFMImageStack.load_data(your_path, channel=\"height_trace\") # uncomment this to use your_path\n",
    "\n",
    "print(f\"Loaded {stack.n_frames} frames; each frame shape: {stack.image_shape}\")\n",
    "print(f\"Pixel size: {stack.pixel_size_nm} nm\")\n",
    "print(stack.frame_metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985738f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Inspect the first frame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b9a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame0 = stack.get_frame(0)\n",
    "meta0 = stack.get_frame_metadata(0)\n",
    "print(\"Frame 0 metadata:\", meta0)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(frame0, cmap=\"afmhot\", origin=\"lower\")\n",
    "plt.title(\"Raw Frame 0\")\n",
    "plt.colorbar(label=\"Height (nm)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53820b89",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. üîß Processing Data\n",
    "\n",
    "Now that the raw data is loaded, the frames can be processed and flattened using a reproducible pipeline for tilt correction, row alignmnent, and smoothing.\n",
    "\n",
    "AFM data often has background tilt (scanner bow) and line-by-line hysteresis. We will apply a reproducible pipeline using the following playNano processing functions through the ProcessingPipeline class that record and applies all the processing steps:\n",
    "\n",
    "1. **`remove_plane`**: Fits a 2D plane to each frame and subtracts it, removing large-scale tilt and scanner bow.\n",
    "2. **`mask_mean_offset`**: Computes the mean height of each frame, masks detected features via a threshold on that mean, and subtracts a fraction (`factor=0.4`) of this offset to correct global drift while preserving particle signal.\n",
    "3. **`row_median_align`**: Subtracts the median of unmasked pixels in each row, correcting line-by-line hysteresis and scan artefacts.\n",
    "4. **`polynomial_flatten`**: Fits and subtracts a 2nd-order polynomial surface to each frame for higher-order background correction.\n",
    "5. **`gaussian_filter`**: Applies a Gaussian filter with `sigma=1` to smooth residual noise.\n",
    "\n",
    "Each of these functions includes detailed docstrings explaining parameters, mask usage, and behaviour.\n",
    "\n",
    "### 3.1 üîÑ Reproducible Processing Pipeline\n",
    "\n",
    "The different filters and masks are added as steps in the pipeline using the `add_filter` and `add_mask` functions depending on whether the step is a filtering of masking operation. Some steps take parameters that can be specifed when add the step.\n",
    "\n",
    "Once the pipeline is complete the process can be applied with the `apply` method, this applies the steps to the data, saving a copy or mask array after each step in either `stack.processed` or `stack.masks`. The origonal data is also retained in `stack.processed['raw']`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e28b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Restore raw data\n",
    "# Restore raw data if available\n",
    "raw_data = stack.processed.get('raw')\n",
    "if raw_data is not None:\n",
    "    stack.data = raw_data\n",
    "\n",
    "\n",
    "pipe = ProcessingPipeline(stack)\n",
    "pipe.add_filter('remove_plane')\n",
    "pipe.add_mask('mask_mean_offset', factor=1)\n",
    "pipe.add_filter('row_median_align')\n",
    "pipe.add_filter('polynomial_flatten', order=2)\n",
    "pipe.add_filter('gaussian_filter', sigma=1.5)\n",
    "\n",
    "proc_record = pipe.run()\n",
    "\n",
    "# The processing steps and the associated parameters are stored\n",
    "# within the 'providence' AFMImageStack attirbute.\n",
    "# Acessing this provides are record of the processing steps used.\n",
    "print(\"Processing steps executed with parameters:\")\n",
    "for step in stack.provenance['processing']['steps']:\n",
    "    print(f\" ‚Ä¢ {step['name']}: {step['params']}\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "im = ax.imshow(stack.data[0], cmap='afmhot', origin='lower')\n",
    "cb = plt.colorbar(im, label=\"Height / nm\")\n",
    "plt.title(\"Processed Frame 0\")\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc361db2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3.2 üéûÔ∏è Animation of the Processed Stack\n",
    "\n",
    "\n",
    "The process is applied to each frame of the AFM video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96804e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "def update(frame):\n",
    "    global cb\n",
    "    if cb:\n",
    "        cb.remove()\n",
    "        cb = None\n",
    "    im.set_data(stack.data[frame])\n",
    "    ax.set_title(f\"Frame {frame}\")\n",
    "    return [im]\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, frames=range(stack.n_frames), interval=100)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd5807",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3.3 üé¨ Exporting as GIF\n",
    "\n",
    "There is built in functions for the export of raw and processed data as GIF animations, these are annotated with a scale bar and a timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from playNano.io.gif_export import export_gif\n",
    "\n",
    "# Define output path and frame interval (ms)\n",
    "out_path = Path('output') \n",
    "out_name = 'processed_stack'\n",
    "# Write GIF from processed data\n",
    "export_gif(\n",
    "    afm_stack=stack,\n",
    "    make_gif=True,\n",
    "    output_folder=out_path,\n",
    "    output_name=out_name,\n",
    "    scale_bar_nm= 100,\n",
    ")\n",
    "print(f\"GIF saved to {out_path}\")\n",
    "\n",
    "\n",
    "full_output_path = f\"./{out_path}/{out_name}_filtered.gif\"\n",
    "\n",
    "display(Image(filename=full_output_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d63c3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. üîç Analysis\n",
    "\n",
    "Once data is processed, it can be fed into an analysis pipeline with various analysis steps. Currently, there are built in modules to detect features (feature_detection and log_blob_detection) and then cluster or track these detections `particle_tracking`, `x_means_clustering`, `x_means_clustering` and `dbscan_clustering`).\n",
    "\n",
    "In this example, `feature_detection` is used to identify particles using a threshold mask and then `particle_tracking` links these detections between frames. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a913eb-5730-490b-b46d-5a871c1428c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clear any previous analysis\n",
    "stack.analysis.clear()\n",
    "stack.provenance['analysis']['steps'].clear()\n",
    "\n",
    "# Initiallise an analysis pipeline \n",
    "analysis_pipeline = AnalysisPipeline()\n",
    "\n",
    "# Add analysis steps:\n",
    "analysis_pipeline.add(\n",
    "    'feature_detection',\n",
    "    mask_fn=\"mask_mean_offset\",\n",
    "    factor=1.15,\n",
    "    min_size =100,\n",
    "    fill_holes= True\n",
    ")\n",
    "analysis_pipeline.add('particle_tracking', max_distance=10)\n",
    "\n",
    "# Run analysis\n",
    "analysis_record = analysis_pipeline.run(stack)\n",
    "print(\n",
    "    \"Analysis modules run:\", [s['name'] for s in analysis_record['provenance']['steps']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cecf8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1 üïµÔ∏è‚Äç‚ôÇÔ∏è Feature Detection\n",
    "\n",
    "Feature detection using the `feature_detection` module uses a threshold mask to identify features as mask, 'islands', which are then identified and filtered by size and location. Masks can either be generated during analysis, set by the argument `mask_fn`, or a mask previously generated during processing can be used by identifying the mask key in `previous_results` with `masks_key`.  \n",
    "\n",
    "As well as detecting features, this module measures various features of the detected feature (min, max and mean values, centroid position and area etc.). The feature detection result dictionary contains a list of the features detected under `features_per_frame` with these metrics and others. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e814066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fd = stack.analysis['step_1_feature_detection']\n",
    "total_feats = sum(len(f) for f in fd['features_per_frame'])\n",
    "print(f\"Detected {total_feats} features across all frames.\")\n",
    "\n",
    "# Inspect the frames 0-3 by changing frame_idx \n",
    "frame_idx = 0\n",
    "\n",
    "im = plt.imshow(fd['labeled_masks'][frame_idx], cmap='plasma')\n",
    "plt.title(f'Detected Features Frame {frame_idx}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1e36a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.2 üîó Particle Tracking\n",
    "\n",
    "Particle tracking uses nearest neighbours to track the position of particles across frames. These 'tracks' are output in the 'tracks' dictionary of the particle tracking output dictionary.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670fd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tracks_out = stack.analysis['step_2_particle_tracking']['tracks']\n",
    "print(f\"Constructed {len(tracks_out)} tracks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef72bc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.3 üóÉÔ∏è Flatten Tracks into Table\n",
    "\n",
    "Within the analysis package, there are various utility functions to help with the processing of analysis output data. These are found in the `untils` subpackage which has helper functions for various analyses. Those built for particle analysis and tracking are in the `particles` module within `analysis.utils`.\n",
    "\n",
    "The `flatten_particle_features` function in this module can be used to combine the results of particle detection modules with the corresponding results of a particle grouping (tracking or clustering) module. This means all the data and statistics measured when the particles were detected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11491e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tab = flatten_particle_features(\n",
    "    grouping_output=stack.analysis['step_2_particle_tracking'],\n",
    "    detection_output=fd,\n",
    "    object_key='tracks',\n",
    "    object_id_field='track_id'\n",
    ")\n",
    "print(f\"Flattened table has {len(tab)} rows.\")\n",
    "tab.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50d2d9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.4 üìà Visualising Tracks in 3D\n",
    "\n",
    "Once tracked and in a table, various feature or particle metrics can be plotted per particle over time. A simple example is plotting the centroid position per track in 3D, with the centroid coordinates as the X and Y values and the detection's timestamp as the Z value. This is enabled by the `plot_particle_labels_3d` in the `playNano.analysis.utils.particles' module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plot_particle_labels_3d(tab, object_id_field='track_id')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28338a59",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. üíæ Exporting Results\n",
    "\n",
    "### 5.1 üì¶ Processed Data Bundles\n",
    "\n",
    "In addition to being able to save processed data as GIF animations for presentation, the raw and processed 3D numpy arrays can be exported as either a TIF files containing a stack of frames along with metadata compliant with the OME-TIF format (.ome.tif), a numpy zippied archive containing the array and metadata (.npz) or an HDF5 container with same data (.h5). \n",
    "\n",
    "There are functions within the `playNano.io.export` module for these operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Path('output')\n",
    "base = 'demo'\n",
    "save_ome_tiff_stack(out/f\"{base}.ome.tif\", \n",
    "                    stack,\n",
    "                    raw=False)\n",
    "save_npz_bundle(out/base,\n",
    "                    stack,\n",
    "                    raw=False)\n",
    "save_h5_bundle(out/base, \n",
    "               stack,\n",
    "               raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5332a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 5.2 üìä Analysis Exports\n",
    "\n",
    "The results from the analysis modules can be exported to a JSON file using the `export_analysis_to_json` function within `playNano.analysis.utils.common` and the df generated by `flatten_particle_features` can be simply saved as a CSV file with the `.to_csv()` pandas method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "export_analysis_to_json(out/f\"{base}_analysis.json\", analysis_record)\n",
    "csv_path = out/f\"{base}_tracks.csv\"\n",
    "tab.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c6501",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Next Steps:** Try different thresholds in `feature_detection`, adjust `max_distance` in `particle_tracking`, or experiment with `log_blob_detection` as an alternative feature detector. **Enjoy exploring your time-series AFM data!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
