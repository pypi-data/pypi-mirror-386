{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numba_extinction.numba_extinction as ne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import speclite.filters as filters\n",
    "from astropy import units\n",
    "\n",
    "# can be anything from astropy.cosmology\n",
    "from astropy.cosmology import Planck18 as cosmology\n",
    "\n",
    "from quest_qso import mlconfig as cfg\n",
    "from quest_qso.photometry import generate_photometry as gp\n",
    "from quest_qso.scripts import generate_photometry as gpscript\n",
    "from quest_qso.utils import generate_photometry_utils as gp_qa\n",
    "from quest_qso.utils import resources, utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the variables. This would be handled by argparse in the script version\n",
    "#  but for the purpose of this notebook we are setting them manually here\n",
    "globals_ = {}\n",
    "\n",
    "# only related to this notebook\n",
    "globals_[\"PLOT_FILTER_RESPONSE\"] = True\n",
    "\n",
    "# default folder for everything\n",
    "globals_[\"LOCAL_PATH\"] = Path(os.getenv(\"ML_QSO_MODEL_LOCALPATH\"))\n",
    "# This should be the path that contains the json model file and the trained model files\n",
    "globals_[\"MODEL_PATH\"] = Path(os.getenv(\"QUEST_GP_MODEL_LOCALPATH\"))\n",
    "\n",
    "# timestamps, used to save globals_puts in unique folders\n",
    "globals_[\"DAY\"] = datetime.today().strftime(\"%Y%m%d\")\n",
    "globals_[\"TIMESTAMP\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# clean intermediate products, useful to lower the memory footprint\n",
    "globals_[\"CLEAR_MEMORY\"] = False\n",
    "globals_[\"SEED\"] = 42\n",
    "\n",
    "# make QA plots? How many examples to plot?\n",
    "globals_[\"MAKE_QA_PLOTS\"] = True\n",
    "globals_[\"N_EXAMPLES\"] = 10\n",
    "\n",
    "# Simulation parameters for the quasar grid\n",
    "# number of objects per mag-z bin\n",
    "globals_[\"N_PER_BIN\"] = 5\n",
    "\n",
    "# number of redshift bins, and redshift limits\n",
    "globals_[\"N_Z\"] = 20\n",
    "globals_[\"LOW_Z_LIM\"] = 1.0\n",
    "globals_[\"HIGH_Z_LIM\"] = 5.0\n",
    "\n",
    "# number of magnitude bins, and magnitude limits\n",
    "globals_[\"N_M1450\"] = 20\n",
    "globals_[\"FAINT_M1450_LIM\"] = -22.0\n",
    "globals_[\"BRIGHT_M1450_LIM\"] = -30.0\n",
    "\n",
    "# Reddening parameters\n",
    "globals_[\"REDDENING_MODEL\"] = ne.Go23\n",
    "globals_[\"B_BOUNDS\"] = 15 * units.deg\n",
    "globals_[\"R_V\"] = 3.1\n",
    "\n",
    "# Sampling mode, valid are \"uniform\", \"lf\" and \"hist2d\",\n",
    "# note that hist2d is currently not supported as an option from command line and as a consequence here\n",
    "globals_[\"SAMPLE_MODE\"] = \"uniform\"\n",
    "\n",
    "# These parameters are only needed for \"lf\" mode and ignored otherwise\n",
    "# The package currently leverages Atelier (https://github.com/jtschindler/atelier) to perform the sampling\n",
    "#  in lf mode\n",
    "# has to be the same as one of the classes in atelier/lumfun.py\n",
    "globals_[\"CHOSEN_LF\"] = \"Matsuoka2023DPLQLF\"\n",
    "globals_[\"LF_SKY_AREA\"] = 10000  # in sq deg\n",
    "\n",
    "# print summary of parameters\n",
    "gpscript.print_cfg_summary(globals_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eea439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the speclite filters\n",
    "SVO_SDSS = filters.load_filters(\"sdss2010-*\")\n",
    "\n",
    "# optionally, plot them too\n",
    "if globals_[\"PLOT_FILTER_RESPONSE\"]:\n",
    "    from quest_qso.photometry import custom_filters as cf\n",
    "\n",
    "    fig, ax = cf.plot_filters(\n",
    "        SVO_SDSS,\n",
    "        figsize=(8, 8 / 1.61 / 2),\n",
    "        legend=False,\n",
    "        add_filter_name=True,\n",
    "        add_effective_wavelength=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a128b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the grid parameters used in generating the photometry\n",
    "# this sets the redshift and magnitude grid according to the input parameters\n",
    "#  i.e., generates a list of tuples (M1450, z) that will be assigned to each sampled quasar\n",
    "#  and use to scale its flux\n",
    "\n",
    "# generate the parameters\n",
    "z_M1450_grid_params = gpscript.generate_grid_params(globals_)\n",
    "\n",
    "# actually instantiate the grid\n",
    "z_M1450_grid = gp.generate_grid(params=z_M1450_grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample spectra from the VAE model based on the generated grid\n",
    "\n",
    "# Set the parameters of the model, and load a pre-trained model\n",
    "model_param_fname = globals_[\"MODEL_PATH\"] / \"params.json\"\n",
    "model_params = cfg.MLConfig().from_json(model_param_fname)\n",
    "model_params.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model, prepare it for sampling and generate spectra based on the user defined\n",
    "#  parameters\n",
    "spectra, dispersion = gp.sample_from_VAE(z_M1450_grid, model_params)\n",
    "\n",
    "# Plot some example spectra\n",
    "gp_qa.plot_example_spectra(\n",
    "    globals_[\"N_EXAMPLES\"],\n",
    "    spectra,\n",
    "    dispersion,\n",
    "    \"GenPhotExample.png\",\n",
    "    ylabel=\"Flux Density [A.U.]\",\n",
    "    dir=globals_[\"LOCAL_PATH\"] / \"QA\" / str(globals_[\"DAY\"]) / \"GeneratePhotometry\",\n",
    "    make_qa=globals_[\"MAKE_QA_PLOTS\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The spectra we have now are in arbitrary units, we need to scale them to physical units\n",
    "#  based on the assigned redshift and M1450\n",
    "\n",
    "# computes the scaling factor for each spectra, based on its assigned redshift and M1450\n",
    "# NB: it modifies grid.grid_data in place, adding the corresponding columns\n",
    "# Worth noting:\n",
    "# - The scaling is done to produce a spectrum in erg / (cm^2 s AA)\n",
    "# - Cosmology is currently Planck 18, but can be easily changed as long as it is an astropy cosmology object\n",
    "gp.compute_scale_factor(dispersion, spectra, z_M1450_grid.grid_data, cosmology)\n",
    "\n",
    "# Scale each spectrum based on the scale value compute in the previous cell\n",
    "scaled_spectra = gp.scale_VAE_spectra(spectra, z_M1450_grid.grid_data[\"scale\"])\n",
    "\n",
    "gp_qa.plot_example_spectra(\n",
    "    globals_[\"N_EXAMPLES\"],\n",
    "    scaled_spectra,\n",
    "    dispersion,\n",
    "    \"GenPhotExample_Scaled.png\",\n",
    "    ylabel=r\"Flux density [erg s$^{-1}$ cm$^{-2}$ $\\AA^{-1}$]\",\n",
    "    dir=globals_[\"LOCAL_PATH\"] / \"QA\" / str(globals_[\"DAY\"]) / \"GeneratePhotometry\",\n",
    "    make_qa=globals_[\"MAKE_QA_PLOTS\"],\n",
    ")\n",
    "\n",
    "if globals_[\"CLEAR_MEMORY\"]:\n",
    "    print(\"[INFO] Clearing memory and removing intermediate products.\")\n",
    "    del spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample and shift to observed frame the spectra on a new wavelength grid.\n",
    "\n",
    "# The user can specify the desired wavelength grid, or the grid can be computed based\n",
    "#  on the requested filters.\n",
    "# In the first case, the easiest thing is to use utilities.gen_wave_grid(), as follows:\n",
    "#  new_rest_frame_dispersion = utilities.gen_wave_grid(7000 * units.AA, 10000 * units.AA, 140 * utilities.kms)\n",
    "# Note that the new grid will be equally spaced in velocity space, and units are required.\n",
    "#  the returned array is a quantity array!\n",
    "# Otherwise, if no grid is provided, then the grid is computed based on the filters set used\n",
    "# Likewise, the wavelength grid has constant bin width in velocity space\n",
    "\n",
    "# returns the resampled spectra, and the new (common) wavelength grid\n",
    "resampled_spectra, new_dispersion = gp.resample_on_wavelength_grid(\n",
    "    SVO_SDSS,  # Set of filter response functions\n",
    "    dispersion,  # Current dispersion (rest frame, it is multiplied by redshif)\n",
    "    z_M1450_grid.grid_data[\"redshift\"].to_numpy(),  # redshfit per each object\n",
    "    scaled_spectra,  # Spectra in physical units\n",
    "    new_rest_frame_dispersion=None,  # Computed based on filters, otherwise see above\n",
    ")\n",
    "\n",
    "gp_qa.plot_example_spectra(\n",
    "    globals_[\"N_EXAMPLES\"],\n",
    "    resampled_spectra,\n",
    "    new_dispersion,\n",
    "    \"GenPhotExample_Scaled_Resampled.png\",\n",
    "    ylabel=r\"Flux density [erg s$^{-1}$ cm$^{-2}$ $\\AA^{-1}$]\",\n",
    "    dir=globals_[\"LOCAL_PATH\"] / \"QA\" / str(globals_[\"DAY\"]) / \"GeneratePhotometry\",\n",
    "    make_qa=globals_[\"MAKE_QA_PLOTS\"],\n",
    ")\n",
    "\n",
    "# clear out some memory, otherwise things get very, very slow\n",
    "if globals_[\"CLEAR_MEMORY\"]:\n",
    "    print(\"[INFO] Clearing memory and removing intermediate products.\")\n",
    "    del scaled_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IGM transmission from SimQSO and apply it to the resampled spectra\n",
    "# Note that this is slow! And it gets slower the wider the wavelength coverage is\n",
    "resampled_spectra_applied_IGM = gp.compute_apply_IGM_simqso(\n",
    "    new_dispersion,\n",
    "    z_M1450_grid,\n",
    "    resampled_spectra,\n",
    ")\n",
    "\n",
    "gp_qa.plot_example_spectra(\n",
    "    globals_[\"N_EXAMPLES\"],\n",
    "    resampled_spectra_applied_IGM,\n",
    "    new_dispersion,\n",
    "    \"GenPhotExample_Scaled_Resampled_IGMApplied.png\",\n",
    "    ylabel=r\"Flux density [erg s$^{-1}$ cm$^{-2}$ $\\AA^{-1}$]\",\n",
    "    dir=globals_[\"LOCAL_PATH\"] / \"QA\" / str(globals_[\"DAY\"]) / \"GeneratePhotometry\",\n",
    "    make_qa=globals_[\"MAKE_QA_PLOTS\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, re-apply reddening to the spectra as we use dereddened spectra while training\n",
    "# Note that this modifies the spectra in place!\n",
    "gp.redden_sampled_spectra(\n",
    "    new_dispersion,\n",
    "    resampled_spectra_applied_IGM,\n",
    "    globals_[\"REDDENING_MODEL\"],\n",
    "    globals_[\"R_V\"],\n",
    "    b_bounds=globals_[\"B_BOUNDS\"],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save array of generated spectra and dataframe grid\n",
    "generated_spectra_output = globals_[\"LOCAL_PATH\"] / \"generated_spectra\"\n",
    "if not generated_spectra_output.exists():\n",
    "    generated_spectra_output.mkdir(parents=True)\n",
    "\n",
    "np.save(\n",
    "    generated_spectra_output\n",
    "    / f\"VAE_Spectra_with_IGM_dispersion_{globals_['TIMESTAMP']}.npy\",\n",
    "    new_dispersion.value,\n",
    ")\n",
    "\n",
    "np.save(\n",
    "    generated_spectra_output / f\"VAE_Spectra_with_IGM_{globals_['TIMESTAMP']}.npy\",\n",
    "    resampled_spectra_applied_IGM,\n",
    ")\n",
    "\n",
    "z_M1450_grid.grid_data.to_hdf(\n",
    "    generated_spectra_output / f\"Param_grid_{globals_['TIMESTAMP']}.hdf5\",\n",
    "    key=\"data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, generate new magnitudes based on the output of the previous cells\n",
    "mags = pd.concat(\n",
    "    (\n",
    "        z_M1450_grid.grid_data,\n",
    "        SVO_SDSS.get_ab_magnitudes(\n",
    "            resampled_spectra_applied_IGM, new_dispersion\n",
    "        ).to_pandas(),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# get the bands used - note that this does not ensure that the order of the filters is always the same\n",
    "bands = gp_qa.merge_bands(mags.columns[5:])\n",
    "\n",
    "# generate a (long but informative) filename\n",
    "outfilepath = globals_[\"LOCAL_PATH\"] / \"generated_photometry\" / str(globals_[\"DAY\"])\n",
    "if not outfilepath.exists():\n",
    "    outfilepath.mkdir(parents=True)\n",
    "\n",
    "# Conventionally, - indicates separation between different fields, _ indicates separation within fields\n",
    "outfilename = (\n",
    "    f\"GeneratedPhot-no_pert-{bands}-\"\n",
    "    + f\"{globals_['SAMPLE_MODE']}-\"\n",
    "    + (f\"{globals_['CHOSEN_LF']}\" if globals_[\"SAMPLE_MODE\"] == \"lf\" else \"\")\n",
    "    + (f\"{globals_['LF_SKY_AREA']}-\" if globals_[\"SAMPLE_MODE\"] == \"lf\" else \"\")\n",
    "    + f\"seed_{globals_['SEED']}-\"\n",
    "    + f\"redsh_{str(globals_['LOW_Z_LIM']).replace('.', 'p')}to{str(globals_['HIGH_Z_LIM']).replace('.', 'p')}_\"\n",
    "    + f\"M1450_m{np.abs(globals_['BRIGHT_M1450_LIM'])}tom{np.abs(globals_['FAINT_M1450_LIM'])}_{globals_['TIMESTAMP']}.hdf5\"\n",
    ")\n",
    "\n",
    "# save catalogues\n",
    "mags.to_hdf(\n",
    "    outfilepath / outfilename,\n",
    "    key=\"data\",\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Catalogue saved to {outfilepath / outfilename}\")\n",
    "print(\"[INFO] Photometry generation completed!\")\n",
    "print(\"[INFO] Edit and run `add_pert.py` with the appropriate filters to add noise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the magnitudes we generated are error-free\n",
    "# we add some noise in the next cells\n",
    "\n",
    "# pandas does not like units, so we temporarily go back to numpy arrays\n",
    "mags_np = mags[\n",
    "    [\n",
    "        \"sdss2010-u\",\n",
    "        \"sdss2010-g\",\n",
    "        \"sdss2010-r\",\n",
    "        \"sdss2010-i\",\n",
    "        \"sdss2010-z\",\n",
    "    ]\n",
    "].to_numpy()\n",
    "\n",
    "flux_np = gp.AB_to_flux(mags_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the error functions\n",
    "error_function_sdss = (\n",
    "    utilities.pandas_to_recarray(resources.load_sdss_error_functions())\n",
    "    * units.microJansky\n",
    ")\n",
    "\n",
    "perturbed_photometry = {}\n",
    "for n, band in enumerate([\"U\", \"G\", \"R\", \"I\", \"Z\"]):\n",
    "    # the output are in this order:\n",
    "    # band_perturbed, band_err_perturbed, band_flux_perturbed, band_snr\n",
    "    perturbed_photometry[f\"SDSS_{band}\"] = gp.generate_perturbed_magnitudes(\n",
    "        flux_np[:, n],\n",
    "        error_function_sdss,\n",
    "        f\"SDSS_{band}\",\n",
    "        flag=99.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93223274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure the output in a pandas dataframe\n",
    "# _pert -> perturbed magnitudes\n",
    "# _sigma -> errors on perturbed magnitudes\n",
    "# _flux -> perturbed flux from which I compute the magnitudes\n",
    "\n",
    "mags_perturbed = utilities.numpy_to_pandas(\n",
    "    [\n",
    "        \"SDSS_U_pert\",\n",
    "        \"SDSS_U_sigma\",\n",
    "        \"SDSS_U_flux\",\n",
    "        \"SDSS_U_snr\",\n",
    "        \"SDSS_G_pert\",\n",
    "        \"SDSS_G_sigma\",\n",
    "        \"SDSS_G_flux\",\n",
    "        \"SDSS_G_snr\",\n",
    "        \"SDSS_R_pert\",\n",
    "        \"SDSS_R_sigma\",\n",
    "        \"SDSS_R_flux\",\n",
    "        \"SDSS_R_snr\",\n",
    "        \"SDSS_I_pert\",\n",
    "        \"SDSS_I_sigma\",\n",
    "        \"SDSS_I_flux\",\n",
    "        \"SDSS_I_snr\",\n",
    "        \"SDSS_Z_pert\",\n",
    "        \"SDSS_Z_sigma\",\n",
    "        \"SDSS_Z_flux\",\n",
    "        \"SDSS_Z_snr\",\n",
    "    ],\n",
    "    np.array(\n",
    "        (\n",
    "            perturbed_photometry[\"SDSS_U\"][0].value,\n",
    "            perturbed_photometry[\"SDSS_U\"][1].value,\n",
    "            perturbed_photometry[\"SDSS_U\"][2].value,\n",
    "            perturbed_photometry[\"SDSS_U\"][3].value,\n",
    "            perturbed_photometry[\"SDSS_G\"][0].value,\n",
    "            perturbed_photometry[\"SDSS_G\"][1].value,\n",
    "            perturbed_photometry[\"SDSS_G\"][2].value,\n",
    "            perturbed_photometry[\"SDSS_G\"][3].value,\n",
    "            perturbed_photometry[\"SDSS_R\"][0].value,\n",
    "            perturbed_photometry[\"SDSS_R\"][1].value,\n",
    "            perturbed_photometry[\"SDSS_R\"][2].value,\n",
    "            perturbed_photometry[\"SDSS_R\"][3].value,\n",
    "            perturbed_photometry[\"SDSS_I\"][0].value,\n",
    "            perturbed_photometry[\"SDSS_I\"][1].value,\n",
    "            perturbed_photometry[\"SDSS_I\"][2].value,\n",
    "            perturbed_photometry[\"SDSS_I\"][3].value,\n",
    "            perturbed_photometry[\"SDSS_Z\"][0].value,\n",
    "            perturbed_photometry[\"SDSS_Z\"][1].value,\n",
    "            perturbed_photometry[\"SDSS_Z\"][2].value,\n",
    "            perturbed_photometry[\"SDSS_Z\"][3].value,\n",
    "        )\n",
    "    ).T,\n",
    ")\n",
    "\n",
    "catalogue = pd.concat((mags, mags_perturbed), axis=1)\n",
    "catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save catalogues in the same folder as the previous one, but with an updated filename\n",
    "catalogue.to_hdf(\n",
    "    outfilepath / outfilename.replace(\"no_pert\", \"w_pert\"),\n",
    "    key=\"data\",\n",
    ")\n",
    "\n",
    "print(f\"Catalogue saved to {outfilepath / outfilename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fce1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
