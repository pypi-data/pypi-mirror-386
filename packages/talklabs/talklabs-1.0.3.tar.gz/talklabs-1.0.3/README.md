# ğŸ™ï¸ TalkLabs - ElevenLabs Compatible TTS

<div align="center">

![TalkLabs Logo](https://img.shields.io/badge/TalkLabs-v1.0.0-blue)
[![Python](https://img.shields.io/badge/Python-3.9+-green.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**Text-to-Speech de alta qualidade compatÃ­vel com ElevenLabs, powered by XTTS2**

[DocumentaÃ§Ã£o](https://docs.talklabs.ai) â€¢ [API Reference](https://api.talklabs.ai/docs) â€¢ [Exemplos](examples/)

</div>

---

## âœ¨ Features

- ğŸ¯ **100% compatÃ­vel com ElevenLabs API** - Drop-in replacement
- ğŸš€ **Streaming em tempo real** - HTTP e WebSocket
- ğŸŒ **Multi-idioma** - PortuguÃªs, InglÃªs, Espanhol, FrancÃªs, AlemÃ£o, Italiano
- ğŸ­ **Voice Cloning** - Clone qualquer voz com 3-5 amostras
- âš¡ **Alta Performance** - CUDA acelerado com suporte RTX
- ğŸ”’ **Self-hosted** - Seus dados, seu servidor

## ğŸš€ Quick Start

### InstalaÃ§Ã£o

```bash
# Instalar TalkLabs
cd /home/francisco/talklabs
pip install -e .

# Ou via pip (quando publicado)
pip install talklabs
```

### Iniciar API

```bash
# Iniciar servidor
python api/main.py

# Ou via uvicorn
uvicorn api.main:app --host 0.0.0.0 --port 5000
```

### Uso do SDK

```python
from talklabs import TalkLabsClient

# Inicializar cliente
client = TalkLabsClient(
    api_key="TALKLABS_SECRET_KEY",
    base_url="http://localhost:5000"
)

# Gerar Ã¡udio
audio = client.generate(
    text="OlÃ¡, mundo!",
    voice="yasmin_alves",
    speed=1.0
)

# Salvar arquivo
with open("output.wav", "wb") as f:
    f.write(audio)
```

## ğŸ“– Exemplos

### 1. GeraÃ§Ã£o Simples

```python
from talklabs import generate

audio = generate(
    text="Bem-vindo ao TalkLabs!",
    voice="yasmin_alves",
    api_key="TALKLABS_SECRET_KEY"
)
```

### 2. Streaming

```python
from talklabs import TalkLabsClient

client = TalkLabsClient(api_key="...")

with open("stream.wav", "wb") as f:
    for chunk in client.generate_stream(
        text="Texto longo para streaming...",
        voice="yasmin_alves"
    ):
        f.write(chunk)
```

### 3. Com Timestamps

```python
result = client.generate_with_timestamps(
    text="OlÃ¡ mundo",
    voice="yasmin_alves"
)

# Ãudio em base64
audio_bytes = base64.b64decode(result["audio_base64"])

# Timestamps de cada palavra
for word in result["alignment"]:
    print(f"{word['word']}: {word['start']}s - {word['end']}s")
```

### 4. WebSocket Streaming

```python
import asyncio

async def main():
    client = TalkLabsClient(api_key="...")
    
    async def text_stream():
        yield "OlÃ¡, "
        await asyncio.sleep(0.5)
        yield "mundo!"
    
    async for audio_chunk in client.stream_input(
        text_iterator=text_stream(),
        voice="yasmin_alves"
    ):
        # Processar chunk de Ã¡udio
        pass

asyncio.run(main())
```

## ğŸ­ Clonando Vozes

```bash
# 1. Criar diretÃ³rio para nova voz
mkdir -p samples/minha_voz

# 2. Adicionar 3-5 amostras WAV (16kHz, mono, 10-30s cada)
cp amostra1.wav samples/minha_voz/
cp amostra2.wav samples/minha_voz/
cp amostra3.wav samples/minha_voz/

# 3. Reiniciar servidor
# A voz estarÃ¡ disponÃ­vel automaticamente!
```

## ğŸ”Œ API Endpoints

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/v1/text-to-speech/{voice_id}` | POST | TTS padrÃ£o |
| `/v1/text-to-speech/{voice_id}/stream` | POST | Streaming HTTP |
| `/v1/text-to-speech/{voice_id}/with-timestamps` | POST | TTS com timestamps |
| `/v1/text-to-speech/{voice_id}/stream-input` | WS | WebSocket streaming |
| `/v1/voices` | GET | Listar vozes |
| `/v1/models` | GET | Listar modelos |
| `/health` | GET | Health check |

## ğŸ›ï¸ ParÃ¢metros

```python
client.generate(
    text="Seu texto aqui",
    voice="yasmin_alves",
    speed=1.0,           # 0.25 a 4.0
    language="pt",       # pt, en, es, fr, de, it
    voice_settings={
        "stability": 0.75,        # 0.0 a 1.0
        "similarity_boost": 0.75,
        "style": 0.0,
        "use_speaker_boost": True
    }
)
```

## ğŸŒ Usando via cURL

```bash
curl -X POST "http://localhost:5000/v1/text-to-speech/yasmin_alves" \
     -H "xi-api-key: TALKLABS_SECRET_KEY" \
     -H "Content-Type: application/json" \
     -d '{"text":"OlÃ¡ mundo!","speed":1.2}' \
     --output audio.wav
```

## ğŸ”§ ConfiguraÃ§Ã£o

```python
# .env ou variÃ¡veis de ambiente
TALKLABS_API_KEY=your_secret_key_here
TALKLABS_HOST=0.0.0.0
TALKLABS_PORT=5000
CUDA_VISIBLE_DEVICES=0  # GPU a usar
```

## ğŸ“Š Benchmarks

| MÃ©trica | Valor |
|---------|-------|
| LatÃªncia primeira chunk | ~200ms |
| Throughput | ~50 caracteres/segundo |
| Qualidade MOS | 4.2/5.0 |
| Idiomas suportados | 6+ |
| GPU mÃ­nima | GTX 1060 6GB |
| GPU recomendada | RTX 3090+ |

## ğŸ› Troubleshooting

### CUDA Out of Memory
```python
# Reduzir batch size ou usar CPU
engine = TalkLabsEngine(device="cpu")
```

### Voz nÃ£o encontrada
```bash
# Verificar vozes disponÃ­veis
curl http://localhost:5000/v1/voices
```

### LatÃªncia alta
```python
# Usar modelo flash
client.generate(text="...", model="eleven_flash_v2_5")
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

## ğŸ™ CrÃ©ditos

- XTTS2 by [Coqui.ai](https://github.com/coqui-ai/TTS)
- Inspirado em [ElevenLabs](https://elevenlabs.io)

---

<div align="center">

**[Website](https://talklabs.ai)** â€¢ **[DocumentaÃ§Ã£o](https://docs.talklabs.ai)** â€¢ **[Discord](https://discord.gg/talklabs)**

Made with â¤ï¸ by TalkLabs Team

</div>
