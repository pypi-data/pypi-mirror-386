provider: ollama
description: "Local Ollama models for privacy-focused inference"
models:
  - model_id: "llama3.2:3b-instruct-fp16"
    model_type: "text"
    capabilities:
      - "text_generation"
      - "chat"
    metadata:
      description: "Local running Llama model for privacy-focused text generation and conversation. Fast inference with good quality for common tasks."
      performance_tier: "efficient"
      specialized_tasks:
        - "local inference"
        - "privacy-first chat"
        - "fast generation"
        - "offline usage"
        - "no API costs"
      provider_model_name: "llama3.2:3b-instruct-fp16"
      supports_streaming: true
      max_tokens: 8192
      context_window: 8192
      pricing_tier: "free"
      requires_local_setup: true

  - model_id: "bge-m3"
    model_type: "embedding"
    capabilities:
      - "text_embedding"
    metadata:
      description: "Local multilingual embedding model supporting Chinese, English and other languages. Great for privacy-focused semantic tasks."
      performance_tier: "efficient"
      specialized_tasks:
        - "multilingual embeddings"
        - "local inference"
        - "privacy-first search"
        - "Chinese text processing"
        - "semantic similarity"
        - "no API costs"
      provider_model_name: "bge-m3"
      vector_dimensions: 1024
      pricing_tier: "free"
      requires_local_setup: true