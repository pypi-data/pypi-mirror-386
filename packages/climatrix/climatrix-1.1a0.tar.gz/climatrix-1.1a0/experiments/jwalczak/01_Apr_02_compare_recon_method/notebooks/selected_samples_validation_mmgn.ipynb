{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b247b8b",
   "metadata": {},
   "source": [
    "### Selected samples MMGN validation\n",
    "\n",
    "**Author:** Jakub Walczak, PhD\n",
    "\n",
    "This notebook contains validation of the MMGN method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d8615ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import shutil\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable\n",
    "\n",
    "import xarray as xr\n",
    "from rich.console import Console\n",
    "\n",
    "import climatrix as cm\n",
    "\n",
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9edcee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Using NaN policy: </span> resample\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUsing NaN policy: \u001b[0m resample\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Using seed: </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUsing seed: \u001b[0m \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Using dataset path: </span> <span style=\"color: #800080; text-decoration-color: #800080\">/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">data</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUsing dataset path: \u001b[0m \u001b[35m/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/\u001b[0m\u001b[95mdata\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "\n",
    "NAN_POLICY = \"resample\"\n",
    "console.print(\"[bold green]Using NaN policy: [/bold green]\", NAN_POLICY)\n",
    "\n",
    "SEED = 1\n",
    "console.print(\"[bold green]Using seed: [/bold green]\", SEED)\n",
    "\n",
    "DSET_PATH = Path(__session__).parent.parent.joinpath(\"data\")\n",
    "console.print(\"[bold green]Using dataset path: [/bold green]\", DSET_PATH)\n",
    "\n",
    "EUROPE_BOUNDS = {\"north\": 71, \"south\": 36, \"west\": -24, \"east\": 35}\n",
    "EUROPE_DOMAIN = cm.Domain.from_lat_lon(\n",
    "    lat=slice(EUROPE_BOUNDS[\"south\"], EUROPE_BOUNDS[\"north\"], 0.1),\n",
    "    lon=slice(EUROPE_BOUNDS[\"west\"], EUROPE_BOUNDS[\"east\"], 0.1),\n",
    "    kind=\"dense\",\n",
    ")\n",
    "cm.seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a16911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataset_idx() -> list[str]:\n",
    "    return sorted(\n",
    "        list({path.stem.split(\"_\")[-1] for path in DSET_PATH.glob(\"*.nc\")})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe293711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_method(\n",
    "    d: str, i: int, method: str, reconstruct_dense: bool = True, **params\n",
    "):\n",
    "    cm.seed_all(SEED)\n",
    "    train_dset = xr.open_dataset(\n",
    "        DSET_PATH / f\"ecad_obs_europe_train_{d}.nc\"\n",
    "    ).cm\n",
    "    val_dset = xr.open_dataset(DSET_PATH / f\"ecad_obs_europe_val_{d}.nc\").cm\n",
    "    reconstructed_dset = train_dset.reconstruct(\n",
    "        val_dset.domain,\n",
    "        method=method,\n",
    "        checkpoint=\"./checkpoint\",\n",
    "        overwrite_checkpoint=True,\n",
    "        validation=val_dset,\n",
    "        **params,\n",
    "    )\n",
    "    if reconstruct_dense:\n",
    "        reconstructed_dense = train_dset.reconstruct(\n",
    "            EUROPE_DOMAIN, method=method, checkpoint=\"./checkpoint\", **params\n",
    "        )\n",
    "    return val_dset, reconstructed_dset, reconstructed_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d43dfa-7613-49fa-b3e6-f1e38f9e23d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">There is </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">100</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> samples available </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mThere is \u001b[0m\u001b[1;33m100\u001b[0m\u001b[1;32m samples available \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset_idx = get_all_dataset_idx()\n",
    "console.print(\n",
    "    f\"[bold green]There is [bold yellow]{len(dset_idx)}[/bold yellow] samples available [/bold green]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9703e971-a500-4a61-805c-2d329dea92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9900186-1c3b-4f2d-9299-99fbcc04f1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Using checkpoint path: /home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/notebooks/checkpoint\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.mmgn.mmgn | Initializing MMGN model...\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.mmgn.mmgn | Configuring Adam optimizer with learning rate: 1.000398\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Configuring epoch schedulers...\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Training MMGNet model...\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Validation dataset is available. Using it for validation.\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 1/1000: train loss = 0.3183 | val loss = 39.7533\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 2/1000: train loss = 40.0149 | val loss = 233956.6406\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 3/1000: train loss = 230126.5156 | val loss = 11684108.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 4/1000: train loss = 10667995.0000 | val loss = 1242285824.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 5/1000: train loss = 1191012736.0000 | val loss = 863559286784.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 6/1000: train loss = 794400456704.0000 | val loss = 184667045888.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 7/1000: train loss = 313299959808.0000 | val loss = 515363200.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 8/1000: train loss = 570609920.0000 | val loss = 7113525248.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 9/1000: train loss = 3565287680.0000 | val loss = 3854902.7500\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 10/1000: train loss = 3277975.7500 | val loss = 29653850.0000\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 11/1000: train loss = 26389182.0000 | val loss = 180488.7969\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 12/1000: train loss = 159069.1562 | val loss = 370263.1250\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 13/1000: train loss = 335348.5938 | val loss = 3158278.7500\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 14/1000: train loss = 2173192.2500 | val loss = 182038.7656\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 15/1000: train loss = 147044.0625 | val loss = 16754.6699\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 16/1000: train loss = 18123.8730 | val loss = 6922.8345\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 17/1000: train loss = 7477.0449 | val loss = 3782.1230\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 18/1000: train loss = 3835.6968 | val loss = 3172.6584\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 19/1000: train loss = 3060.9053 | val loss = 2674.7839\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 20/1000: train loss = 2431.6870 | val loss = 2088.0181\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 21/1000: train loss = 2046.8889 | val loss = 1700.0580\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 22/1000: train loss = 1720.1785 | val loss = 1073.7252\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 23/1000: train loss = 1046.4749 | val loss = 630.7115\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 24/1000: train loss = 702.8149 | val loss = 347.1772\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 25/1000: train loss = 381.9654 | val loss = 278.9882\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 26/1000: train loss = 277.3049 | val loss = 286.3055\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 27/1000: train loss = 267.5183 | val loss = 170.9045\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 28/1000: train loss = 166.5894 | val loss = 111.3461\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 29/1000: train loss = 118.7581 | val loss = 101.8299\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 30/1000: train loss = 109.3126 | val loss = 103.3499\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 31/1000: train loss = 106.7938 | val loss = 97.1609\n",
      "11-09-2025 12:35:11 INFO | climatrix.reconstruct.nn.base_nn | Epoch 32/1000: train loss = 97.8265 | val loss = 85.9206\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 33/1000: train loss = 85.5566 | val loss = 77.5464\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 34/1000: train loss = 73.4503 | val loss = 77.0293\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 35/1000: train loss = 68.8360 | val loss = 79.5685\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 36/1000: train loss = 75.6386 | val loss = 81.1088\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 37/1000: train loss = 81.1704 | val loss = 78.7932\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 38/1000: train loss = 80.6775 | val loss = 71.9564\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 39/1000: train loss = 73.7325 | val loss = 66.3790\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 40/1000: train loss = 66.3227 | val loss = 62.5214\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 41/1000: train loss = 59.7810 | val loss = 62.6361\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 42/1000: train loss = 58.2207 | val loss = 65.9455\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 43/1000: train loss = 64.3091 | val loss = 68.7566\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 44/1000: train loss = 67.7011 | val loss = 71.2169\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 45/1000: train loss = 70.4022 | val loss = 69.0148\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 46/1000: train loss = 69.0141 | val loss = 61.7437\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 47/1000: train loss = 63.4755 | val loss = 53.7998\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 48/1000: train loss = 56.4978 | val loss = 49.6761\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 49/1000: train loss = 51.0459 | val loss = 55.6738\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 50/1000: train loss = 54.0960 | val loss = 64.5440\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 51/1000: train loss = 62.6370 | val loss = 72.6577\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 52/1000: train loss = 71.0333 | val loss = 77.1196\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 53/1000: train loss = 75.7202 | val loss = 80.8090\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 54/1000: train loss = 77.2145 | val loss = 79.6650\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 55/1000: train loss = 76.2369 | val loss = 73.3239\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 56/1000: train loss = 70.9472 | val loss = 67.4954\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 57/1000: train loss = 64.4511 | val loss = 66.4578\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 58/1000: train loss = 59.8266 | val loss = 103.3344\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 59/1000: train loss = 101.6526 | val loss = 67.7422\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 60/1000: train loss = 64.8522 | val loss = 70.7424\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 61/1000: train loss = 69.0746 | val loss = 75.2261\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 62/1000: train loss = 74.6500 | val loss = 80.1854\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 63/1000: train loss = 81.1606 | val loss = 83.6412\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 64/1000: train loss = 85.2389 | val loss = 84.8933\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 65/1000: train loss = 86.1732 | val loss = 85.3096\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 66/1000: train loss = 84.6258 | val loss = 85.4573\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 67/1000: train loss = 82.1622 | val loss = 86.5632\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 68/1000: train loss = 80.5924 | val loss = 85.7304\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 69/1000: train loss = 78.3686 | val loss = 83.1476\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 70/1000: train loss = 76.8183 | val loss = 82.8904\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 71/1000: train loss = 79.9223 | val loss = 82.5501\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 72/1000: train loss = 83.9399 | val loss = 79.8988\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 73/1000: train loss = 84.9627 | val loss = 76.0855\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 74/1000: train loss = 83.2136 | val loss = 72.6628\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 75/1000: train loss = 81.4140 | val loss = 74.5109\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 76/1000: train loss = 82.6500 | val loss = 111.1214\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 77/1000: train loss = 124.3928 | val loss = 83.6995\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 78/1000: train loss = 84.8444 | val loss = 89.1478\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 79/1000: train loss = 88.6018 | val loss = 93.4316\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 80/1000: train loss = 90.3213 | val loss = 94.5903\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 81/1000: train loss = 88.8466 | val loss = 99.7385\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 82/1000: train loss = 91.7176 | val loss = 107.9699\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 83/1000: train loss = 94.6787 | val loss = 104.6264\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 84/1000: train loss = 94.1937 | val loss = 106.1477\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 85/1000: train loss = 95.0396 | val loss = 105.7247\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 86/1000: train loss = 96.3812 | val loss = 103.6751\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 87/1000: train loss = 95.7157 | val loss = 99.6009\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 88/1000: train loss = 93.2803 | val loss = 96.7140\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 89/1000: train loss = 91.2757 | val loss = 96.1146\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 90/1000: train loss = 91.1820 | val loss = 93.2650\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 91/1000: train loss = 90.0626 | val loss = 89.4640\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 92/1000: train loss = 88.7627 | val loss = 86.5602\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 93/1000: train loss = 87.2432 | val loss = 85.3690\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 94/1000: train loss = 85.7832 | val loss = 89.8961\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 95/1000: train loss = 89.6531 | val loss = 90.0308\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 96/1000: train loss = 89.4752 | val loss = 96.1334\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 97/1000: train loss = 93.6443 | val loss = 101.2802\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 98/1000: train loss = 96.9458 | val loss = 105.4610\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 99/1000: train loss = 100.6616 | val loss = 108.6934\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 100/1000: train loss = 105.1277 | val loss = 112.7749\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 101/1000: train loss = 110.1562 | val loss = 116.3479\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 102/1000: train loss = 114.1297 | val loss = 119.0361\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 103/1000: train loss = 116.7659 | val loss = 123.0471\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 104/1000: train loss = 118.7848 | val loss = 126.1742\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 105/1000: train loss = 119.5356 | val loss = 128.6799\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 106/1000: train loss = 119.9505 | val loss = 131.5776\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 107/1000: train loss = 120.7219 | val loss = 133.9324\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 108/1000: train loss = 121.3198 | val loss = 135.0916\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 109/1000: train loss = 120.7469 | val loss = 136.5108\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 110/1000: train loss = 120.6660 | val loss = 138.7397\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 111/1000: train loss = 121.3310 | val loss = 140.0477\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 112/1000: train loss = 121.0633 | val loss = 139.9927\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 113/1000: train loss = 120.2652 | val loss = 139.3372\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 114/1000: train loss = 121.0877 | val loss = 139.0482\n",
      "11-09-2025 12:35:12 INFO | climatrix.reconstruct.nn.base_nn | Epoch 115/1000: train loss = 123.1391 | val loss = 138.0757\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 116/1000: train loss = 125.2113 | val loss = 133.0452\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 117/1000: train loss = 124.3493 | val loss = 216.0057\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 118/1000: train loss = 200.4451 | val loss = 124.4413\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 119/1000: train loss = 125.6928 | val loss = 124.7185\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 120/1000: train loss = 129.6146 | val loss = 120.2455\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 121/1000: train loss = 128.4949 | val loss = 170.3873\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 122/1000: train loss = 177.6083 | val loss = 115.4955\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 123/1000: train loss = 125.8378 | val loss = 112.5165\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 124/1000: train loss = 122.8781 | val loss = 110.8314\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 125/1000: train loss = 121.3201 | val loss = 103.5616\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 126/1000: train loss = 116.9263 | val loss = 110.6110\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 127/1000: train loss = 118.3710 | val loss = 110.8682\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 128/1000: train loss = 117.3848 | val loss = 110.2392\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 129/1000: train loss = 114.4242 | val loss = 114.7853\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 130/1000: train loss = 110.3149 | val loss = 142.4701\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 131/1000: train loss = 124.9179 | val loss = 107.0884\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 132/1000: train loss = 103.2865 | val loss = 102.2898\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 133/1000: train loss = 102.6297 | val loss = 102.6559\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 134/1000: train loss = 101.4501 | val loss = 101.9305\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 135/1000: train loss = 98.2821 | val loss = 96.8433\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 136/1000: train loss = 90.3464 | val loss = 121.6922\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 137/1000: train loss = 112.7578 | val loss = 100.6688\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 138/1000: train loss = 90.5675 | val loss = 91.6256\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 139/1000: train loss = 81.8402 | val loss = 86.6776\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 140/1000: train loss = 79.3220 | val loss = 89.2915\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 141/1000: train loss = 81.1093 | val loss = 84.2302\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 142/1000: train loss = 76.7987 | val loss = 195.8267\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 143/1000: train loss = 192.1323 | val loss = 83.1043\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 144/1000: train loss = 79.0962 | val loss = 92.7945\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 145/1000: train loss = 90.1938 | val loss = 100.2059\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 146/1000: train loss = 100.4951 | val loss = 99.3478\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 147/1000: train loss = 99.8513 | val loss = 94.6208\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 148/1000: train loss = 90.7740 | val loss = 108.4804\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 149/1000: train loss = 94.5702 | val loss = 113.7449\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 150/1000: train loss = 99.8173 | val loss = 91.6743\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 151/1000: train loss = 83.5837 | val loss = 90.8792\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 152/1000: train loss = 86.1392 | val loss = 92.5675\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 153/1000: train loss = 87.0063 | val loss = 92.2206\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 154/1000: train loss = 86.1205 | val loss = 88.2967\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 155/1000: train loss = 81.7893 | val loss = 85.4117\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 156/1000: train loss = 77.6870 | val loss = 84.4234\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 157/1000: train loss = 73.2699 | val loss = 82.8755\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 158/1000: train loss = 73.2118 | val loss = 81.8480\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 159/1000: train loss = 71.1863 | val loss = 80.3733\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 160/1000: train loss = 69.5903 | val loss = 75.5371\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 161/1000: train loss = 65.5882 | val loss = 70.2600\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 162/1000: train loss = 63.3234 | val loss = 70.6054\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 163/1000: train loss = 63.9090 | val loss = 71.0532\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 164/1000: train loss = 63.6814 | val loss = 70.0956\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 165/1000: train loss = 63.5882 | val loss = 69.5957\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 166/1000: train loss = 63.7442 | val loss = 70.1017\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 167/1000: train loss = 64.1948 | val loss = 70.0007\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 168/1000: train loss = 63.5820 | val loss = 69.5574\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 169/1000: train loss = 62.6379 | val loss = 64.4643\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 170/1000: train loss = 56.9327 | val loss = 74.4970\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 171/1000: train loss = 65.5936 | val loss = 68.3972\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 172/1000: train loss = 62.7784 | val loss = 66.5588\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 173/1000: train loss = 59.5795 | val loss = 65.6002\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 174/1000: train loss = 58.5583 | val loss = 64.7847\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 175/1000: train loss = 57.7754 | val loss = 62.2344\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 176/1000: train loss = 57.1913 | val loss = 62.9742\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 177/1000: train loss = 58.3671 | val loss = 62.9843\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 178/1000: train loss = 56.9911 | val loss = 61.1225\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 179/1000: train loss = 54.3925 | val loss = 59.5729\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 180/1000: train loss = 53.7003 | val loss = 59.3350\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 181/1000: train loss = 53.0750 | val loss = 60.7403\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 182/1000: train loss = 49.9494 | val loss = 63.6649\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 183/1000: train loss = 49.9111 | val loss = 61.5619\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 184/1000: train loss = 46.6679 | val loss = 62.6028\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 185/1000: train loss = 49.9907 | val loss = 61.7283\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 186/1000: train loss = 46.8866 | val loss = 76.2558\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 187/1000: train loss = 64.2149 | val loss = 61.2168\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 188/1000: train loss = 47.0000 | val loss = 63.7351\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 189/1000: train loss = 49.9214 | val loss = 62.2338\n",
      "11-09-2025 12:35:13 INFO | climatrix.reconstruct.nn.base_nn | Epoch 190/1000: train loss = 49.0416 | val loss = 59.0826\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 191/1000: train loss = 48.3279 | val loss = 60.0656\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 192/1000: train loss = 48.1135 | val loss = 59.5449\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 193/1000: train loss = 50.9998 | val loss = 68.9251\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 194/1000: train loss = 63.0328 | val loss = 61.1053\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 195/1000: train loss = 55.8578 | val loss = 57.4820\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 196/1000: train loss = 48.6994 | val loss = 56.2303\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 197/1000: train loss = 43.9370 | val loss = 60.5505\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 198/1000: train loss = 46.3193 | val loss = 57.5622\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 199/1000: train loss = 45.2746 | val loss = 57.7970\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 200/1000: train loss = 44.6976 | val loss = 58.9060\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 201/1000: train loss = 45.9317 | val loss = 55.5150\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 202/1000: train loss = 43.4765 | val loss = 53.6395\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 203/1000: train loss = 44.1945 | val loss = 55.0474\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 204/1000: train loss = 46.3812 | val loss = 55.8921\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 205/1000: train loss = 48.1438 | val loss = 53.1717\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 206/1000: train loss = 44.1635 | val loss = 57.3972\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 207/1000: train loss = 48.4062 | val loss = 59.7990\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 208/1000: train loss = 48.1020 | val loss = 55.6537\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 209/1000: train loss = 44.0883 | val loss = 58.9422\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 210/1000: train loss = 48.3250 | val loss = 59.8946\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 211/1000: train loss = 50.2705 | val loss = 56.5168\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 212/1000: train loss = 46.3111 | val loss = 55.9790\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 213/1000: train loss = 45.4187 | val loss = 59.5071\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 214/1000: train loss = 49.1448 | val loss = 53.3483\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 215/1000: train loss = 41.6312 | val loss = 57.3537\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 216/1000: train loss = 46.9819 | val loss = 57.2795\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 217/1000: train loss = 47.2208 | val loss = 51.3771\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 218/1000: train loss = 41.6422 | val loss = 51.3588\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 219/1000: train loss = 42.1369 | val loss = 52.5783\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 220/1000: train loss = 42.1233 | val loss = 48.0230\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 221/1000: train loss = 37.0927 | val loss = 48.6430\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 222/1000: train loss = 37.5519 | val loss = 49.2171\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 223/1000: train loss = 40.0725 | val loss = 48.6832\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 224/1000: train loss = 38.1063 | val loss = 51.3760\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 225/1000: train loss = 40.4192 | val loss = 49.8399\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 226/1000: train loss = 39.3981 | val loss = 46.2801\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 227/1000: train loss = 37.6188 | val loss = 47.3059\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 228/1000: train loss = 39.1830 | val loss = 47.0291\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 229/1000: train loss = 37.2095 | val loss = 46.3822\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 230/1000: train loss = 36.0660 | val loss = 46.1293\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 231/1000: train loss = 35.6757 | val loss = 44.8864\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 232/1000: train loss = 34.7547 | val loss = 47.7573\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 233/1000: train loss = 35.7400 | val loss = 45.1726\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 234/1000: train loss = 34.3109 | val loss = 46.3531\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 235/1000: train loss = 35.9540 | val loss = 43.5509\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 236/1000: train loss = 32.8246 | val loss = 49.0651\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 237/1000: train loss = 38.2447 | val loss = 41.9731\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 238/1000: train loss = 31.8395 | val loss = 42.6810\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 239/1000: train loss = 32.3132 | val loss = 41.2162\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 240/1000: train loss = 30.6511 | val loss = 40.6491\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 241/1000: train loss = 29.3110 | val loss = 43.7015\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 242/1000: train loss = 30.7747 | val loss = 45.6066\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 243/1000: train loss = 33.1083 | val loss = 43.1724\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 244/1000: train loss = 29.8884 | val loss = 42.6384\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 245/1000: train loss = 31.2707 | val loss = 43.5765\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 246/1000: train loss = 32.1224 | val loss = 41.6322\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 247/1000: train loss = 30.6104 | val loss = 41.3938\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 248/1000: train loss = 29.9025 | val loss = 41.4067\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 249/1000: train loss = 30.7198 | val loss = 41.9829\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 250/1000: train loss = 30.6593 | val loss = 40.4136\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 251/1000: train loss = 28.9219 | val loss = 43.5347\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 252/1000: train loss = 31.8602 | val loss = 41.8027\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 253/1000: train loss = 31.1938 | val loss = 41.7669\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 254/1000: train loss = 30.7944 | val loss = 41.3718\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 255/1000: train loss = 30.0877 | val loss = 41.8672\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 256/1000: train loss = 30.8037 | val loss = 41.9242\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 257/1000: train loss = 30.8737 | val loss = 41.8971\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 258/1000: train loss = 30.4983 | val loss = 41.4556\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 259/1000: train loss = 30.1239 | val loss = 43.0029\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 260/1000: train loss = 29.8700 | val loss = 42.5122\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 261/1000: train loss = 28.0499 | val loss = 44.9200\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 262/1000: train loss = 29.9713 | val loss = 43.0047\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 263/1000: train loss = 27.3894 | val loss = 44.4407\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 264/1000: train loss = 27.8061 | val loss = 42.9561\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 265/1000: train loss = 28.0772 | val loss = 42.6906\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 266/1000: train loss = 26.8448 | val loss = 45.2017\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 267/1000: train loss = 28.3615 | val loss = 49.3869\n",
      "11-09-2025 12:35:14 INFO | climatrix.reconstruct.nn.base_nn | Epoch 268/1000: train loss = 30.9210 | val loss = 45.1017\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 269/1000: train loss = 28.5628 | val loss = 47.4606\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 270/1000: train loss = 31.6159 | val loss = 46.0451\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 271/1000: train loss = 29.4249 | val loss = 43.6611\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 272/1000: train loss = 26.2132 | val loss = 49.8485\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 273/1000: train loss = 31.6226 | val loss = 48.8410\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 274/1000: train loss = 30.5503 | val loss = 44.6188\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 275/1000: train loss = 28.8512 | val loss = 47.2439\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 276/1000: train loss = 31.6620 | val loss = 47.7988\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 277/1000: train loss = 30.5021 | val loss = 46.1146\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 278/1000: train loss = 28.7690 | val loss = 46.1369\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 279/1000: train loss = 28.9236 | val loss = 45.3249\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 280/1000: train loss = 27.7316 | val loss = 43.6126\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 281/1000: train loss = 27.7954 | val loss = 43.8641\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 282/1000: train loss = 27.8006 | val loss = 43.8638\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 283/1000: train loss = 27.2185 | val loss = 42.0972\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 284/1000: train loss = 25.4584 | val loss = 42.4748\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 285/1000: train loss = 25.2977 | val loss = 42.6361\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 286/1000: train loss = 25.5283 | val loss = 41.5730\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 287/1000: train loss = 25.2155 | val loss = 42.1200\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 288/1000: train loss = 25.3770 | val loss = 41.2957\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 289/1000: train loss = 25.0433 | val loss = 41.3896\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 290/1000: train loss = 25.6591 | val loss = 41.1370\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 291/1000: train loss = 24.8301 | val loss = 39.0211\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 292/1000: train loss = 24.3385 | val loss = 39.3189\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 293/1000: train loss = 26.3570 | val loss = 40.2575\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 294/1000: train loss = 26.2106 | val loss = 41.1401\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 295/1000: train loss = 25.2637 | val loss = 41.4746\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 296/1000: train loss = 24.5438 | val loss = 40.6742\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 297/1000: train loss = 24.0133 | val loss = 40.6755\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 298/1000: train loss = 23.7729 | val loss = 42.3167\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 299/1000: train loss = 24.5182 | val loss = 42.6355\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 300/1000: train loss = 24.8841 | val loss = 40.2819\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 301/1000: train loss = 23.1416 | val loss = 41.2872\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 302/1000: train loss = 24.1087 | val loss = 39.9556\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 303/1000: train loss = 22.8139 | val loss = 38.2660\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 304/1000: train loss = 23.2436 | val loss = 39.2028\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 305/1000: train loss = 25.0072 | val loss = 36.6221\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 306/1000: train loss = 22.1738 | val loss = 38.5721\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 307/1000: train loss = 23.7606 | val loss = 38.5373\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 308/1000: train loss = 23.2104 | val loss = 38.5453\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 309/1000: train loss = 23.3478 | val loss = 39.3068\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 310/1000: train loss = 23.1959 | val loss = 38.1476\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 311/1000: train loss = 22.2339 | val loss = 38.9478\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 312/1000: train loss = 22.7695 | val loss = 38.8135\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 313/1000: train loss = 22.7323 | val loss = 37.0736\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 314/1000: train loss = 20.8630 | val loss = 38.2017\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 315/1000: train loss = 23.1680 | val loss = 36.7672\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 316/1000: train loss = 22.2467 | val loss = 35.7977\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 317/1000: train loss = 22.0490 | val loss = 36.6915\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 318/1000: train loss = 22.4895 | val loss = 35.6433\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 319/1000: train loss = 20.8295 | val loss = 38.2999\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 320/1000: train loss = 23.4572 | val loss = 38.2609\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 321/1000: train loss = 23.8353 | val loss = 35.8892\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 322/1000: train loss = 21.6169 | val loss = 36.9330\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 323/1000: train loss = 22.7630 | val loss = 38.4089\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 324/1000: train loss = 24.3389 | val loss = 36.5180\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 325/1000: train loss = 22.3241 | val loss = 35.2178\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 326/1000: train loss = 22.1346 | val loss = 37.6682\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 327/1000: train loss = 24.4886 | val loss = 35.5595\n",
      "11-09-2025 12:35:15 INFO | climatrix.reconstruct.nn.base_nn | Epoch 328/1000: train loss = 22.0204 | val loss = 35.6463\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 329/1000: train loss = 22.0001 | val loss = 33.8849\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 330/1000: train loss = 21.0595 | val loss = 34.8463\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 331/1000: train loss = 21.4590 | val loss = 35.2072\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 332/1000: train loss = 21.7959 | val loss = 33.8768\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 333/1000: train loss = 21.0461 | val loss = 32.3954\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 334/1000: train loss = 20.1000 | val loss = 34.6009\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 335/1000: train loss = 22.4482 | val loss = 35.3151\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 336/1000: train loss = 21.7493 | val loss = 35.1883\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 337/1000: train loss = 21.9276 | val loss = 32.4970\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 338/1000: train loss = 19.8567 | val loss = 34.1538\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 339/1000: train loss = 22.4180 | val loss = 34.2480\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 340/1000: train loss = 22.5784 | val loss = 32.6200\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 341/1000: train loss = 19.6625 | val loss = 33.9825\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 342/1000: train loss = 20.8792 | val loss = 33.1900\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 343/1000: train loss = 19.8628 | val loss = 32.7577\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 344/1000: train loss = 20.0626 | val loss = 33.1038\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 345/1000: train loss = 20.0685 | val loss = 31.9499\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 346/1000: train loss = 19.1683 | val loss = 32.9641\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 347/1000: train loss = 20.4126 | val loss = 32.9372\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 348/1000: train loss = 20.4122 | val loss = 32.5915\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 349/1000: train loss = 20.2284 | val loss = 31.6287\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 350/1000: train loss = 19.8423 | val loss = 31.4216\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 351/1000: train loss = 20.3878 | val loss = 31.6930\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 352/1000: train loss = 20.8365 | val loss = 31.0667\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 353/1000: train loss = 19.4860 | val loss = 32.0156\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 354/1000: train loss = 19.5794 | val loss = 33.1785\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 355/1000: train loss = 19.9062 | val loss = 32.2134\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 356/1000: train loss = 19.1174 | val loss = 32.3501\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 357/1000: train loss = 19.3106 | val loss = 32.0498\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 358/1000: train loss = 19.8950 | val loss = 31.3955\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 359/1000: train loss = 19.2872 | val loss = 31.8682\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 360/1000: train loss = 18.9163 | val loss = 32.3586\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 361/1000: train loss = 19.3814 | val loss = 31.4825\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 362/1000: train loss = 18.7571 | val loss = 31.4565\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 363/1000: train loss = 18.9778 | val loss = 30.6966\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 364/1000: train loss = 18.1056 | val loss = 30.7659\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 365/1000: train loss = 18.2574 | val loss = 30.8224\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 366/1000: train loss = 18.2804 | val loss = 31.0146\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 367/1000: train loss = 18.2863 | val loss = 30.5075\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 368/1000: train loss = 17.7332 | val loss = 30.8386\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 369/1000: train loss = 18.2015 | val loss = 30.9850\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 370/1000: train loss = 17.9914 | val loss = 30.8895\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 371/1000: train loss = 17.5570 | val loss = 30.5132\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 372/1000: train loss = 17.3804 | val loss = 30.0743\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 373/1000: train loss = 17.6387 | val loss = 29.8825\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 374/1000: train loss = 17.4920 | val loss = 30.2432\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 375/1000: train loss = 17.4244 | val loss = 30.2906\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 376/1000: train loss = 17.5419 | val loss = 30.2259\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 377/1000: train loss = 17.4734 | val loss = 31.1347\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 378/1000: train loss = 17.9150 | val loss = 30.8757\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 379/1000: train loss = 17.4827 | val loss = 31.3732\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 380/1000: train loss = 17.8119 | val loss = 31.7611\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 381/1000: train loss = 17.8759 | val loss = 30.5755\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 382/1000: train loss = 17.1238 | val loss = 30.3502\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 383/1000: train loss = 17.8103 | val loss = 30.1745\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 384/1000: train loss = 17.8338 | val loss = 29.7332\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 385/1000: train loss = 17.2438 | val loss = 29.9786\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 386/1000: train loss = 17.2753 | val loss = 30.5214\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 387/1000: train loss = 17.3570 | val loss = 30.3229\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 388/1000: train loss = 16.8746 | val loss = 29.7202\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 389/1000: train loss = 16.6912 | val loss = 29.9970\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 390/1000: train loss = 17.3514 | val loss = 29.5805\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 391/1000: train loss = 16.7812 | val loss = 30.3876\n",
      "11-09-2025 12:35:16 INFO | climatrix.reconstruct.nn.base_nn | Epoch 392/1000: train loss = 17.3091 | val loss = 31.1990\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 393/1000: train loss = 17.9246 | val loss = 30.6200\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 394/1000: train loss = 17.3211 | val loss = 29.6779\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 395/1000: train loss = 16.8465 | val loss = 29.7086\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 396/1000: train loss = 17.0153 | val loss = 29.6297\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 397/1000: train loss = 16.7395 | val loss = 29.8593\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 398/1000: train loss = 16.7932 | val loss = 30.7214\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 399/1000: train loss = 17.1929 | val loss = 30.4048\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 400/1000: train loss = 16.8341 | val loss = 29.6380\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 401/1000: train loss = 16.1754 | val loss = 29.7545\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 402/1000: train loss = 16.3557 | val loss = 30.0789\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 403/1000: train loss = 16.4856 | val loss = 29.9246\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 404/1000: train loss = 15.7559 | val loss = 30.2736\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 405/1000: train loss = 16.2670 | val loss = 29.6798\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 406/1000: train loss = 16.0121 | val loss = 29.3058\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 407/1000: train loss = 15.7927 | val loss = 28.6970\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 408/1000: train loss = 15.1791 | val loss = 28.7535\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 409/1000: train loss = 15.3213 | val loss = 29.0079\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 410/1000: train loss = 15.4186 | val loss = 28.7309\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 411/1000: train loss = 15.0214 | val loss = 28.9478\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 412/1000: train loss = 15.2534 | val loss = 29.1775\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 413/1000: train loss = 15.3508 | val loss = 29.6331\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 414/1000: train loss = 15.3232 | val loss = 29.8832\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 415/1000: train loss = 15.5901 | val loss = 29.2135\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 416/1000: train loss = 15.2162 | val loss = 28.7822\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 417/1000: train loss = 15.1134 | val loss = 29.1068\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 418/1000: train loss = 15.4541 | val loss = 28.7096\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 419/1000: train loss = 14.8549 | val loss = 28.9421\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 420/1000: train loss = 14.6171 | val loss = 29.3715\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 421/1000: train loss = 14.8596 | val loss = 29.0242\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 422/1000: train loss = 14.5070 | val loss = 29.1264\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 423/1000: train loss = 14.8422 | val loss = 28.8896\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 424/1000: train loss = 14.9027 | val loss = 28.7153\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 425/1000: train loss = 14.7675 | val loss = 28.8296\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 426/1000: train loss = 14.6122 | val loss = 28.8074\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 427/1000: train loss = 14.4108 | val loss = 28.8840\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 428/1000: train loss = 14.5060 | val loss = 28.6140\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 429/1000: train loss = 14.5196 | val loss = 28.8200\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 430/1000: train loss = 14.6261 | val loss = 28.5385\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 431/1000: train loss = 14.2060 | val loss = 28.4818\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 432/1000: train loss = 13.9933 | val loss = 28.5168\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 433/1000: train loss = 14.0543 | val loss = 28.5019\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 434/1000: train loss = 13.9560 | val loss = 28.9461\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 435/1000: train loss = 14.0646 | val loss = 28.9008\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 436/1000: train loss = 13.9989 | val loss = 29.0270\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 437/1000: train loss = 13.8883 | val loss = 29.4545\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 438/1000: train loss = 14.3255 | val loss = 28.6431\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 439/1000: train loss = 13.8396 | val loss = 28.4434\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 440/1000: train loss = 14.1427 | val loss = 28.1807\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 441/1000: train loss = 13.7834 | val loss = 28.7693\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 442/1000: train loss = 14.3335 | val loss = 28.5168\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 443/1000: train loss = 13.9334 | val loss = 28.3193\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 444/1000: train loss = 14.0467 | val loss = 28.7716\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 445/1000: train loss = 14.3764 | val loss = 29.1760\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 446/1000: train loss = 14.1040 | val loss = 29.0038\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 447/1000: train loss = 13.8464 | val loss = 28.8930\n",
      "11-09-2025 12:35:17 INFO | climatrix.reconstruct.nn.base_nn | Epoch 448/1000: train loss = 13.8827 | val loss = 28.0847\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in &lt;module&gt;:2                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>mmgn_val_dset, mmgn_reconstructed_dset, mmgn_reconstructed_dense = (                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 2 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"font-weight: bold; text-decoration: underline\">run_single_method(</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"font-weight: bold; text-decoration: underline\">dset_idx[IDX],</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"font-weight: bold; text-decoration: underline\">IDX,</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"mmgn\"</span><span style=\"font-weight: bold; text-decoration: underline\">,</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in run_single_method:9                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>DSET_PATH / <span style=\"color: #808000; text-decoration-color: #808000\">f\"ecad_obs_europe_train_{</span>d<span style=\"color: #808000; text-decoration-color: #808000\">}.nc\"</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>).cm                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>val_dset = xr.open_dataset(DSET_PATH / <span style=\"color: #808000; text-decoration-color: #808000\">f\"ecad_obs_europe_val_{</span>d<span style=\"color: #808000; text-decoration-color: #808000\">}.nc\"</span>).cm                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 9 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>reconstructed_dset = <span style=\"font-weight: bold; text-decoration: underline\">train_dset.reconstruct(</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"font-weight: bold; text-decoration: underline\">val_dset.domain,</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"font-weight: bold; text-decoration: underline\">method=method,</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"font-weight: bold; text-decoration: underline\">checkpoint=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"./checkpoint\"</span><span style=\"font-weight: bold; text-decoration: underline\">,</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/src/climatrix/dataset/</span><span style=\"font-weight: bold\">base.py</span>:919 in reconstruct                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 916 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> (                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 917 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>ReconstructionType.get(method)                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 918 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>.value(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, target_domain=target, **recon_kwargs)                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 919 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>.<span style=\"font-weight: bold; text-decoration: underline\">reconstruct()</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 920 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 921 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 922 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># ###############################</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/src/climatrix/decorators/</span><span style=\"font-weight: bold\">runtime.py</span>:31 in wrapper                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Please install them using pip or conda before \"</span>                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"calling '{</span>func.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}()'.\"</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>31 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"font-weight: bold; text-decoration: underline\">func(*args, **kwargs)</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/src/climatrix/reconstruct/mmgn/</span><span style=\"font-weight: bold\">mmgn.py</span>:141 in reconstruct         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@raise_if_not_installed</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"torch\"</span>)                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">reconstruct</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; BaseClimatrixDataset:                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>141 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">super</span><span style=\"font-weight: bold; text-decoration: underline\">().reconstruct()</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/src/climatrix/reconstruct/nn/</span><span style=\"font-weight: bold\">base_nn.py</span>:237 in reconstruct        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">234 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_epochs + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>):                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>nn_model.train()                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">236 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>log.debug(<span style=\"color: #808000; text-decoration-color: #808000\">\"Starting epoch %d/%d...\"</span>, epoch, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_epochs)               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>237 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>train_epoch_loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._single_epoch_pass(</span>                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"font-weight: bold; text-decoration: underline\">data_loader=train_data_loader,</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"font-weight: bold; text-decoration: underline\">nn_model=nn_model,</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"font-weight: bold; text-decoration: underline\">optimizer=optimizer,</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/src/climatrix/reconstruct/nn/</span><span style=\"font-weight: bold\">base_nn.py</span>:178 in _single_epoch_pass <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>optimizer: torch.optim.Optimizer | <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>epoch_loss = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>178 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">for</span><span style=\"font-weight: bold; text-decoration: underline\"> xy, true_z </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold; text-decoration: underline\">in</span><span style=\"font-weight: bold; text-decoration: underline\"> data_loader:</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"font-weight: bold; text-decoration: underline\">xy = xy.to(</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.device)</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"font-weight: bold; text-decoration: underline\">true_z = true_z.to(</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.device)</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"font-weight: bold; text-decoration: underline\">xy = xy.detach().requires_grad_(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">True</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/python3.12/site-packages/torch/utils/data/</span><span style=\"font-weight: bold\">dataloader.py</span>:701 in __next__                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 698 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 699 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 700 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 701 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._next_data()</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 702 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 703 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 704 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/python3.12/site-packages/torch/utils/data/</span><span style=\"font-weight: bold\">dataloader.py</span>:759 in _next_data                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 756 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 757 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 758 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 759 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>data = <span style=\"font-weight: bold; text-decoration: underline\">_utils.pin_memory.pin_memory(data, </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._pin_memory_device)</span>            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 760 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 761 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 762 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/python3.12/site-packages/torch/utils/data/_utils/</span><span style=\"font-weight: bold\">pin_memory.py</span>:90 in pin_memory                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 88 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>pin_memory(sample, device) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> sample <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> data                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 89 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>]  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Backwards compatibility.</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 90 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">isinstance</span><span style=\"font-weight: bold; text-decoration: underline\">(data, collections.abc.Sequence)</span>:                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(data, collections.abc.MutableSequence):                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The sequence type may have extra properties, so we can't just</span>            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in __instancecheck__:117                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in <module>:2                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 1 \u001b[0mmmgn_val_dset, mmgn_reconstructed_dset, mmgn_reconstructed_dense = (                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 2 \u001b[2m   \u001b[0m\u001b[1;4mrun_single_method(\u001b[0m                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;4mdset_idx[IDX],\u001b[0m                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;4mIDX,\u001b[0m                                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mmmgn\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in run_single_method:9                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m      \u001b[0mDSET_PATH / \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mecad_obs_europe_train_\u001b[0m\u001b[33m{\u001b[0md\u001b[33m}\u001b[0m\u001b[33m.nc\u001b[0m\u001b[33m\"\u001b[0m                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m   \u001b[0m).cm                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m   \u001b[0mval_dset = xr.open_dataset(DSET_PATH / \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mecad_obs_europe_val_\u001b[0m\u001b[33m{\u001b[0md\u001b[33m}\u001b[0m\u001b[33m.nc\u001b[0m\u001b[33m\"\u001b[0m).cm                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 9 \u001b[2m   \u001b[0mreconstructed_dset = \u001b[1;4mtrain_dset.reconstruct(\u001b[0m                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;4mval_dset.domain,\u001b[0m                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;4mmethod=method,\u001b[0m                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;4mcheckpoint=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m./checkpoint\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/src/climatrix/dataset/\u001b[0m\u001b[1mbase.py\u001b[0m:919 in reconstruct                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 916 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m (                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 917 \u001b[0m\u001b[2m         \u001b[0mReconstructionType.get(method)                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 918 \u001b[0m\u001b[2m         \u001b[0m.value(\u001b[96mself\u001b[0m, target_domain=target, **recon_kwargs)                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 919 \u001b[2m         \u001b[0m.\u001b[1;4mreconstruct()\u001b[0m                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 920 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 921 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 922 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# ###############################\u001b[0m                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/src/climatrix/decorators/\u001b[0m\u001b[1mruntime.py\u001b[0m:31 in wrapper                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m               \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mPlease install them using pip or conda before \u001b[0m\u001b[33m\"\u001b[0m                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m               \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mcalling \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mfunc.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m()\u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m            \u001b[0m)                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m31 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfunc(*args, **kwargs)\u001b[0m                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m      \u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m34 \u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/src/climatrix/reconstruct/mmgn/\u001b[0m\u001b[1mmmgn.py\u001b[0m:141 in reconstruct         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m   \u001b[0m\u001b[1;95m@raise_if_not_installed\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m)                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mreconstruct\u001b[0m(\u001b[96mself\u001b[0m) -> BaseClimatrixDataset:                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m141 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4;96msuper\u001b[0m\u001b[1;4m().reconstruct()\u001b[0m                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m142 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/src/climatrix/reconstruct/nn/\u001b[0m\u001b[1mbase_nn.py\u001b[0m:237 in reconstruct        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m1\u001b[0m, \u001b[96mself\u001b[0m.num_epochs + \u001b[94m1\u001b[0m):                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m            \u001b[0mnn_model.train()                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m236 \u001b[0m\u001b[2m            \u001b[0mlog.debug(\u001b[33m\"\u001b[0m\u001b[33mStarting epoch \u001b[0m\u001b[33m%d\u001b[0m\u001b[33m/\u001b[0m\u001b[33m%d\u001b[0m\u001b[33m...\u001b[0m\u001b[33m\"\u001b[0m, epoch, \u001b[96mself\u001b[0m.num_epochs)               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m237 \u001b[2m            \u001b[0mtrain_epoch_loss = \u001b[1;4;96mself\u001b[0m\u001b[1;4m._single_epoch_pass(\u001b[0m                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m               \u001b[0m\u001b[1;4mdata_loader=train_data_loader,\u001b[0m                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2m               \u001b[0m\u001b[1;4mnn_model=nn_model,\u001b[0m                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m240 \u001b[0m\u001b[2m               \u001b[0m\u001b[1;4moptimizer=optimizer,\u001b[0m                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/src/climatrix/reconstruct/nn/\u001b[0m\u001b[1mbase_nn.py\u001b[0m:178 in _single_epoch_pass \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m      \u001b[0moptimizer: torch.optim.Optimizer | \u001b[94mNone\u001b[0m = \u001b[94mNone\u001b[0m,                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m   \u001b[0m) -> \u001b[96mfloat\u001b[0m:                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m      \u001b[0mepoch_loss = \u001b[94m0.0\u001b[0m                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m178 \u001b[2m      \u001b[0m\u001b[1;4;94mfor\u001b[0m\u001b[1;4m xy, true_z \u001b[0m\u001b[1;4;95min\u001b[0m\u001b[1;4m data_loader:\u001b[0m                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m         \u001b[0m\u001b[1;4mxy = xy.to(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.device)\u001b[0m                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m         \u001b[0m\u001b[1;4mtrue_z = true_z.to(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.device)\u001b[0m                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m181 \u001b[0m\u001b[2m         \u001b[0m\u001b[1;4mxy = xy.detach().requires_grad_(\u001b[0m\u001b[1;4;94mTrue\u001b[0m\u001b[1;4m)\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/python3.12/site-packages/torch/utils/data/\u001b[0m\u001b[1mdataloader.py\u001b[0m:701 in __next__                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 698 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 699 \u001b[0m\u001b[2m            \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 700 \u001b[0m\u001b[2m            \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 701 \u001b[2m         \u001b[0mdata = \u001b[1;4;96mself\u001b[0m\u001b[1;4m._next_data()\u001b[0m                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 702 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 703 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m (                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 704 \u001b[0m\u001b[2m            \u001b[0m\u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/python3.12/site-packages/torch/utils/data/\u001b[0m\u001b[1mdataloader.py\u001b[0m:759 in _next_data                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 756 \u001b[0m\u001b[2m      \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 757 \u001b[0m\u001b[2m      \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 758 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 759 \u001b[2m         \u001b[0mdata = \u001b[1;4m_utils.pin_memory.pin_memory(data, \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._pin_memory_device)\u001b[0m            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 760 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 761 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 762 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2m/python3.12/site-packages/torch/utils/data/_utils/\u001b[0m\u001b[1mpin_memory.py\u001b[0m:90 in pin_memory                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m [                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 88 \u001b[0m\u001b[2m         \u001b[0mpin_memory(sample, device) \u001b[94mfor\u001b[0m sample \u001b[95min\u001b[0m data                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 89 \u001b[0m\u001b[2m      \u001b[0m]  \u001b[2m# Backwards compatibility.\u001b[0m                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 90 \u001b[2m   \u001b[0m\u001b[94melif\u001b[0m \u001b[1;4;96misinstance\u001b[0m\u001b[1;4m(data, collections.abc.Sequence)\u001b[0m:                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(data, collections.abc.MutableSequence):                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m            \u001b[0m\u001b[2m# The sequence type may have extra properties, so we can't just\u001b[0m            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in __instancecheck__:117                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mmgn_val_dset, mmgn_reconstructed_dset, mmgn_reconstructed_dense = (\n",
    "    run_single_method(\n",
    "        dset_idx[IDX],\n",
    "        IDX,\n",
    "        \"mmgn\",\n",
    "        lr=1.000398223348225,\n",
    "        weight_decay=0.01,\n",
    "        batch_size=1024,\n",
    "        hidden_dim=512,\n",
    "        latent=115,\n",
    "        n_layers=1,\n",
    "        scale=122,\n",
    "        alpha=1.0,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826876b7-c842-4ee7-bc90-64346cce5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.Comparison(mmgn_val_dset, mmgn_reconstructed_dset).compute_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e64ee-7601-41d6-bed0-a942fda810ec",
   "metadata": {},
   "source": [
    "### After optimising hyperpararmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9776e675-5f71-4d76-aa18-74dbc60ec9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Hyperparameter bounds: </span>\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'mse_loss_weight'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eikonal_loss_weight'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'laplace_loss_weight'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.0</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'scale'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_dim'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mHyperparameter bounds: \u001b[0m\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'lr'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1e-05\u001b[0m, \u001b[1;36m10.0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'weight_decay'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0.1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'batch_size'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'mse_loss_weight'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1e-05\u001b[0m, \u001b[1;36m100\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'eikonal_loss_weight'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m0.0\u001b[0m, \u001b[1;36m10.0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'laplace_loss_weight'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m0.0\u001b[0m, \u001b[1;36m10.0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'scale'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m0.01\u001b[0m, \u001b[1;36m100.0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'hidden_dim'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m16\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Using nbr initial points for optimization: </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUsing nbr initial points for optimization: \u001b[0m \u001b[1;36m50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Using iterations for optimization</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUsing iterations for optimization\u001b[0m \u001b[1;36m100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Dataset: </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18850916</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mDataset: \u001b[0m \u001b[1;36m18850916\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BOUNDS = {\n",
    "    \"lr\": (1e-5, 10.0),\n",
    "    \"weight_decay\": (0, 1e-1),\n",
    "    \"batch_size\": (32, 4096),\n",
    "    \"mse_loss_weight\": (1e-5, 100),\n",
    "    \"eikonal_loss_weight\": (0.0, 10.0),\n",
    "    \"laplace_loss_weight\": (0.0, 10.0),\n",
    "    \"scale\": (0.01, 100.0),\n",
    "    \"hidden_dim\": [16, 64, 128, 256],\n",
    "}\n",
    "console.print(\"[bold green]Hyperparameter bounds: [/bold green]\", BOUNDS)\n",
    "\n",
    "OPTIM_INIT_POINTS: int = 50\n",
    "console.print(\n",
    "    \"[bold green]Using nbr initial points for optimization: [/bold green]\",\n",
    "    OPTIM_INIT_POINTS,\n",
    ")\n",
    "\n",
    "OPTIM_N_ITERS: int = 100\n",
    "console.print(\n",
    "    \"[bold green]Using iterations for optimization[/bold green]\", OPTIM_N_ITERS\n",
    ")\n",
    "console.print(\n",
    "    \"[bold green]Dataset: [/bold green]\", dset_idx[IDX]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa250c9-8552-48bf-a6b0-921045731a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparameters(\n",
    "    train_dset: cm.BaseClimatrixDataset,\n",
    "    val_dset: cm.BaseClimatrixDataset,\n",
    "    bounds: dict[str, tuple],\n",
    "    n_init_points: int = 30,\n",
    "    n_iter: int = 200,\n",
    "    seed: int = 0,\n",
    "    verbose: int = 2,\n",
    ") -> tuple[float, dict[str, float]]:\n",
    "    finder = cm.optim.HParamFinder(\n",
    "        \"sinet\",\n",
    "        train_dset,\n",
    "        val_dset,\n",
    "        metric=\"mae\",\n",
    "        n_iters=OPTIM_N_ITERS,\n",
    "        bounds=BOUNDS,\n",
    "        random_seed=SEED,\n",
    "        exclude=[\"num_epochs\"]\n",
    "    )\n",
    "    result = finder.optimize()\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_single_experiment(d: str):\n",
    "    train_dset = xr.open_dataset(\n",
    "        DSET_PATH / f\"ecad_obs_europe_train_{d}.nc\"\n",
    "    ).cm\n",
    "    val_dset = xr.open_dataset(DSET_PATH / f\"ecad_obs_europe_val_{d}.nc\").cm\n",
    "    result = find_hyperparameters(\n",
    "        train_dset,\n",
    "        val_dset,\n",
    "        BOUNDS,\n",
    "        n_init_points=OPTIM_INIT_POINTS,\n",
    "        n_iter=OPTIM_N_ITERS,\n",
    "        seed=SEED,\n",
    "        verbose=2,\n",
    "    )\n",
    "    console.print(\"[bold yellow]Optimized parameters:[/bold yellow]\")\n",
    "    console.print(\n",
    "        \"[yellow]Learning rate (lr):[/yellow]\", result[\"best_params\"][\"lr\"]\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Number of epochs:[/yellow]\",\n",
    "        result[\"best_params\"][\"num_epochs\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Scale:[/yellow]\",\n",
    "        result[\"best_params\"][\"scale\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Batch size:[/yellow]\", result[\"best_params\"][\"batch_size\"]\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]MSE loss weight:[/yellow]\",\n",
    "        result[\"best_params\"][\"mse_loss_weight\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Eikonal loss weight:[/yellow]\",\n",
    "        result[\"best_params\"][\"eikonal_loss_weight\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Laplace loss weight:[/yellow]\",\n",
    "        result[\"best_params\"][\"laplace_loss_weight\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Early stopping patience:[/yellow]\",\n",
    "        result[\"best_params\"][\"patience\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Hidden dimension:[/yellow]\",\n",
    "        result[\"best_params\"][\"hidden_dim\"],\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Weight decay:[/yellow]\",\n",
    "        result[\"best_params\"][\"weight_decay\"],\n",
    "    )    \n",
    "    console.print(\"[yellow]Best loss:[/yellow]\", result[\"best_score\"])\n",
    "    reconstructed_dset = train_dset.reconstruct(\n",
    "        val_dset.domain,\n",
    "        method=\"sinet\",\n",
    "        device=\"cuda\",\n",
    "        lr=result[\"best_params\"][\"lr\"],\n",
    "        weight_decay=result[\"best_params\"][\"weight_decay\"],\n",
    "        num_epochs=result[\"best_params\"][\"num_epochs\"],\n",
    "        batch_size=result[\"best_params\"][\"batch_size\"],\n",
    "        num_workers=0,\n",
    "        scale=result[\"best_params\"][\"scale\"],\n",
    "        mse_loss_weight=result[\"best_params\"][\"mse_loss_weight\"],\n",
    "        eikonal_loss_weight=result[\"best_params\"][\"eikonal_loss_weight\"],\n",
    "        laplace_loss_weight=result[\"best_params\"][\"laplace_loss_weight\"],\n",
    "        patience=result[\"best_params\"][\"patience\"],\n",
    "        hidden_dim=result[\"best_params\"][\"hidden_dim\"],\n",
    "        checkpoint=\"./mmgn_checkpoint.pth\",\n",
    "        overwrite_checkpoint=True,\n",
    "    )\n",
    "    cmp = cm.Comparison(reconstructed_dset, val_dset)\n",
    "    metrics = cmp.compute_report()\n",
    "    metrics[\"dataset_id\"] = d\n",
    "    hyperparams = {\n",
    "        \"dataset_id\": d,\n",
    "        \"lr\": result[\"best_params\"][\"lr\"],\n",
    "        \"num_epochs\": result[\"best_params\"][\"num_epochs\"],\n",
    "        \"scale\": result[\"best_params\"][\"scale\"],\n",
    "        \"batch_size\": result[\"best_params\"][\"batch_size\"],\n",
    "        \"mse_loss_weight\": result[\"best_params\"][\"mse_loss_weight\"],\n",
    "        \"eikonal_loss_weight\": result[\"best_params\"][\"eikonal_loss_weight\"],\n",
    "        \"laplace_loss_weight\": result[\"best_params\"][\"laplace_loss_weight\"],\n",
    "        \"patience\": result[\"best_params\"][\"patience\"],\n",
    "        \"hidden_dim\": result[\"best_params\"][\"hidden_dim\"],\n",
    "        \"weight_decay\":result[\"best_params\"][\"weight_decay\"],\n",
    "        \"opt_loss\": result[\"best_score\"],\n",
    "    }\n",
    "    return (metrics, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8efba9-c84b-4393-929c-1f4ff588c9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-09-2025 16:11:59 INFO | climatrix.optim.bayesian | Starting Bayesian optimization for method 'sinet'\n",
      "10-09-2025 16:11:59 INFO | climatrix.optim.bayesian | Bounds: OrderedDict({'batch_size': (32, 4096, <class 'int'>), 'eikonal_loss_weight': (0.0, 10.0, <class 'float'>), 'hidden_dim': [16, 64, 128, 256], 'laplace_loss_weight': (0.0, 10.0, <class 'float'>), 'lr': (1e-05, 10.0, <class 'float'>), 'mse_loss_weight': (1e-05, 100, <class 'float'>), 'scale': (0.01, 100.0, <class 'float'>), 'weight_decay': (0, 0.1, <class 'float'>)})\n",
      "10-09-2025 16:11:59 INFO | climatrix.optim.bayesian | Using 100 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jakub/projects/climatrix/src/climatrix/optim/bayesian.py:406: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler = optuna.samplers.GPSampler(\n",
      "[I 2025-09-10 16:11:59,498] A new study created in memory with name: sinet_study\n",
      "  0%|                                                                                                             | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-09-2025 16:11:59 INFO | climatrix.optim.bayesian | Suggested parameters for trial 0: {'batch_size': 1727, 'eikonal_loss_weight': 7.203244934421581, 'hidden_dim': 64, 'laplace_loss_weight': 1.862602113776709, 'lr': 3.455613814823207, 'mse_loss_weight': 39.67675345539225, 'scale': 53.886285232995654, 'weight_decay': 0.041919451440329485}\n",
      "10-09-2025 16:11:59 INFO | climatrix.reconstruct.sinet.sinet | Initializing SiNET model...\n",
      "10-09-2025 16:11:59 INFO | climatrix.reconstruct.sinet.sinet | Configuring Adam optimizer with learning rate: 3.455614\n",
      "10-09-2025 16:12:00 INFO | climatrix.reconstruct.nn.base_nn | Training SiNET model...\n",
      "10-09-2025 16:12:00 WARNING | climatrix.reconstruct.nn.base_nn | Validation dataset is not available. Skipping validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/projects/climatrix/experiments/jwalczak/01_Apr_02_compare_recon_method/conf/exp1/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "metrics, hyperparams = run_single_experiment(dset_idx[IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e1d46-9f26-49c0-a497-e49ee9650c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmgn_val_dset, mmgn_reconstructed_dset, mmgn_reconstructed_dense = (\n",
    "    run_single_method(\n",
    "        dset_idx[IDX],\n",
    "        IDX,\n",
    "        \"sinet\",\n",
    "        lr=hyperparams[\"lr\"],\n",
    "        weight_decay=hyperparams[\"weight_decay\"],\n",
    "        num_epochs=hyperparams[\"num_epochs\"],\n",
    "        batch_size=hyperparams[\"batch_size\"],\n",
    "        num_workers=0,\n",
    "        device=\"cuda\",\n",
    "        mse_loss_weight=hyperparams[\"mse_loss_weight\"],\n",
    "        hidden_dim=hyperparams[\"hidden_dim\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9784f-46e9-4b0b-bbb8-5c8e860becb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmgn_reconstructed_dense.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47df248-df07-4468-9657-d70e43ae9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = xr.open_dataset(\n",
    "    DSET_PATH / f\"ecad_obs_europe_train_{dset_idx[IDX]}.nc\"\n",
    ").cm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ab7c8-e2bf-41cd-8118-8de775c1c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmgn_reconstructed_dset.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5e66d-256b-4957-a729-3f0360121454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.Comparison(mmgn_val_dset, mmgn_reconstructed_dset).compute_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f287b6-c29b-4e7a-a6cd-f7f037eaf191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
