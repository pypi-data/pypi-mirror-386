{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b247b8b",
   "metadata": {},
   "source": [
    "### Selected samples Oridnary Kriging validation\n",
    "\n",
    "**Author:** Jakub Walczak, PhD\n",
    "\n",
    "This notebook contains validation of the OK method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8615ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import shutil\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable\n",
    "\n",
    "import xarray as xr\n",
    "from bayes_opt import BayesianOptimization\n",
    "from rich.console import Console\n",
    "\n",
    "import climatrix as cm\n",
    "\n",
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "INF_LOSS = -1e4\n",
    "\n",
    "NAN_POLICY = \"resample\"\n",
    "console.print(\"[bold green]Using NaN policy: [/bold green]\", NAN_POLICY)\n",
    "\n",
    "SEED = 1\n",
    "console.print(\"[bold green]Using seed: [/bold green]\", SEED)\n",
    "\n",
    "DSET_PATH = Path(__session__).parent.parent.joinpath(\"data\")\n",
    "console.print(\"[bold green]Using dataset path: [/bold green]\", DSET_PATH)\n",
    "\n",
    "EUROPE_BOUNDS = {\"north\": 71, \"south\": 36, \"west\": -24, \"east\": 35}\n",
    "EUROPE_DOMAIN = cm.Domain.from_lat_lon(\n",
    "    lat=slice(EUROPE_BOUNDS[\"south\"], EUROPE_BOUNDS[\"north\"], 0.1),\n",
    "    lon=slice(EUROPE_BOUNDS[\"west\"], EUROPE_BOUNDS[\"east\"], 0.1),\n",
    "    kind=\"dense\",\n",
    ")\n",
    "cm.seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a16911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataset_idx() -> list[str]:\n",
    "    return sorted(\n",
    "        list({path.stem.split(\"_\")[-1] for path in DSET_PATH.glob(\"*.nc\")})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe293711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_method(\n",
    "    d: str, i: int, method: str, reconstruct_dense: bool = True, **params\n",
    "):\n",
    "    cm.seed_all(SEED)\n",
    "    train_dset = xr.open_dataset(\n",
    "        DSET_PATH / f\"ecad_obs_europe_train_{d}.nc\"\n",
    "    ).cm\n",
    "    val_dset = xr.open_dataset(DSET_PATH / f\"ecad_obs_europe_val_{d}.nc\").cm\n",
    "    reconstructed_dset = train_dset.reconstruct(\n",
    "        val_dset.domain,\n",
    "        method=method,\n",
    "        **params,\n",
    "    )\n",
    "    if reconstruct_dense:\n",
    "        reconstructed_dense = train_dset.reconstruct(\n",
    "            EUROPE_DOMAIN, method=method, **params\n",
    "        )\n",
    "    return val_dset, reconstructed_dset, reconstructed_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d43dfa-7613-49fa-b3e6-f1e38f9e23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_idx = get_all_dataset_idx()\n",
    "console.print(\n",
    "    f\"[bold green]There is [bold yellow]{len(dset_idx)}[/bold yellow] samples available [/bold green]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703e971-a500-4a61-805c-2d329dea92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9900186-1c3b-4f2d-9299-99fbcc04f1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ok_val_dset, ok_reconstructed_dset, ok_reconstructed_dense = run_single_method(\n",
    "    dset_idx[IDX],\n",
    "    IDX,\n",
    "    \"ok\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826876b7-c842-4ee7-bc90-64346cce5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.Comparison(ok_val_dset, ok_reconstructed_dset).compute_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e64ee-7601-41d6-bed0-a942fda810ec",
   "metadata": {},
   "source": [
    "### After optimising hyperpararmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776e675-5f71-4d76-aa18-74dbc60ec9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDS = {\n",
    "    \"nlags\": (2, 50),\n",
    "    \"anisotropy_scaling\": (1e-5, 5.0),\n",
    "    \"coordinates_type_code\": (\"1\", \"2\"),\n",
    "    \"variogram_model_code\": (\"1\", \"5\"),\n",
    "}\n",
    "console.print(\"[bold green]Hyperparameter bounds: [/bold green]\", BOUNDS)\n",
    "\n",
    "OPTIM_INIT_POINTS: int = 50\n",
    "console.print(\n",
    "    \"[bold green]Using nbr initial points for optimization: [/bold green]\",\n",
    "    OPTIM_INIT_POINTS,\n",
    ")\n",
    "\n",
    "OPTIM_N_ITERS: int = 100\n",
    "console.print(\n",
    "    \"[bold green]Using iterations for optimization[/bold green]\", OPTIM_N_ITERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa250c9-8552-48bf-a6b0-921045731a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_criterion(\n",
    "    train_dset: cm.BaseClimatrixDataset,\n",
    "    val_dset: cm.BaseClimatrixDataset,\n",
    "    **hparams,\n",
    ") -> float:\n",
    "    coordinates_type_code = int(hparams[\"coordinates_type_code\"])\n",
    "    variogram_model_code = int(hparams[\"variogram_model_code\"])\n",
    "    nlags = int(hparams[\"nlags\"])\n",
    "    anisotropy_scaling = float(hparams[\"anisotropy_scaling\"])\n",
    "    coordinates_type = coordinates_type_mapping[coordinates_type_code]\n",
    "    variogram_model = variogram_model_mapping[variogram_model_code]\n",
    "\n",
    "    try:\n",
    "        recon_dset = train_dset.reconstruct(\n",
    "            val_dset.domain,\n",
    "            method=\"ok\",\n",
    "            nlags=int(nlags),\n",
    "            anisotropy_scaling=float(anisotropy_scaling),\n",
    "            coordinates_type=coordinates_type,\n",
    "            variogram_model=variogram_model,\n",
    "            backend=\"vectorized\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        console.print(\n",
    "            f\"[yellow]Error during reconstruction with parameters: \"\n",
    "            f\"{hparams}[/yellow]\"\n",
    "        )\n",
    "        console.print(f\"[yellow]{e}[/yellow]\")\n",
    "        return INF_LOSS\n",
    "    metrics = cm.Comparison(\n",
    "        recon_dset, val_dset, map_nan_from_source=False\n",
    "    ).compute_report()\n",
    "    # NOTE: minus to force maximizing\n",
    "    return -metrics[\"MAE\"]\n",
    "\n",
    "\n",
    "def find_hyperparameters(\n",
    "    train_dset: cm.BaseClimatrixDataset,\n",
    "    val_dset: cm.BaseClimatrixDataset,\n",
    "    func: Callable[\n",
    "        [cm.BaseClimatrixDataset, cm.BaseClimatrixDataset, dict], float\n",
    "    ],\n",
    "    bounds: dict[str, tuple],\n",
    "    n_init_points: int = 30,\n",
    "    n_iter: int = 200,\n",
    "    seed: int = 0,\n",
    "    verbose: int = 2,\n",
    ") -> tuple[float, dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Find hyperparameters using Bayesian Optimization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_dset : cm.BaseClimatrixDataset\n",
    "        Training dataset.\n",
    "    val_dset : cm.BaseClimatrixDataset\n",
    "        Validation dataset.\n",
    "    func : Callable\n",
    "        Function to optimize.\n",
    "        It should take two datasets and a dictionary of hyperparameters,\n",
    "        and return a float score.\n",
    "    bounds : dict[str, tuple]\n",
    "        Dictionary of hyperparameter bounds.\n",
    "        Keys are hyperparameter names, values are tuples (min, max).\n",
    "    n_init_points : int, optional\n",
    "        Number of initial random points to sample, by default 30.\n",
    "    n_iter : int, optional\n",
    "        Number of iterations for optimization, by default 200.\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility, by default 0.\n",
    "    verbose : int, optional\n",
    "        Verbosity level of the optimizer, by default 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, dict[str, float]]\n",
    "        Best score and best hyperparameters found.\n",
    "    \"\"\"\n",
    "    func = partial(func, train_dset=train_dset, val_dset=val_dset)\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=func, pbounds=bounds, random_state=seed, verbose=verbose\n",
    "    )\n",
    "    optimizer.maximize(\n",
    "        init_points=n_init_points,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "    return optimizer.max[\"target\"], (\n",
    "        int(optimizer.max[\"params\"][\"nlags\"]),\n",
    "        float(optimizer.max[\"params\"][\"anisotropy_scaling\"]),\n",
    "        coordinates_type_mapping[\n",
    "            int(optimizer.max[\"params\"][\"coordinates_type_code\"])\n",
    "        ],\n",
    "        variogram_model_mapping[\n",
    "            int(optimizer.max[\"params\"][\"variogram_model_code\"])\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def run_single_experiment(d: str):\n",
    "    cm.seed_all(SEED)\n",
    "    train_dset = xr.open_dataset(\n",
    "        DSET_PATH / f\"ecad_obs_europe_train_{d}.nc\"\n",
    "    ).cm\n",
    "    val_dset = xr.open_dataset(DSET_PATH / f\"ecad_obs_europe_val_{d}.nc\").cm\n",
    "    best_loss, (\n",
    "        nlags,\n",
    "        anisotroty_scaling,\n",
    "        coordinates_type,\n",
    "        variogram_model,\n",
    "    ) = find_hyperparameters(\n",
    "        train_dset,\n",
    "        val_dset,\n",
    "        compute_criterion,\n",
    "        BOUNDS,\n",
    "        n_init_points=OPTIM_INIT_POINTS,\n",
    "        n_iter=OPTIM_N_ITERS,\n",
    "        seed=SEED,\n",
    "        verbose=2,\n",
    "    )\n",
    "    console.print(\"[bold yellow]Optimized parameters:[/bold yellow]\")\n",
    "    console.print(\"[yellow]Number of lags:[/yellow]\", nlags)\n",
    "    console.print(\n",
    "        \"[yellow]Anisotropy scaling factor:[/yellow]\",\n",
    "        anisotroty_scaling,\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Coordinates type:[/yellow]\",\n",
    "        coordinates_type,\n",
    "    )\n",
    "    console.print(\n",
    "        \"[yellow]Variogram model:[/yellow]\",\n",
    "        variogram_model,\n",
    "    )\n",
    "    console.print(\"[yellow]Best loss:[/yellow]\", best_loss)\n",
    "    reconstructed_dset = train_dset.reconstruct(\n",
    "        val_dset.domain,\n",
    "        method=\"ok\",\n",
    "        nlags=nlags,\n",
    "        anisotropy_scaling=anisotroty_scaling,\n",
    "        coordinates_type=coordinates_type,\n",
    "        variogram_model=variogram_model,\n",
    "        backend=\"vectorized\",\n",
    "        pseudo_inv=True,\n",
    "    )\n",
    "    cmp = cm.Comparison(reconstructed_dset, val_dset)\n",
    "    metrics = cmp.compute_report()\n",
    "    hyperparams = {\n",
    "        \"dataset_id\": d,\n",
    "        \"nlags\": nlags,\n",
    "        \"anisotropy_scaling\": anisotroty_scaling,\n",
    "        \"coordinates_type\": coordinates_type,\n",
    "        \"variogram_model\": variogram_model,\n",
    "        \"opt_loss\": best_loss,\n",
    "    }\n",
    "    return (metrics, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8efba9-c84b-4393-929c-1f4ff588c9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics, hyperparams = run_single_experiment(dset_idx[IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a4e41-9e17-40b3-b3c7-6e9f11c12bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.Comparison(ok_val_dset, ok_reconstructed_dset).compute_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9ce04-67ec-4943-8dd6-1643ce72adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab116d-6588-475d-85d3-0a7557f9a16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
