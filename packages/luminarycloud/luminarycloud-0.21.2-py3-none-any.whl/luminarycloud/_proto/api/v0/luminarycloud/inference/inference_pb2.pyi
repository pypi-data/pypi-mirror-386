"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _Status:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _StatusEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Status.ValueType], builtins.type):  # noqa: F821
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    STATUS_PENDING: _Status.ValueType  # 0
    STATUS_SUCCESS: _Status.ValueType  # 1
    STATUS_FAILURE: _Status.ValueType  # 2

class Status(_Status, metaclass=_StatusEnumTypeWrapper): ...

STATUS_PENDING: Status.ValueType  # 0
STATUS_SUCCESS: Status.ValueType  # 1
STATUS_FAILURE: Status.ValueType  # 2
global___Status = Status

class CreateInferenceServiceJobRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODEL_VERSION_ID_FIELD_NUMBER: builtins.int
    STL_URL_FIELD_NUMBER: builtins.int
    SETTINGS_FIELD_NUMBER: builtins.int
    CONDITIONS_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    WRITE_VISUALIZATION_DATA_FIELD_NUMBER: builtins.int
    model_version_id: builtins.str
    """ID of the trained model version to use for inference"""
    stl_url: builtins.str
    settings: builtins.bytes
    """JSON encoded settings, like stencil_size."""
    conditions: builtins.bytes
    """JSON encoded conditions, like alpha, beta, etc."""
    project_id: builtins.str
    write_visualization_data: builtins.bool
    def __init__(
        self,
        *,
        model_version_id: builtins.str = ...,
        stl_url: builtins.str = ...,
        settings: builtins.bytes = ...,
        conditions: builtins.bytes = ...,
        project_id: builtins.str = ...,
        write_visualization_data: builtins.bool = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["conditions", b"conditions", "model_version_id", b"model_version_id", "project_id", b"project_id", "settings", b"settings", "stl_url", b"stl_url", "write_visualization_data", b"write_visualization_data"]) -> None: ...

global___CreateInferenceServiceJobRequest = CreateInferenceServiceJobRequest

class CreateInferenceServiceJobResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    STATUS_FIELD_NUMBER: builtins.int
    RESPONSE_FIELD_NUMBER: builtins.int
    status: global___Status.ValueType
    response: builtins.bytes
    def __init__(
        self,
        *,
        status: global___Status.ValueType = ...,
        response: builtins.bytes | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["_response", b"_response", "response", b"response"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["_response", b"_response", "response", b"response", "status", b"status"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["_response", b"_response"]) -> typing_extensions.Literal["response"] | None: ...

global___CreateInferenceServiceJobResponse = CreateInferenceServiceJobResponse
