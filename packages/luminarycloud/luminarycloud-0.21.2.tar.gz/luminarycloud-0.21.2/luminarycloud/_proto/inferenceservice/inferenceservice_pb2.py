# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: proto/inferenceservice/inferenceservice.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from luminarycloud._proto.base import base_pb2 as proto_dot_base_dot_base__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n-proto/inferenceservice/inferenceservice.proto\x12\x1fluminary.proto.inferenceservice\x1a\x15proto/base/base.proto\"\xaf\x01\n CreateInferenceServiceJobRequest\x12\x18\n\x10model_version_id\x18\x08 \x01(\t\x12\x0f\n\x07stl_url\x18\x02 \x01(\t\x12\x10\n\x08settings\x18\x07 \x01(\x0c\x12\x12\n\nconditions\x18\x03 \x01(\x0c\x12\x12\n\nproject_id\x18\x05 \x01(\t\x12 \n\x18write_visualization_data\x18\x06 \x01(\x08J\x04\x08\x04\x10\x05\"5\n!CreateInferenceServiceJobResponse\x12\x10\n\x08response\x18\x01 \x01(\x0c\"*\n\x1bPingInferenceServiceRequest\x12\x0b\n\x03msg\x18\x01 \x01(\t\"+\n\x1cPingInferenceServiceResponse\x12\x0b\n\x03msg\x18\x01 \x01(\t2\xcd\x02\n\x10InferenceService\x12\xa2\x01\n\x19\x43reateInferenceServiceJob\x12\x41.luminary.proto.inferenceservice.CreateInferenceServiceJobRequest\x1a\x42.luminary.proto.inferenceservice.CreateInferenceServiceJobResponse\x12\x93\x01\n\x14PingInferenceService\x12<.luminary.proto.inferenceservice.PingInferenceServiceRequest\x1a=.luminary.proto.inferenceservice.PingInferenceServiceResponseB/Z-luminarycloud.com/core/proto/inferenceserviceb\x06proto3')



_CREATEINFERENCESERVICEJOBREQUEST = DESCRIPTOR.message_types_by_name['CreateInferenceServiceJobRequest']
_CREATEINFERENCESERVICEJOBRESPONSE = DESCRIPTOR.message_types_by_name['CreateInferenceServiceJobResponse']
_PINGINFERENCESERVICEREQUEST = DESCRIPTOR.message_types_by_name['PingInferenceServiceRequest']
_PINGINFERENCESERVICERESPONSE = DESCRIPTOR.message_types_by_name['PingInferenceServiceResponse']
CreateInferenceServiceJobRequest = _reflection.GeneratedProtocolMessageType('CreateInferenceServiceJobRequest', (_message.Message,), {
  'DESCRIPTOR' : _CREATEINFERENCESERVICEJOBREQUEST,
  '__module__' : 'proto.inferenceservice.inferenceservice_pb2'
  # @@protoc_insertion_point(class_scope:luminary.proto.inferenceservice.CreateInferenceServiceJobRequest)
  })
_sym_db.RegisterMessage(CreateInferenceServiceJobRequest)

CreateInferenceServiceJobResponse = _reflection.GeneratedProtocolMessageType('CreateInferenceServiceJobResponse', (_message.Message,), {
  'DESCRIPTOR' : _CREATEINFERENCESERVICEJOBRESPONSE,
  '__module__' : 'proto.inferenceservice.inferenceservice_pb2'
  # @@protoc_insertion_point(class_scope:luminary.proto.inferenceservice.CreateInferenceServiceJobResponse)
  })
_sym_db.RegisterMessage(CreateInferenceServiceJobResponse)

PingInferenceServiceRequest = _reflection.GeneratedProtocolMessageType('PingInferenceServiceRequest', (_message.Message,), {
  'DESCRIPTOR' : _PINGINFERENCESERVICEREQUEST,
  '__module__' : 'proto.inferenceservice.inferenceservice_pb2'
  # @@protoc_insertion_point(class_scope:luminary.proto.inferenceservice.PingInferenceServiceRequest)
  })
_sym_db.RegisterMessage(PingInferenceServiceRequest)

PingInferenceServiceResponse = _reflection.GeneratedProtocolMessageType('PingInferenceServiceResponse', (_message.Message,), {
  'DESCRIPTOR' : _PINGINFERENCESERVICERESPONSE,
  '__module__' : 'proto.inferenceservice.inferenceservice_pb2'
  # @@protoc_insertion_point(class_scope:luminary.proto.inferenceservice.PingInferenceServiceResponse)
  })
_sym_db.RegisterMessage(PingInferenceServiceResponse)

_INFERENCESERVICE = DESCRIPTOR.services_by_name['InferenceService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'Z-luminarycloud.com/core/proto/inferenceservice'
  _CREATEINFERENCESERVICEJOBREQUEST._serialized_start=106
  _CREATEINFERENCESERVICEJOBREQUEST._serialized_end=281
  _CREATEINFERENCESERVICEJOBRESPONSE._serialized_start=283
  _CREATEINFERENCESERVICEJOBRESPONSE._serialized_end=336
  _PINGINFERENCESERVICEREQUEST._serialized_start=338
  _PINGINFERENCESERVICEREQUEST._serialized_end=380
  _PINGINFERENCESERVICERESPONSE._serialized_start=382
  _PINGINFERENCESERVICERESPONSE._serialized_end=425
  _INFERENCESERVICE._serialized_start=428
  _INFERENCESERVICE._serialized_end=761
# @@protoc_insertion_point(module_scope)
