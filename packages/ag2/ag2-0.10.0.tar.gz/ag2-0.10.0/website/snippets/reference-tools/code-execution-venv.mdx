```python
from autogen import ConversableAgent, LLMConfig, register_function

# Import the environment, working directory, and code execution tool
from autogen.environments import VenvPythonEnvironment, WorkingDirectory
from autogen.tools.experimental import PythonCodeExecutionTool

# Create a new virtual environment using a Python version
# Change this to match a version you have installed
venv = VenvPythonEnvironment(python_version="3.11")

# Create a temporary directory
working_dir = WorkingDirectory.create_tmp()

# Create our code execution tool
python_executor = PythonCodeExecutionTool(
    working_directory=working_dir,
    python_environment=venv,
)

llm_config = LLMConfig(config_list={
    "model": "gpt-5",
    "api_type": "openai",
})

# code_runner has the code execution tool available to execute
code_runner = ConversableAgent(
    name="code_runner",
    system_message="You are a code executor agent, when you don't execute code write the message 'TERMINATE' by itself.",
    human_input_mode="NEVER",
    llm_config=llm_config,
)

# question_agent has the code execution tool available to its LLM
question_agent = ConversableAgent(
    name="question_agent",
    system_message=("You are a developer AI agent. "
        "Send all your code suggestions to the python_executor tool where it will be executed and result returned to you. "
        "Keep refining the code until it works."
    ),
    llm_config=llm_config,
)

# Register the python execution tool with the agents
register_function(
    python_executor,
    caller=question_agent,
    executor=code_runner,
    description="Run Python code",
)

result = code_runner.initiate_chat(
    recipient=question_agent,
    message=("Write a Python program to write a poem to a file. "
             "Follow up with another program to read the poem from the file and print it."
    ),
    max_turns=5,
)

print(f"Result: {result.summary}")
```
