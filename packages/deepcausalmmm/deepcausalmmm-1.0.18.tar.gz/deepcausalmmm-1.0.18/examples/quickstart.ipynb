{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepCausalMMM Quick Start Guide\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adityapt/deepcausalmmm/blob/main/examples/quickstart.ipynb)\n",
        "[![PyPI](https://badge.fury.io/py/deepcausalmmm.svg)](https://pypi.org/project/deepcausalmmm/)\n",
        "\n",
        "Welcome! This notebook demonstrates **DeepCausalMMM** for Marketing Mix Modeling. If Colab throws Numpy Error run this in your local.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. Install DeepCausalMMM\n",
        "2. Generate synthetic MMM data\n",
        "3. Train a model\n",
        "4. Analyze results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install deepcausalmmm -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import deepcausalmmm\n",
        "\n",
        "from deepcausalmmm.core import get_default_config\n",
        "from deepcausalmmm.core.trainer import ModelTrainer\n",
        "from deepcausalmmm.core.data import UnifiedDataPipeline\n",
        "from deepcausalmmm.utils.data_generator import ConfigurableDataGenerator\n",
        "\n",
        "print(f\" DeepCausalMMM v{deepcausalmmm.__version__} loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Synthetic Data\n",
        "\n",
        "Generate realistic MMM data with:\n",
        "- 10 regions (DMAs)\n",
        "- 52 weeks\n",
        "- 5 media channels\n",
        "- 3 control variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get config\n",
        "config = get_default_config()\n",
        "config['n_epochs'] = 200  # Reduce for quick demo\n",
        "config['random_seed'] = 42\n",
        "\n",
        "# Generate data\n",
        "generator = ConfigurableDataGenerator(config)\n",
        "X_media, X_control, y = generator.generate_mmm_dataset(\n",
        "    n_regions=10,\n",
        "    n_weeks=52,\n",
        "    n_media_channels=5,\n",
        "    n_control_channels=3\n",
        ")\n",
        "\n",
        "print(f\" Data generated:\")\n",
        "print(f\"   Media: {X_media.shape}\")\n",
        "print(f\"   Control: {X_control.shape}\")\n",
        "print(f\"   Target: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Split and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize pipeline\n",
        "pipeline = UnifiedDataPipeline(config)\n",
        "\n",
        "# Split into train/holdout\n",
        "train_data, holdout_data = pipeline.temporal_split(X_media, X_control, y)\n",
        "\n",
        "# Process training data\n",
        "train_tensors = pipeline.fit_and_transform_training(train_data)\n",
        "\n",
        "print(f\" Data processed:\")\n",
        "print(f\"   Training: {train_tensors['X_media'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = ModelTrainer(config)\n",
        "\n",
        "# Get dimensions\n",
        "n_media = train_tensors['X_media'].shape[2]\n",
        "n_control = train_tensors['X_control'].shape[2]\n",
        "n_regions = train_tensors['X_media'].shape[0]\n",
        "\n",
        "# Create model\n",
        "model = trainer.create_model(n_media, n_control, n_regions)\n",
        "trainer.create_optimizer_and_scheduler()\n",
        "\n",
        "# Prepare full data for baseline\n",
        "full_data = {'X_media': X_media, 'X_control': X_control, 'y': y}\n",
        "full_tensors = pipeline.fit_and_transform_training(full_data)\n",
        "\n",
        "# Train\n",
        "print(\" Training model...\")\n",
        "results = trainer.train(\n",
        "    train_tensors['X_media'], train_tensors['X_control'],\n",
        "    train_tensors['R'], train_tensors['y'],\n",
        "    y_full_for_baseline=full_tensors['y'],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\" Performance Metrics:\\n\")\n",
        "print(f\"Final Training R²: {results.get('final_train_r2', 0):.4f}\")\n",
        "print(f\"Final Training RMSE: {results.get('final_train_rmse', 0):,.0f}\")\n",
        "print(f\"\\nBest RMSE (log-space): {results.get('best_rmse', float('inf')):.4f}\")\n",
        "\n",
        "# Show holdout metrics if available\n",
        "if 'final_holdout_r2' in results and results['final_holdout_r2'] is not None:\n",
        "    print(f\"\\n Holdout Metrics:\")\n",
        "    print(f\"   R²: {results['final_holdout_r2']:.4f}\")\n",
        "    print(f\"   RMSE: {results['final_holdout_rmse']:,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions\n",
        "model.eval()\n",
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        train_tensors['X_media'],\n",
        "        train_tensors['X_control'],\n",
        "        train_tensors['R']\n",
        "    )\n",
        "    predictions = outputs[0]\n",
        "    media_contrib = outputs[1]\n",
        "\n",
        "print(f\" Predictions: {predictions.shape}\")\n",
        "print(f\" Media contributions: {media_contrib.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Analyze Channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Channel contributions\n",
        "channel_totals = media_contrib.sum(dim=(0, 1)).cpu().numpy()\n",
        "channels = [f\"Channel_{i+1}\" for i in range(len(channel_totals))]\n",
        "\n",
        "contrib_df = pd.DataFrame({\n",
        "    'Channel': channels,\n",
        "    'Contribution': channel_totals,\n",
        "    'Percentage': channel_totals / channel_totals.sum() * 100\n",
        "}).sort_values('Contribution', ascending=False)\n",
        "\n",
        "print(\" Channel Impact:\\n\")\n",
        "print(contrib_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Congratulations!\n",
        "\n",
        "You've successfully:\n",
        "-  Installed DeepCausalMMM\n",
        "-  Generated synthetic data\n",
        "-  Trained a model\n",
        "-  Analyzed channel contributions\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "###  Learn More:\n",
        "- [Documentation](https://deepcausalmmm.readthedocs.io/)\n",
        "- [API Reference](https://deepcausalmmm.readthedocs.io/en/latest/api/)\n",
        "- [GitHub](https://github.com/adityapt/deepcausalmmm)\n",
        "\n",
        "###  Advanced Features:\n",
        "- **Response Curves**: Analyze saturation effects\n",
        "- **DAG Discovery**: Explore causal relationships\n",
        "- **Multi-Region Analysis**: Compare regional performance\n",
        "- **Comprehensive Dashboard**: Interactive visualizations\n",
        "- **Hyperparameter Tuning**: Optimize model performance\n",
        "\n",
        "### Citation:\n",
        "```bibtex\n",
        "@article{tirumala2025deepcausalmmm,\n",
        "  title={DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference},\n",
        "  author={Puttaparthi Tirumala, Aditya},\n",
        "  journal={arXiv preprint arXiv:2510.13087},\n",
        "  year={2025}\n",
        "}\n",
        "```\n",
        "\n",
        "**Happy Modeling/Users/adityapu/Documents/GitHub/deepcausalmmm && grep -n zenodo|version|1.0.17 examples/quickstart.ipynb | head -20*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}