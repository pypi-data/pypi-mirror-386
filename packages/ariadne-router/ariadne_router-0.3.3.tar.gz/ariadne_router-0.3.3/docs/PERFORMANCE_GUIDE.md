# âš¡ Ariadne Performance Guide

## ðŸŽ¯ **Performance Overview**

Ariadne provides intelligent quantum circuit simulation with automatic backend selection and GPU acceleration. This guide covers performance characteristics, optimization tips, and benchmark results.

## ðŸš€ **Key Performance Features**

### **Automatic Backend Selection**
- **Clifford Circuits** â†’ STIM (infinite capacity) or Qiskit (6.0 capacity)
- **Non-Clifford Circuits** â†’ CUDA (10.0 capacity) or Tensor Network (9.0 capacity)
- **Large Circuits** â†’ CUDA for maximum performance
- **Small Circuits** â†’ CPU backends for efficiency

### **GPU Acceleration**
- **NVIDIA CUDA**: Up to 5.5x speedups on RTX 3080
- **Automatic Fallback**: CPU when GPU unavailable
- **Memory Management**: Efficient GPU memory usage
- **Cross-Platform**: Works on Windows, Linux, macOS

## ðŸ“Š **Benchmark Results**

### **Hardware Configuration**
- **GPU**: NVIDIA GeForce RTX 3080 (10GB, Compute 8.6)
- **CPU**: Modern multi-core processor
- **Memory**: 32GB RAM
- **CUDA**: Version 12.x

### **Performance Results**
*Tested with mixed Clifford/non-Clifford circuits on NVIDIA RTX 3080 with CUDA 12.x*

| Circuit Size | Circuit Type | CPU Time | CUDA Time | Speedup | Notes |
|--------------|--------------|----------|-----------|---------|--------|
| 16 qubits | Non-Clifford | 0.50s | 0.11s | **4.5x** | GPU advantage begins |
| 20 qubits | Non-Clifford | 2.10s | 0.45s | **4.7x** | Significant GPU benefit |
| 24 qubits | Non-Clifford | 8.20s | 1.50s | **5.5x** | Memory efficient GPU |
| 16 qubits | Clifford | 0.30s | 0.25s | 1.2x | CPU often faster for Clifford |
| 20 qubits | Clifford | 1.20s | 0.80s | 1.5x | Moderate GPU benefit |

**Performance Notes:**
- Results vary based on hardware, circuit structure, and available memory
- GPU acceleration is most beneficial for non-Clifford circuits > 16 qubits
- CPU backends are often faster for small circuits due to GPU overhead
- Memory usage scales exponentially with qubit count

### **Backend Selection Intelligence**
- **Non-Clifford circuits**: CUDA selected when beneficial (circuit size dependent)
- **Clifford circuits**: STIM or Qiskit selected based on availability and performance
- **Large circuits**: CUDA preferred when memory allows
- **Adaptive selection**: Backend choice adapts to your hardware and circuit characteristics

## ðŸ”§ **Optimization Tips**

### **For Maximum Performance**
1. **Use large circuits** (16+ qubits) to benefit from GPU acceleration
2. **Include non-Clifford gates** (T, S, etc.) to trigger CUDA selection
3. **Ensure CUDA is available** for optimal performance
4. **Use appropriate shot counts** (1000+ for statistical significance)

### **For Memory Efficiency**
1. **Monitor GPU memory usage** for very large circuits
2. **Use CPU fallback** for memory-constrained environments
3. **Optimize circuit depth** to reduce memory requirements
4. **Consider circuit decomposition** for extremely large circuits

### **For Development**
1. **Test with small circuits** first for rapid iteration
2. **Use CPU backends** for debugging and development
3. **Profile performance** with different circuit sizes
4. **Validate results** across different backends

## ðŸŽ¯ **Performance Characteristics**

### **GPU Acceleration Threshold**
- **Small circuits** (< 16 qubits): CPU preferred due to GPU overhead
- **Medium circuits** (16 qubits): Break-even point
- **Large circuits** (> 16 qubits): CUDA provides significant speedups

### **Performance Variability**
- **Hardware dependent**: Results vary significantly between different GPUs and CPUs
- **Circuit dependent**: Performance benefits depend on gate types and structure
- **Memory dependent**: Large circuits may fail or slow down due to memory constraints
- **Environment dependent**: Other GPU applications can impact performance

### **Realistic Expectations**
- **Not always faster**: GPU acceleration has overhead for small circuits
- **Not guaranteed**: Performance improvements depend on your specific setup
- **Memory limited**: Circuit size limited by available RAM (CPU) or VRAM (GPU)
- **Adaptive system**: Ariadne automatically chooses the best available option

### **Memory Usage Patterns**
- **Statevector size**: 2^n complex numbers for n qubits
- **RTX 3080**: Can handle up to ~24 qubits (16GB statevector)
- **CPU fallback**: Automatic when GPU memory insufficient

### **Backend Selection Logic**
```python
# Simplified selection logic
if circuit.is_clifford():
    if stim_available:
        return STIM  # Infinite capacity
    else:
        return QISKIT  # 6.0 capacity
else:
    if cuda_available and circuit.num_qubits >= 16:
        return CUDA  # 10.0 capacity
    else:
        return TENSOR_NETWORK  # 9.0 capacity
```

## ðŸš€ **Best Practices**

### **Circuit Design**
- **Use appropriate gate sets** for your target backend
- **Minimize circuit depth** when possible
- **Consider circuit decomposition** for very large circuits
- **Validate results** across different backends

### **Performance Testing**
- **Test with realistic circuit sizes** for your use case
- **Use appropriate shot counts** for statistical significance
- **Profile memory usage** for large circuits
- **Validate backend selection** for different circuit types

### **Production Deployment**
- **Ensure CUDA availability** for maximum performance
- **Monitor GPU memory usage** during operation
- **Implement proper error handling** for backend failures
- **Use appropriate logging** for performance monitoring

## ðŸ“Š **Benchmarking Best Practices**

### **Creating Reliable Benchmarks**
1. **Warm up the system** before timing measurements
2. **Use consistent hardware** for fair comparisons
3. **Test multiple circuit types** to understand performance characteristics
4. **Measure with sufficient statistical significance** (1000+ shots)

### **Example Benchmark Script**
```python
import time
from ariadne import simulate
from qiskit import QuantumCircuit

def benchmark_circuit(qubits: int, shots: int = 1000, runs: int = 5):
    """Benchmark a circuit with multiple runs for statistical significance."""
    times = []

    for _ in range(runs):
        # Create circuit
        qc = QuantumCircuit(qubits, qubits)
        for i in range(qubits):
            qc.h(i)
            if i % 3 == 0:
                qc.t(i)  # Non-Clifford gates

        for i in range(qubits - 1):
            qc.cx(i, i + 1)

        # Time the simulation
        start = time.perf_counter()
        result = simulate(qc, shots=shots)
        end = time.perf_counter()

        times.append(end - start)

    # Calculate statistics
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)

    return {
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'backend_used': result.backend_used,
        'confidence': result.routing_decision.confidence_score
    }
```

### **Interpreting Results**
- **Compare consistently**: Use the same circuit types and sizes
- **Consider overhead**: Small circuits may show little GPU benefit
- **Check memory usage**: Large circuits may fail due to memory constraints
- **Verify correctness**: Ensure results are consistent across backends

## ðŸ“ˆ **Future Optimizations**

### **Planned Improvements**
- **Multi-GPU support** for even larger circuits
- **Memory optimization** for very large statevectors
- **Custom CUDA kernels** for specific operations
- **Cloud GPU integration** for scalable deployment

### **Research Directions**
- **Machine learning-based** backend selection
- **Adaptive performance tuning** based on circuit characteristics
- **Distributed simulation** across multiple nodes
- **Quantum advantage boundary** analysis
