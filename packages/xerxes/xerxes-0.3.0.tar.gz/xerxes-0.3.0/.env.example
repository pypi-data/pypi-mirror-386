# Xerxes Environment Configuration
# Copy this file to .env and fill in your values

# GCP Vertex AI Configuration (Required)
# Your GCP project ID where Vertex AI is enabled
XERXES_VERTEX_PROJECT_ID=your-gcp-project-id

# GCP region for Vertex AI API calls (Optional, defaults to us-central1)
# XERXES_VERTEX_LOCATION=us-central1

# Vertex AI model to use (Optional, defaults to claude-3-5-sonnet@20240620)
# Available models: claude-3-5-sonnet@20240620, gemini-1.5-pro, gemini-1.5-flash
# XERXES_VERTEX_MODEL=claude-3-5-sonnet@20240620

# LLM Configuration (Optional)
# Maximum tokens for LLM responses (default: 4096)
# XERXES_MAX_TOKENS=4096

# LLM temperature for response generation (default: 0.0, range: 0.0-1.0)
# XERXES_TEMPERATURE=0.0

# Agent Behavior (Optional)
# Auto-execute read-only commands without confirmation (default: true)
# XERXES_AUTO_EXECUTE_READONLY=true

# Require confirmation before executing destructive operations (default: true)
# XERXES_CONFIRM_DESTRUCTIVE=true

# GCP Authentication
# Path to your GCP service account JSON key file
XERXES_GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json
