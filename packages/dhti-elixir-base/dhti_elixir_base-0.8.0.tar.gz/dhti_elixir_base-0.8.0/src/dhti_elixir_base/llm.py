from abc import abstractmethod
from typing import Any, List, Mapping, Optional
import requests
import json
from langchain.llms.base import LLM
from pydantic import Field


class BaseLLM(LLM):

    base_url: Optional[str] = Field(
        None, alias="base_url"
    )  #! Alias is important when inheriting from LLM
    model: Optional[str] = Field(None, alias="model")
    api_key: Optional[str] = Field(None, alias="api_key")
    params: Mapping[str, Any] = Field(default_factory=dict, alias="params")
    timeout: int = 60
    backend: Optional[str] = "dhti"
    temperature: Optional[float] = 0.1
    top_p: Optional[float] = 0.8
    top_k: Optional[int] = 40
    n_batch: Optional[int] = 8
    n_threads: Optional[int] = 4
    n_predict: Optional[int] = 256
    max_output_tokens: Optional[int] = 512
    repeat_last_n: Optional[int] = 64
    repeat_penalty: Optional[float] = 1.18

    def __init__(self, base_url: str, model: str, **kwargs):
        super().__init__(**kwargs)
        self.base_url = base_url
        self.model = model
        self.params = {**self._get_model_default_parameters, **kwargs}

    @property
    def _get_model_default_parameters(self):
        return {
            "max_output_tokens": self.max_output_tokens,
            "n_predict": self.n_predict,
            "top_k": self.top_k,
            "top_p": self.top_p,
            "temperature": self.temperature,
            "n_batch": self.n_batch,
            "repeat_penalty": self.repeat_penalty,
            "repeat_last_n": self.repeat_last_n,
        }

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """
        Get all the identifying parameters
        """
        return {
            "model": self.model,
            "base_url": self.base_url,
            "model_parameters": self._get_model_default_parameters,
        }

    @property
    def _llm_type(self) -> str:
        return "dhti"

    def _prepare_payload(self, prompt: str) -> dict:
        # Basic chat messages wrapper; user prompt placed as single user message
        return {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[Any] = None,
        **kwargs
    ) -> str:
        """
        Args:
            prompt: The prompt to pass into the model.
            stop: A list of strings to stop generation when encountered
            run_manager: Optional run manager for callbacks and tracing

        Returns:
            The string generated by the model
        """

        payload = self._prepare_payload(prompt)
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }
        resp = requests.post(
            self.base_url, headers=headers, json=payload, timeout=self.timeout # type: ignore
        )
        try:
            resp.raise_for_status()
        except Exception as e:
            raise RuntimeError(
                f"API request failed: {e}; status={resp.status_code}; body={resp.text}"
            )

        data = resp.json()
        # Expecting structure like: { "choices": [ { "message": { "role":"assistant","content":"..." } } ] }
        # Adapt this path if the API differs
        if "choices" in data and len(data["choices"]) > 0:
            choice = data["choices"][0]
            # support both "message" and direct "text"
            text = None
            if (
                isinstance(choice, dict)
                and "message" in choice
                and isinstance(choice["message"], dict)
            ):
                text = choice["message"].get("content")
            elif "text" in choice:
                text = choice.get("text")
            if text is not None:
                return text
        # Fallback: return raw JSON string for debugging
        return json.dumps(data)
