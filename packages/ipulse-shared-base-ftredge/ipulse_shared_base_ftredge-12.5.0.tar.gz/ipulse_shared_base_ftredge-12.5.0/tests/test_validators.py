"""
Test script for schema_registry_item_validators.py

Comprehensive tests including the regex field extraction bug fixes.
Tests cover basic functionality and the specific "description" field case
that was causing false positives in constraint validation.
"""

from ipulse_shared_base_ftredge.validators.schema_registry_item_validators import (
    validate_schema_consistency,
    validate_schema_registry_formats_for_all_schemas,
    SchemaConsistencyChecker,
    SchemaFieldExtractor,
    IssueType,
    StorageType
)

def test_basic_functionality():
    """Test basic functionality of the validators"""
    print("üß™ Testing Schema Registry Item Validators")
    print("=" * 50)
    
    # Sample schema data
    sample_schema = {
        'storage_resource': 'DB_BIGQUERY_TABLE',
        'schema_fields_descriptions': {
            'id': {'description': 'Unique identifier'},
            'name': {'description': 'Name field'}
        },
        'schema_cerberus': {
            'id': {'type': 'string', 'required': True},
            'name': {'type': 'string', 'maxlength': 100}
        },
        'schema_bigquery_create_ddl': '''
            CREATE TABLE test_table (
                id STRING NOT NULL,
                name STRING(100)
            )
        '''
    }
    
    # Test single schema validation
    print("üìã Testing single schema validation...")
    is_valid = validate_schema_consistency(sample_schema, "test_schema")
    
    # Test batch validation
    print("\nüìã Testing batch validation...")
    schemas = {
        'test_schema_1': sample_schema,
        'test_schema_2': sample_schema
    }
    
    all_valid = validate_schema_registry_formats_for_all_schemas(schemas)
    
    # Test classes
    print("\nüìã Testing individual classes...")
    checker = SchemaConsistencyChecker()
    issues = checker.check_schema_consistency(sample_schema)
    
    print(f"‚úÖ Single schema valid: {is_valid}")
    print(f"‚úÖ All schemas valid: {all_valid}")
    print(f"‚úÖ Issues found: {sum(len(issue_list) for issue_list in issues.values())}")
    print(f"‚úÖ IssueType enum works: {IssueType.MISSING.value}")
    print(f"‚úÖ StorageType enum works: {StorageType.BIGQUERY_TABLE.value}")
    
    print("\nüéâ All tests passed! The refactored code is working correctly.")


def test_bigquery_field_extraction():
    """Test BigQuery DDL field extraction regex patterns.
    
    This test specifically covers the bug where field names appearing in
    OPTIONS clauses were incorrectly matched as field definitions.
    """
    
    # Test DDL with the problematic pattern that was causing false positives
    test_ddl = """
    CREATE TABLE `project.dataset.specs_charges` (
      charge_specification_id STRING NOT NULL OPTIONS(description='The charge specification ID'),
      name STRING NOT NULL OPTIONS(description='The name of the charge specification'),
      version_description STRING NOT NULL,
      description STRING NOT NULL OPTIONS(description='A full description of what this charge specification contains'),
      status STRING NOT NULL,
      pulse_status STRING NOT NULL,
      charge_type STRING NOT NULL
    )
    """
    
    # Test fields that should be found
    test_fields = [
        'charge_specification_id',
        'name', 
        'version_description',
        'description',  # This was the problematic field
        'status',
        'pulse_status',
        'charge_type'
    ]
    
    print("\nüß™ Testing BigQuery field extraction:")
    for field_name in test_fields:
        field_def = SchemaFieldExtractor.extract_bigquery_field_definition(test_ddl, field_name)
        has_not_null = 'NOT NULL' in field_def if field_def else False
        
        print(f"  {field_name}: NOT NULL: {1 if has_not_null else 0}")
        print(f"    Field definition: {field_def[:80] if field_def else 'None'}...")
        
        # All test fields should have NOT NULL constraint
        assert has_not_null, f"Field {field_name} should have NOT NULL constraint but doesn't"
    
    print("‚úÖ test_bigquery_field_extraction passed - all fields correctly detected as NOT NULL")


def test_field_extraction_edge_cases():
    """Test edge cases for field extraction."""
    
    # Test case 1: Field name appears in OPTIONS but not as actual field
    ddl_with_false_match = """
    CREATE TABLE test (
      id STRING NOT NULL,
      other_field STRING OPTIONS(description='This mentions description but is not the description field')
    )
    """
    
    # Should not find 'description' as a field since it only appears in OPTIONS
    field_def = SchemaFieldExtractor.extract_bigquery_field_definition(ddl_with_false_match, 'description')
    assert field_def is None or field_def.strip() == "", "Should not match field name inside OPTIONS clause"
    
    # Test case 2: Field with complex OPTIONS
    ddl_complex_options = """
    CREATE TABLE test (
      metadata JSON NOT NULL OPTIONS(description='Complex field with nested options', another_option='value')
    )
    """
    
    field_def = SchemaFieldExtractor.extract_bigquery_field_definition(ddl_complex_options, 'metadata')
    has_not_null = 'NOT NULL' in field_def if field_def else False
    assert has_not_null, "Should correctly identify NOT NULL constraint even with complex OPTIONS"
    
    print("‚úÖ test_field_extraction_edge_cases passed")


def test_validate_schema_consistency_mock_data():
    """Test the main validation function with mock data."""
    
    # Mock schema data in the expected format
    mock_schema = {
        'storage_resource': 'DB_BIGQUERY_TABLE',
        'schema_fields_descriptions': {
            'id': {'description': 'Unique identifier'},
            'name': {'description': 'Name field'},
            'description': {'description': 'Description field'}
        },
        'schema_cerberus': {
            'id': {'type': 'string', 'required': True},
            'name': {'type': 'string', 'required': False},
            'description': {'type': 'string', 'required': True}
        },
        'schema_bigquery_create_ddl': '''
            CREATE TABLE test_table (
              id STRING NOT NULL,
              name STRING,
              description STRING NOT NULL
            )
        '''
    }
    
    # Test validation (returns bool)
    is_valid = validate_schema_consistency(mock_schema, "test_table")
    
    print(f"‚úÖ test_validate_schema_consistency_mock_data passed - schema validation returned: {is_valid}")


def test_validate_all_schemas_with_mock():
    """Test batch validation with mock data."""
    
    mock_schema = {
        'storage_resource': 'DB_BIGQUERY_TABLE',
        'schema_fields_descriptions': {'id': {'description': 'ID'}},
        'schema_cerberus': {'id': {'type': 'string', 'required': True}},
        'schema_bigquery_create_ddl': 'CREATE TABLE table1 (id STRING NOT NULL)'
    }
    
    mock_schemas = {
        "table1": mock_schema,
        "table2": mock_schema
    }
    
    # Test batch validation (returns bool)
    all_valid = validate_schema_registry_formats_for_all_schemas(mock_schemas)
    
    print(f"‚úÖ test_validate_all_schemas_with_mock passed - batch validation returned: {all_valid}")

if __name__ == "__main__":
    print("Running comprehensive validator tests...")
    print("=" * 60)
    
    try:
        # Original basic functionality test
        test_basic_functionality()
        
        # New comprehensive tests for the regex fix
        test_bigquery_field_extraction()
        test_field_extraction_edge_cases()
        test_validate_schema_consistency_mock_data()
        test_validate_all_schemas_with_mock()
        
        print("\n" + "=" * 60)
        print("üéâ All comprehensive tests passed!")
        print("‚úÖ The regex field extraction bug has been properly fixed")
        print("‚úÖ Schema validation working correctly for all test cases")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        raise
