
dataset_system_prompt: "You are a helpful AI assistant that solves problems step by step with clear reasoning."

# Topic Tree Configuration
topic_tree:
  topic_prompt: "Customer requests for refund and return scenarios"

  # LLM Settings
  provider: "gemini"
  model: "gemini-2.5-flash-lite"
  temperature: 0.7

  # Tree Structure
  degree: 3
  depth: 2

  # Output
  save_as: "customer-care_topics.jsonl"

# Data Engine Configuration - CoT Free-text
data_engine:
  instructions: "Create clear and engaging mocked customer service scenarios. Where you the user is a customer, and the assistant is a customer service agent"
  # LLM Settings
  provider: "gemini"
  model: "gemini-2.5-flash-lite"
  temperature: 0.3
  max_retries: 3

  # Content generation prompt
  generation_system_prompt: "You are to mock customers as a user and assistants as a customer service agent creating engaging problems: Example: user: I want to return an item I bought last week. assistant: Sure, can you provide the order number?"

# Dataset Assembly Configuration
dataset:
  creation:
    num_steps: 9
    batch_size: 1
    sys_msg: false  # Free-text CoT doesn't use system messages

  save_as: "customer-care_freetext_cot.jsonl"

# Optional: HuggingFace Hub Integration
# huggingface:
#   repository: "username/math-reasoning-freetext-cot"
#   tags:
#     - "mathematics"
#     - "reasoning"
#     - "chain-of-thought"
#     - "freetext"
#     - "deepfabric"