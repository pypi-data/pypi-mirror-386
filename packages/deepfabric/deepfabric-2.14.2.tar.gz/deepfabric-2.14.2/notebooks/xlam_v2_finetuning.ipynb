{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWly-3CW9E95"
   },
   "source": [
    "# XLAM 2.0 Function Calling Fine-tuning\n",
    "\n",
    "Fine-tune Qwen 2.5 Instruct on XLAM 2.0 (APIGen-MT) format dataset for improved function calling.\n",
    "\n",
    "**Model**: Qwen/Qwen2.5-7B-Instruct  \n",
    "**Method**: LoRA with 4-bit quantization  \n",
    "**Framework**: Unsloth for 2x faster training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4ET8Pet9E96"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMNdKll89E97",
    "outputId": "aa4ef5c8-29df-4a35-da76-aa58276db412"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q unsloth\n",
    "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install -q xformers trl peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kmYkGJ7M9E97"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5RNtweX9E97"
   },
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lVAsQ0nt9E97"
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"unsloth/Qwen2.5-7B-Instruct\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "LOAD_IN_4BIT = True\n",
    "\n",
    "# LoRA configuration (from APIGen-MT paper)\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.0\n",
    "TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "\n",
    "# Training configuration\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 10\n",
    "LOGGING_STEPS = 10\n",
    "SAVE_STEPS = 100\n",
    "\n",
    "# Dataset configuration\n",
    "HF_DATASET_REPO = \"alwaysfurther/deepfabric-xlam-tools\"  # Set to your HuggingFace repo, e.g., \"username/xlam-dataset\"\n",
    "#LOCAL_DATASET_PATH = \"xlam_v2_formatted.jsonl\"  # XLAM 2.0 formatted dataset\n",
    "\n",
    "# Output configuration\n",
    "OUTPUT_DIR = \"./xlam_checkpoints\"\n",
    "FINAL_MODEL_NAME = \"/content/xlam-qwen2.5-7b-lora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlW4UUNF9E97"
   },
   "source": [
    "## 3. Load Model with Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210,
     "referenced_widgets": [
      "2974563aedc746f082a9646db7eeef32",
      "84b016b32a2449cf99cd1a3547fe3de5",
      "72152f07ba0a4e5ea06b2a2081e33353",
      "08536b2a45f149528333a6a486bee68c",
      "21861ebf41f246149cb4a3e74662eaca",
      "773196883bc143f4bf84be5f39c7051c",
      "6aa026d2a1534b1cb804fa49df022013",
      "0b659080302c4eee806719aeb7b2e9b6",
      "a207e35795414567ad55d9cefc732840",
      "5728f449f0644b2db909eac0b56d676d",
      "df4480956e8c4e97b4be4d1f1420a556"
     ]
    },
    "id": "NkNAGlA89E97",
    "outputId": "ee531f4e-0b0e-4c73-9c19-5710c6117068"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.10.1: Fast Qwen2 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 4. Max memory: 39.494 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2974563aedc746f082a9646db7eeef32"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model loaded: unsloth/Qwen2.5-7B-Instruct\n",
      "Max sequence length: 2048\n",
      "4-bit quantization: True\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,  # Auto-detect\n",
    "    load_in_4bit=LOAD_IN_4BIT,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {MODEL_NAME}\")\n",
    "print(f\"Max sequence length: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"4-bit quantization: {LOAD_IN_4BIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvoUWmRZ9E97"
   },
   "source": [
    "## 4. Configure LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMKRoKqr9E98",
    "outputId": "b301850a-61e2-4e56-d72e-1ca10a2ef2b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LoRA configured with rank=16, alpha=16\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=TARGET_MODULES,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"LoRA configured with rank={LORA_R}, alpha={LORA_ALPHA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ge468sTN9E98"
   },
   "source": [
    "## 5. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3CKkZPwW9E98",
    "outputId": "964509a8-af9a-4a22-b0af-06d75520f4b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading dataset from HuggingFace: alwaysfurther/deepfabric-xlam-tools\n",
      "Dataset loaded: 4004 samples\n",
      "Dataset format: ['conversations', 'tools', 'system']\n",
      "\n",
      "=== Dataset Stats ===\n",
      "Example turns: 12\n",
      "Function calls in first sample: 1\n",
      "Example: {\"name\": \"process_appointment_cancellation\", \"arguments\": {\"patient_name\": \"Jane...\n"
     ]
    }
   ],
   "source": [
    "# ===================================\n",
    "# 5. Load and Prepare Dataset\n",
    "# ===================================\n",
    "\n",
    "\n",
    "dataset = load_dataset(HF_DATASET_REPO, split=\"train\")\n",
    "print(f\"Dataset loaded: {len(dataset)} samples\")\n",
    "print(f\"Dataset format: {dataset.column_names}\")\n",
    "\n",
    "# Verify XLAM 2.0 format\n",
    "if \"conversations\" not in dataset.column_names:\n",
    "    raise ValueError(\"Expected XLAM 2.0 format with 'conversations' field\")\n",
    "\n",
    "print(f\"\\n=== Dataset Stats ===\")\n",
    "sample = dataset[0]\n",
    "print(f\"Example turns: {len(sample['conversations'])}\")\n",
    "func_calls = [t for t in sample['conversations'] if t.get('from') == 'function_call']\n",
    "print(f\"Function calls in first sample: {len(func_calls)}\")\n",
    "if func_calls:\n",
    "    print(f\"Example: {func_calls[0]['value'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248,
     "referenced_widgets": [
      "77c80278fbdf4927ad2a6813caea8ba4",
      "5c889cee2c9947929f4cafcbe939a1a3",
      "c9452f665bc14a1abfde86480936d2d6",
      "47c7f9bcc984412082fd285fae9712b1",
      "89e941ab6e5f44a48d112dbaecbf13e7",
      "57671556a2c74b4097a8a3994011460f",
      "fc8b42db3b624ac18f66021908fdfd04",
      "973597680e5b435aa1038ddcadc6284a",
      "e9d3d4f4807b4b4daa15b08584a17037",
      "3f6b081bc4e1400e8e687730057938a2",
      "f145e4cc69424c9488f36ab4814585c5"
     ]
    },
    "id": "_QBhMfVp9E98",
    "outputId": "e6523fbb-fa86-465c-9baa-7c7494fc9d1b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Re-loading dataset with tools included...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4004 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77c80278fbdf4927ad2a6813caea8ba4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Dataset re-converted: 4004 samples\n",
      "\n",
      "=== Example with Tools ===\n",
      "<|im_start|>system\n",
      "Dental Appointment Cancellation Policy: Appointments can be cancelled without a fee if at least 24 hours' notice is provided. Cancellations made with less than 24 hours' notice will incur a $50 cancellation fee. Patients must verify their full name and date of birth to initiate a cancellation. The system will confirm the appointment details before processing. Fees are automatically applied to the patient's account upon cancellation.\n",
      "\n",
      "Available tools:\n",
      "[{\"name\": \"get_weather\", \"description\": \"Get current weather conditions for a location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"City name or location (e.g., 'Paris', 'New York')\"}, \"time\": {\"type\": \"string\", \"description\": \"Time period for weather data\"}}, \"required\": [\"location\"]}}, {\"name\": \"get_time\", \"description\": \"Get current time for a timezone\", \"parameters\": {\"type\": \"object\", \"properties\": {\"timezone\": {\"type\": \"string\", \"description\": \"Timezone name (e.g., 'UTC', 'America/New_York')\"}}, \"required\": []}}, {\"name\": \"search_web\", \"description\": \"Search the web for information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query terms\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Maximum number of results to return\"}}, \"required\": [\"query\"]}}, {\"name\": \"get_news\", \"description\": \"Get recent news articles on a topic\", \"parameters\": {\"type\": \"object\", \"properties\": {\"topic\": {\"type\": \"string\", \"d\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Better conversion: Include tools in the system message\n",
    "def xlam_to_chat_template_with_tools(sample):\n",
    "    \"\"\"\n",
    "    Convert XLAM 2.0 to chat template WITH tool definitions.\n",
    "    This teaches the model when to use which tools.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Build system message with domain policy AND tools\n",
    "    system_parts = []\n",
    "\n",
    "    if sample.get(\"system\"):\n",
    "        system_parts.append(sample[\"system\"])\n",
    "\n",
    "    if sample.get(\"tools\"):\n",
    "        system_parts.append(\"\\nAvailable tools:\")\n",
    "        system_parts.append(sample[\"tools\"])\n",
    "\n",
    "    if system_parts:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\\n\".join(system_parts)\n",
    "        })\n",
    "\n",
    "    # Convert conversation turns\n",
    "    role_mapping = {\n",
    "        \"human\": \"user\",\n",
    "        \"gpt\": \"assistant\",\n",
    "        \"function_call\": \"assistant\",\n",
    "        \"observation\": \"user\"\n",
    "    }\n",
    "\n",
    "    for turn in sample[\"conversations\"]:\n",
    "        role = role_mapping.get(turn[\"from\"], \"user\")\n",
    "        messages.append({\n",
    "            \"role\": role,\n",
    "            \"content\": turn[\"value\"]\n",
    "        })\n",
    "\n",
    "    # Apply Qwen chat template\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "\n",
    "    return {\"text\": formatted}\n",
    "\n",
    "# Re-load and convert dataset\n",
    "print(\"Re-loading dataset with tools included...\")\n",
    "dataset = load_dataset(HF_DATASET_REPO, split=\"train\")\n",
    "dataset = dataset.map(xlam_to_chat_template_with_tools, remove_columns=dataset.column_names)\n",
    "\n",
    "print(f\"✓ Dataset re-converted: {len(dataset)} samples\")\n",
    "print(f\"\\n=== Example with Tools ===\")\n",
    "print(dataset[0]['text'][:1500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNPDVomj9E98"
   },
   "source": [
    "## 6. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XD8r7etn9E98",
    "outputId": "520347a9-87ba-4b77-edd4-a01de765725e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training configuration:\n",
      "  Batch size: 2\n",
      "  Gradient accumulation: 4\n",
      "  Effective batch size: 8\n",
      "  Learning rate: 0.0002\n",
      "  Epochs: 3\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=3,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=42,\n",
    "    report_to=\"none\",  # Change to \"wandb\" if you want logging\n",
    ")\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"  Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V9rYp9v9E98"
   },
   "source": [
    "## 7. Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "ef110224ec1e4eaaa28044b83b5bcf99",
      "586fb4b27d3d4690bcfbbf25c8f2a956",
      "a2e04d0243874b46bd1ce65d5270de47",
      "37cef20b37074f7dbc58ecd23017a8fe",
      "1f6c00c87b7b48fdb6c83aa5cf0aaced",
      "b27dc29e9cf8452d8ce208a2a60db440",
      "1faee93812484351af8332c086c7e310",
      "9e3fa75c965146db81eeb823f810d104",
      "0d2b1251bec44313b3e053b4a8a95cb8",
      "cb033ee525904363a7529fe8f1bdb128",
      "b00259dcba774e468623d40d71dddc32"
     ]
    },
    "id": "bs7zwlB89E98",
    "outputId": "3ece216a-7950-4b55-e6ac-19f091403409"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=52):   0%|          | 0/4004 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef110224ec1e4eaaa28044b83b5bcf99"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trainer initialized\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    args=training_args,\n",
    "    packing=False,  # Disable packing for function calling (needs clear boundaries)\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "# VERIFY DATASET BEFORE TRAINING\n",
    "# ========================================\n",
    "print(\"=== PRE-TRAINING VERIFICATION ===\")\n",
    "print(f\"Dataset variable name: 'dataset'\")\n",
    "print(f\"Number of samples: {len(dataset)}\")\n",
    "print(f\"Has 'text' column: {'text' in dataset.column_names}\")\n",
    "\n",
    "# Check first sample\n",
    "sample_text = dataset[0]['text']\n",
    "print(f\"\\nFirst sample length: {len(sample_text)} chars\")\n",
    "\n",
    "# Critical checks\n",
    "if \"Available tools:\" in sample_text:\n",
    "    print(\"✅ Tools ARE included in training data\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Tools NOT included - DO NOT TRAIN YET!\")\n",
    "\n",
    "if '{\"name\":' in sample_text and '\"arguments\":' in sample_text:\n",
    "    print(\"✅ Function call examples ARE present\")\n",
    "else:\n",
    "    print(\"⚠️  Warning: No function calls found in first sample\")\n",
    "\n",
    "print(\"\\n=== First 1500 characters ===\")\n",
    "print(sample_text[:1500])\n",
    "print(\"...\")\n",
    "\n",
    "print(\"\\n=== Ready to train? ===\")\n",
    "if \"Available tools:\" in sample_text:\n",
    "    print(\"YES - proceed with training\")\n",
    "else:\n",
    "    print(\"NO - re-run conversion first!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpW2ax4DBuTE",
    "outputId": "2cd0ffe9-af3e-4ff3-f31b-7228222ee92b"
   },
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== PRE-TRAINING VERIFICATION ===\n",
      "Dataset variable name: 'dataset'\n",
      "Number of samples: 4004\n",
      "Has 'text' column: True\n",
      "\n",
      "First sample length: 5795 chars\n",
      "✅ Tools ARE included in training data\n",
      "✅ Function call examples ARE present\n",
      "\n",
      "=== First 1500 characters ===\n",
      "<|im_start|>system\n",
      "Dental Appointment Cancellation Policy: Appointments can be cancelled without a fee if at least 24 hours' notice is provided. Cancellations made with less than 24 hours' notice will incur a $50 cancellation fee. Patients must verify their full name and date of birth to initiate a cancellation. The system will confirm the appointment details before processing. Fees are automatically applied to the patient's account upon cancellation.\n",
      "\n",
      "Available tools:\n",
      "[{\"name\": \"get_weather\", \"description\": \"Get current weather conditions for a location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"City name or location (e.g., 'Paris', 'New York')\"}, \"time\": {\"type\": \"string\", \"description\": \"Time period for weather data\"}}, \"required\": [\"location\"]}}, {\"name\": \"get_time\", \"description\": \"Get current time for a timezone\", \"parameters\": {\"type\": \"object\", \"properties\": {\"timezone\": {\"type\": \"string\", \"description\": \"Timezone name (e.g., 'UTC', 'America/New_York')\"}}, \"required\": []}}, {\"name\": \"search_web\", \"description\": \"Search the web for information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query terms\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Maximum number of results to return\"}}, \"required\": [\"query\"]}}, {\"name\": \"get_news\", \"description\": \"Get recent news articles on a topic\", \"parameters\": {\"type\": \"object\", \"properties\": {\"topic\": {\"type\": \"string\", \"d\n",
      "...\n",
      "\n",
      "=== Ready to train? ===\n",
      "YES - proceed with training\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NViKiY5W9E98"
   },
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SBm1Zfuu9E98",
    "outputId": "932d7237-7392-4296-deb6-0564a0b6268d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU: NVIDIA A100-SXM4-40GB\n",
      "Memory: 33.594 GB / 39.494 GB reserved\n",
      "\n",
      "Starting training: \n",
      "2025-10-11 16:54:33.195109\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 4,004 | Num Epochs = 3 | Total steps = 378\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 49:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.117900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.088800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.065400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training complete!\n",
      "Peak memory reserved: 33.594 GB (85.061%)\n",
      "Memory used for training: 0.0 GB\n",
      "\\Finished training: \n",
      "2025-10-11 17:44:27.440057\n"
     ]
    }
   ],
   "source": [
    "# Show GPU memory before training\n",
    "import datetime\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU: {gpu_stats.name}\")\n",
    "print(f\"Memory: {start_gpu_memory} GB / {max_memory} GB reserved\")\n",
    "print(\"\\nStarting training: \")\n",
    "print(datetime.datetime.now())\n",
    "# Train\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Show GPU memory after training\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_training = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Peak memory reserved: {used_memory} GB ({used_percentage}%)\")\n",
    "print(f\"Memory used for training: {used_memory_for_training} GB\")\n",
    "print(\"\\Finished training: \")\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRO5pyQy9E98"
   },
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVxqA0sL9E98",
    "outputId": "0aba6782-346c-4639-97b3-f6157fbefc46"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model saved to /content/xlam-qwen2.5-7b-lora\n"
     ]
    }
   ],
   "source": [
    "# Save LoRA adapters locally\n",
    "model.save_pretrained(FINAL_MODEL_NAME)\n",
    "tokenizer.save_pretrained(FINAL_MODEL_NAME)\n",
    "print(f\"Model saved to {FINAL_MODEL_NAME}\")\n",
    "\n",
    "# Optionally push to HuggingFace Hub\n",
    "# model.push_to_hub(\"your-username/xlam-qwen2.5-7b-lora\", token=\"your_token\")\n",
    "# tokenizer.push_to_hub(\"your-username/xlam-qwen2.5-7b-lora\", token=\"your_token\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify the model has LoRA adapters loaded and trained\n",
    "print(\"=== Model Verification ===\")\n",
    "\n",
    "# Check if model has PEFT adapters\n",
    "if hasattr(model, 'peft_config'):\n",
    "    print(\"✅ Model has PEFT adapters loaded\")\n",
    "    print(f\"   Adapter names: {list(model.peft_config.keys())}\")\n",
    "else:\n",
    "    print(\"❌ WARNING: Model doesn't have PEFT adapters!\")\n",
    "\n",
    "# Check if adapters are enabled (not disabled/merged)\n",
    "if hasattr(model, 'active_adapter'):\n",
    "    print(f\"✅ Active adapter: {model.active_adapter}\")\n",
    "else:\n",
    "    print(\"⚠️  Can't detect active adapter\")\n",
    "\n",
    "# Check trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTrainable params: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "\n",
    "if trainable_params > 0:\n",
    "    print(\"✅ Model has trainable parameters (LoRA is active)\")\n",
    "else:\n",
    "    print(\"❌ WARNING: No trainable parameters!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYZa0HAEcOHd",
    "outputId": "c0b27401-c05c-44d8-c82a-6325dc49e859"
   },
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Model Verification ===\n",
      "✅ Model has PEFT adapters loaded\n",
      "   Adapter names: ['default']\n",
      "✅ Active adapter: default\n",
      "\n",
      "Trainable params: 40,370,176 (0.82%)\n",
      "✅ Model has trainable parameters (LoRA is active)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umiyZE7f9E98"
   },
   "source": [
    "## 10. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7rUAEFrT9E98"
   },
   "outputs": [],
   "source": [
    "# Enable inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Test with tools in system message (matching training format)\n",
    "test_tools = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current weather for a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\": \"City name\"},\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "test_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"Weather Service Policy: Provides weather information for any location.\n",
    "\n",
    "Available tools:\n",
    "{json.dumps(test_tools)}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in San Francisco?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate\n",
    "inputs = tokenizer.apply_chat_template(test_messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_new_tokens=128, temperature=0.1, do_sample=True)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Extract just the assistant response\n",
    "if \"<|im_start|>assistant\\n\" in response:\n",
    "    assistant_msg = response.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0].strip()\n",
    "    print(\"=== Assistant Response ===\")\n",
    "    print(assistant_msg)\n",
    "\n",
    "    # Check if it's a function call\n",
    "    if assistant_msg.startswith(\"{\") and '\"name\"' in assistant_msg:\n",
    "        print(\"\\n✓ SUCCESS: Function call generated!\")\n",
    "        try:\n",
    "            call_json = json.loads(assistant_msg)\n",
    "            print(f\"Function: {call_json.get('name')}\")\n",
    "            print(f\"Arguments: {call_json.get('arguments')}\")\n",
    "        except:\n",
    "            print(\"(JSON parsing failed but format looks correct)\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  Still conversational, not a function call\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"=== Training Data Format ===\")\n",
    "print(dataset[0]['text'][:1200])\n",
    "\n",
    "# Check if tools are mentioned anywhere\n",
    "sample_with_func = None\n",
    "for i in range(min(100, len(dataset))):\n",
    "    if 'function_call' in dataset[i]['text']:\n",
    "        sample_with_func = dataset[i]['text']\n",
    "        break\n",
    "\n",
    "if sample_with_func:\n",
    "    print(\"\\n=== Sample with Function Call ===\")\n",
    "    print(sample_with_func[:1500])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdcVogNCbr7k",
    "outputId": "22169bfe-9baf-4f1b-a842-7dca36d47b8e"
   },
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Training Data Format ===\n",
      "<|im_start|>system\n",
      "Dental Appointment Cancellation Policy: Appointments can be cancelled without a fee if at least 24 hours' notice is provided. Cancellations made with less than 24 hours' notice will incur a $50 cancellation fee. Patients must verify their full name and date of birth to initiate a cancellation. The system will confirm the appointment details before processing. Fees are automatically applied to the patient's account upon cancellation.\n",
      "\n",
      "Available tools:\n",
      "[{\"name\": \"get_weather\", \"description\": \"Get current weather conditions for a location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"City name or location (e.g., 'Paris', 'New York')\"}, \"time\": {\"type\": \"string\", \"description\": \"Time period for weather data\"}}, \"required\": [\"location\"]}}, {\"name\": \"get_time\", \"description\": \"Get current time for a timezone\", \"parameters\": {\"type\": \"object\", \"properties\": {\"timezone\": {\"type\": \"string\", \"description\": \"Timezone name (e.g., 'UTC', 'America/New_York')\"}}, \"required\": []}}, {\"name\": \"search_web\", \"description\": \"Search the web for information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"\n",
      "\n",
      "=== Sample with Function Call ===\n",
      "<|im_start|>system\n",
      "Data Cleaning Assistance Policy: The AI agent will assist users in data cleaning tasks by providing information, generating lists, or suggesting methods. For custom stop word list generation, the agent will combine standard, widely recognized stop word lists (e.g., from NLTK, SpaCy) with user-provided domain-specific terms. The agent will confirm the domain and the specific terms to be added. The agent will not perform the actual data cleaning on the user's dataset but will provide the necessary components or guidance. The agent will prioritize using reliable web search results for standard lists and will clearly state the components of the final custom list.\n",
      "\n",
      "Available tools:\n",
      "[{\"name\": \"get_weather\", \"description\": \"Get current weather conditions for a location\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"City name or location (e.g., 'Paris', 'New York')\"}, \"time\": {\"type\": \"string\", \"description\": \"Time period for weather data\"}}, \"required\": [\"location\"]}}, {\"name\": \"get_time\", \"description\": \"Get current time for a timezone\", \"parameters\": {\"type\": \"object\", \"properties\": {\"timezone\": {\"type\": \"string\", \"description\": \"Timezone name (e.g., 'UTC', 'America/New_York')\"}}, \"required\": []}}, {\"name\": \"search_web\", \"description\": \"Search the web for information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query terms\"}, \"limit\": {\"type\": \"integer\", \"de\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Show actual outputs, not just accuracy\n",
    "print(\"=== ACTUAL MODEL OUTPUTS ===\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"Book a flight from NYC to LAX for tomorrow\",\n",
    "        \"expected_tool\": \"book_flight\",\n",
    "        \"tools\": [\n",
    "            {\"name\": \"book_flight\", \"description\": \"Book airline tickets\"},\n",
    "            {\"name\": \"get_weather\", \"description\": \"Get weather info\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the temperature in Paris?\",\n",
    "        \"expected_tool\": \"get_weather\",\n",
    "        \"tools\": [\n",
    "            {\"name\": \"get_weather\", \"description\": \"Get weather info\"},\n",
    "            {\"name\": \"book_hotel\", \"description\": \"Book hotel rooms\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"You are a helpful assistant.\\n\\nAvailable tools:\\n{json.dumps(case['tools'])}\"},\n",
    "        {\"role\": \"user\", \"content\": case['query']}\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(inputs, max_new_tokens=128, temperature=0.1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract assistant response\n",
    "    if \"<|im_start|>assistant\\n\" in response:\n",
    "        assistant_msg = response.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0].strip()\n",
    "    else:\n",
    "        assistant_msg = response.split(\"assistant\\n\")[-1].strip()\n",
    "\n",
    "    print(f\"Test {i}: {case['query']}\")\n",
    "    print(f\"Expected: {case['expected_tool']}\")\n",
    "    print(f\"Output: {assistant_msg[:200]}\")\n",
    "\n",
    "    # Check format\n",
    "    if assistant_msg.startswith(\"{\") and '\"name\"' in assistant_msg:\n",
    "        print(\"✅ Proper function call format\")\n",
    "    else:\n",
    "        print(\"⚠️  Not a function call - conversational response\")\n",
    "    print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4j6O6uMc6kt",
    "outputId": "6e912d9a-7ae0-4a09-e95d-86bd6886506e"
   },
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== ACTUAL MODEL OUTPUTS ===\n",
      "\n",
      "Test 1: Book a flight from NYC to LAX for tomorrow\n",
      "Expected: book_flight\n",
      "Output: I can help with that! To confirm, which airline would you prefer and what time would you like to depart?\n",
      "⚠️  Not a function call - conversational response\n",
      "\n",
      "Test 2: What's the temperature in Paris?\n",
      "Expected: get_weather\n",
      "Output: Let me check the current temperature in Paris for you.\n",
      "⚠️  Not a function call - conversational response\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# Try adding explicit instruction to use tools\n# ========================================\nprint(\"=== TESTING WITH EXPLICIT INSTRUCTION ===\\n\")\n\ntest_messages_instructed = [\n    {\n        \"role\": \"system\",\n        \"content\": f\"\"\"You are a helpful assistant with access to tools.\n\nAvailable tools:\n{json.dumps(test_tools)}\n\nWhen the user's request requires a tool, respond ONLY with a JSON function call in this format:\n{{\"name\": \"tool_name\", \"arguments\": {{\"param\": \"value\"}}}}\"\"\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What's the weather in Paris?\"\n    }\n]\n\ninputs = tokenizer.apply_chat_template(\n    test_messages_instructed,\n    tokenize=True,\n    add_generation_prompt=True,\n    return_tensors=\"pt\"\n).to(\"cuda\")\n\noutputs = model.generate(\n    inputs,\n    max_new_tokens=128,\n    temperature=None,\n    do_sample=False,\n    pad_token_id=tokenizer.pad_token_id\n)\n\nresponse = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True).strip()\n\nprint(f\"Response: {response}\")\nprint()\n\nif response.startswith('{') and '\"name\"' in response:\n    print(\"✅ Explicit instruction helped! Generated function call\")\nelse:\n    print(\"❌ Still conversational even with explicit instruction\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# Test with temperature=0.0 (completely greedy)\n# ========================================\nprint(\"=== TESTING WITH TEMPERATURE 0.0 ===\\n\")\n\ntest_tools = [\n    {\n        \"name\": \"get_weather\",\n        \"description\": \"Get current weather for a location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\"type\": \"string\", \"description\": \"City name\"}\n            },\n            \"required\": [\"location\"]\n        }\n    }\n]\n\ntest_messages = [\n    {\n        \"role\": \"system\",\n        \"content\": f\"You are a helpful assistant.\\n\\nAvailable tools:\\n{json.dumps(test_tools)}\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"What's the weather in Paris?\"\n    }\n]\n\nFastLanguageModel.for_inference(model)\n\ninputs = tokenizer.apply_chat_template(\n    test_messages,\n    tokenize=True,\n    add_generation_prompt=True,\n    return_tensors=\"pt\"\n).to(\"cuda\")\n\n# Completely greedy decoding\noutputs = model.generate(\n    inputs,\n    max_new_tokens=128,\n    temperature=None,  # Greedy\n    do_sample=False,\n    pad_token_id=tokenizer.pad_token_id\n)\n\nresponse = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True).strip()\n\nprint(f\"Response: {response}\")\nprint()\n\nif response.startswith('{') and '\"name\"' in response:\n    print(\"✅ Generated a JSON function call!\")\n    try:\n        parsed = json.loads(response)\n        print(f\"   Function: {parsed.get('name')}\")\n        print(f\"   Arguments: {parsed.get('arguments')}\")\n    except:\n        print(\"   (JSON parsing failed but format looks correct)\")\nelse:\n    print(\"❌ Still conversational, not a function call\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# CRITICAL: Check how function calls appear in training data\n# ========================================\nimport re\n\nprint(\"=== ANALYZING FUNCTION CALL FORMAT ===\\n\")\n\nsamples_with_json_calls = 0\nsamples_with_conversational = 0\n\nfor i in range(min(200, len(dataset))):\n    text = dataset[i]['text']\n    \n    # Find all assistant responses\n    assistant_responses = re.findall(r'<\\|im_start\\|>assistant\\n(.*?)<\\|im_end\\|>', text, re.DOTALL)\n    \n    for response in assistant_responses:\n        response = response.strip()\n        \n        # Check if it's a JSON function call\n        if response.startswith('{') and '\"name\"' in response and '\"arguments\"' in response:\n            samples_with_json_calls += 1\n            \n            # Print first example\n            if samples_with_json_calls == 1:\n                print(\"✓ Found JSON function call example:\")\n                print(\"=\" * 80)\n                print(response[:300])\n                print(\"=\" * 80)\n            break\n        # Check if it's conversational\n        elif len(response) > 10 and not response.startswith('{'):\n            samples_with_conversational += 1\n            break\n\nprint(f\"\\n📊 Analysis of first 200 samples:\")\nprint(f\"  - Samples with JSON function calls: {samples_with_json_calls}\")\nprint(f\"  - Samples with conversational responses: {samples_with_conversational}\")\nprint(f\"  - Ratio: {samples_with_conversational/max(samples_with_json_calls, 1):.1f}x more conversational\")\n\nif samples_with_json_calls == 0:\n    print(\"\\n❌ CRITICAL: No JSON function calls found in training data!\")\n    print(\"This explains why the model doesn't generate them.\")\nelif samples_with_conversational > samples_with_json_calls * 3:\n    print(\"\\n⚠️  WARNING: Much more conversational data than function calls\")\n    print(\"Model is learning conversational responses more strongly\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYwmdy9z9E98"
   },
   "source": [
    "## 11. Evaluation (Optional)\n",
    "\n",
    "Compare fine-tuned model vs base model on function calling accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478,
     "referenced_widgets": [
      "acff6a4f48d5449ca48c125ae5104237",
      "ba842f65be6b4f2c9ab6496817b690fd",
      "9eff94bd56904372aef839f131994600",
      "dea36797855a474d94f22a61d458a7da",
      "bc2f3f059a1b4cf1aaddd9b8ef20a009",
      "b1fb964f8323407f82d2ac95fef196dd",
      "0598813b96d0434586dbb72493370d42",
      "acc3c1560fff46b0b9e5962da9190cbe",
      "5655bf0cd91f4b80a4f117bf65ffb4df",
      "15e8b1271f464793879db4e7c504bb5a",
      "a358fb01ccae43829f9b38929fea2257"
     ]
    },
    "id": "ROIKxQWz9E98",
    "outputId": "9e7811dd-a948-4eb0-e861-21787b3feeb6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Evaluating Fine-tuned Model ===\n",
      "✓ Book a flight from NYC to LAX for tomorrow -> book_flight\n",
      "✓ What's the temperature in Paris? -> get_weather\n",
      "\n",
      "Accuracy: 100.0% (2/2)\n",
      "\n",
      "=== Loading Base Model for Comparison ===\n",
      "==((====))==  Unsloth 2025.10.1: Fast Qwen2 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 4. Max memory: 39.494 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acff6a4f48d5449ca48c125ae5104237"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Evaluating Base Model ===\n",
      "✓ Book a flight from NYC to LAX for tomorrow -> book_flight\n",
      "✓ What's the temperature in Paris? -> get_weather\n",
      "\n",
      "Accuracy: 100.0% (2/2)\n",
      "\n",
      "=== Results ===\n",
      "Base Model Accuracy: 100.0%\n",
      "Fine-tuned Model Accuracy: 100.0%\n",
      "Improvement: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation test cases\n",
    "eval_cases = [\n",
    "    {\n",
    "        \"query\": \"Book a flight from NYC to LAX for tomorrow\",\n",
    "        \"expected_tool\": \"book_flight\",\n",
    "        \"tools\": [\n",
    "            {\"name\": \"book_flight\", \"description\": \"Book airline tickets\"},\n",
    "            {\"name\": \"get_weather\", \"description\": \"Get weather info\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the temperature in Paris?\",\n",
    "        \"expected_tool\": \"get_weather\",\n",
    "        \"tools\": [\n",
    "            {\"name\": \"get_weather\", \"description\": \"Get weather info\"},\n",
    "            {\"name\": \"book_hotel\", \"description\": \"Book hotel rooms\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "def evaluate_tool_calling(model, tokenizer, test_cases):\n",
    "    \"\"\"Evaluate model's tool calling accuracy.\"\"\"\n",
    "    correct = 0\n",
    "    total = len(test_cases)\n",
    "\n",
    "    for case in test_cases:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Available tools:\\n{json.dumps(case['tools'])}\\n\\nUser: {case['query']}\"}\n",
    "        ]\n",
    "\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        outputs = model.generate(inputs, max_new_tokens=128, temperature=0.1)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Check if expected tool is called\n",
    "        if case['expected_tool'] in response:\n",
    "            correct += 1\n",
    "            print(f\"✓ {case['query']} -> {case['expected_tool']}\")\n",
    "        else:\n",
    "            print(f\"✗ {case['query']} -> Expected {case['expected_tool']}, got: {response[:100]}\")\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f\"\\nAccuracy: {accuracy:.1f}% ({correct}/{total})\")\n",
    "    return accuracy\n",
    "\n",
    "# Run evaluation\n",
    "print(\"=== Evaluating Fine-tuned Model ===\")\n",
    "finetuned_accuracy = evaluate_tool_calling(model, tokenizer, eval_cases)\n",
    "\n",
    "# Compare with base model\n",
    "print(\"\\n=== Loading Base Model for Comparison ===\")\n",
    "base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,\n",
    "    load_in_4bit=LOAD_IN_4BIT,\n",
    ")\n",
    "FastLanguageModel.for_inference(base_model)\n",
    "\n",
    "print(\"\\n=== Evaluating Base Model ===\")\n",
    "base_accuracy = evaluate_tool_calling(base_model, base_tokenizer, eval_cases)\n",
    "\n",
    "print(f\"\\n=== Results ===\")\n",
    "print(f\"Base Model Accuracy: {base_accuracy:.1f}%\")\n",
    "print(f\"Fine-tuned Model Accuracy: {finetuned_accuracy:.1f}%\")\n",
    "print(f\"Improvement: {finetuned_accuracy - base_accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI6dJz7v9E99"
   },
   "source": [
    "## 12. Export for Production\n",
    "\n",
    "Merge LoRA weights with base model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192,
     "referenced_widgets": [
      "5c5f8fbac83b473a81d7982a5a51b8c4",
      "4f186a48ed684b808684a1c832b33590",
      "dcf6767baf92451d8c06279f077674c6",
      "5dfa84732cc44ec28dfea5e72c832ab8",
      "4e5ff2613409489eb0098fd542bf2dfa",
      "d387c27c67f4499a8cf408604d55d5f0",
      "b3f7d6f6eb9f4c3399d387a55e31c2e2",
      "89ad189c04a44c4e803de9775ff0bf02",
      "597c846692b04507ac207e60a4a01996",
      "c6fa27f42ee74a01a89f47da1187dcc1",
      "06f97680af734d2f8fd062ec644a4c8a"
     ]
    },
    "id": "p-XXLaBj9E99",
    "outputId": "1448bd2e-af91-4c73-8e26-31f3c706f31f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c5f8fbac83b473a81d7982a5a51b8c4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|██████████| 4/4 [00:00<00:00, 31068.92it/s]\n",
      "Unsloth: Merging weights into 16bit: 100%|██████████| 4/4 [02:36<00:00, 39.00s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Merge process complete. Saved to `/content/xlam-qwen2.5-7b-lora-merged`\n",
      "Merged model saved to /content/xlam-qwen2.5-7b-lora-merged\n"
     ]
    }
   ],
   "source": [
    "# Merge and save full model (larger but faster inference)\n",
    "model.save_pretrained_merged(\n",
    "    f\"{FINAL_MODEL_NAME}-merged\",\n",
    "    tokenizer,\n",
    "    save_method=\"merged_16bit\",  # or \"merged_4bit\" for smaller size\n",
    ")\n",
    "print(f\"Merged model saved to {FINAL_MODEL_NAME}-merged\")\n",
    "\n",
    "# Save in GGUF format for llama.cpp (optional)\n",
    "# model.save_pretrained_gguf(\n",
    "#     f\"{FINAL_MODEL_NAME}-gguf\",\n",
    "#     tokenizer,\n",
    "#     quantization_method=\"q4_k_m\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "name": "xlam_v2_finetuning.ipynb"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2974563aedc746f082a9646db7eeef32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84b016b32a2449cf99cd1a3547fe3de5",
       "IPY_MODEL_72152f07ba0a4e5ea06b2a2081e33353",
       "IPY_MODEL_08536b2a45f149528333a6a486bee68c"
      ],
      "layout": "IPY_MODEL_21861ebf41f246149cb4a3e74662eaca"
     }
    },
    "84b016b32a2449cf99cd1a3547fe3de5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_773196883bc143f4bf84be5f39c7051c",
      "placeholder": "​",
      "style": "IPY_MODEL_6aa026d2a1534b1cb804fa49df022013",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "72152f07ba0a4e5ea06b2a2081e33353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b659080302c4eee806719aeb7b2e9b6",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a207e35795414567ad55d9cefc732840",
      "value": 2
     }
    },
    "08536b2a45f149528333a6a486bee68c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5728f449f0644b2db909eac0b56d676d",
      "placeholder": "​",
      "style": "IPY_MODEL_df4480956e8c4e97b4be4d1f1420a556",
      "value": " 2/2 [00:02&lt;00:00,  1.03s/it]"
     }
    },
    "21861ebf41f246149cb4a3e74662eaca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "773196883bc143f4bf84be5f39c7051c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aa026d2a1534b1cb804fa49df022013": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b659080302c4eee806719aeb7b2e9b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a207e35795414567ad55d9cefc732840": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5728f449f0644b2db909eac0b56d676d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df4480956e8c4e97b4be4d1f1420a556": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77c80278fbdf4927ad2a6813caea8ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c889cee2c9947929f4cafcbe939a1a3",
       "IPY_MODEL_c9452f665bc14a1abfde86480936d2d6",
       "IPY_MODEL_47c7f9bcc984412082fd285fae9712b1"
      ],
      "layout": "IPY_MODEL_89e941ab6e5f44a48d112dbaecbf13e7"
     }
    },
    "5c889cee2c9947929f4cafcbe939a1a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57671556a2c74b4097a8a3994011460f",
      "placeholder": "​",
      "style": "IPY_MODEL_fc8b42db3b624ac18f66021908fdfd04",
      "value": "Map: 100%"
     }
    },
    "c9452f665bc14a1abfde86480936d2d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_973597680e5b435aa1038ddcadc6284a",
      "max": 4004,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9d3d4f4807b4b4daa15b08584a17037",
      "value": 4004
     }
    },
    "47c7f9bcc984412082fd285fae9712b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f6b081bc4e1400e8e687730057938a2",
      "placeholder": "​",
      "style": "IPY_MODEL_f145e4cc69424c9488f36ab4814585c5",
      "value": " 4004/4004 [00:01&lt;00:00, 2948.91 examples/s]"
     }
    },
    "89e941ab6e5f44a48d112dbaecbf13e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57671556a2c74b4097a8a3994011460f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc8b42db3b624ac18f66021908fdfd04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "973597680e5b435aa1038ddcadc6284a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9d3d4f4807b4b4daa15b08584a17037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f6b081bc4e1400e8e687730057938a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f145e4cc69424c9488f36ab4814585c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef110224ec1e4eaaa28044b83b5bcf99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_586fb4b27d3d4690bcfbbf25c8f2a956",
       "IPY_MODEL_a2e04d0243874b46bd1ce65d5270de47",
       "IPY_MODEL_37cef20b37074f7dbc58ecd23017a8fe"
      ],
      "layout": "IPY_MODEL_1f6c00c87b7b48fdb6c83aa5cf0aaced"
     }
    },
    "586fb4b27d3d4690bcfbbf25c8f2a956": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b27dc29e9cf8452d8ce208a2a60db440",
      "placeholder": "​",
      "style": "IPY_MODEL_1faee93812484351af8332c086c7e310",
      "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=52): 100%"
     }
    },
    "a2e04d0243874b46bd1ce65d5270de47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e3fa75c965146db81eeb823f810d104",
      "max": 4004,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d2b1251bec44313b3e053b4a8a95cb8",
      "value": 4004
     }
    },
    "37cef20b37074f7dbc58ecd23017a8fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb033ee525904363a7529fe8f1bdb128",
      "placeholder": "​",
      "style": "IPY_MODEL_b00259dcba774e468623d40d71dddc32",
      "value": " 4004/4004 [00:12&lt;00:00, 656.78 examples/s]"
     }
    },
    "1f6c00c87b7b48fdb6c83aa5cf0aaced": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b27dc29e9cf8452d8ce208a2a60db440": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1faee93812484351af8332c086c7e310": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e3fa75c965146db81eeb823f810d104": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2b1251bec44313b3e053b4a8a95cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb033ee525904363a7529fe8f1bdb128": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b00259dcba774e468623d40d71dddc32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acff6a4f48d5449ca48c125ae5104237": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba842f65be6b4f2c9ab6496817b690fd",
       "IPY_MODEL_9eff94bd56904372aef839f131994600",
       "IPY_MODEL_dea36797855a474d94f22a61d458a7da"
      ],
      "layout": "IPY_MODEL_bc2f3f059a1b4cf1aaddd9b8ef20a009"
     }
    },
    "ba842f65be6b4f2c9ab6496817b690fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1fb964f8323407f82d2ac95fef196dd",
      "placeholder": "​",
      "style": "IPY_MODEL_0598813b96d0434586dbb72493370d42",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "9eff94bd56904372aef839f131994600": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acc3c1560fff46b0b9e5962da9190cbe",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5655bf0cd91f4b80a4f117bf65ffb4df",
      "value": 2
     }
    },
    "dea36797855a474d94f22a61d458a7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15e8b1271f464793879db4e7c504bb5a",
      "placeholder": "​",
      "style": "IPY_MODEL_a358fb01ccae43829f9b38929fea2257",
      "value": " 2/2 [00:02&lt;00:00,  1.01s/it]"
     }
    },
    "bc2f3f059a1b4cf1aaddd9b8ef20a009": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1fb964f8323407f82d2ac95fef196dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0598813b96d0434586dbb72493370d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acc3c1560fff46b0b9e5962da9190cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5655bf0cd91f4b80a4f117bf65ffb4df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15e8b1271f464793879db4e7c504bb5a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a358fb01ccae43829f9b38929fea2257": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c5f8fbac83b473a81d7982a5a51b8c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f186a48ed684b808684a1c832b33590",
       "IPY_MODEL_dcf6767baf92451d8c06279f077674c6",
       "IPY_MODEL_5dfa84732cc44ec28dfea5e72c832ab8"
      ],
      "layout": "IPY_MODEL_4e5ff2613409489eb0098fd542bf2dfa"
     }
    },
    "4f186a48ed684b808684a1c832b33590": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d387c27c67f4499a8cf408604d55d5f0",
      "placeholder": "​",
      "style": "IPY_MODEL_b3f7d6f6eb9f4c3399d387a55e31c2e2",
      "value": "Fetching 1 files: 100%"
     }
    },
    "dcf6767baf92451d8c06279f077674c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89ad189c04a44c4e803de9775ff0bf02",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_597c846692b04507ac207e60a4a01996",
      "value": 1
     }
    },
    "5dfa84732cc44ec28dfea5e72c832ab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6fa27f42ee74a01a89f47da1187dcc1",
      "placeholder": "​",
      "style": "IPY_MODEL_06f97680af734d2f8fd062ec644a4c8a",
      "value": " 1/1 [00:00&lt;00:00, 119.27it/s]"
     }
    },
    "4e5ff2613409489eb0098fd542bf2dfa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d387c27c67f4499a8cf408604d55d5f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3f7d6f6eb9f4c3399d387a55e31c2e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89ad189c04a44c4e803de9775ff0bf02": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "597c846692b04507ac207e60a4a01996": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6fa27f42ee74a01a89f47da1187dcc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06f97680af734d2f8fd062ec644a4c8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}