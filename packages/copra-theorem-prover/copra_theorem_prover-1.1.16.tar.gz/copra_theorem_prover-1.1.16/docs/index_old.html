<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="A Language-Agent Approach To Formal Theorem-Proving"/>
  <meta property="og:description" content="Language agents, which use a large language model (LLM) capable of in-context
  learning to interact with an external environment, have recently emerged as a
  promising approach to control tasks. We present the first language-agent
  approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
  black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
  During the search, the policy can select proof tactics and retrieve lemmas and
  definitions from an external database. Each selected tactic is executed in the
  underlying proof framework, and the execution feedback is used to build the
  prompt for the next policy invocation. The search also tracks selected
  information from its history and uses it to reduce hallucinations and
  unnecessary LLM queries.
    We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks
  from the Compcert project. On these benchmarks, COPRA is significantly better
  than one-shot invocations of GPT-4, as well as state-of-the-art models
  fine-tuned on proof data, at finding correct proofs quickly."/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="A Language-Agent Approach To Formal Theorem-Proving">
  <meta name="twitter:description" content="Language agents, which use a large language model (LLM) capable of in-context
  learning to interact with an external environment, have recently emerged as a
  promising approach to control tasks. We present the first language-agent
  approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
  black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
  During the search, the policy can select proof tactics and retrieve lemmas and
  definitions from an external database. Each selected tactic is executed in the
  underlying proof framework, and the execution feedback is used to build the
  prompt for the next policy invocation. The search also tracks selected
  information from its history and uses it to reduce hallucinations and
  unnecessary LLM queries.
    We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks
  from the Compcert project. On these benchmarks, COPRA is significantly better
  than one-shot invocations of GPT-4, as well as state-of-the-art models
  fine-tuned on proof data, at finding correct proofs quickly.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content=" theorem proving, formal methods, large language models, agents">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>A Language-Agent Approach To Formal Theorem-Proving</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">A Language-Agent Approach To Formal Theorem-Proving</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://amit9oct.github.io/aboutme/" target="_blank">Amitayush Thakur</a>,</span>
                <span class="author-block">
                  <a href="https://ywen666.github.io/" target="_blank">Yeming Wen</a>,</span>
                  <span class="author-block">
                    <a href="https://www.cs.utexas.edu/~swarat/" target="_blank">Swarat Chaudhuri</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Texas at Austin<!--<br>Conferance name and year--></span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Later change with Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/trishullab/copra" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2310.04353" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Language agents, which use a large language model (LLM) capable of in-context
            learning to interact with an external environment, have recently emerged as a
            promising approach to control tasks. We present the first language-agent
            approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
            black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
            During the search, the policy can select proof tactics and retrieve lemmas and
            definitions from an external database. Each selected tactic is executed in the
            underlying proof framework, and the execution feedback is used to build the
            prompt for the next policy invocation. The search also tracks selected
            information from its history and uses it to reduce hallucinations and
            unnecessary LLM queries.
              We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks
            from the Compcert project. On these benchmarks, COPRA is significantly better
            than one-shot invocations of GPT-4, as well as state-of-the-art models
            fine-tuned on proof data, at finding correct proofs quickly.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <center>
          <img src="static/images/copra_overview.png" alt="MY ALT TEXT" width="50%" height="50%"/>
        </center>
        <h2 class="subtitle has-text-centered">
          An overview of COPRA. The system implements a policy that interacts with a proof environment (Coq or Lean). Internally, a COPRA policy consists of an LLM (GPT-4), a stackbased backtracking search, a retrieval mechanism, a dictionary tracking past failures, and a prompt
          serialization protocol that constructs LLM prompts using the stack and environment feedback and parse LLM outputs into actions.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <center>
          <img src="static/images/copra_prompts.png" alt="MY ALT TEXT" width="50%" height="50%"/>
        </center>
        <h2 class="subtitle has-text-centered">
          The prompt serialization protocol. We highlight the different parts of the prompts to show
          how we use the state stack and the textual reward from the environment.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <center>
          <img src="static/images/copra_lean_proofs.png" alt="MY ALT TEXT" width="50%" height="50%"/>
        </center>
        <h2 class="subtitle has-text-centered">
          Some other interesting proofs generated for miniF2F by COPRA. The length of the proofs
          generated shows that interaction with the environment helps in fixing the errors encountered while
          writing long proofs. These long sequences of rewrites are not easy to synthesize without knowing
          the exact verbal reward from the environment which often contains the hint to fix the rewrites.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <center>
        <img src="static/images/copra_coq_proofs.png" alt="MY ALT TEXT" width="50%" height="50%"/>
      </center>
      <h2 class="subtitle has-text-centered">
        Some other interesting proofs generated for CompCert by COPRA. We can see that
        these proofs are long, and often use ‘apply’ tactic which shows that COPRA can effectively use the
        retrieved information to discharge the current proof state.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<!--Add it when announced on arxiv-->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{thakur2023languageagent,
      title={A Language-Agent Approach to Formal Theorem-Proving}, 
      author={Amitayush Thakur and Yeming Wen and Swarat Chaudhuri},
      year={2023},
      eprint={2310.04353},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
