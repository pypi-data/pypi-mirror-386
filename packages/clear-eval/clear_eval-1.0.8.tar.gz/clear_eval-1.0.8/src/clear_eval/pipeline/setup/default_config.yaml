# supported: rits, azure, watsonx, openai
provider: watsonx
provider_defaults:
  openai:
    eval_model_name: gpt-4o
    gen_model_name: gpt-3.5-turbo
    max_workers: 10
  azure:
    eval_model_name: gpt-4o-2024-08-06
    gen_model_name: gpt-4o-mini-2024-07-18
    max_workers: 20
  watsonx:
    gen_model_name: ibm/granite-3-3-8b-instruct
    eval_model_name: meta-llama/llama-3-3-70b-instruct
    max_workers: 5
  rits:
    gen_model_name: ibm-granite/granite-3.3-8b-instruct
    eval_model_name: meta-llama/llama-3-3-70b-instruct
    max_workers: 20


# unique run_ identifier (to appear in file name)
run_name: null

# whether to perform generation or take existing ones from data
perform_generation: true

# full path to cinput sv
data_path:  "gsm8k/gsm8k_default_predictions.csv"
#full path to output dr
output_dir: "results/gsm8k/sample_output/"

max_examples_to_analyze: null # for debugging

high_score_threshold: 0.91
# whether to use reference in the evaluations.
is_reference_based: false

#use cached results if available
resume_enabled: true

# dict {criteria_name: criteria_desc}, specific
evaluation_criteria: null

use_general_prompt: true
perform_clustering: true

#general, rag, math
task: general

question_column: question
model_output_column: response
reference_column: ground_truth # required when is_reference_based is true
model_input_column: model_input # optional
qid_column: id # optional
documents_column: documents # required for rag

use_full_text_for_analysis: false
#max_workers: 20
max_shortcomings: 15
min_shortcomings: 3
max_eval_text_for_synthesis: 1000

