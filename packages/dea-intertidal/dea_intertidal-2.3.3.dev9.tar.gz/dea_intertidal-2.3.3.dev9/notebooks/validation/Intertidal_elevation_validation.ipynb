{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d59afff-387d-456b-a791-35c3b64996d7",
   "metadata": {},
   "source": [
    "# DEA Intertidal Elevation validation\n",
    "\n",
    "This notebook calculates validation statistics for DEA Intertidal Elevation by comparing elevation values against external validation LiDAR and multibeam datasets.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** This is an experimental notebook containing preliminary validation results. These results will be updated upon publication of the DEA Intertidal Elevation scientific paper.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181531a0-1f9a-4380-a477-871790d847b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120fbe6c-7e77-42e7-b94e-ffe3b98adfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r dev-requirements.in --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f3279-b557-49d1-8d5d-9962776f6182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.errors import RasterioIOError\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datacube\n",
    "import odc.geo.xr\n",
    "from dea_tools.dask import create_local_dask_cluster\n",
    "from dea_tools.datahandling import load_reproject\n",
    "from dea_tools.spatial import xr_interpolate\n",
    "from dea_tools.validation import eval_metrics\n",
    "from odc.geo.geom import Geometry\n",
    "\n",
    "from intertidal.validation import preprocess_validation\n",
    "\n",
    "\n",
    "def add_substrate(gdf_lines, gdf_poly):\n",
    "    substrate_dict = {\n",
    "        \"Sandy beach undiff\": \"Sandy beach\",\n",
    "        \"Unclassified\": \"Other\",\n",
    "        \"Mixed sandy shore undiff\": \"Sandy beach\",\n",
    "        \"Mixed sand tidal flats undiff\": \"Tidal flats\",\n",
    "        \"Sandy shore undiff\": \"Sandy beach\",\n",
    "        \"Sandy tidal flats\": \"Tidal flats\",\n",
    "        \"Flat boulder deposit (rock) undiff\": \"Rocky\",\n",
    "        \"Pebble/cobble (rock shingle) beach\": \"Rocky\",\n",
    "        \"Sloping hard rock shore\": \"Rocky\",\n",
    "        \"Hard rocky shore platform\": \"Rocky\",\n",
    "        \"Fine-medium sand beach\": \"Sandy beach\",\n",
    "        \"Hard bedrock shore\": \"Rocky\",\n",
    "        \"Tidal sediment flats (inferred from mangroves)\": \"Tidal flats\",\n",
    "        \"Tidal flats (sediment undiff)\": \"Tidal flats\",\n",
    "        \"Rocky shore platform (undiff)\": \"Rocky\",\n",
    "        \"Sloping rocky shore (undiff)\": \"Rocky\",\n",
    "        \"Boulder seawall\": \"Rocky\",\n",
    "        \"Mixed sand and shell beach\": \"Sandy beach\",\n",
    "        \"Muddy shore undiff\": \"Tidal flats\",\n",
    "        \"Boulder or shingle-grade shore undiff\": \"Rocky\",\n",
    "        \"Coarse sand beach\": \"Sandy beach\",\n",
    "        \"Muddy tidal flats\": \"Tidal flats\",\n",
    "        \"Sandy-mud tidal flats\": \"Tidal flats\",\n",
    "        \"Soft `bedrockÂ¿ shore platform\": \"Rocky\",\n",
    "        \"Boulder (rock) beach\": \"Rocky\",\n",
    "        \"Sandy beach with cobbles/pebbles (rock)\": \"Rocky\",\n",
    "        \"Boulder/cobble (rock) beach\": \"Rocky\",\n",
    "        \"Flat pebble/cobble deposit (rock) undiff\": \"Rocky\",\n",
    "        \"Hard bedrock shore inferred\": \"Rocky\",\n",
    "    }\n",
    "\n",
    "    # Ensure both GeoDataFrames use the same CRS\n",
    "    gdf_lines = gdf_lines.to_crs(gdf_poly.crs)\n",
    "\n",
    "    # Spatial join: which line features intersect which polygons\n",
    "    joined = gpd.sjoin(gdf_lines, gdf_poly, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Group by polygon index, get most common INTERTD1_V value\n",
    "    most_common = (\n",
    "        joined.groupby(\"index_right\")[\"INTERTD1_V\"]\n",
    "        .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else None)\n",
    "        .rename(\"substrate\")\n",
    "        .map(substrate_dict)\n",
    "    )\n",
    "\n",
    "    # Join back to original polygons\n",
    "    return gdf_poly.join(most_common)\n",
    "\n",
    "\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "client = create_local_dask_cluster(return_client=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe22192-b961-4ba1-bd2b-711c0e485d69",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6f259-5dbf-4552-8bd6-39e9ecb72f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datum transformation geopackage\n",
    "datum_gdf = gpd.read_file(\"/gdata1/data/tide_datums/AHD_to_MSL.gpkg\", engine=\"pyogrio\", use_arrow=True)\n",
    "\n",
    "# Load polygons and set data paths\n",
    "validation_sites_gdf = gpd.read_file(\"data/raw/validation_sites.geojson\")\n",
    "validation_sites_gdf[\"val_path\"] = (\n",
    "    \"/gdata1/projects/coastal/intertidal/Elevation_data/Processed/\" + validation_sites_gdf.year + \"_combined.tif\"\n",
    ")\n",
    "\n",
    "# Load smartline and add as column\n",
    "smartline_gdf = gpd.read_file(\"/gdata1/data/smartline/Smartline.gpkg\", engine=\"pyogrio\", use_arrow=True)\n",
    "validation_sites_gdf = add_substrate(smartline_gdf, validation_sites_gdf)\n",
    "\n",
    "# Set up data paths\n",
    "resampling = \"average\"\n",
    "resolution = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869fd6c-b597-41c0-8f94-3087e009f586",
   "metadata": {},
   "source": [
    "## Run validation analysis for each polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ddc00-c4da-4be0-9361-9ab79d6f90e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for i, row in tqdm(validation_sites_gdf.iterrows(), total=len(validation_sites_gdf.index)):\n",
    "    try:\n",
    "        # Convert to Geometry and create GeoBox to load data into\n",
    "        poly = Geometry(row.geometry, crs=\"EPSG:4326\")\n",
    "        poly_geobox = odc.geo.geobox.GeoBox.from_geopolygon(poly, crs=\"EPSG:3577\", resolution=resolution)\n",
    "\n",
    "        # Obtain tide metadata from intertidal datasets, and summarise\n",
    "        # if multiple datasets are returned per polygon site\n",
    "        dss = dc.find_datasets(\n",
    "            product=\"ga_s2ls_intertidal_cyear_3\",\n",
    "            time=row.year,\n",
    "            like=poly_geobox,\n",
    "        )\n",
    "        tr_vals = [i.metadata.search_fields[\"intertidal_tr\"] for i in dss]\n",
    "        otr_vals = [i.metadata.search_fields[\"intertidal_otr\"] for i in dss]\n",
    "        lat_vals = [i.metadata.search_fields[\"intertidal_lat\"] for i in dss]\n",
    "        hat_vals = [i.metadata.search_fields[\"intertidal_hat\"] for i in dss]\n",
    "        tr = np.max(tr_vals) if tr_vals else np.nan\n",
    "        otr = np.max(otr_vals) if otr_vals else np.nan\n",
    "        lat = np.min(lat_vals) if lat_vals else np.nan\n",
    "        hat = np.max(hat_vals) if hat_vals else np.nan\n",
    "\n",
    "        # Load elevation and uncertainty data from datacube\n",
    "        modelled_ds = (\n",
    "            dc.load(\n",
    "                datasets=dss,\n",
    "                like=poly_geobox,\n",
    "                measurements=[\"elevation\", \"uncertainty\"],\n",
    "                dask_chunks={\"x\": 2048, \"y\": 2048},\n",
    "                resampling=resampling,\n",
    "                driver=\"rio\",\n",
    "            )\n",
    "            .squeeze(\"time\")\n",
    "            .compute()\n",
    "        )\n",
    "        modelled_da = modelled_ds.elevation\n",
    "        uncertainty_da = modelled_ds.uncertainty\n",
    "\n",
    "        # modelled_ds = dc.load(\n",
    "        #             product=\"nidem\",\n",
    "        #             like=poly_geobox,\n",
    "        #             dask_chunks={\"x\": 2048, \"y\": 2048},\n",
    "        #             resampling=resampling,\n",
    "        #         ).squeeze(\"time\").compute()\n",
    "        # modelled_da = modelled_ds.nidem\n",
    "        # uncertainty_da = modelled_ds.nidem\n",
    "\n",
    "        # Skip polygon if no modelled data available\n",
    "        if (~modelled_da.isnull()).sum().item() > 0:\n",
    "            # Mask our data by our input polygon\n",
    "            modelled_da = modelled_da.odc.mask(poly=poly)\n",
    "\n",
    "            # Load validation data into polygon GeoBox\n",
    "            validation_da = load_reproject(path=row.val_path, how=poly_geobox, resampling=resampling).compute()\n",
    "\n",
    "            # Preprocess AHD data\n",
    "            validation_m_ahd, modelled_m, uncertainty_m = preprocess_validation(\n",
    "                validation_da,\n",
    "                modelled_da,\n",
    "                uncertainty_da,\n",
    "                lat=lat,\n",
    "                hat=hat,\n",
    "            )\n",
    "\n",
    "            # Interpolate AHD to MSL correction and apply to data\n",
    "            ahd_to_msl = xr_interpolate(ds=validation_da, gdf=datum_gdf, columns=[\"ahd_to_msl\"]).ahd_to_msl\n",
    "            validation_m_msl = validation_m_ahd + ahd_to_msl.mean().item()\n",
    "\n",
    "            output_df = pd.DataFrame({\n",
    "                \"i\": i,\n",
    "                \"year\": row.year,\n",
    "                \"tr\": tr,\n",
    "                \"otr\": otr,\n",
    "                \"lat\": lat,\n",
    "                \"hat\": hat,\n",
    "                \"validation_m_ahd\": validation_m_ahd,\n",
    "                \"validation_m_msl\": validation_m_msl,\n",
    "                \"modelled_m\": modelled_m,\n",
    "                \"uncertainty_m\": uncertainty_m,\n",
    "                \"substrate\": row.substrate,\n",
    "            })\n",
    "            outputs.append(output_df)\n",
    "\n",
    "    except (KeyError, RasterioIOError, IndexError, AssertionError):\n",
    "        pass\n",
    "\n",
    "# Combine and add additional columns\n",
    "outputs_all_df = pd.concat(outputs)\n",
    "outputs_all_df[\"uncertainty_perc\"] = outputs_all_df.uncertainty_m / outputs_all_df.tr\n",
    "outputs_all_df[\"category\"] = pd.cut(\n",
    "    outputs_all_df.tr,\n",
    "    bins=(0, 2, 4, np.inf),\n",
    "    labels=[\"microtidal\", \"mesotidal\", \"macrotidal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434decaf-9d5b-480d-990b-e9751975ae3e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e2ba5-d4bb-4a03-bc15-59bae95e03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare - heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "lim_min, lim_max = np.nanpercentile(\n",
    "    np.concatenate([outputs_all_df.validation_m_ahd, outputs_all_df.modelled_m]), [1, 99]\n",
    ")\n",
    "lim_min -= 0.5\n",
    "lim_max += 0.5\n",
    "plt.hexbin(\n",
    "    x=outputs_all_df.validation_m_ahd,\n",
    "    y=outputs_all_df.modelled_m,\n",
    "    extent=(lim_min, lim_max, lim_min, lim_max),\n",
    "    cmap=\"inferno\",\n",
    ")\n",
    "plt.gca().set_facecolor(\"#0C0C0C\")\n",
    "plt.plot([lim_min, lim_max], [lim_min, lim_max], \"--\", c=\"white\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.xlabel(\"LiDAR DEM (m AHD)\")\n",
    "plt.ylabel(\"Intertidal DEM (m MSL)\")\n",
    "\n",
    "# Accuracy statistics\n",
    "print(eval_metrics(x=outputs_all_df.validation_m_ahd, y=outputs_all_df.modelled_m, round=3))\n",
    "print(f\"n                   {len(outputs_all_df.modelled_m)}\")\n",
    "print(f\"area                {len(outputs_all_df.modelled_m) * (10 * 10) * 0.000001:.2f} km sq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9dcf73-4a28-4cba-bd4a-97319cece350",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().savefig(\"DEAIntertidal_validation_all_ahd.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271b98c-269e-4a68-84de-3f8b5acc23b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot and compare - heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "lim_min, lim_max = np.nanpercentile(\n",
    "    np.concatenate([outputs_all_df.validation_m_msl, outputs_all_df.modelled_m]), [1, 99]\n",
    ")\n",
    "lim_min -= 0.5\n",
    "lim_max += 0.5\n",
    "plt.hexbin(\n",
    "    x=outputs_all_df.validation_m_msl,\n",
    "    y=outputs_all_df.modelled_m,\n",
    "    extent=(lim_min, lim_max, lim_min, lim_max),\n",
    "    cmap=\"inferno\",\n",
    ")\n",
    "plt.gca().set_facecolor(\"#0C0C0C\")\n",
    "plt.plot([lim_min, lim_max], [lim_min, lim_max], \"--\", c=\"white\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.xlabel(\"LiDAR DEM (m MSL)\")\n",
    "plt.ylabel(\"Intertidal DEM (m MSL)\")\n",
    "\n",
    "# Accuracy statistics\n",
    "print(eval_metrics(x=outputs_all_df.validation_m_msl, y=outputs_all_df.modelled_m, round=3))\n",
    "print(f\"n                   {len(outputs_all_df.modelled_m)}\")\n",
    "print(f\"area                {len(outputs_all_df.modelled_m) * (10 * 10) * 0.000001:.2f} km sq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be4239-6459-4a8d-aa77-f99b28e7148c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.savefig(\"DEAIntertidal_validation_all_msl.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ca6ea-0c42-40c1-9930-5aececcdbe1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Assorted plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558cc44-403e-4eff-bfa1-5acc5e5cd352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs_all_df.groupby(\"year\").apply(lambda x: eval_metrics(x=x.validation_m_msl, y=x.modelled_m, round=3)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20481100-f77e-474d-a235-0d0b626782b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs_all_df.groupby([\"year\", \"category\"]).validation_m_msl.count().unstack(level=-1).plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50add4e-9a6e-4048-aa82-ba3b5146fc49",
   "metadata": {},
   "source": [
    "### By certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab448b-9034-43ce-8b95-71df6939c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_min, lim_max = np.nanpercentile(\n",
    "    np.concatenate([outputs_all_df.validation_m_msl, outputs_all_df.modelled_m]), [1, 99]\n",
    ")\n",
    "lim_min -= 0.1\n",
    "lim_max += 0.1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5.5))\n",
    "\n",
    "# Define a set of certainty ranges\n",
    "cert_ranges = [(0, 0.3), (0.3, 10)]\n",
    "scale_dict = [(-2.0, 1.0), (-2.0, 1.0)]\n",
    "titles = [\"Uncertainty (< Â±0.30 m)\", \"Uncertainty (> Â±0.30 m)\"]\n",
    "\n",
    "out = {}\n",
    "for i, (min_thresh, max_thresh) in enumerate(cert_ranges):\n",
    "    # outputs_subset_df = outputs_all_df.query(\n",
    "    #     \"(uncertainty_perc >= @min_thresh) & (uncertainty_perc < @max_thresh)\"\n",
    "    # )\n",
    "    outputs_subset_df = outputs_all_df.query(\"(uncertainty_m >= @min_thresh) & (uncertainty_m < @max_thresh)\")\n",
    "\n",
    "    lim_min, lim_max = scale_dict[i]\n",
    "\n",
    "    # Plot and compare - heatmap\n",
    "    axes[i].hexbin(\n",
    "        x=outputs_subset_df.validation_m_msl,\n",
    "        y=outputs_subset_df.modelled_m,\n",
    "        extent=(lim_min, lim_max, lim_min, lim_max),\n",
    "        cmap=\"inferno\",\n",
    "        bins=100,\n",
    "        vmin=0,\n",
    "        vmax=50,\n",
    "    )\n",
    "    axes[i].plot([lim_min, lim_max], [lim_min, lim_max], \"--\", c=\"white\")\n",
    "    axes[i].margins(x=0, y=0)\n",
    "    axes[i].set_title(titles[i])\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Intertidal DEM (m MSL)\")\n",
    "    elif i == 1:\n",
    "        axes[i].set_xlabel(\"LiDAR DEM (m MSL)\")\n",
    "\n",
    "    # Accuracy statistics\n",
    "    stats_df = eval_metrics(x=outputs_subset_df.validation_m_msl, y=outputs_subset_df.modelled_m, round=3)\n",
    "    stats_df[\"n\"] = len(outputs_subset_df.modelled_m)\n",
    "    out[titles[i]] = stats_df\n",
    "\n",
    "pd.DataFrame.from_records(\n",
    "    out,\n",
    "    index=[\"n\", \"Correlation\", \"R-squared\", \"RMSE\", \"MAE\", \"Bias\"],\n",
    "    columns=titles,\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5062fc6-723f-4acd-a468-db192662c32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"DEAIntertidal_validation_uncertainty.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424b960-373b-4bff-bc96-41e743d173ff",
   "metadata": {},
   "source": [
    "### By tide range class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd828165-45c3-4fa7-a3ec-6b8239d6177e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3.6))\n",
    "\n",
    "# Define a set of certainty ranges\n",
    "cat_ranges = [\"microtidal\", \"mesotidal\", \"macrotidal\"]\n",
    "\n",
    "scale_dict = {\"microtidal\": (-0.9, 0.6), \"mesotidal\": (-2, 1.2), \"macrotidal\": (-2, 2.5)}\n",
    "\n",
    "out = {}\n",
    "for i, cat in enumerate(cat_ranges):\n",
    "    outputs_subset_df = outputs_all_df.query(\"category == @cat\")\n",
    "\n",
    "    lim_min, lim_max = scale_dict[cat]\n",
    "\n",
    "    # Plot and compare - heatmap\n",
    "    axes[i].hexbin(\n",
    "        x=outputs_subset_df.validation_m_ahd,\n",
    "        y=outputs_subset_df.modelled_m,\n",
    "        extent=(lim_min, lim_max, lim_min, lim_max),\n",
    "        cmap=\"inferno\",\n",
    "        bins=100,\n",
    "        vmin=0,\n",
    "        vmax=50,\n",
    "    )\n",
    "    axes[i].set_facecolor(\"#0C0C0C\")\n",
    "    axes[i].plot([lim_min, lim_max], [lim_min, lim_max], \"--\", c=\"white\", linewidth=0.5)\n",
    "    axes[i].margins(x=0, y=0)\n",
    "    axes[i].set_title(cat)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"DEA Intertidal Elevation (m MSL)\")\n",
    "    elif i == 1:\n",
    "        axes[i].set_xlabel(\"Validation DEM (m AHD)\")\n",
    "\n",
    "    # Accuracy statistics\n",
    "    stats_df = eval_metrics(x=outputs_subset_df.validation_m_ahd, y=outputs_subset_df.modelled_m, round=3)\n",
    "    stats_df[\"n\"] = len(outputs_subset_df.modelled_m)\n",
    "    out[cat] = stats_df\n",
    "\n",
    "\n",
    "pd.DataFrame.from_records(\n",
    "    out,\n",
    "    index=[\"n\", \"Correlation\", \"R-squared\", \"RMSE\", \"MAE\", \"Bias\"],\n",
    "    columns=cat_ranges,\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbfc5d-0855-4ef0-9717-11e156da0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"DEAIntertidal_validation_micromesomacro_ahd.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdaa9a-ba58-4082-bc6b-30a74cd89516",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3.6))\n",
    "\n",
    "# Define a set of certainty ranges\n",
    "cat_ranges = [\"microtidal\", \"mesotidal\", \"macrotidal\"]\n",
    "\n",
    "scale_dict = {\"microtidal\": (-0.9, 0.8), \"mesotidal\": (-2, 1.2), \"macrotidal\": (-2, 2.5)}\n",
    "\n",
    "out = {}\n",
    "for i, cat in enumerate(cat_ranges):\n",
    "    outputs_subset_df = outputs_all_df.query(\"category == @cat\")\n",
    "    # )\n",
    "    outputs_subset_df[\"modelled_m\"] = outputs_subset_df.modelled_m.replace(-9999, np.nan)\n",
    "\n",
    "    lim_min, lim_max = scale_dict[cat]\n",
    "\n",
    "    # Plot and compare - heatmap\n",
    "    axes[i].hexbin(\n",
    "        x=outputs_subset_df.validation_m_msl,\n",
    "        y=outputs_subset_df.modelled_m,\n",
    "        extent=(lim_min, lim_max, lim_min, lim_max),\n",
    "        cmap=\"inferno\",\n",
    "        bins=100,\n",
    "        vmin=0,\n",
    "        vmax=50,\n",
    "    )\n",
    "    axes[i].set_facecolor(\"#0C0C0C\")\n",
    "    axes[i].plot([lim_min, lim_max], [lim_min, lim_max], \"--\", c=\"white\", linewidth=0.5)\n",
    "    axes[i].margins(x=0, y=0)\n",
    "    axes[i].set_title(cat)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"DEA Intertidal Elevation (m MSL)\")\n",
    "    elif i == 1:\n",
    "        axes[i].set_xlabel(\"Validation DEM (m MSL)\")\n",
    "\n",
    "    # Accuracy statistics\n",
    "    stats_df = eval_metrics(x=outputs_subset_df.validation_m_msl, y=outputs_subset_df.modelled_m, round=3)\n",
    "    stats_df[\"n\"] = len(outputs_subset_df.modelled_m)\n",
    "    out[cat] = stats_df\n",
    "\n",
    "\n",
    "pd.DataFrame.from_records(\n",
    "    out,\n",
    "    index=[\"n\", \"Correlation\", \"R-squared\", \"RMSE\", \"MAE\", \"Bias\"],\n",
    "    columns=cat_ranges,\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56747c28-2b0f-486e-94a6-e57fac0edf77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"DEAIntertidal_validation_micromesomacro_msl.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643a427-22fe-4451-a043-491b24dfd88d",
   "metadata": {},
   "source": [
    "## By substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25f783-2f1c-45e6-a6c1-ca1ca16807ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3.6))\n",
    "\n",
    "# Define a set of certainty ranges\n",
    "cat_ranges = [\"Sandy beach\", \"Tidal flats\", \"Rocky\"]\n",
    "\n",
    "scale_dict = {\"Sandy beach\": (-2.0, 1.1), \"Tidal flats\": (-2.0, 1.1), \"Rocky\": (-1.5, 1.1)}\n",
    "\n",
    "out = {}\n",
    "for i, cat in enumerate(cat_ranges):\n",
    "    outputs_subset_df = outputs_all_df.query(\"substrate == @cat\")\n",
    "\n",
    "    lim_min, lim_max = scale_dict[cat]\n",
    "\n",
    "    # Plot and compare - heatmap\n",
    "    axes[i].hexbin(\n",
    "        x=outputs_subset_df.validation_m_msl,\n",
    "        y=outputs_subset_df.modelled_m,\n",
    "        extent=(lim_min, lim_max, lim_min, lim_max),\n",
    "        cmap=\"inferno\",\n",
    "        bins=100,\n",
    "        vmin=0,\n",
    "        vmax=50,\n",
    "    )\n",
    "    axes[i].set_facecolor(\"#0C0C0C\")\n",
    "    axes[i].plot([lim_min, lim_max], [lim_min, lim_max], \"--\", c=\"white\", linewidth=0.5)\n",
    "    axes[i].margins(x=0, y=0)\n",
    "    axes[i].set_title(cat)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"DEA Intertidal Elevation (m MSL)\")\n",
    "    elif i == 1:\n",
    "        axes[i].set_xlabel(\"Validation DEM (m MSL)\")\n",
    "\n",
    "    # Accuracy statistics\n",
    "    stats_df = eval_metrics(x=outputs_subset_df.validation_m_msl, y=outputs_subset_df.modelled_m, round=3)\n",
    "    stats_df[\"n\"] = len(outputs_subset_df.modelled_m)\n",
    "    out[cat] = stats_df\n",
    "\n",
    "pd.DataFrame.from_records(\n",
    "    out,\n",
    "    index=[\"n\", \"Correlation\", \"R-squared\", \"RMSE\", \"MAE\", \"Bias\", \"Regression slope\"],\n",
    "    columns=cat_ranges,\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5851132-a568-4d99-ba62-fe8920e2a9a2",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
