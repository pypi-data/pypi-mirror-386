redis = "12800"

[train]
resume = false
epoch = 10
output_dir = "./outputs/deepseek-v3-fsdp8-r-tp1-grpo"
epsilon = 1e-6
optm_name = "AdamW"
optm_lr = 2e-6
optm_impl = "foreach"
optm_weight_decay = 1.0
optm_betas = [ 0.9, 0.95,]
optm_warmup_steps = 20
optm_grad_norm_clip = 0.0
async_tp_enabled = false
compile = false
param_dtype = "bfloat16"
fsdp_reduce_dtype = "float32"
fsdp_offload = false
fsdp_reshard_after_forward = "default"
train_batch_per_replica = 128
sync_weight_interval = 1

[rollout]
gpu_memory_utilization = 0.9
enable_chunked_prefill = false
n_generation = 8
batch_size = 8
quantization = "none"
max_response_length = 128

[rollout.sampling_config]
temperature = 0.6
top_p = 0.95
top_k = 50
repetition_penalty = 1.05

[policy]
model_name_or_path = "/lustre/fsw/portfolios/sw/users/yufhuang/cache/deepseek-v3/dcp_hf"
model_max_length = 4096
model_gradient_checkpointing = true

[logging]
logger = ['console', 'wandb']
project_name = "cosmos_rl"
experiment_name = "deepseek_v3_grpo"

[train.train_policy]
type = "grpo"
dataset.name = "openai/gsm8k"
dataset.subset = "main"
dataset.split = "train"
prompt_column_name = "question"
response_column_name = "answer"
reward_function = "gsm8k"
enable_dataset_cache = false
temperature = 0.9
epsilon_low = 0.2
epsilon_high = 0.2
kl_beta = 0.0
mu_iterations = 1
mini_batch = 1

[train.ckpt]
enable_checkpoint = true
save_freq = 50
save_mode = "async"

[rollout.parallelism]
n_init_replicas = 1
tp_size = 32
pp_size = 1
dp_replicate_size = 1
cp_size = 1
dp_shard_size = 1

[policy.parallelism]
n_init_replicas = 1
tp_size = 1
cp_size = 4
ep_size = 64
dp_shard_size = 64
pp_size = 1
dp_replicate_size = 1
cp_rotate_method = "allgather"