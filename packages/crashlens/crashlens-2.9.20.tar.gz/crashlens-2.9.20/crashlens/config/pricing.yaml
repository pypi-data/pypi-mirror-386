# CrashLens Pricing Configuration
# Model pricing per 1M tokens (normalized for accuracy)

models:
  # GPT-4 Models (Latest Pricing - July 2025)
  gpt-4:
    input_cost_per_1m: 30.00      # $30/1M tokens
    output_cost_per_1m: 60.00     # $60/1M tokens
    description: "GPT-4 (8K context)"
  
  gpt-4-32k:
    input_cost_per_1m: 60.00      # $60/1M tokens
    output_cost_per_1m: 120.00    # $120/1M tokens
    description: "GPT-4 (32K context)"
  
  gpt-4-turbo:
    input_cost_per_1m: 10.00      # $10/1M tokens
    output_cost_per_1m: 30.00     # $30/1M tokens
    description: "GPT-4 Turbo"
    
  gpt-4o:
    input_cost_per_1m: 5.00       # $5/1M tokens
    output_cost_per_1m: 15.00     # $15/1M tokens
    description: "GPT-4o (Optimized)"
  
  # GPT-3.5 Models
  gpt-3.5-turbo:
    input_cost_per_1m: 1.50       # $1.50/1M tokens
    output_cost_per_1m: 2.00      # $2.00/1M tokens
    description: "GPT-3.5 Turbo"
  
  gpt-3.5-turbo-16k:
    input_cost_per_1m: 3.00       # $3.00/1M tokens
    output_cost_per_1m: 4.00      # $4.00/1M tokens
    description: "GPT-3.5 Turbo (16K context)"
  
  # Claude Models (Latest Anthropic Pricing)
  claude-3-opus:
    input_cost_per_1m: 15.00      # $15/1M tokens
    output_cost_per_1m: 75.00     # $75/1M tokens
    description: "Claude 3 Opus"
  
  claude-3-sonnet:
    input_cost_per_1m: 3.00       # $3/1M tokens
    output_cost_per_1m: 15.00     # $15/1M tokens
    description: "Claude 3 Sonnet"
  
  claude-3-haiku:
    input_cost_per_1m: 0.25       # $0.25/1M tokens
    output_cost_per_1m: 1.25      # $1.25/1M tokens
    description: "Claude 3 Haiku"
  
  claude-2.1:
    input_cost_per_1m: 8.00       # $8/1M tokens
    output_cost_per_1m: 24.00     # $24/1M tokens
    description: "Claude 2.1"
  
  claude-2.0:
    input_cost_per_1m: 8.00       # $8/1M tokens
    output_cost_per_1m: 24.00     # $24/1M tokens
    description: "Claude 2.0"
  
  claude-instant-1:
    input_cost_per_1m: 1.63       # $1.63/1M tokens
    output_cost_per_1m: 5.51      # $5.51/1M tokens
    description: "Claude Instant 1"
    
  # Google Gemini Models
  gemini-pro:
    input_cost_per_1m: 0.50       # $0.50/1M tokens
    output_cost_per_1m: 1.50      # $1.50/1M tokens
    description: "Gemini Pro"
    
  gemini-pro-vision:
    input_cost_per_1m: 0.25       # $0.25/1M tokens
    output_cost_per_1m: 0.50      # $0.50/1M tokens
    description: "Gemini Pro Vision"

# Detection thresholds
thresholds:
  retry_loop:
    max_retries: 3
    time_window_minutes: 5
    max_retry_interval_minutes: 2
  
  overkill_model:
    min_tokens_for_gpt4: 100
    gpt4_cost_multiplier: 20.0
    # Models considered expensive for short prompts
    expensive_models:
      - gpt-4
      - gpt-4-32k
      - gpt-4-turbo
      - claude-3-opus
      - claude-3-sonnet
      - claude-2.1
      - claude-2.0
  
  fallback_storm:
    fallback_threshold: 3
    time_window_minutes: 10
  
  fallback_failure:
    time_window_seconds: 300

# Waste calculation settings
waste_calculation:
  # Multiplier for estimating monthly costs from daily samples
  monthly_projection_multiplier: 30
  
  # Minimum cost threshold to report (in dollars)
  min_report_cost: 0.001
  
  # Severity thresholds
  high_severity_cost: 0.10
  medium_severity_cost: 0.01

# ðŸ“ˆ 4. Cost Estimation Logic - Updated for 1M token normalization
cost_calculation:
  # Base unit for pricing (all models normalized to this)
  base_unit: 1000000  # 1M tokens
  
  # Token counting preferences
  token_counting:
    prefer_actual_usage: true     # Use logged usage if available
    fallback_to_estimation: true  # Estimate if usage missing
    
  # Cost attribution
  attribution:
    per_call_accuracy: true       # Cost = tokens Ã— model rate
    total_waste_summation: true   # Sum of all affected calls
    include_estimated_waste_usd: true  # Add to detector output