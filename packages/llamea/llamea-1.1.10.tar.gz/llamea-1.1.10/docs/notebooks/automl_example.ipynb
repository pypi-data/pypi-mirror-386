{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XAI-liacs/LLaMEA/blob/main/docs/notebooks/automl_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1LWh5tyENBl"
      },
      "source": [
        "# LLaMEA AutoML example\n",
        "\n",
        "This notebook shows a simple usage of LLaMEA to automatically generate and refine a Python-based machine learning pipelines for a given task and dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this dependency is sometimes missed by poetry\n",
        "!pip install swig\n",
        "!pip install llamea==1.1.4\n"
      ],
      "metadata": {
        "id": "G2ftkZUgEOsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaing up\n",
        "!rm -R exp-*"
      ],
      "metadata": {
        "id": "SnFysV-pSSwr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "is1v9tqgENBn"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "import os\n",
        "import numpy as np\n",
        "from llamea import LLaMEA, Gemini_LLM\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import random\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it54SL2xENBo"
      },
      "source": [
        "## Cell 1: Set up the LLM\n",
        "\n",
        "If you haven't already, set your OpenAI or other API key in your environment variables, e.g.,\n",
        "`export OPENAI_API_KEY=\"...\"` or `export GEMINI_API_KEY=\"....\"`\n",
        "\n",
        "You can also use Gemini in most countries for free."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "s26irM3RENBo"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set environment variables\n",
        "api_key = userdata.get('GOOGLE_API_KEY_1')\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "\n",
        "#api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "llm = Gemini_LLM(api_key, \"gemini-2.0-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc6ngnrQENBo"
      },
      "source": [
        "## Cell 2: Define an evaluation function for LLaMEA\n",
        "\n",
        "- The function must accept a \"solution\" argument, which contains code, a name, etc.\n",
        "- You parse solution.code (the raw code), dynamically load it, and run it on your problem(s).\n",
        "- You then set_scores() to record how well it did.\n",
        "\n",
        "We'll define a simple example on the breast cancer dataset.\n",
        "We'll ask the solution code to build a machine learning model that can predict the test set.\n",
        "We'll then return a score based on the accuracy of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "scNf3N4YENBo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the data set\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ") = train_test_split(X, y, random_state=1)\n",
        "\n",
        "def evaluate(solution, explogger=None):\n",
        "        \"\"\"\n",
        "        Evaluates a solution on the breast cancer dataset.\n",
        "        \"\"\"\n",
        "        code = solution.code\n",
        "        algorithm_name = solution.name\n",
        "\n",
        "        exec(code, globals())\n",
        "\n",
        "        algorithm = None\n",
        "\n",
        "        # Final validation\n",
        "        algorithm = globals()[algorithm_name](X_train, y_train)\n",
        "        y_pred = algorithm(X_test)\n",
        "        score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        solution.set_scores(\n",
        "            score,\n",
        "            f\"The algorithm {algorithm_name} scored {score:.3f} on accuracy (higher is better, 1.0 is the best).\",\n",
        "        )\n",
        "\n",
        "        return solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBca3rn1ENBp"
      },
      "source": [
        "## Cell 3 - define the instructions\n",
        "\n",
        "Now we define the instructions that LLamEA will provide to the LLM.\n",
        "The instructions are split into the following parts:\n",
        "- task_prompt: the main task description with a general overview of the task.\n",
        "- example_prompt: one or more code examples to guide the search in the beginning.\n",
        "- output_format_prompt: how the LLM should generate the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5ucxxzK5ENBp"
      },
      "outputs": [],
      "source": [
        "task_prompt = f\"\"\"\n",
        "You are a highly skilled computer scientist in the field machine learning. Your task is to design novel machine learning pipelines for a given dataset and task.\n",
        "The pipeline in this case should handle a breast cancer classification task. Your task is to write the Python code. The code should contain an `__init__(self, X, y)` function that trains a machine learning model and the function `def __call__(self, X)`, which should predict the samples in X and return the predictions.\n",
        "The training data X has shape {X_train.shape} and y has shape {y_train.shape}.\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = \"\"\"\n",
        "An example code structure is as follows:\n",
        "```python\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "class AlgorithmName:\n",
        "    \"Template for a ML pipeline\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.train(X, y)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        # Standardize the feature data\n",
        "        scaler = sklearn.preprocessing.StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Let's create and train a logistic regression model\n",
        "        lr_model = sklearn.linear_model.LogisticRegression()\n",
        "        lr_model.fit(X_train, y_train)\n",
        "        self.model = lr_model\n",
        "\n",
        "    def __call__(self, X):\n",
        "        # predict using the trained model\n",
        "        return self.model.predict(X)\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "output_format_prompt = \"\"\"\n",
        "Give an excellent and novel ML pipeline to solve this task (within a 120 second time-limit) and also give it a one-line description, describing the main idea. Give the response in the format:\n",
        "# Description: <short-description>\n",
        "# Code:\n",
        "```python\n",
        "<code>\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEDBr192ENBp"
      },
      "source": [
        "## Cell 4: Create and run the LLaMEA search\n",
        "\n",
        "Now just simply run LLaMEA and see the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "collapsed": true,
        "id": "tEfomhhfENBp",
        "outputId": "ae535900-fa29-4419-e9fe-bf9b2626d7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/parallel.py:1383: UserWarning: The backend class 'SequentialBackend' does not support timeout. You have set 'timeout=135' in Parallel but the 'timeout' parameter will not be used.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/parallel.py:1383: UserWarning: The backend class 'SequentialBackend' does not support timeout. You have set 'timeout=135' in Parallel but the 'timeout' parameter will not be used.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/parallel.py:1383: UserWarning: The backend class 'SequentialBackend' does not support timeout. You have set 'timeout=135' in Parallel but the 'timeout' parameter will not be used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best found solution: StackingEnsemble, Score=0.9790\n",
            "Generated code:\n",
            "import numpy as np\n",
            "import sklearn\n",
            "from sklearn.model_selection import StratifiedKFold\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "from sklearn.ensemble import VotingClassifier\n",
            "from sklearn.pipeline import Pipeline\n",
            "\n",
            "class StackingEnsemble:\n",
            "    \"\"\"\n",
            "    A stacking ensemble of Logistic Regression, SVM, and Decision Tree classifiers,\n",
            "    using cross-validation for robust performance.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, X, y):\n",
            "        self.train(X, y)\n",
            "\n",
            "    def train(self, X, y):\n",
            "        # Define the base models\n",
            "        lr = LogisticRegression(solver='liblinear', random_state=42, C=0.1)\n",
            "        svm = SVC(probability=True, random_state=42, kernel='rbf', C=1)  # Enable probability estimates\n",
            "        dt = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
            "\n",
            "        # Create a voting classifier (soft voting)\n",
            "        estimators = [('lr', lr), ('svm', svm), ('dt', dt)]\n",
            "        self.ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
            "        \n",
            "        # Create a pipeline with scaling and the ensemble\n",
            "        self.pipeline = Pipeline([\n",
            "            ('scaler', StandardScaler()),\n",
            "            ('ensemble', self.ensemble)\n",
            "        ])\n",
            "\n",
            "        # Train the ensemble using cross-validation\n",
            "        self.pipeline.fit(X, y)\n",
            "\n",
            "    def __call__(self, X):\n",
            "        # Predict using the trained pipeline\n",
            "        return self.pipeline.predict(X)\n",
            "Additional feedback: The algorithm StackingEnsemble scored 0.979 on accuracy (higher is better, 1.0 is the best).\n"
          ]
        }
      ],
      "source": [
        "# We'll use a small number of iterations for demonstration\n",
        "es = LLaMEA(\n",
        "    evaluate,\n",
        "    n_parents=1,\n",
        "    n_offspring=1,\n",
        "    llm=llm,\n",
        "    eval_timeout=120,\n",
        "    task_prompt=task_prompt,\n",
        "    example_prompt=example_prompt,\n",
        "    output_format_prompt=output_format_prompt,\n",
        "    experiment_name=\"AutoML-example\",\n",
        "    elitism=True,\n",
        "    HPO=False,\n",
        "    budget=3,\n",
        ")\n",
        "\n",
        "best_solution = es.run()\n",
        "print(f\"Best found solution: {best_solution.name}, Score={best_solution.fitness:.4f}\")\n",
        "print(f\"Generated code:\\n{best_solution.code}\")\n",
        "print(f\"Additional feedback: {best_solution.feedback}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llamea-84rNYHzd-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
