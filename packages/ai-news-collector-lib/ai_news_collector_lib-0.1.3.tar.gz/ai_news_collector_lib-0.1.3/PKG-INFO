Metadata-Version: 2.4
Name: ai-news-collector-lib
Version: 0.1.3
Summary: A Python library for collecting AI-related news from multiple sources
Home-page: https://github.com/ai-news-collector/ai-news-collector-lib
Author: AI News Collector Team
Author-email: AI News Collector Team <support@ai-news-collector.com>
Maintainer-email: AI News Collector Team <support@ai-news-collector.com>
License: MIT
Project-URL: Homepage, https://github.com/ai-news-collector/ai-news-collector-lib
Project-URL: Documentation, https://ai-news-collector-lib.readthedocs.io/
Project-URL: Repository, https://github.com/ai-news-collector/ai-news-collector-lib.git
Project-URL: Bug Tracker, https://github.com/ai-news-collector/ai-news-collector-lib/issues
Keywords: ai,news,collector,search,web scraping,machine learning,artificial intelligence
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Internet :: WWW/HTTP :: Indexing/Search
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.28.0
Requires-Dist: beautifulsoup4>=4.11.0
Requires-Dist: feedparser>=6.0.0
Requires-Dist: python-dotenv>=0.19.0
Requires-Dist: google-generativeai>=0.3.0
Provides-Extra: advanced
Requires-Dist: aiohttp>=3.8.0; extra == "advanced"
Requires-Dist: redis>=4.0.0; extra == "advanced"
Requires-Dist: schedule>=1.2.0; extra == "advanced"
Requires-Dist: apscheduler>=3.9.0; extra == "advanced"
Provides-Extra: nlp
Requires-Dist: nltk>=3.8; extra == "nlp"
Requires-Dist: spacy>=3.4.0; extra == "nlp"
Requires-Dist: textblob>=0.17.0; extra == "nlp"
Provides-Extra: web
Requires-Dist: fastapi>=0.80.0; extra == "web"
Requires-Dist: uvicorn>=0.18.0; extra == "web"
Requires-Dist: streamlit>=1.20.0; extra == "web"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.20.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: flake8>=5.0.0; extra == "dev"
Requires-Dist: mypy>=0.950; extra == "dev"
Requires-Dist: vcrpy>=4.4.0; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# ğŸ”° AI News Collector Library

> ä¸€ä¸ªç”¨äºæ”¶é›†AIç›¸å…³æ–°é—»çš„Pythonåº“ï¼Œæ”¯æŒå¤šç§æœç´¢æºå’Œé«˜çº§åŠŸèƒ½ã€‚

[![Python Version](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![PyPI](https://img.shields.io/badge/PyPI-ai--news--collector--lib-blue)](https://pypi.org/project/ai-news-collector-lib/)
[![Latest Release](https://img.shields.io/badge/Latest-v0.1.3-brightgreen)](https://github.com/ai-news-collector/ai-news-collector-lib/releases/tag/v0.1.3)

---

## ğŸš€ æœ€æ–°æ›´æ–° (v0.1.3 - LLM æŸ¥è¯¢å¢å¼º)

> **è¿™æ˜¯ v0.1.3 ç‰ˆæœ¬çš„é‡å¤§æ›´æ–°ï¼** å¼•å…¥äº† AI é©±åŠ¨çš„æŸ¥è¯¢å¢å¼ºåŠŸèƒ½ã€‚å¼ºçƒˆå»ºè®®æ‰€æœ‰ç”¨æˆ·å‡çº§ã€‚

### ğŸ¤– LLM æŸ¥è¯¢å¢å¼ºï¼ˆæ–°åŠŸèƒ½ï¼‰
- âœ… **AI é©±åŠ¨æŸ¥è¯¢ä¼˜åŒ–** - é›†æˆ Google Gemini LLMï¼Œæ™ºèƒ½ä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢
- âœ… **å¤šå¼•æ“æ”¯æŒ** - ä¸ºæ‰€æœ‰ 11 ä¸ªæœç´¢å¼•æ“ç”Ÿæˆä¼˜åŒ–æŸ¥è¯¢ï¼ˆå•ä¸€ LLM è°ƒç”¨ï¼‰
- âœ… **æ™ºèƒ½ç¼“å­˜** - 24 å°æ—¶ç¼“å­˜ï¼Œé¿å…é‡å¤ LLM è°ƒç”¨
- âœ… **çµæ´»é…ç½®** - å¯é€‰å¯ç”¨/ç¦ç”¨ï¼Œæ”¯æŒè‡ªå®šä¹‰ LLM æä¾›å•†å’Œæ¨¡å‹
- âœ… **ä¼˜é›…é™çº§** - LLM è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼Œç¡®ä¿æœåŠ¡å¯ç”¨æ€§

### ğŸ”§ æ ¸å¿ƒæ”¹è¿›
- âœ… **å¢å¼ºçš„æŸ¥è¯¢å¯¹è±¡** - æ–°å¢ `EnhancedQuery` æ¨¡å‹ï¼ˆæ”¯æŒ 11 ä¸ªæœç´¢å¼•æ“ï¼‰
- âœ… **æŸ¥è¯¢ä¼˜åŒ–å™¨** - æ–°å¢ `QueryEnhancer` å·¥å…·ç±»ï¼ˆ500+ è¡Œé«˜è´¨é‡ä»£ç ï¼‰
- âœ… **é›†æˆä¼˜åŒ–** - AdvancedAINewsCollector æ— ç¼é›†æˆæŸ¥è¯¢å¢å¼º

ğŸ“‹ è¯¦è§: [å®ç°æ€»ç»“](IMPLEMENTATION_SUMMARY.md) | [LLM é…ç½®æŒ‡å—](docs/README_BADGES.md) | [å®Œæ•´æŒ‡å—](USAGE_GUIDE.md)

---

## âœ¨ ä¸»è¦ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ”¥ **å¤šæºèšåˆ** - æ”¯æŒHackerNewsã€ArXivã€DuckDuckGoç­‰å¤šä¸ªæœç´¢æº
- ğŸ“° **ä»˜è´¹APIé›†æˆ** - NewsAPIã€Tavilyã€Google Searchã€Bing Searchã€Serperç­‰
- ğŸ¤– **æ™ºèƒ½å†…å®¹å¤„ç†** - è‡ªåŠ¨æå–æ–‡ç« å†…å®¹å’Œå…³é”®è¯
- ğŸ’¾ **æ™ºèƒ½ç¼“å­˜** - é¿å…é‡å¤æœç´¢ï¼Œæé«˜æ•ˆç‡
- â° **å®šæ—¶ä»»åŠ¡** - æ”¯æŒå®šæ—¶è‡ªåŠ¨æ”¶é›†å’ŒæŠ¥å‘Šç”Ÿæˆ
- ğŸ” **å»é‡å¤„ç†** - åŸºäºç›¸ä¼¼åº¦çš„æ™ºèƒ½å»é‡
- ğŸ“Š **æ•°æ®åˆ†æ** - ç”Ÿæˆè¯¦ç»†çš„æ”¶é›†ç»“æœæŠ¥å‘Š

### æµ‹è¯•ä¸è´¨é‡
- ğŸ§ª **ç¦»çº¿æµ‹è¯•** - ä½¿ç”¨VCR cassetteså®ç°å®Œå…¨ç¦»çº¿çš„ä»˜è´¹APIæµ‹è¯•
- ğŸ” **å®‰å…¨ä¼˜å…ˆ** - æ‰€æœ‰æµ‹è¯•æ•°æ®ä¸­çš„å‡­è¯å·²æ¸…ç†
- ğŸ“ˆ **è¦†ç›–ç‡** - pytest-cové›†æˆï¼Œè¯¦ç»†çš„æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
- ğŸ¤– **è‡ªåŠ¨åŒ–** - GitHub Actionsè‡ªåŠ¨åŒ–æµ‹è¯•å’Œå‘å¸ƒ

---

## ğŸ“¦ å®‰è£…

### ä»PyPIå®‰è£…ï¼ˆæ¨èï¼‰

```bash
# åŸºç¡€å®‰è£…
pip install ai-news-collector-lib

# å®‰è£…å¼€å‘/æµ‹è¯•ä¾èµ–
pip install ai-news-collector-lib[dev]

# æˆ–ä»æºä»£ç å®‰è£…
pip install -e .[dev]
```

### ç³»ç»Ÿè¦æ±‚
- Python 3.9+
- pip æˆ– conda

---

## ğŸ”‘ é…ç½®APIå¯†é’¥

åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œä»…ç”¨äºä»˜è´¹APIï¼‰ï¼š

```bash
# APIå¯†é’¥é…ç½®
NEWS_API_KEY=your_newsapi_key
TAVILY_API_KEY=your_tavily_key
GOOGLE_SEARCH_API_KEY=your_google_key
GOOGLE_SEARCH_ENGINE_ID=your_engine_id
BING_SEARCH_API_KEY=your_bing_key
SERPER_API_KEY=your_serper_key
BRAVE_SEARCH_API_KEY=your_brave_key
METASOSEARCH_API_KEY=your_metasota_key
```

> âš ï¸ **é‡è¦**ï¼šè¯·å‹¿å°† `.env` æ–‡ä»¶æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ã€‚å‚è§ [APIå¯†é’¥å®‰å…¨æŒ‡å—](API_KEY_SECURITY_AUDIT.md)ã€‚

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ä½¿ç”¨ï¼ˆå…è´¹æºï¼‰

```python
import asyncio
from ai_news_collector_lib import AINewsCollector, SearchConfig

async def main():
    # åˆ›å»ºé…ç½®
    config = SearchConfig(
        enable_hackernews=True,
        enable_arxiv=True,
        enable_duckduckgo=True,
        max_articles_per_source=10,
        days_back=7
    )
    
    # åˆ›å»ºæ”¶é›†å™¨
    collector = AINewsCollector(config)
    
    # æ”¶é›†æ–°é—»
    result = await collector.collect_news("machine learning")
    
    # è¾“å‡ºç»“æœ
    print(f"æ”¶é›† {result.total_articles} ç¯‡æ–‡ç« ï¼ˆå»é‡å {result.unique_articles} ç¯‡ï¼‰")
    for article in result.articles[:5]:
        print(f"- {article.title}")
    
    return result

# è¿è¡Œ
asyncio.run(main())
```

### ğŸ¤– LLM æŸ¥è¯¢å¢å¼ºï¼ˆæ–°ï¼‰

```python
import asyncio
from ai_news_collector_lib import AdvancedAINewsCollector, AdvancedSearchConfig

async def main():
    # åˆ›å»ºå¸¦ LLM æŸ¥è¯¢å¢å¼ºçš„é…ç½®
    config = AdvancedSearchConfig(
        enable_hackernews=True,
        enable_arxiv=True,
        enable_tavily=True,
        enable_query_enhancement=True,        # âœ¨ å¯ç”¨ LLM æŸ¥è¯¢å¢å¼º
        llm_provider="google",                # ä½¿ç”¨ Google Gemini
        llm_model="gemini-1.5-flash",         # é«˜æ€§èƒ½æ¨¡å‹
        llm_api_key="your-google-api-key",    # ä»ç¯å¢ƒå˜é‡è®¾ç½®æ›´å®‰å…¨
        query_enhancement_cache_ttl=86400,    # 24 å°æ—¶ç¼“å­˜
        max_articles_per_source=10
    )
    
    # åˆ›å»ºæ”¶é›†å™¨
    collector = AdvancedAINewsCollector(config)
    
    # LLM ä¼šè‡ªåŠ¨ä¸ºå„ä¸ªæœç´¢å¼•æ“ä¼˜åŒ–æŸ¥è¯¢
    # ä¾‹å¦‚ï¼šè¾“å…¥ "machine learning" â†’ 
    #   HackerNews: "machine learning frameworks algorithms"
    #   ArXiv: "machine learning optimization techniques"
    #   Tavily: "latest machine learning applications 2024"
    result = await collector.collect_news_advanced("machine learning")
    
    # æŸ¥çœ‹å¢å¼ºåçš„æŸ¥è¯¢
    if result.get('enhanced_query'):
        enhanced = result['enhanced_query']
        print(f"åŸå§‹æŸ¥è¯¢: {enhanced.original_query}")
        print(f"å¢å¼ºæŸ¥è¯¢æ•°: {len(enhanced.get_enabled_engines())}")
        for engine in enhanced.get_enabled_engines():
            print(f"  - {engine}: {getattr(enhanced, engine)}")
    
    return result

asyncio.run(main())
```

**LLM æŸ¥è¯¢å¢å¼ºçš„ä¼˜åŠ¿ï¼š**
- ğŸ¯ **ç²¾å‡†æœç´¢** - AI è‡ªåŠ¨ä¸ºä¸åŒæœç´¢å¼•æ“ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢
- âš¡ **æ™ºèƒ½ç¼“å­˜** - ç›¸åŒæŸ¥è¯¢åœ¨ 24 å°æ—¶å†…æ— éœ€é‡æ–°è°ƒç”¨ LLM
- ğŸ’° **ç»æµé«˜æ•ˆ** - å•ä¸€ LLM è°ƒç”¨å¤„ç†æ‰€æœ‰æœç´¢å¼•æ“
- ğŸ”„ **çµæ´»é™çº§** - LLM ä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨åŸå§‹æŸ¥è¯¢
- ğŸ“Š **å®Œæ•´æ”¯æŒ** - æ”¯æŒæ‰€æœ‰ 11 ä¸ªæœç´¢å¼•æ“ï¼ˆHackerNewsã€ArXivã€DuckDuckGoã€NewsAPIã€Tavilyã€Google Searchã€Bing Searchã€Serperã€Redditã€Hacker News APIã€Mediumï¼‰

### é«˜çº§ä½¿ç”¨ï¼ˆåŒ…å«å†…å®¹æå–å’Œå…³é”®è¯æå–ï¼‰

```python
import asyncio
from ai_news_collector_lib import AdvancedAINewsCollector, AdvancedSearchConfig

async def main():
    # åˆ›å»ºé«˜çº§é…ç½®
    config = AdvancedSearchConfig(
        enable_hackernews=True,
        enable_arxiv=True,
        enable_duckduckgo=True,
        enable_content_extraction=True,      # è‡ªåŠ¨æå–å†…å®¹
        enable_keyword_extraction=True,      # è‡ªåŠ¨æå–å…³é”®è¯
        cache_results=True,                  # å¯ç”¨ç¼“å­˜
        max_articles_per_source=10
    )
    
    # åˆ›å»ºé«˜çº§æ”¶é›†å™¨
    collector = AdvancedAINewsCollector(config)
    
    # æ”¶é›†å¢å¼ºæ–°é—»
    result = await collector.collect_news_advanced("artificial intelligence")
    
    # åˆ†æç»“æœ
    total_words = sum(article.get('word_count', 0) for article in result['articles'])
    print(f"æ€»å­—æ•°: {total_words}")
    print(f"å…³é”®è¯: {', '.join(result.get('top_keywords', [])[:10])}")
    
    return result

# è¿è¡Œ
asyncio.run(main())
```

### ä»˜è´¹APIä½¿ç”¨ï¼ˆå¸¦ç¼“å­˜ï¼‰

```python
import asyncio
from ai_news_collector_lib import AdvancedAINewsCollector, AdvancedSearchConfig

async def main():
    # åˆ›å»ºé…ç½® - æ··åˆä½¿ç”¨å…è´¹å’Œä»˜è´¹æº
    config = AdvancedSearchConfig(
        enable_hackernews=True,
        enable_arxiv=True,
        enable_tavily=True,              # ä»˜è´¹æœç´¢API
        enable_google_search=True,       # è°·æ­Œè‡ªå®šä¹‰æœç´¢
        enable_serper=True,              # Serperæœç´¢API
        cache_results=True,              # å¯ç”¨ç¼“å­˜å‡å°‘APIè°ƒç”¨
        max_articles_per_source=15,
        similarity_threshold=0.85
    )
    
    collector = AdvancedAINewsCollector(config)
    result = await collector.collect_news_advanced("deep learning")
    
    return result

asyncio.run(main())
```

---

## ğŸ“Š æ”¯æŒçš„æœç´¢æº

### âœ… å…è´¹æºï¼ˆæ— éœ€APIå¯†é’¥ï¼‰

| æº | æè¿° | ç‰¹ç‚¹ |
|---|---|---|
| ğŸ”¥ **HackerNews** | æŠ€æœ¯ç¤¾åŒºè®¨è®º | å®æ—¶çƒ­ç‚¹ï¼Œå¼€å‘è€…å‹å¥½ |
| ğŸ“š **ArXiv** | å­¦æœ¯è®ºæ–‡é¢„å°æœ¬ | å­¦æœ¯è´¨é‡ï¼Œå¤šå­¦ç§‘è¦†ç›– |
| ğŸ¦† **DuckDuckGo** | éšç§æœç´¢å¼•æ“ | éšç§ä¿æŠ¤ï¼Œå¹¿æ³›è¦†ç›– |

### ğŸ’° ä»˜è´¹æºï¼ˆéœ€è¦APIå¯†é’¥ï¼‰

| æº | API | ç‰¹ç‚¹ | å…è´¹é¢åº¦ |
|---|---|---|---|
| ğŸ“¡ **NewsAPI** | newsapi.org | å¤šæºèšåˆã€æ–°é—»åˆ†ç±» | 100 è¯·æ±‚/å¤© |
| ğŸ” **Tavily** | tavily.com | AIé©±åŠ¨æœç´¢ã€å®æ—¶ | 1000 è¯·æ±‚/æœˆ |
| ğŸŒ **Google Search** | googleapis.com | ç²¾å‡†æœç´¢ã€è¦†ç›–å¹¿ | 100 è¯·æ±‚/å¤© |
| ğŸ”µ **Bing Search** | bing.com | å¤šåª’ä½“æ”¯æŒã€å›½é™…åŒ– | 3000 è¯·æ±‚/æœˆ |
| âš¡ **Serper** | serper.dev | é«˜é€Ÿã€ä¾¿å®œ | 100 è¯·æ±‚/æœˆ |
| ğŸ¦ **Brave Search** | search.brave.com | ç‹¬ç«‹éšç§æœç´¢ | 100 è¯·æ±‚/æœˆ |
| ğŸ”¬ **MetaSota** | metaso.cn | MCPåè®®æœç´¢ | æŒ‰é…é¢ |

---

## âš™ï¸ è¯¦ç»†é…ç½®

### æœç´¢é…ç½®é€‰é¡¹

```python
from ai_news_collector_lib import AdvancedSearchConfig

config = AdvancedSearchConfig(
    # ä¼ ç»Ÿæº
    enable_hackernews=True,
    enable_arxiv=True,
    enable_rss_feeds=False,
    
    # ä»˜è´¹æœç´¢æº
    enable_tavily=False,
    enable_google_search=False,
    enable_bing_search=False,
    enable_serper=False,
    enable_brave_search=False,
    enable_metasota_search=False,
    enable_newsapi=False,
    
    # ç½‘é¡µæœç´¢
    enable_duckduckgo=True,
    
    # é«˜çº§åŠŸèƒ½
    enable_content_extraction=False,     # è‡ªåŠ¨æå–æ–‡ç« å†…å®¹
    enable_keyword_extraction=False,     # è‡ªåŠ¨æå–å…³é”®è¯
    cache_results=False,                 # ç¼“å­˜ç»“æœ
    
    # æœç´¢å‚æ•°
    max_articles_per_source=10,
    days_back=7,
    similarity_threshold=0.85,
    timeout_seconds=30
)
```

---

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### å®šæ—¶æ”¶é›†

```python
from ai_news_collector_lib import DailyScheduler, AdvancedAINewsCollector, AdvancedSearchConfig

async def collect_news():
    config = AdvancedSearchConfig(
        enable_hackernews=True,
        enable_arxiv=True,
        cache_results=True
    )
    collector = AdvancedAINewsCollector(config)
    return await collector.collect_news_advanced("AI")

# åˆ›å»ºå®šæ—¶ä»»åŠ¡ - æ¯å¤©ä¸Šåˆ9ç‚¹
scheduler = DailyScheduler(
    collector_func=collect_news,
    schedule_time="09:00",
    timezone="Asia/Shanghai"
)

# å¯åŠ¨è°ƒåº¦å™¨
scheduler.start()
```

### ç¼“å­˜ç®¡ç†

```python
from ai_news_collector_lib import CacheManager

# åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
cache = CacheManager(cache_dir="./cache", default_ttl_hours=24)

# è·å–ç¼“å­˜
cache_key = cache.get_cache_key("AI news", ["hackernews", "arxiv"])
cached_result = cache.get_cached_result(cache_key)

if cached_result:
    print("ä½¿ç”¨ç¼“å­˜ç»“æœ")
    result = cached_result
else:
    # æ‰§è¡Œæœç´¢
    result = await collector.collect_news("AI news")
    # ç¼“å­˜ç»“æœ
    cache.cache_result(cache_key, result)
```

### æŠ¥å‘Šç”Ÿæˆ

```python
from ai_news_collector_lib import ReportGenerator

# åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
reporter = ReportGenerator(output_dir="./reports")

# ç”ŸæˆMarkdownæŠ¥å‘Š
report = reporter.generate_daily_report(result, format="markdown")
reporter.save_report(result, filename="daily_report.md")

# ç”ŸæˆCSVæŠ¥å‘Š
reporter.generate_daily_report(result, format="csv")
```

---

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
# è¿è¡ŒåŸºç¡€æµ‹è¯•
pytest

# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆåŒ…æ‹¬ä»˜è´¹APIæµ‹è¯•ï¼‰
pytest -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=ai_news_collector_lib --cov-report=html
```

### ç¦»çº¿ä»˜è´¹APIæµ‹è¯•ï¼ˆä½¿ç”¨VCR Cassettesï¼‰

é¡¹ç›®åŒ…å«é¢„å½•åˆ¶çš„VCR cassettesï¼Œå…è®¸åœ¨å®Œå…¨ç¦»çº¿çŠ¶æ€ä¸‹æµ‹è¯•æ‰€æœ‰ä»˜è´¹APIé›†æˆ - **æ— éœ€çœŸå®APIå¯†é’¥**ã€‚

```bash
# è¿è¡Œä»˜è´¹APIæµ‹è¯•ï¼ˆä½¿ç”¨cassettesï¼Œå®Œå…¨ç¦»çº¿ï¼‰
pytest tests/test_integration_advanced.py -v

# æŸ¥çœ‹cassetteè®°å½•è¯¦æƒ…
cat tests/cassettes/advanced_ml_hn_ddg.yaml
```

### VCR CassetteåŸç†

VCRåº“è®°å½•çœŸå®çš„HTTPè¯·æ±‚/å“åº”ï¼Œç„¶ååœ¨æµ‹è¯•ä¸­é‡æ”¾ï¼ˆæ— éœ€çœŸå®APIè°ƒç”¨ï¼‰ï¼š

```python
import pytest
from vcr import VCR

# ä½¿ç”¨cassetteè¿›è¡Œæµ‹è¯•
@pytest.mark.vcr
def test_with_cassette(vcr):
    # é¦–æ¬¡è¿è¡Œè®°å½•HTTPäº¤äº’ï¼Œåç»­æµ‹è¯•ç›´æ¥é‡æ”¾
    result = collector.search(query="AI")
    assert len(result) > 0
```

è¯¦è§: [VCR Cassetteè¯¦è§£](VCR_CASSETTE_EXPLANATION.md) | [æµ‹è¯•æŒ‡å—](TESTING_GUIDE.md) | [FAQ](FAQ_PR_TESTING.md)

---

## ğŸ”„ CI/CD ä¸è‡ªåŠ¨åŒ–

### GitHub Actions å·¥ä½œæµ

é¡¹ç›®ä½¿ç”¨GitHub Actionså®ç°å®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•å’Œå‘å¸ƒï¼š

| å·¥ä½œæµ | è§¦å‘æ¡ä»¶ | åŠŸèƒ½ |
|---|---|---|
| **test-paid-apis** | Pushåˆ°ä»»ä½•åˆ†æ”¯ | è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼Œç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š |
| **publish** | Push gitæ ‡ç­¾ (v*) | è‡ªåŠ¨æ„å»ºå¹¶å‘å¸ƒåˆ°PyPI |
| **release** | å‘å¸ƒæ—¶ | åˆ›å»ºGitHub Releaseé¡µé¢ |

### å‘å¸ƒæ–°ç‰ˆæœ¬

```bash
# 1. ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
pytest

# 2. åˆ›å»ºç‰ˆæœ¬æ ‡ç­¾
git tag -a v0.1.3 -m "Release v0.1.3"

# 3. æ¨é€æ ‡ç­¾ï¼ˆè‡ªåŠ¨è§¦å‘å‘å¸ƒå·¥ä½œæµï¼‰
git push origin v0.1.3
```

è¯¦è§: [å‘å¸ƒæŒ‡å—](RELEASE_GUIDE.md) | [å¿«é€Ÿå‘å¸ƒ](QUICK_RELEASE.md)

---

## ğŸ“š æ–‡æ¡£

### æ ¸å¿ƒæ–‡æ¡£
- [æ¶æ„è®¾è®¡](ARCHITECTURE.md) - é¡¹ç›®ç»“æ„å’Œè®¾è®¡ç†å¿µ
- [å®ç°æ€»ç»“](IMPLEMENTATION_SUMMARY.md) - v0.1.3 LLM æŸ¥è¯¢å¢å¼ºå®ç°è¯¦æƒ…
- [VCRè¯´æ˜](VCR_CASSETTE_EXPLANATION.md) - ç¦»çº¿æµ‹è¯•æœºåˆ¶è§£æ
- [æµ‹è¯•æŒ‡å—](TESTING_GUIDE.md) - å®Œæ•´æµ‹è¯•è¯´æ˜
- [ä½¿ç”¨æŒ‡å—](USAGE_GUIDE.md) - è¯¦ç»†ä½¿ç”¨æ–‡æ¡£

### å¿«é€Ÿå‚è€ƒ
- [å‘å¸ƒæŒ‡å—](RELEASE_GUIDE.md) - ç‰ˆæœ¬å‘å¸ƒæµç¨‹
- [å¿«é€Ÿå‘å¸ƒ](QUICK_RELEASE.md) - å¿«é€Ÿå‘å¸ƒæ¸…å•
- [PyPIæŒ‡å—](PYPI_RELEASE_GUIDE.md) - PyPIå‘å¸ƒè¯´æ˜
- [FAQ](FAQ_PR_TESTING.md) - å¸¸è§é—®é¢˜è§£ç­”

### APIå‚è€ƒ
- [æœç´¢é…ç½®](ai_news_collector_lib/config/) - é…ç½®é€‰é¡¹è¯´æ˜
- [æ¨¡å‹å¯¹è±¡](ai_news_collector_lib/models/) - æ•°æ®æ¨¡å‹å®šä¹‰
- [æœç´¢å·¥å…·](ai_news_collector_lib/tools/) - å„æºå·¥å…·å®ç°

---

## ğŸ—“ï¸ ArXiv æ—¥æœŸå¤„ç†

ArXivæ—¥æœŸè§£æåŒ…å«å®Œæ•´çš„å›é€€æœºåˆ¶ï¼š

- é»˜è®¤ä½¿ç”¨BeautifulSoupçš„XMLè§£æè·å–`published`å­—æ®µ
- è‹¥è§£æå¼‚å¸¸åˆ™å›é€€åˆ°feedparser
- åœ¨feedparserä¸­æ”¯æŒ`published_parsed`å’Œ`updated_parsed`å­—æ®µ
- å›é€€é¡ºåº: `published_parsed` â†’ `updated_parsed` â†’ `datetime.now()`
- æ—¶åŒºå¤„ç†: Atomæ ¼å¼ä¸­`Z`è¡¨ç¤ºUTCï¼Œä½¿ç”¨`datetime.fromisoformat`è§£æ

æœ€å°éªŒè¯è„šæœ¬ï¼š

```bash
python scripts/min_check_feedparser_fallback.py
```

è¯¥è„šæœ¬éªŒè¯RSSå’ŒAtomæ ¼å¼åœ¨ç¼ºå°‘æ—¥æœŸå­—æ®µæ—¶çš„å›é€€é€»è¾‘ã€‚

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæ”¹è¿›å»ºè®®ï¼

### è´¡çŒ®æµç¨‹
1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯Pull Request

### å¼€å‘æŒ‡å—
- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£

è¯¦è§: [å®Œæ•´è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ†˜ æ”¯æŒ

### è·å–å¸®åŠ©

- ğŸ“– [å®Œæ•´æ–‡æ¡£](https://ai-news-collector-lib.readthedocs.io/)
- ğŸ› [æäº¤Issue](https://github.com/ai-news-collector/ai-news-collector-lib/issues)
- ğŸ’¬ [è®¨è®ºåŒº](https://github.com/ai-news-collector/ai-news-collector-lib/discussions)
- ğŸ“§ [é‚®ä»¶æ”¯æŒ](mailto:support@ai-news-collector.com)

### å¸¸è§é—®é¢˜

**Q: å¦‚ä½•ä¸ä½¿ç”¨APIå¯†é’¥è¿è¡Œæµ‹è¯•ï¼Ÿ**
A: ä½¿ç”¨VCR cassettesï¼æµ‹è¯•ä¼šè‡ªåŠ¨ä½¿ç”¨é¢„å½•åˆ¶çš„HTTPå“åº”ã€‚è¯¦è§[VCRè¯´æ˜](VCR_CASSETTE_EXPLANATION.md)ã€‚

**Q: æ˜¯å¦å¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æ­¤åº“ï¼Ÿ**
A: å¯ä»¥ï¼Œä½†è¯·ç¡®ä¿ï¼š
   - å®‰å…¨åœ°ç®¡ç†APIå¯†é’¥ï¼ˆä½¿ç”¨.envæ–‡ä»¶ï¼‰
   - åˆç†è®¾ç½®ç¼“å­˜TTLé¿å…è¿‡æ—¶æ•°æ®
   - ç›‘æ§APIè°ƒç”¨é™åˆ¶

**Q: å¦‚ä½•è´¡çŒ®æ–°çš„æœç´¢æºï¼Ÿ**
A: è¯¦è§[æ¶æ„è®¾è®¡](ARCHITECTURE.md)ä¸­çš„"æ·»åŠ æ–°æœç´¢æº"éƒ¨åˆ†ã€‚

è¯¦è§: [å®Œæ•´FAQ](FAQ_PR_TESTING.md)

---

## ğŸ“ˆ æ›´æ–°æ—¥å¿—

### v0.1.3 (2025-10-22) - ğŸ¤– LLM æŸ¥è¯¢å¢å¼º
- âœ¨ **AI é©±åŠ¨æŸ¥è¯¢ä¼˜åŒ–** - é›†æˆ Google Gemini LLMï¼Œä¸ºæ‰€æœ‰æœç´¢å¼•æ“ç”Ÿæˆä¼˜åŒ–æŸ¥è¯¢
- âœ… æ–°å¢ `EnhancedQuery` æ•°æ®æ¨¡å‹ï¼ˆæ”¯æŒ 11 ä¸ªæœç´¢å¼•æ“ï¼‰
- âœ… æ–°å¢ `QueryEnhancer` å·¥å…·ç±»ï¼ˆ500+ è¡Œï¼Œå•ä¸€ LLM è°ƒç”¨æ¶æ„ï¼‰
- âœ… æ™ºèƒ½ç¼“å­˜ - 24 å°æ—¶ TTL é¿å…é‡å¤ LLM è°ƒç”¨
- âœ… çµæ´»é…ç½® - å¯é€‰å¯ç”¨/ç¦ç”¨ï¼Œæ”¯æŒè‡ªå®šä¹‰ LLM æä¾›å•†
- âœ… ä¼˜é›…é™çº§ - LLM ä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨åŸå§‹æŸ¥è¯¢
- âœ… å®Œæ•´æµ‹è¯• - 8 ä¸ªå•å…ƒæµ‹è¯•ï¼Œ81% ä»£ç è¦†ç›–ç‡
- âœ… ä»£ç è´¨é‡ - Black & Flake8 æ£€æŸ¥é€šè¿‡

### v0.1.2 (2025-10-21) - ğŸ”’ å®‰å…¨ç‰ˆæœ¬
- âœ… å…¨é¢å®‰å…¨å®¡è®¡ - æ¸…ç†VCR cassettesä¸­çš„æ‰€æœ‰å‡­è¯
- âœ… å°†æµ‹è¯•APIå¯†é’¥æ›¿æ¢ä¸º"FILTERED"å ä½ç¬¦
- âœ… æ›´æ–°æ‰€æœ‰cassette URLä¸ºçœŸå®APIç«¯ç‚¹
- âœ… é›†æˆpytest-covæä¾›è¦†ç›–ç‡æŠ¥å‘Š
- âœ… GitHub Actionsè‡ªåŠ¨åŒ–æµ‹è¯•å’ŒPyPIå‘å¸ƒ

### v0.1.0 (2025-10-07)
- åˆå§‹é¢„å‘å¸ƒç‰ˆæœ¬
- æ”¯æŒåŸºç¡€æœç´¢åŠŸèƒ½
- æ”¯æŒå¤šç§æœç´¢æº
- æ”¯æŒé«˜çº§åŠŸèƒ½ï¼ˆå†…å®¹æå–ã€å…³é”®è¯åˆ†æã€ç¼“å­˜ç­‰ï¼‰

---

## ğŸ“Š é¡¹ç›®ç»“æ„

```
ai_news_collector_lib/
â”œâ”€â”€ __init__.py                    # ä¸»æ¨¡å—å…¥å£
â”œâ”€â”€ cli.py                        # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ config/                       # é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py              # æœç´¢é…ç½®
â”‚   â””â”€â”€ api_keys.py              # APIå¯†é’¥ç®¡ç†
â”œâ”€â”€ core/                        # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ collector.py             # åŸºç¡€æ”¶é›†å™¨
â”‚   â””â”€â”€ advanced_collector.py    # é«˜çº§æ”¶é›†å™¨
â”œâ”€â”€ models/                      # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ article.py              # æ–‡ç« æ¨¡å‹
â”‚   â””â”€â”€ result.py               # ç»“æœæ¨¡å‹
â”œâ”€â”€ tools/                       # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ search_tools.py         # å„ç§æœç´¢å·¥å…·
â”œâ”€â”€ utils/                       # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cache.py                # ç¼“å­˜ç®¡ç†
â”‚   â”œâ”€â”€ content_extractor.py    # å†…å®¹æå–
â”‚   â”œâ”€â”€ keyword_extractor.py    # å…³é”®è¯æå–
â”‚   â”œâ”€â”€ reporter.py             # æŠ¥å‘Šç”Ÿæˆ
â”‚   â””â”€â”€ scheduler.py            # å®šæ—¶ä»»åŠ¡
â””â”€â”€ examples/                    # ä½¿ç”¨ç¤ºä¾‹
    â”œâ”€â”€ basic_usage.py
    â””â”€â”€ advanced_usage.py

tests/
â”œâ”€â”€ conftest.py                 # pytesté…ç½®
â”œâ”€â”€ test_basic.py               # åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ test_integration_basic.py    # åŸºç¡€é›†æˆæµ‹è¯•
â”œâ”€â”€ test_integration_advanced.py # ä»˜è´¹APIé›†æˆæµ‹è¯•
â”œâ”€â”€ cassettes/                  # VCR cassetteæ–‡ä»¶
â”‚   â”œâ”€â”€ basic_ai_hn_ddg.yaml
â”‚   â”œâ”€â”€ advanced_ml_hn_ddg.yaml
â”‚   â””â”€â”€ ...
â””â”€â”€ test_arxiv_fallback_offline.py # ArXivç‰¹æ®Šæµ‹è¯•
```

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿[æäº¤Issue](https://github.com/ai-news-collector/ai-news-collector-lib/issues)æˆ–åŠ å…¥[è®¨è®ºåŒº](https://github.com/ai-news-collector/ai-news-collector-lib/discussions)ã€‚
