Metadata-Version: 2.4
Name: semantic_digital_twin
Version: 0.0.3
Summary: A world model that unifies kinematic information and semantic meaning for robotic world representations.
Author-email: Tom Schierenbeck <tom_sch@uni-bremen.de>
License: LGPL-3.0-only
Project-URL: Source, https://github.com/cram2/semantic_digital_twin
Project-URL: Bug Tracker, https://github.com/cram2/semantic_digital_twin/issues
Keywords: robotics
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
Classifier: Operating System :: OS Independent
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: rustworkx
Requires-Dist: numpy
Requires-Dist: trimesh
Requires-Dist: typing_extensions
Requires-Dist: urdf-parser-py
Requires-Dist: matplotlib
Requires-Dist: casadi~=3.7.0
Requires-Dist: hypothesis
Requires-Dist: pytest
Requires-Dist: scipy
Requires-Dist: ormatic>=1.1.16
Requires-Dist: sqlacodegen
Requires-Dist: ripple_down_rules>=0.6.51
Requires-Dist: pytest-order
Requires-Dist: sqlalchemy
Requires-Dist: embreex
Requires-Dist: rtree
Requires-Dist: random_events
Requires-Dist: plotly
Requires-Dist: rtree
Requires-Dist: daqp
Requires-Dist: pathlib
Requires-Dist: probabilistic_model
Requires-Dist: python-fcl
Requires-Dist: manifold3d
Requires-Dist: entity_query_language>=2.0.5
Requires-Dist: polytope
Requires-Dist: ortools
Requires-Dist: fbxloader
Requires-Dist: coacd
Requires-Dist: pymysql
Requires-Dist: pyglet==1.5.31
Requires-Dist: pycollada
Provides-Extra: gui
Requires-Dist: ripple_down_rules[gui]; extra == "gui"
Dynamic: license-file

# Welcome to the Semantic Digital Twin Package
Introducing Semantic Digital Twin: A unified interface for scene data and asserted meaning.

The Semantic Digital Twin Python package streamlines the integration and management of scene graphs with explicit semantic assertions.
Agents and autonomous systems require more than just coordinates, they need contextual understanding. 
Semantic Digital Twin bridges geometry, kinematics, and meaning, allowing systems for planning, 
learning, and reasoning to process the environment through actionable, high-level concepts.

This enables the construction of environments that can be readily understood,
queried, transformed, and shared across projects.
Whether for research prototypes or robust data pipelines,
Semantic Digital Twin translates raw environment data into structured knowledge.

## Assimilated Technologies

<image alt="Assimilation Icon" src="doc/_static/images/assimilation_dark_mode.png#gh-dark-mode-only" style="width: 300px; height: auto; object-fit: contain;"></image>
<image alt="Assimilation Icon" src="doc/_static/images/assimilation.png#gh-light-mode-only" style="width: 300px; height: auto; object-fit: contain;"></image>


🌍 **Model full kinematic worlds, not just meshes**. Define bodies, regions, connections, and degrees of freedom as primary, first-class entities within a clean, composable Python API.

🤔 **Enhance meaning with Views.** Transform raw geometry into actionable concepts like drawers, handles, containers, and task-relevant regions. Express relationships and intent beyond simple shapes.

💡 **Intelligent Querying.** Use a high-level entity query language to precisely locate relevant elements—e.g., "the handle attached to the drawer that is currently accessible"—to enable targeted interaction.


🛢️️ **Reproducible Persistence and Replay.** 
Serialize annotated worlds into a SQL format, allowing for faithful reconstruction as consistent, interactive objects. 
This facilitates reproducible experiments and robust machine learning data pipelines.

🛠️ **Effortless Composition.** 
Leverage factories and dataclasses for simple authoring of complex scenes and extending semantics. 
Share domain knowledge efficiently without reliance on fragile glue code.

📈 **Scale and Consistency.** 
The integrated kinematic tree, DoF registry, 
and robust world validation ensure model consistency and integrity from initial prototype to large-scale production deployment.

🔮 **Flexible Visualization.** 
View worlds in lightweight RViz2, explore within notebooks, or integrate with richer simulation environments. 
Quickly understand both the structural and semantic layers of your models.

🔌 **Pluggable Integration.** 
Use a multitude of adapters for seamless import, no matter if its URDF, USD, MJCF, etc. 

🦾 **Reliable Kinematics.** 
Compute forward transforms and inverse (backward) kinematics cleanly across the tree, 
providing a straightforward and robust foundation for pose queries, control, and reasoning.

👯‍ **Real-Time World Synchronization.** 
Maintain a consistent state across multiple processes and robotic agents using lightweight, 
real-time world synchronization. 
Structures can be created, merged, and updated at once, 
ensuring they are accurately reflected across all connected instances.

🚀 Get started with the [user-guide](https://cram2.github.io/semantic_digital_twin/user_guide.html#user-guide)!

📖 Read the full [documentation](https://cram2.github.io/semantic_digital_twin/intro.html)!

🤝 Contribute with the [developer-guide](https://cram2.github.io/semantic_digital_twin/developer_guide.html#developer-guide)!


# User Installation


You can install the package directly from PyPI:

```bash
pip install -U semantic_digital_twin
```

# Contributing

If you are interested in contributing, you can check out the source code from GitHub:

```bash
git clone https://github.com/cram2/semantic_digital_twin.git
```

### Development Dependencies

```bash
sudo apt install -y graphviz graphviz-dev
pip install -r requirements.txt
```


# Tests
The tests can be run with `pytest` directly in PyCharm or from the terminal after installing Semantic Digital Twin as a python package.

```bash
pip install -e .
pytest test/
```
