# Supported Providers

`any-llm` supports the below providers. In order to discover information about what models are supported by a provider
as well as what features the provider supports for each model, refer to the provider documentation.

Provider source code can be found in the [`src/any_llm/providers/`](https://github.com/mozilla-ai/any-llm/tree/main/src/any_llm/providers) directory of the repository.

!!! note "Legend"

    - **Reasoning (Completions)**: Provider can return reasoning traces alongside the assistant message via the completions and/or streaming endpoints. This does not indicate whether the provider offers separate "reasoning models".See [this](https://github.com/mozilla-ai/any-llm/issues/95)
    - **Streaming (Completions)**: Provider can stream completion results back as an iterator.
    discussion for more information.
    - **Image (Completions)**: Provider supports passing an `image_data` parameter for vision capabilities, as defined by the OpenAI spec [here](https://platform.openai.com/docs/api-reference/chat/create#chat_create-messages).
    - **Responses API**: Provider supports the Responses API variant for text generation.  See [this](https://github.com/mozilla-ai/any-llm/issues/26) to follow along with our implementation effort.
    - **List Models API**: Provider supports listing available models programmatically via the `list_models()` function. This allows you to discover what models are available from the provider at runtime, which can be useful for dynamic model selection or validation.


<!-- The below table is auto-generated by the mkdocs build hook. It will display in the generated site -->
<!-- AUTO-GENERATED TABLE START -->
<!-- AUTO-GENERATED TABLE END -->
