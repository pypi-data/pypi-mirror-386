# langchain-dev-utils

[![PyPI](https://img.shields.io/pypi/v/langchain-dev-utils.svg)](https://pypi.org/project/langchain-dev-utils/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/your-username/langchain-dev-utils/blob/main/LICENSE)
[![Python](https://img.shields.io/badge/python-3.11%2B-blue)](https://www.python.org/downloads/)

> å½“å‰ä¸ºä¸­æ–‡ç‰ˆï¼Œè‹±æ–‡ç‰ˆè¯·è®¿é—®[English Documentation](https://github.com/TBice123123/langchain-dev-utils/blob/master/README.md)

**langchain-dev-utils** æ˜¯ä¸€ä¸ªä¸“æ³¨äºæå‡ LangChain å’Œ LangGraph å¼€å‘ä½“éªŒçš„å®ç”¨å·¥å…·åº“ã€‚å®ƒæä¾›äº†ä¸€ç³»åˆ—å¼€ç®±å³ç”¨çš„å·¥å…·å‡½æ•°ï¼Œæ—¢èƒ½å‡å°‘é‡å¤ä»£ç ç¼–å†™ï¼Œåˆèƒ½æé«˜ä»£ç çš„ä¸€è‡´æ€§å’Œå¯è¯»æ€§ã€‚é€šè¿‡ç®€åŒ–å¼€å‘å·¥ä½œæµç¨‹ï¼Œè¿™ä¸ªåº“å¯ä»¥å¸®åŠ©ä½ æ›´å¿«åœ°æ„å»ºåŸå‹ã€æ›´é¡ºç•…åœ°è¿›è¡Œè¿­ä»£ï¼Œå¹¶åˆ›å»ºæ›´æ¸…æ™°ã€æ›´å¯é çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ AI åº”ç”¨ã€‚

## ğŸ“š æ–‡æ¡£

- [English Documentation](https://tbice123123.github.io/langchain-dev-utils-docs/en/)
- [ä¸­æ–‡æ–‡æ¡£](https://tbice123123.github.io/langchain-dev-utils-docs/zh/)

## ğŸš€ å®‰è£…

```bash
pip install -U langchain-dev-utils

# å®‰è£…å®Œæ•´åŠŸèƒ½ç‰ˆï¼š
pip install -U langchain-dev-utils[standard]
```

## ğŸ“¦ æ ¸å¿ƒåŠŸèƒ½

### 1. **æ¨¡å‹ç®¡ç†**

åœ¨ `langchain` ä¸­ï¼Œ`init_chat_model` å‡½æ•°å¯ç”¨äºåˆå§‹åŒ–å¯¹è¯æ¨¡å‹å®ä¾‹ï¼Œä½†å…¶æ”¯æŒçš„æ¨¡å‹æä¾›å•†è¾ƒä¸ºæœ‰é™ã€‚æœ¬æ¨¡å—æä¾›äº†ä¸€ä¸ªæ³¨å†Œå‡½æ•°ï¼ˆ`register_model_provider`/`register_embeddings_provider`ï¼‰ï¼Œæ–¹ä¾¿æ³¨å†Œä»»æ„æ¨¡å‹æä¾›å•†ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ `load_chat_model` / `load_embeddings` è¿›è¡Œæ¨¡å‹åŠ è½½ã€‚

`register_model_provider` å‚æ•°è¯´æ˜ï¼š

- `provider_name`ï¼šæ¨¡å‹æä¾›å•†åç§°ï¼Œä½œä¸ºåç»­æ¨¡å‹åŠ è½½çš„æ ‡è¯†
- `chat_model`ï¼šå¯¹è¯æ¨¡å‹ï¼Œå¯ä»¥æ˜¯ ChatModel æˆ–å­—ç¬¦ä¸²ï¼ˆç›®å‰æ”¯æŒ "openai-compatible"ï¼‰
- `base_url`ï¼šæ¨¡å‹æä¾›å•†çš„ API åœ°å€

`register_embeddings_provider` å‚æ•°è¯´æ˜ï¼š

- `provider_name`ï¼šåµŒå…¥æ¨¡å‹æä¾›å•†åç§°ï¼Œä½œä¸ºåç»­æ¨¡å‹åŠ è½½çš„æ ‡è¯†
- `embeddings_model`ï¼šåµŒå…¥æ¨¡å‹ï¼Œå¯ä»¥æ˜¯ Embeddings æˆ–å­—ç¬¦ä¸²ï¼ˆç›®å‰æ”¯æŒ "openai-compatible"ï¼‰
- `base_url`ï¼šæ¨¡å‹æä¾›å•†çš„ API åœ°å€

ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
# å¯¹è¯æ¨¡å‹ç®¡ç†
from langchain_dev_utils.chat_models import (
    register_model_provider,
    load_chat_model,
)

# æ³¨å†Œæ¨¡å‹æä¾›å•†
register_model_provider(
    provider_name="vllm",
    chat_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# åŠ è½½æ¨¡å‹
model = load_chat_model("vllm:qwen3-4b")
print(model.invoke("Hello"))
```

åµŒå…¥æ¨¡å‹ä½¿ç”¨ï¼š

```python
from langchain_dev_utils.embeddings import register_embeddings_provider, load_embeddings

register_embeddings_provider(
    provider_name="vllm",
    embeddings_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)
embeddings = load_embeddings("vllm:qwen3-embedding-4b")
emb = embeddings.embed_query("Hello")
print(emb)
```

**äº†è§£æ›´å¤š**ï¼š[æ¨¡å‹ç®¡ç†](https://tbice123123.github.io/langchain-dev-utils-docs/zh/model-management.html)

### 2. **æ¶ˆæ¯è½¬æ¢**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- å°†æ€ç»´é“¾å†…å®¹åˆå¹¶åˆ°æœ€ç»ˆå“åº”ä¸­
- æµå¼å†…å®¹åˆå¹¶
- å†…å®¹æ ¼å¼åŒ–å·¥å…·

å°†æ€ç»´é“¾å†…å®¹åˆå¹¶åˆ°æœ€ç»ˆå“åº”ï¼š

```python
from langchain_dev_utils.message_convert import (
    convert_reasoning_content_for_ai_message,
    convert_reasoning_content_for_chunk_iterator,
    merge_ai_message_chunk,
    format_sequence
)

response = model.invoke("Hello")

cleaned = convert_reasoning_content_for_ai_message(
    response, think_tag=("<think>", "</think>")
)

for chunk in convert_reasoning_content_for_chunk_iterator(
    model.stream("Hello")
):
    print(chunk.content, end="", flush=True)
```

åˆå¹¶æµå¼å“åº”ï¼š

```python
chunks = list(model.stream("Hello"))
merged = merge_ai_message_chunk(chunks)
```

æ ¼å¼åŒ–åºåˆ—ï¼š

```python
text = format_sequence([
    "str1",
    "str2",
    "str3"
], separator="\n", with_num=True)
```

**äº†è§£æ›´å¤š**ï¼š[æ¶ˆæ¯è½¬æ¢](https://tbice123123.github.io/langchain-dev-utils-docs/zh/message-conversion.html)

### 3. **å·¥å…·è°ƒç”¨**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- æ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨
- æ·»åŠ äººæœºäº¤äº’åŠŸèƒ½

ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
import datetime
from langchain_core.tools import tool
from langchain_dev_utils.tool_calling import has_tool_calling, parse_tool_calling, human_in_the_loop
from langchain_core.messages import AIMessage
from typing import cast

@human_in_the_loop
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return str(datetime.datetime.now().timestamp())

response = model.bind_tools([get_current_time]).invoke("ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ")

if has_tool_calling(cast(AIMessage, response)):
    name, args = parse_tool_calling(
        cast(AIMessage, response), first_tool_call_only=True
    )
    print(name, args)
```

**äº†è§£æ›´å¤š**ï¼š[å·¥å…·è°ƒç”¨](https://tbice123123.github.io/langchain-dev-utils-docs/zh/tool-calling.html)

### 4. **æ™ºèƒ½ä½“å¼€å‘**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- é¢„è®¾çš„æ™ºèƒ½ä½“å·¥å‚å‡½æ•°
- å¸¸ç”¨çš„ä¸­é—´ä»¶ç»„ä»¶

ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
from langchain_dev_utils.agents import create_agent
from langchain.agents import AgentState

agent = create_agent("vllm:qwen3-4b", tools=[get_current_time], name="time-agent")
response = agent.invoke({"messages": [{"role": "user", "content": "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ"}]})
print(response)
```

ä¸­é—´ä»¶ä½¿ç”¨ï¼š

```python
from langchain_dev_utils.agents.middleware import (
    SummarizationMiddleware,
    LLMToolSelectorMiddleware,
    PlanMiddleware,
)

agent=create_agent(
    "vllm:qwen3-4b",
    name="plan-agent",
    middleware=[PlanMiddleware(), SummarizationMiddleware(model="vllm:qwen3-4b"), LLMToolSelectorMiddleware(model="vllm:qwen3-4b")]
)
response = agent.invoke({"messages": [{"role": "user", "content": "ç»™æˆ‘ä¸€ä¸ªå»çº½çº¦æ—…è¡Œçš„è®¡åˆ’"}]}))
print(response)
```

**äº†è§£æ›´å¤š**ï¼š[æ™ºèƒ½ä½“å¼€å‘](https://tbice123123.github.io/langchain-dev-utils-docs/zh/agent-development.html)

### 5. **çŠ¶æ€å›¾ç¼–æ’**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- é¡ºåºå›¾ç¼–æ’
- å¹¶è¡Œå›¾ç¼–æ’

```python
from langchain_dev_utils.pipeline import sequential_pipeline, parallel_pipeline

# æ„å»ºé¡ºåºæµç¨‹
graph = sequential_pipeline(
    sub_graphs=[
        make_graph("graph1"),
        make_graph("graph2"),
        make_graph("graph3"),
    ],
    state_schema=State,
)

# æ„å»ºå¹¶è¡Œæµç¨‹
graph = parallel_pipeline(
    sub_graphs=[
        make_graph("graph1"),
        make_graph("graph2"),
        make_graph("graph3"),
    ],
    state_schema=State,
)
```

**äº†è§£æ›´å¤š**ï¼š[çŠ¶æ€å›¾ç¼–æ’](https://tbice123123.github.io/langchain-dev-utils-docs/zh/graph-orchestration.html)

## ğŸ’¬ åŠ å…¥ç¤¾åŒº

- ğŸ™ [GitHub ä»“åº“](https://github.com/TBice123123/langchain-dev-utils) â€” æµè§ˆæºä»£ç ï¼Œæäº¤ Pull Request
- ğŸ [é—®é¢˜è¿½è¸ª](https://github.com/TBice123123/langchain-dev-utils/issues) â€” æŠ¥å‘Š Bug æˆ–æå‡ºæ”¹è¿›å»ºè®®
- ğŸ’¡ æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ® â€”â€” æ— è®ºæ˜¯ä»£ç ã€æ–‡æ¡£è¿˜æ˜¯ä½¿ç”¨ç¤ºä¾‹ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ„å»ºä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´å®ç”¨çš„ LangChain å¼€å‘ç”Ÿæ€ç³»ç»Ÿï¼
