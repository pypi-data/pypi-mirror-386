import os

from picsellia.sdk.asset import Asset, MultiAsset
from picsellia.types.enums import InferenceType

from picsellia_cv_engine.core.contexts import (
    LocalDatasetProcessingContext,
    LocalTrainingContext,
    PicselliaDatasetProcessingContext,
    PicselliaTrainingContext,
)
from picsellia_cv_engine.core.models import (
    PicselliaClassificationPrediction,
    PicselliaOCRPrediction,
    PicselliaPolygonPrediction,
    PicselliaRectanglePrediction,
)
from picsellia_cv_engine.core.models.model import TModel
from picsellia_cv_engine.core.services.model.evaluator.model_evaluator import (
    ModelEvaluator,
)


def build_model_impl(
    context: PicselliaDatasetProcessingContext
    | PicselliaTrainingContext
    | LocalDatasetProcessingContext
    | LocalTrainingContext,
    model_cls: type[TModel],
    pretrained_weights_name: str | None = None,
    trained_weights_name: str | None = None,
    config_name: str | None = None,
    exported_weights_name: str | None = None,
) -> TModel:
    """
    Instantiate and initialize a model object within the current Picsellia pipeline context.

    This function supports both training and processing contexts and uses the appropriate model version
    to build the model. It also downloads any associated model weights (pretrained, trained, exported).

    Args:
        context: The current pipeline context, which must be either a training or processing context.
        model_cls (type[TModel]): The model class to instantiate.
        pretrained_weights_name (str, optional): The name of the pretrained weights to download.
        trained_weights_name (str, optional): The name of the trained weights to download.
        config_name (str, optional): The name of the model configuration file.
        exported_weights_name (str, optional): The name of the exported weights for inference.

    Returns:
        TModel: An instance of the initialized model with weights downloaded.

    Raises:
        ValueError: If the context is invalid or no model version ID is provided in a processing context.
    """
    if isinstance(context, PicselliaTrainingContext | LocalTrainingContext):
        model_version = context.experiment.get_base_model_version()
    elif isinstance(
        context, PicselliaDatasetProcessingContext | LocalDatasetProcessingContext
    ):
        if context.model_version_id:
            model_version = context.model_version
        else:
            raise ValueError("No model_version_id provided in the processing context.")
    else:
        raise ValueError("The current context is not a training or processing context.")

    model = model_cls(
        name=model_version.name,
        model_version=model_version,
        pretrained_weights_name=pretrained_weights_name,
        trained_weights_name=trained_weights_name,
        config_name=config_name,
        exported_weights_name=exported_weights_name,
    )
    model.download_weights(
        destination_dir=os.path.join((context.working_dir), "models")
    )
    return model


def evaluate_model_impl(
    context: PicselliaDatasetProcessingContext
    | PicselliaTrainingContext
    | LocalDatasetProcessingContext
    | LocalTrainingContext,
    picsellia_predictions: (
        list[PicselliaClassificationPrediction]
        | list[PicselliaRectanglePrediction]
        | list[PicselliaPolygonPrediction]
        | list[PicselliaOCRPrediction]
    ),
    inference_type: InferenceType,
    assets: list[Asset] | MultiAsset,
    output_dir: str,
    training_labelmap: dict[str, str] | None = None,
) -> None:
    """
    Run evaluation of model predictions using the appropriate evaluation strategy based on inference type.

    This function leverages Picsellia's `ModelEvaluator` to:
    - Compare predictions to ground truth.
    - Compute classification metrics for classification tasks.
    - Compute COCO metrics for detection and segmentation tasks.

    Args:
        context: The current pipeline context, expected to contain an experiment.
        picsellia_predictions: List of predictions generated by the model, matching the inference type.
        inference_type (InferenceType): The type of model inference performed (e.g., classification, detection).
        assets (list[Asset] | MultiAsset): Ground truth assets against which predictions are evaluated.
        output_dir (str): The directory where evaluation metrics and results will be written.
        training_labelmap (dict[str, str] | None): Optional mapping of training labels for evaluation alignment.

    Raises:
        ValueError: If the provided inference type is not supported for evaluation.
    """
    evaluator = ModelEvaluator(
        experiment=context.experiment, inference_type=inference_type
    )
    evaluator.evaluate(picsellia_predictions=picsellia_predictions)

    if inference_type == InferenceType.CLASSIFICATION:
        evaluator.compute_classification_metrics(
            assets=assets, output_dir=output_dir, training_labelmap=training_labelmap
        )
    elif inference_type in (InferenceType.OBJECT_DETECTION, InferenceType.SEGMENTATION):
        evaluator.compute_coco_metrics(
            assets=assets, output_dir=output_dir, training_labelmap=training_labelmap
        )
    else:
        raise ValueError(f"Unsupported model type: {inference_type}")
