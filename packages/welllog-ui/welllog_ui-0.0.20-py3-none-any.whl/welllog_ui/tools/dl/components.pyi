# This file was generated by Nuitka

# Stubs included by default
from __future__ import annotations
from WTConv.wtconv1d import WTConv1d
from typing import Any
from typing_extensions import Self
import torch
import torch.nn
import torch.nn.functional

class GlobalContextFuser:
    def forward(self: Self, x: Any) -> Any: ...

def Normalize(in_channels: Any, num_groups: Any) -> Any:
    ...

class Swish:
    def forward(self: Self, x: Any) -> Any: ...

class Downsample1x:
    def __init__(self: Self, in_channels: Any, groups: Any, kernel_size: Any, stride: Any, padding: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class Upsample1x:
    def __init__(self: Self, in_channels: Any, out_channels: Any, groups: Any, kernel_size: Any, stride: Any, padding: Any) -> None: ...
    def forward(self: Self, x: Any, output_size: Any) -> Any: ...

class SEModule1D:
    def __init__(self: Self, channels: Any, reduction_ratio: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class AttnBlock1D:
    def __init__(self: Self, in_channels: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

def make_attn_1d(in_channels: Any, using_sa: Any, groups: Any) -> Any:
    ...

class ResnetBlock1D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class WTResnetBlock1D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

Block1D = WTResnetBlock1D
class DownsampleBlock1D:
    def __init__(self: Self, in_channels: Any, out_channels: Any, dropout: Any, use_se: Any, num_res_blocks: Any, use_attn: Any, groups: Any, same: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class UpsampleBlock1D:
    def __init__(self: Self, in_channels: Any, out_channels: Any, dropout: Any, use_se: Any, num_res_blocks: Any, use_attn: Any, groups: Any, same: Any) -> None: ...
    def forward(self: Self, x: Any, output_size: Any) -> Any: ...

class Encoder1D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, x: Any, get_h_private: Any) -> Any: ...

class Decoder1D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, z: Any, shapes: Any, get_h_shared: Any) -> Any: ...

def Normalize3D(in_channels: Any, num_groups: Any) -> Any:
    ...

class Downsample3D:
    def __init__(self: Self, in_channels: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class Upsample3D:
    def __init__(self: Self, in_channels: Any, out_channels: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any, output_size: Any) -> Any: ...

class SEModule3D:
    def __init__(self: Self, channels: Any, reduction_ratio: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class AttnBlock3D:
    def __init__(self: Self, in_channels: Any, num_heads: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

def make_attn_3d(in_channels: Any, num_heads: Any, using_sa: Any, groups: Any) -> Any:
    ...

class ResnetBlock3D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

Block3D = ResnetBlock3D
class DownsampleBlock3D:
    def __init__(self: Self, in_channels: Any, out_channels: Any, dropout: Any, use_se: Any, num_res_blocks: Any, use_attn: Any, num_heads: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any) -> Any: ...

class UpsampleBlock3D:
    def __init__(self: Self, in_channels: Any, out_channels: Any, dropout: Any, use_se: Any, num_res_blocks: Any, use_attn: Any, num_heads: Any, groups: Any) -> None: ...
    def forward(self: Self, x: Any, output_size: Any) -> Any: ...

class Encoder3D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, x: Any, get_h_private: Any) -> Any: ...

class Decoder3D:
    def __init__(self: Self) -> None: ...
    def forward(self: Self, z: Any, shapes: Any, get_h_shared: Any) -> Any: ...


__name__ = ...



# Modules used internally, to allow implicit dependencies to be seen:
import torch
import torch.nn
import torch.nn.functional