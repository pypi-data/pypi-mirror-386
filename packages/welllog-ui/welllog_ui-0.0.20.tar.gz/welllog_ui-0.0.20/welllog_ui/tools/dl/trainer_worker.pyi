# This file was generated by Nuitka

# Stubs included by default
from __future__ import annotations
from PySide6 import QtCore
from __future__ import annotations
from base_dl import RandomDataModule, SimpleRegressor, UiProgressCallback
from cfg import WellLogTrainConfig
from data_utils.well_data_utils import WellDataModule
from pytorch_lightning import LightningModule, Trainer
from pytorch_lightning.callbacks import ModelCheckpoint
from services.db import get_data_service
from typing import Any, Dict, Optional, Union
from typing_extensions import Self
import math
import numpy
import os
import pytorch_lightning
import torch

class DataReady:
    def __init__(self: Self, data_usage: Any, curve_names: Any, data_dict: Any) -> None: ...

class CosineAnnealingLRCallback:
    def __init__(self: Self, initial_lr: float, total_steps: int) -> None: ...
    def get_lr(self: Self, current_step: int) -> float: ...
    def on_train_batch_start(self: Self, trainer: 'Trainer', pl_module: 'LightningModule', batch: any, batch_idx: int) -> None: ...

class LightningTrainWorker:
    def __init__(self: Self, stage: str, cfg_dict: Dict[str, Any], parent: Optional[QtCore.QObject]) -> None: ...
    def request_stop(self: Self) -> None: ...
    def _should_stop(self: Self) -> bool: ...
    def run(self: Self) -> None: ...


__name__ = ...



# Modules used internally, to allow implicit dependencies to be seen:
import __future__
import typing
import os
import PySide6
import PySide6.QtCore
import pytorch_lightning
import pytorch_lightning.callbacks
import pytorch_lightning.callbacks.ModelCheckpoint
import pytorch_lightning.Trainer
import pytorch_lightning.LightningModule
import math
import torch
import numpy
import ntpath
import sys
import traceback