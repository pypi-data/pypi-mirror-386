# DcisionAI Manufacturing MCP Server Configuration
# Production configuration for AWS deployment

server:
  host: "0.0.0.0"
  port: 8000
  debug: false
  log_level: "WARNING"

aws:
  region: "us-east-1"
  # Production credentials via IAM roles or environment variables
  
  bedrock:
    model_id: "anthropic.claude-3-haiku-20240307-v1:0"
    max_tokens: 2000
    temperature: 0.1
    timeout: 30

agents:
  intent:
    timeout: 30
    max_retries: 3
  
  data:
    timeout: 45
    max_retries: 3
  
  model:
    timeout: 60
    max_retries: 3
  
  solver:
    timeout: 300
    max_iterations: 1000
    solver_type: "pulp_cbc"

logging:
  level: "WARNING"
  format: "%(asctime)s | %(levelname)s | %(name)s | %(message)s"
  file: "/var/log/dcisionai/mcp_server.log"
  max_size: "50MB"
  backup_count: 10

monitoring:
  health_check_interval: 30
  metrics_enabled: true
  performance_tracking: true
  
# Production-specific settings
production:
  max_concurrent_requests: 100
  request_timeout: 300
  rate_limiting:
    enabled: true
    requests_per_minute: 60
  
  security:
    cors_enabled: true
    allowed_origins: ["*"]
    api_key_required: false  # Set to true for production
