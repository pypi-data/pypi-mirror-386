# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from __future__ import annotations

from typing_extensions import Literal, Required, TypedDict

__all__ = ["DefendSubmitEventParams", "ModelInput"]


class DefendSubmitEventParams(TypedDict, total=False):
    model_input: Required[ModelInput]
    """A dictionary of inputs sent to the LLM to generate output.

    The dictionary must contain at least `user_prompt` or `system_prompt` field. For
    ground_truth_aherence guadrail metric, `ground_truth` should be provided.
    """

    model_output: Required[str]
    """Output generated by the LLM to be evaluated."""

    model_used: Required[str]
    """Model ID used to generate the output, like `gpt-4o` or `o3`."""

    run_mode: Required[Literal["precision_plus", "precision", "smart", "economy"]]
    """Run mode for the workflow event.

    The run mode allows the user to optimize for speed, accuracy, and cost by
    determining which models are used to evaluate the event. Available run modes
    include `precision_plus`, `precision`, `smart`, and `economy`. Defaults to
    `smart`.
    """

    nametag: str
    """An optional, user-defined tag for the event."""


class ModelInput(TypedDict, total=False):
    ground_truth: str
    """The ground truth for evaluating Ground Truth Adherence guardrail."""

    system_prompt: str
    """The system prompt used to generate the output."""

    user_prompt: str
    """The user prompt used to generate the output."""
